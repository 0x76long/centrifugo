{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"faq/","text":"Frequently Asked Questions \u00b6 Answers on various questions here. How many connections can one Centrifugo instance handle? \u00b6 This depends on many factors. Hardware, message rate, size of messages, Centrifugo features enabled, client distribution over channels, websocket compression on/off etc. So no certain answer on this question exists. Common sense, tests and monitoring can help here. Generally we suggest to not put more than 50-100k clients on one node - but you should measure for your personal use case. You can find a benchmark we did in this docs chapter \u2013 though the point above is still valid, measure and monitor your own setup. Memory usage per connection? \u00b6 Depending on features enabled an amount of RAM required per each connection can vary. At moment, you can expect that each connection will cost about 30-50 KB of RAM, thus a server with 1 GB of RAM can handle about 20-30k connections. Can Centrifugo scale horizontally? \u00b6 Yes, it can. It can do this using builtin Redis Engine . Redis is very fast \u2013 for example it can handle hundreds of thousands requests per second. This should be OK for most applications in an internet. if you approach Redis resource limits (CPU or memory) then it's possible to use Centrifugo consistent sharding support to balance queries between different Redis instances. Starting from v2.6.0 Centrifugo also scales with Nats server as broker (but for unreliable at most once PUB/SUB only). Message delivery model \u00b6 The model of message delivery of Centrifugo server is at most once. With recovery feature enabled it's possible to achieve at least once guarantee. After network disconnects client have an option to recover missed messages from in-memory message stream that Centrifugo maintains. Without recovery feature on a message you send to Centrifugo can be theoretically lost while moving towards your clients. Centrifugo tries to do the best effort to prevent message losses on a way to online clients, but you should be aware of possible message loss. Your application should tolerate this. As noted Centrifugo has an option called message recovery to automatically recover messages missed due to short network disconnections. Also, it prevents message loss on a way from Redis to nodes over Redis PUB/SUB using additional offset check and periodical synchronization. At this moment Centrifugo message recovery designed for a short term disconnect period (think no more than one hour for a typical chat application). After this period (which can be configured per channel basis) Centrifugo removes messages from in-memory channel stream. In this case Centrifugo let client know that some messages can not be recovered, so you can load application state from your main database. We also recommend modeling your applications in a way that users don't notice when Centrifugo does not work at all. Use graceful degradation. For example if a user posts a new comment over AJAX call to your application backend - you should not rely only on Centrifugo to receive new comment from channel and display it - you should return new comment data in AJAX call response and render it. This way user that posts a comment will think that everything works just fine. Be careful to not draw comments twice in this case - think about idempotent identifiers for your entities. Message order guarantees \u00b6 Message order in channels guaranteed to be the same while you publish messages into channel one after another or publish them in one request. If you do parallel publishes into the same channel then Centrifugo can't guarantee message order. Should I create channels explicitly? \u00b6 No. By default, channels created automatically as soon as first client subscribed to it. And destroyed automatically when last client unsubscribes from a channel. When history inside channel is on then a window of last messages kept automatically during retention period. So client that comes later and subscribes to channel can retrieve those messages using call to history. What about best practices with number of channels? \u00b6 Channel is a very lightweight entity - Centrifugo can deal with lots of channels, don't be afraid to use many channels. But keep in mind that one client should not be subscribed to lots of channels at the same moment (since this makes connection process heavy for a client). Using no more than several channels for a client is what you should try to achieve. A good analogy here is writing SQL queries \u2013 you need to make sure you return content using fixed amount of database queries, as soon as more entries on your page result in more queries - your pages start working very slow at some point. The same for channels - you better to deliver real-time events over fixed amount of channels. It takes a separate frame for a client to subscribe to single channel \u2013 more frames mean more heavy initial connection. Presence for chat apps - online status of your contacts \u00b6 While presence is a good feature it does not fit well for some apps. For example if you make chat app - you may probably use single personal channel for each user. In this case you cannot find who is online at moment using builtin Centrifugo presence feature as users do not share a common channel. You can solve this using your own separate service that tracks online status of your users (for example in Redis) and has a bulk API that returns online status approximation for a list of users. This way you will have efficient scalable way to deal with online statuses. Centrifugo stops accepting new connections, why? \u00b6 The most popular reason behind this is reaching open file limit. Just make it higher, we described how to do this nearby in this doc . Also check out an article in our blog which mentions possible problems when dealing with many persistent connections like WebSocket. Can I use Centrifugo without reverse-proxy like Nginx before it? \u00b6 Yes, you can - Go standard library designed to allow this. Though proxy before Centrifugo can be very useful for load balancing clients. Does Centrifugo work with HTTP/2? \u00b6 Yes, Centrifugo works with HTTP/2. You can disable HTTP/2 running Centrifugo server with GODEBUG environment variable: GODEBUG=\"http2server=0\" centrifugo -c config.json Keep in mind that when using WebSocket you are working only over HTTP/1.1, so HTTP/2 support mostly makes sense for SockJS HTTP transports. Is there a way to use single connection to Centrifugo from different browser tabs? \u00b6 If underlying transport is HTTP-based, and you use HTTP/2 then this will work automatically. For WebSocket each browser tab creates new connection. What if I need to send push notifications to mobile or web applications? \u00b6 Sometimes it's confusing to see a difference between real-time messages and push notifications. Centrifugo is a real-time messaging server. It can not send push notifications to devices - to Apple iOS devices via APNS, Android devices via GCM or browsers over Web Push API. This is a goal for another software. But the reasonable question here is how can you know when you need to send a real-time message to online client or push notification to its device for offline client. The solution is pretty simple. You can keep critical notifications for client in database. And when client reads a message you should send an ack to your backend marking that notification as read by client. Periodically you can check which notifications were sent to clients but they have not read it (no read ack received). For such notifications you can send push notification to its device using your own or another open-source solution. Look at Firebase for example. How can I know a message really delivered to a client? \u00b6 You can, but Centrifugo does not have such API. What you have to do to ensure your client have received a message is sending confirmation ack from your client to your application backend as soon as client processed message coming from Centrifugo channel. Can I publish new messages over WebSocket connection from a client? \u00b6 Centrifugo designed to stream messages from server to client. Even though it's possible to publish messages into channels directly from a client (when publish channel option enabled) - we strongly discourage this in production usage as those messages just go through Centrifugo without any additional control. Theoretically Centrifugo could resend messages published from client to your application backend endpoint (i.e. having some sort of webhook built in) but it does not seem beneficial it terms of overall performance and application architecture. And this will require extra layer of convetions about Centrifugo-to-backend communication. So in general when user generates an event it must be first delivered to your app backend using a convenient way (for example AJAX POST request for web application), processed on backend (validated, saved into main application database) and then published to Centrifugo using Centrifugo HTTP or GRPC API. Sometimes publishing from a client directly into a channel can be useful though - for personal projects, for demonstrations (like we do in our examples ) or if you trust your users and want to build application without backend. In all cases when you don't need any message control on your backend. Since Centrifugo v2.3.0 it's possible to utilize RPC proxy feature \u2013 in this case you can call RPC over Centrifugo WebSocket which will be translated to HTTP request to your backend. After receiving this request on backend you can publish message to Centrifugo server API. This way you can utilize WebSocket transport between client and your server in bidirectional way. HTTP traffic will be concentrated inside your private network. How to create secure channel for two users only (private chat case)? \u00b6 There are several ways to achieve it: use a private channel (starting with $ ) - every time user subscribes on it your backend should provide a sign to confirm that subscription request. Read more in channels chapter next is user limited channels (with # ) - you can create a channel with name like dialog#42,567 to limit subscribers only to user with id 42 and user with ID 567 , this does not fit well for channels with many or dynamic possible subscribers starting from Centrifugo v2.6.0 you can use subscribe proxy feature to validate subscriptions, see chapter about proxy finally, you can create hard to guess channel name (based on some secret key and user IDs or just generate and save this long unique name into your main app database) so other users won't know this channel to subscribe on it. This is the simplest but not the safest way - but can be reasonable to consider in many situations What's the best way to organize channel configuration? \u00b6 In most situations your application need several different real-time features. We suggest to use namespaces for every real-time feature if it requires some option enabled. For example if you need join/leave messages for chat app - create a special channel namespace with this join_leave option enabled. Otherwise, your other channels will receive join/leave messages too - increasing load and traffic in system but not actually used by clients. The same relates to other channel options. Does Centrifugo support webhooks? \u00b6 Centrifugo designed in a way where messages mostly flow one direction: from server to client. In idiomatic case you publish messages to your backend first, then after saving to your main database publish to channel over Centrifugo API to deliver a real-time message to all active channel subscribers. Now if you need any extra callbacks/webhooks you can call your application backend yourself from client side (for example just after connect event fired in client library). There are several reasons why we can't simply add webhooks \u2013 some of them described in this issue . A bit tricky thing are disconnects. The difficulty is because there is no guarantee that disconnect code will have time to execute on client side (as client can just switch off its device or simply lose internet connection). If you need to know that client disconnected and program your business logic around this fact then the only reasonable approach is periodically call your backend from client side and update user status somewhere on backend (use Redis maybe). This is a pretty robust solution where you can't occasionally miss disconnect event. HTTP proxy feature added in v2.3.0 allows integrating Centrifugo with your own session mechanism and provides a way to react on connection events. Also, it opens a road for bidirectional communication with RPC calls. But the note above about disconnects is still true - we can't simply call your app in case of client disconnects as loosing one such event can result in broken business logic inside your app. How scalable is presence and join/leave features? \u00b6 Presence is good for small channels with a reasonable number of subscribers, as soon as there are tons of subscribers presence information becomes very expensive in terms of bandwidth (as it contains full information about all clients in channel). There is presence_stats API method that can be helpful if you only need to know a number of clients (or unique users) in a channel. But in case of Redis engine even presence stats not optimized for channels with more that several thousands active subscribers. You may consider using separate service to deal with presense status information that provides information in near real-time maybe with some reasonable approximation. The same is true for join/leave messages - as soon as you turn on join/leave events for a channel with many subscribers every join/leave event (which generally happen relatively frequently) result into many messages sent to each subscriber in a channel, drastically multiplying amount of messages travelling through the system. So be careful and estimate possible load. There is no magic unfortunately. What is the difference between Centrifugo and Centrifuge \u00b6 Centrifugo is a server built on top of Centrifuge library for Go language. This documentation built to describe Centrifugo. Though many things said here can be considered as extra documentation for Centrifuge library. I have not found an answer on my question here: \u00b6 Ask in our community rooms: I want to contribute to this awesome project \u00b6 We have many things you can help with, just ask us in our chat rooms.","title":"Frequently Asked Questions"},{"location":"faq/#frequently-asked-questions","text":"Answers on various questions here.","title":"Frequently Asked Questions"},{"location":"faq/#how-many-connections-can-one-centrifugo-instance-handle","text":"This depends on many factors. Hardware, message rate, size of messages, Centrifugo features enabled, client distribution over channels, websocket compression on/off etc. So no certain answer on this question exists. Common sense, tests and monitoring can help here. Generally we suggest to not put more than 50-100k clients on one node - but you should measure for your personal use case. You can find a benchmark we did in this docs chapter \u2013 though the point above is still valid, measure and monitor your own setup.","title":"How many connections can one Centrifugo instance handle?"},{"location":"faq/#memory-usage-per-connection","text":"Depending on features enabled an amount of RAM required per each connection can vary. At moment, you can expect that each connection will cost about 30-50 KB of RAM, thus a server with 1 GB of RAM can handle about 20-30k connections.","title":"Memory usage per connection?"},{"location":"faq/#can-centrifugo-scale-horizontally","text":"Yes, it can. It can do this using builtin Redis Engine . Redis is very fast \u2013 for example it can handle hundreds of thousands requests per second. This should be OK for most applications in an internet. if you approach Redis resource limits (CPU or memory) then it's possible to use Centrifugo consistent sharding support to balance queries between different Redis instances. Starting from v2.6.0 Centrifugo also scales with Nats server as broker (but for unreliable at most once PUB/SUB only).","title":"Can Centrifugo scale horizontally?"},{"location":"faq/#message-delivery-model","text":"The model of message delivery of Centrifugo server is at most once. With recovery feature enabled it's possible to achieve at least once guarantee. After network disconnects client have an option to recover missed messages from in-memory message stream that Centrifugo maintains. Without recovery feature on a message you send to Centrifugo can be theoretically lost while moving towards your clients. Centrifugo tries to do the best effort to prevent message losses on a way to online clients, but you should be aware of possible message loss. Your application should tolerate this. As noted Centrifugo has an option called message recovery to automatically recover messages missed due to short network disconnections. Also, it prevents message loss on a way from Redis to nodes over Redis PUB/SUB using additional offset check and periodical synchronization. At this moment Centrifugo message recovery designed for a short term disconnect period (think no more than one hour for a typical chat application). After this period (which can be configured per channel basis) Centrifugo removes messages from in-memory channel stream. In this case Centrifugo let client know that some messages can not be recovered, so you can load application state from your main database. We also recommend modeling your applications in a way that users don't notice when Centrifugo does not work at all. Use graceful degradation. For example if a user posts a new comment over AJAX call to your application backend - you should not rely only on Centrifugo to receive new comment from channel and display it - you should return new comment data in AJAX call response and render it. This way user that posts a comment will think that everything works just fine. Be careful to not draw comments twice in this case - think about idempotent identifiers for your entities.","title":"Message delivery model"},{"location":"faq/#message-order-guarantees","text":"Message order in channels guaranteed to be the same while you publish messages into channel one after another or publish them in one request. If you do parallel publishes into the same channel then Centrifugo can't guarantee message order.","title":"Message order guarantees"},{"location":"faq/#should-i-create-channels-explicitly","text":"No. By default, channels created automatically as soon as first client subscribed to it. And destroyed automatically when last client unsubscribes from a channel. When history inside channel is on then a window of last messages kept automatically during retention period. So client that comes later and subscribes to channel can retrieve those messages using call to history.","title":"Should I create channels explicitly?"},{"location":"faq/#what-about-best-practices-with-number-of-channels","text":"Channel is a very lightweight entity - Centrifugo can deal with lots of channels, don't be afraid to use many channels. But keep in mind that one client should not be subscribed to lots of channels at the same moment (since this makes connection process heavy for a client). Using no more than several channels for a client is what you should try to achieve. A good analogy here is writing SQL queries \u2013 you need to make sure you return content using fixed amount of database queries, as soon as more entries on your page result in more queries - your pages start working very slow at some point. The same for channels - you better to deliver real-time events over fixed amount of channels. It takes a separate frame for a client to subscribe to single channel \u2013 more frames mean more heavy initial connection.","title":"What about best practices with number of channels?"},{"location":"faq/#presence-for-chat-apps-online-status-of-your-contacts","text":"While presence is a good feature it does not fit well for some apps. For example if you make chat app - you may probably use single personal channel for each user. In this case you cannot find who is online at moment using builtin Centrifugo presence feature as users do not share a common channel. You can solve this using your own separate service that tracks online status of your users (for example in Redis) and has a bulk API that returns online status approximation for a list of users. This way you will have efficient scalable way to deal with online statuses.","title":"Presence for chat apps - online status of your contacts"},{"location":"faq/#centrifugo-stops-accepting-new-connections-why","text":"The most popular reason behind this is reaching open file limit. Just make it higher, we described how to do this nearby in this doc . Also check out an article in our blog which mentions possible problems when dealing with many persistent connections like WebSocket.","title":"Centrifugo stops accepting new connections, why?"},{"location":"faq/#can-i-use-centrifugo-without-reverse-proxy-like-nginx-before-it","text":"Yes, you can - Go standard library designed to allow this. Though proxy before Centrifugo can be very useful for load balancing clients.","title":"Can I use Centrifugo without reverse-proxy like Nginx before it?"},{"location":"faq/#does-centrifugo-work-with-http2","text":"Yes, Centrifugo works with HTTP/2. You can disable HTTP/2 running Centrifugo server with GODEBUG environment variable: GODEBUG=\"http2server=0\" centrifugo -c config.json Keep in mind that when using WebSocket you are working only over HTTP/1.1, so HTTP/2 support mostly makes sense for SockJS HTTP transports.","title":"Does Centrifugo work with HTTP/2?"},{"location":"faq/#is-there-a-way-to-use-single-connection-to-centrifugo-from-different-browser-tabs","text":"If underlying transport is HTTP-based, and you use HTTP/2 then this will work automatically. For WebSocket each browser tab creates new connection.","title":"Is there a way to use single connection to Centrifugo from different browser tabs?"},{"location":"faq/#what-if-i-need-to-send-push-notifications-to-mobile-or-web-applications","text":"Sometimes it's confusing to see a difference between real-time messages and push notifications. Centrifugo is a real-time messaging server. It can not send push notifications to devices - to Apple iOS devices via APNS, Android devices via GCM or browsers over Web Push API. This is a goal for another software. But the reasonable question here is how can you know when you need to send a real-time message to online client or push notification to its device for offline client. The solution is pretty simple. You can keep critical notifications for client in database. And when client reads a message you should send an ack to your backend marking that notification as read by client. Periodically you can check which notifications were sent to clients but they have not read it (no read ack received). For such notifications you can send push notification to its device using your own or another open-source solution. Look at Firebase for example.","title":"What if I need to send push notifications to mobile or web applications?"},{"location":"faq/#how-can-i-know-a-message-really-delivered-to-a-client","text":"You can, but Centrifugo does not have such API. What you have to do to ensure your client have received a message is sending confirmation ack from your client to your application backend as soon as client processed message coming from Centrifugo channel.","title":"How can I know a message really delivered to a client?"},{"location":"faq/#can-i-publish-new-messages-over-websocket-connection-from-a-client","text":"Centrifugo designed to stream messages from server to client. Even though it's possible to publish messages into channels directly from a client (when publish channel option enabled) - we strongly discourage this in production usage as those messages just go through Centrifugo without any additional control. Theoretically Centrifugo could resend messages published from client to your application backend endpoint (i.e. having some sort of webhook built in) but it does not seem beneficial it terms of overall performance and application architecture. And this will require extra layer of convetions about Centrifugo-to-backend communication. So in general when user generates an event it must be first delivered to your app backend using a convenient way (for example AJAX POST request for web application), processed on backend (validated, saved into main application database) and then published to Centrifugo using Centrifugo HTTP or GRPC API. Sometimes publishing from a client directly into a channel can be useful though - for personal projects, for demonstrations (like we do in our examples ) or if you trust your users and want to build application without backend. In all cases when you don't need any message control on your backend. Since Centrifugo v2.3.0 it's possible to utilize RPC proxy feature \u2013 in this case you can call RPC over Centrifugo WebSocket which will be translated to HTTP request to your backend. After receiving this request on backend you can publish message to Centrifugo server API. This way you can utilize WebSocket transport between client and your server in bidirectional way. HTTP traffic will be concentrated inside your private network.","title":"Can I publish new messages over WebSocket connection from a client?"},{"location":"faq/#how-to-create-secure-channel-for-two-users-only-private-chat-case","text":"There are several ways to achieve it: use a private channel (starting with $ ) - every time user subscribes on it your backend should provide a sign to confirm that subscription request. Read more in channels chapter next is user limited channels (with # ) - you can create a channel with name like dialog#42,567 to limit subscribers only to user with id 42 and user with ID 567 , this does not fit well for channels with many or dynamic possible subscribers starting from Centrifugo v2.6.0 you can use subscribe proxy feature to validate subscriptions, see chapter about proxy finally, you can create hard to guess channel name (based on some secret key and user IDs or just generate and save this long unique name into your main app database) so other users won't know this channel to subscribe on it. This is the simplest but not the safest way - but can be reasonable to consider in many situations","title":"How to create secure channel for two users only (private chat case)?"},{"location":"faq/#whats-the-best-way-to-organize-channel-configuration","text":"In most situations your application need several different real-time features. We suggest to use namespaces for every real-time feature if it requires some option enabled. For example if you need join/leave messages for chat app - create a special channel namespace with this join_leave option enabled. Otherwise, your other channels will receive join/leave messages too - increasing load and traffic in system but not actually used by clients. The same relates to other channel options.","title":"What's the best way to organize channel configuration?"},{"location":"faq/#does-centrifugo-support-webhooks","text":"Centrifugo designed in a way where messages mostly flow one direction: from server to client. In idiomatic case you publish messages to your backend first, then after saving to your main database publish to channel over Centrifugo API to deliver a real-time message to all active channel subscribers. Now if you need any extra callbacks/webhooks you can call your application backend yourself from client side (for example just after connect event fired in client library). There are several reasons why we can't simply add webhooks \u2013 some of them described in this issue . A bit tricky thing are disconnects. The difficulty is because there is no guarantee that disconnect code will have time to execute on client side (as client can just switch off its device or simply lose internet connection). If you need to know that client disconnected and program your business logic around this fact then the only reasonable approach is periodically call your backend from client side and update user status somewhere on backend (use Redis maybe). This is a pretty robust solution where you can't occasionally miss disconnect event. HTTP proxy feature added in v2.3.0 allows integrating Centrifugo with your own session mechanism and provides a way to react on connection events. Also, it opens a road for bidirectional communication with RPC calls. But the note above about disconnects is still true - we can't simply call your app in case of client disconnects as loosing one such event can result in broken business logic inside your app.","title":"Does Centrifugo support webhooks?"},{"location":"faq/#how-scalable-is-presence-and-joinleave-features","text":"Presence is good for small channels with a reasonable number of subscribers, as soon as there are tons of subscribers presence information becomes very expensive in terms of bandwidth (as it contains full information about all clients in channel). There is presence_stats API method that can be helpful if you only need to know a number of clients (or unique users) in a channel. But in case of Redis engine even presence stats not optimized for channels with more that several thousands active subscribers. You may consider using separate service to deal with presense status information that provides information in near real-time maybe with some reasonable approximation. The same is true for join/leave messages - as soon as you turn on join/leave events for a channel with many subscribers every join/leave event (which generally happen relatively frequently) result into many messages sent to each subscriber in a channel, drastically multiplying amount of messages travelling through the system. So be careful and estimate possible load. There is no magic unfortunately.","title":"How scalable is presence and join/leave features?"},{"location":"faq/#what-is-the-difference-between-centrifugo-and-centrifuge","text":"Centrifugo is a server built on top of Centrifuge library for Go language. This documentation built to describe Centrifugo. Though many things said here can be considered as extra documentation for Centrifuge library.","title":"What is the difference between Centrifugo and Centrifuge"},{"location":"faq/#i-have-not-found-an-answer-on-my-question-here","text":"Ask in our community rooms:","title":"I have not found an answer on my question here:"},{"location":"faq/#i-want-to-contribute-to-this-awesome-project","text":"We have many things you can help with, just ask us in our chat rooms.","title":"I want to contribute to this awesome project"},{"location":"getting_started/","text":"What is Centrifugo \u00b6 Centrifugo is a scalable real-time messaging server in language-agnostic way. The term language-agnostic in this definition means that it does not matter which programming language your application uses on a frontend or backend sides \u2013 Centrifugo works in conjunction with any. Centrifugo is fast and scales well to support millions of client connections. Real-time messages are messages delivered to your application users almost immediately after some event happened - think live comments, chat apps, real-time charts, dynamic counters and multiplayer games. There are several real-time messaging transports Centrifugo supports at moment: Websocket with JSON or binary Protobuf protocols SockJS \u2013 library that tries to establish Websocket connection first and then falls back to HTTP transports (Server-Sent Events, XHR-streaming, XHR-polling etc) automatically in case of problems with Websocket connection Join community \u00b6 We have rooms in Telegram and Discord \u2013 welcome! Motivation of project \u00b6 Centrifugo was originally born to help applications with server side written in language or framework without built-in concurrency support. In this case Centrifugo is a very straightforward and non-obtrusive way to introduce real-time updates. For example frameworks like Django, Flask, Yii, Laravel, Ruby on Rails etc has poor or not very performant support of working with many persistent connections. Centrifugo aims to help with this and continue to write a backend with your favorite language or favorite framework. Centrifugo also has some features (performance, scalability, connection management, message recovery on reconnect etc) that can simplify your life as a developer even if you are writing backend in asynchronous concurrent language. Concepts \u00b6 Centrifugo runs as standalone server and takes care of handling persistent connections from your application users. Your application backend and frontend can be written in any programming language. Your clients connect to Centrifugo from a frontend and subscribe to channels. As soon as some event happens your application backend can publish a message with event into a channel using Centrifugo API. That message will be delivered to all clients currently subscribed on a channel. So actually Centrifugo is a user-facing PUB/SUB server. Here is a simplified scheme: Highlights \u00b6 Here is a list with main Centrifugo highlights: Centrifugo is fast and capable to scale to millions of simultaneous connections Simple integration with any application \u2013 works as separate service Simple server API (HTTP or GRPC) Client-side libraries for popular frontend environments JSON and binary Protobuf Websocket client protocol based on strict schema SockJS polyfill for web browsers without Websocket support User authentication with JWT or over connection request proxy to configured HTTP endpoint Proper connection management and expiration control Various types of channels: private, user-limited Various types of subscriptions: client-side or server-side Transform RPC calls over WebSocket/SockJS to configured HTTP endpoint call Presence information for channels (show all active clients in channel) History information for channels (last messages published into channel) Join/leave events for channels (client goes online/offline) Automatic recovery of missed messages between client reconnects over configured retention period Built-in administrative web panel Cross platform \u2013 works on Linux, MacOS and Windows Ready to deploy (Docker, RPM/DEB packages, automatic Let's Encrypt TLS certificates, Prometheus/Graphite monitoring) MIT license","title":"What is Centrifugo"},{"location":"getting_started/#what-is-centrifugo","text":"Centrifugo is a scalable real-time messaging server in language-agnostic way. The term language-agnostic in this definition means that it does not matter which programming language your application uses on a frontend or backend sides \u2013 Centrifugo works in conjunction with any. Centrifugo is fast and scales well to support millions of client connections. Real-time messages are messages delivered to your application users almost immediately after some event happened - think live comments, chat apps, real-time charts, dynamic counters and multiplayer games. There are several real-time messaging transports Centrifugo supports at moment: Websocket with JSON or binary Protobuf protocols SockJS \u2013 library that tries to establish Websocket connection first and then falls back to HTTP transports (Server-Sent Events, XHR-streaming, XHR-polling etc) automatically in case of problems with Websocket connection","title":"What is Centrifugo"},{"location":"getting_started/#join-community","text":"We have rooms in Telegram and Discord \u2013 welcome!","title":"Join community"},{"location":"getting_started/#motivation-of-project","text":"Centrifugo was originally born to help applications with server side written in language or framework without built-in concurrency support. In this case Centrifugo is a very straightforward and non-obtrusive way to introduce real-time updates. For example frameworks like Django, Flask, Yii, Laravel, Ruby on Rails etc has poor or not very performant support of working with many persistent connections. Centrifugo aims to help with this and continue to write a backend with your favorite language or favorite framework. Centrifugo also has some features (performance, scalability, connection management, message recovery on reconnect etc) that can simplify your life as a developer even if you are writing backend in asynchronous concurrent language.","title":"Motivation of project"},{"location":"getting_started/#concepts","text":"Centrifugo runs as standalone server and takes care of handling persistent connections from your application users. Your application backend and frontend can be written in any programming language. Your clients connect to Centrifugo from a frontend and subscribe to channels. As soon as some event happens your application backend can publish a message with event into a channel using Centrifugo API. That message will be delivered to all clients currently subscribed on a channel. So actually Centrifugo is a user-facing PUB/SUB server. Here is a simplified scheme:","title":"Concepts"},{"location":"getting_started/#highlights","text":"Here is a list with main Centrifugo highlights: Centrifugo is fast and capable to scale to millions of simultaneous connections Simple integration with any application \u2013 works as separate service Simple server API (HTTP or GRPC) Client-side libraries for popular frontend environments JSON and binary Protobuf Websocket client protocol based on strict schema SockJS polyfill for web browsers without Websocket support User authentication with JWT or over connection request proxy to configured HTTP endpoint Proper connection management and expiration control Various types of channels: private, user-limited Various types of subscriptions: client-side or server-side Transform RPC calls over WebSocket/SockJS to configured HTTP endpoint call Presence information for channels (show all active clients in channel) History information for channels (last messages published into channel) Join/leave events for channels (client goes online/offline) Automatic recovery of missed messages between client reconnects over configured retention period Built-in administrative web panel Cross platform \u2013 works on Linux, MacOS and Windows Ready to deploy (Docker, RPM/DEB packages, automatic Let's Encrypt TLS certificates, Prometheus/Graphite monitoring) MIT license","title":"Highlights"},{"location":"guide/","text":"Centrifugo integration guide \u00b6 This chapter aims to help you get started with Centrifugo. We will look at a step-by-step workflow of integrating your application with Centrifugo providing links to relevant parts of this documentation. As Centrifugo is language-agnostic and can be used together with any language/framework we won't be specific here about any backend or frontend technology your application can be built with. Only abstract steps which you can extrapolate to your application stack. So first of all let's look again at a simplified scheme: There are three parts involved into idiomatic Centrifugo usage scenario: your clients (frontend application), your application backend and Centrifugo. It's possible to use Centrifugo without any application backend involved but here we won't consider this use case. Here let's suppose you already have 2 of 3 elements: clients and backend. Now you want to add Centrifugo to receive real-time events on client side. 0. Install \u00b6 First you need to do is download/install Centrifugo server. See install chapter for details. 1. Configure Centrifugo \u00b6 Create basic configuration file with token_hmac_secret_key (or token_rsa_public_key ) and api_key set and then run Centrifugo. See this chapter for details about token_hmac_secret_key / token_rsa_public_key and chapter about API for API description. The simplest way to do this automatically is by using genconfig command: ./centrifugo genconfig \u2013 which will generate config.json file for you with all required fields. A generated configuration also includes v3_use_offset option set to true . This is an option that enables using actual offset field in client-server protocol and will be used by default in Centrifugo v3. This option available since Centrifugo v2.5.0 and described in detail in v2.5.0 release notes . 2. Configure your backend \u00b6 In configuration file of your application backend register several variables: Centrifugo secret and Centrifugo API key you set on a previous step and Centrifugo API address. By default, API address is http://localhost:8000/api . You must never reveal token secret and API key to your users . 3. Connect to Centrifugo \u00b6 Now your users can start connecting to Centrifugo. You should get client library (see list of available client libraries ) for your application frontend. Every library has method to connect to Centrifugo. See information about Centrifugo connection endpoints here . Every client should provide connection token (JWT) on connect. You must generate this token on your backend side using Centrifugo secret key you set to backend configuration (note that in case of RSA tokens you are generating JWT with private key). See how to generate this JWT in special chapter . You pass this token from backend to your frontend app (pass it in template context or use separate request from client side to get user specific JWT from backend side). And use this token when connecting to Centrifugo (for example browser client has special method setToken ). Since Centrifugo v2.3.0 there is a way to authenticate connections without using JWT - see chapter about proxying to backend . You are connecting to Centrifugo using one of available transports. At this moment you can choose from: WebSocket, with JSON or binary protobuf protocol. See more info in a chapter about WebSocket transport SockJS (only supports JSON protocol). See more info about SockJS transport 4. Subscribe to channels \u00b6 After connecting to Centrifugo subscribe clients to channels they are interested in. See more about channels in special chapter . All client libraries provide a way to handle messages coming to client from a channel after subscribing to it. Since Centrifugo v2.4.0 there is a way to subscribe connection to a list of channels on server side at the moment of connection establishment. See chapter about server-side subscriptions . 5. Publish to channel \u00b6 So everything should work now \u2013 as soon as user opens some page of your application it must successfully connect to Centrifugo and subscribe to a channel (or channels). Now let's imagine you want to send a real-time message to users subscribed on a specific channel. This message can be a reaction on some event happened in your app: someone posted new comment, administrator just created new post, user pressed like button etc. Anyway this is an event your backend just got, and you want to immediately share it with interested users. You can do this using Centrifugo HTTP API . To simplify your life we have several API libraries for different languages. You can publish message into channel using one of those libraries or you can simply follow API description to construct API request yourself - this is very simple. Also Centrifugo supports GRPC API . As soon as you published message to channel it must be delivered to your client. 6. Deploy to production \u00b6 To put this all into production you need to deploy Centrifugo on your production server. To help you with this we have many things like Docker image, rpm and deb packages, Nginx configuration. You can find more information in Deploy section of this doc. See OS tuning chapter for some actions you have to do to prepare your server machine for handling many persistent connections. 7. Monitor Centrifugo \u00b6 Don't forget to monitor your production Centrifugo setup. 8. Scale Centrifugo \u00b6 As soon as you are close to machine resource limits you may want to scale Centrifugo \u2013 you can run many Centrifugo instances and load-balance clients between them using Redis engine . 9. Read FAQ \u00b6 That's all for basics. Documentation actually covers lots of other concepts Centrifugo server has: like scalability, private channels, admin web interface, SockJS fallback, Protobuf support and more. And don't forget to read our FAQ .","title":"Integration Guide"},{"location":"guide/#centrifugo-integration-guide","text":"This chapter aims to help you get started with Centrifugo. We will look at a step-by-step workflow of integrating your application with Centrifugo providing links to relevant parts of this documentation. As Centrifugo is language-agnostic and can be used together with any language/framework we won't be specific here about any backend or frontend technology your application can be built with. Only abstract steps which you can extrapolate to your application stack. So first of all let's look again at a simplified scheme: There are three parts involved into idiomatic Centrifugo usage scenario: your clients (frontend application), your application backend and Centrifugo. It's possible to use Centrifugo without any application backend involved but here we won't consider this use case. Here let's suppose you already have 2 of 3 elements: clients and backend. Now you want to add Centrifugo to receive real-time events on client side.","title":"Centrifugo integration guide"},{"location":"guide/#0-install","text":"First you need to do is download/install Centrifugo server. See install chapter for details.","title":"0. Install"},{"location":"guide/#1-configure-centrifugo","text":"Create basic configuration file with token_hmac_secret_key (or token_rsa_public_key ) and api_key set and then run Centrifugo. See this chapter for details about token_hmac_secret_key / token_rsa_public_key and chapter about API for API description. The simplest way to do this automatically is by using genconfig command: ./centrifugo genconfig \u2013 which will generate config.json file for you with all required fields. A generated configuration also includes v3_use_offset option set to true . This is an option that enables using actual offset field in client-server protocol and will be used by default in Centrifugo v3. This option available since Centrifugo v2.5.0 and described in detail in v2.5.0 release notes .","title":"1. Configure Centrifugo"},{"location":"guide/#2-configure-your-backend","text":"In configuration file of your application backend register several variables: Centrifugo secret and Centrifugo API key you set on a previous step and Centrifugo API address. By default, API address is http://localhost:8000/api . You must never reveal token secret and API key to your users .","title":"2. Configure your backend"},{"location":"guide/#3-connect-to-centrifugo","text":"Now your users can start connecting to Centrifugo. You should get client library (see list of available client libraries ) for your application frontend. Every library has method to connect to Centrifugo. See information about Centrifugo connection endpoints here . Every client should provide connection token (JWT) on connect. You must generate this token on your backend side using Centrifugo secret key you set to backend configuration (note that in case of RSA tokens you are generating JWT with private key). See how to generate this JWT in special chapter . You pass this token from backend to your frontend app (pass it in template context or use separate request from client side to get user specific JWT from backend side). And use this token when connecting to Centrifugo (for example browser client has special method setToken ). Since Centrifugo v2.3.0 there is a way to authenticate connections without using JWT - see chapter about proxying to backend . You are connecting to Centrifugo using one of available transports. At this moment you can choose from: WebSocket, with JSON or binary protobuf protocol. See more info in a chapter about WebSocket transport SockJS (only supports JSON protocol). See more info about SockJS transport","title":"3. Connect to Centrifugo"},{"location":"guide/#4-subscribe-to-channels","text":"After connecting to Centrifugo subscribe clients to channels they are interested in. See more about channels in special chapter . All client libraries provide a way to handle messages coming to client from a channel after subscribing to it. Since Centrifugo v2.4.0 there is a way to subscribe connection to a list of channels on server side at the moment of connection establishment. See chapter about server-side subscriptions .","title":"4. Subscribe to channels"},{"location":"guide/#5-publish-to-channel","text":"So everything should work now \u2013 as soon as user opens some page of your application it must successfully connect to Centrifugo and subscribe to a channel (or channels). Now let's imagine you want to send a real-time message to users subscribed on a specific channel. This message can be a reaction on some event happened in your app: someone posted new comment, administrator just created new post, user pressed like button etc. Anyway this is an event your backend just got, and you want to immediately share it with interested users. You can do this using Centrifugo HTTP API . To simplify your life we have several API libraries for different languages. You can publish message into channel using one of those libraries or you can simply follow API description to construct API request yourself - this is very simple. Also Centrifugo supports GRPC API . As soon as you published message to channel it must be delivered to your client.","title":"5. Publish to channel"},{"location":"guide/#6-deploy-to-production","text":"To put this all into production you need to deploy Centrifugo on your production server. To help you with this we have many things like Docker image, rpm and deb packages, Nginx configuration. You can find more information in Deploy section of this doc. See OS tuning chapter for some actions you have to do to prepare your server machine for handling many persistent connections.","title":"6. Deploy to production"},{"location":"guide/#7-monitor-centrifugo","text":"Don't forget to monitor your production Centrifugo setup.","title":"7. Monitor Centrifugo"},{"location":"guide/#8-scale-centrifugo","text":"As soon as you are close to machine resource limits you may want to scale Centrifugo \u2013 you can run many Centrifugo instances and load-balance clients between them using Redis engine .","title":"8. Scale Centrifugo"},{"location":"guide/#9-read-faq","text":"That's all for basics. Documentation actually covers lots of other concepts Centrifugo server has: like scalability, private channels, admin web interface, SockJS fallback, Protobuf support and more. And don't forget to read our FAQ .","title":"9. Read FAQ"},{"location":"quick_start/","text":"Quick start \u00b6 Here we will build a very simple browser application with Centrifugo. It works in a way that users connect to Centrifugo over WebSocket, subscribe to channel and start receiving all messages published to that channel. In our case we will send a counter value to all channel subscribers to update it in all open browser tabs in real-time. First you need to install Centrifugo . Below in this example we will use binary file release for simplicity. We can generate minimal required configuration file with the following command: ./centrifugo genconfig It will generate config.json file in the same directory with content like this: { \"v3_use_offset\": true, \"token_hmac_secret_key\": \"46b38493-147e-4e3f-86e0-dc5ec54f5133\", \"admin_password\": \"ad0dff75-3131-4a02-8d64-9279b4f1c57b\", \"admin_secret\": \"583bc4b7-0fa5-4c4a-8566-16d3ce4ad401\", \"api_key\": \"aaaf202f-b5f8-4b34-bf88-f6c03a1ecda6\" } Now we can start server, and let's start it with built-in admin web interface: ./centrifugo --config=config.json --admin Now open http://localhost:8000 \u2013 and you should see Centrifugo admin web panel. Enter admin_password from configuration file to log in. Inside admin panel you should see that one Centrifugo node is running, and it does not have connected clients. Now let's create index.html file with our simple app: < html > < head > < title > Centrifugo quick start </ title > </ head > < body > < div id = \"counter\" > - </ div > < script src = \"https://cdn.jsdelivr.net/gh/centrifugal/centrifuge-js@2.6.2/dist/centrifuge.min.js\" ></ script > < script type = \"text/javascript\" > const container = document . getElementById ( 'counter' ) const centrifuge = new Centrifuge ( \"ws://localhost:8000/connection/websocket\" ); centrifuge . setToken ( \"<TOKEN>\" ); centrifuge . on ( 'connect' , function ( ctx ) { console . log ( \"connected\" , ctx ); }); centrifuge . on ( 'disconnect' , function ( ctx ) { console . log ( \"disconnected\" , ctx ); }); centrifuge . subscribe ( \"channel\" , function ( ctx ) { container . innerHTML = ctx . data . value ; document . title = ctx . data . value ; }); centrifuge . connect (); </ script > </ body > </ html > Note that we are using centrifuge-js 2.6.2 in this example, you better use its latest version for a moment of reading this. We create an instance of client providing it Centrifugo default WebSocket endpoint address, then we subscribe to channel channel and provide callback function to process real-time messages. Then we call connect method to create WebSocket connection. You need to open this file in a browser, for example on MacOS: open index.html Or just enter sth like file:///path/to/index.html to browser address bar. In real application you will serve your HTML files with a proper web server \u2013 but for this simple example we don't need it. Now if you look at browser developer tools or in Centrifugo logs you will notice that connection not successfully established: 2020-05-16 01:19:59 [INF] invalid connection token error=\"jwt: token format is not valid\" client=45a1b8f4-d6dc-4679-9927-93e41c14ad93 2020-05-16 01:19:59 [INF] disconnect after handling command client=45a1b8f4-d6dc-4679-9927-93e41c14ad93 command=\"id:1 params:\\\"{\\\\\\\"token\\\\\\\":\\\\\\\"<TOKEN>\\\\\\\"}\\\" \" reason=\"invalid token\" user= That's because client should provide valid JWT (JSON Web Token) to authenticate itself. This token must be generated on your backend and passed to client side. Since in our simple example we don't have application backend we can quickly generate example token for a user using centrifugo sub-command gentoken . Like this: ./centrifugo gentoken -u 123722 \u2013 where -u flag sets user ID. The output should be like: HMAC SHA-256 JWT for user 123722 with expiration TTL 168h0m0s: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM3MjIiLCJleHAiOjE1OTAxODYzMTZ9.YMJVJsQbK_p1fYFWkcoKBYr718AeavAk3MAYvxcMk0M \u2013 you will have another token value since this one based on randomly generated token_hmac_secret_key from configuration file we created in the beginning of this tutorial. Now we can copy generated HMAC SHA-256 JWT and paste it into centrifuge.setToken call instead of <TOKEN> placeholder in index.html file. I.e.: centrifuge.setToken(\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM3MjIiLCJleHAiOjE1OTAxODYzMTZ9.YMJVJsQbK_p1fYFWkcoKBYr718AeavAk3MAYvxcMk0M\"); That's it! Now if you reload your browser tab \u2013 connection will be successfully established and client will subscribe to channel. If you open developer tools and look at WebSocket frames panel you should see sth like this: OK, the last thing we need to do here is publish new counter value to channel and make sure our app works properly. We can do this over Centrifugo API sending HTTP request to default API endpoint http://localhost:8000/api , but let's do this over admin web panel first. Open Centrifugo admin web panel in another browser tab and go to Actions section. Select publish action, insert channel name that you want to publish to \u2013 in our case this is string channel and insert into data area JSON like this: { \"value\" : 1 } Click Submit button and check out application browser tab \u2013 counter value must be immediately received and displayed. Open several browser tabs with our app and make sure all tabs receive message as soon as you publish it. BTW, let's also look at how you can publish data to channel over Centrifugo API from a terminal using curl tool: curl --header \"Content-Type: application/json\" \\ --header \"Authorization: apikey aaaf202f-b5f8-4b34-bf88-f6c03a1ecda6\" \\ --request POST \\ --data '{\"method\": \"publish\", \"params\": {\"channel\": \"channel\", \"data\": {\"value\": 2}}}' \\ http://localhost:8000/api \u2013 where for Authorization header we set api_key value from Centrifugo config file generated above. We did it! We built the simplest app with Centrifugo and its Javascript client. It does not have backend, it's not very useful to be honest, but it should give you an insight on how to start working with Centrifugo server. Read more about Centrifugo server in next documentations chapters \u2013 it can do much-much more than we just showed here. Integration guide describes a process of idiomatic Centrifugo integration with your application backend. More examples \u00b6 Several more examples located on Github \u2013 check out this repo","title":"Quick start"},{"location":"quick_start/#quick-start","text":"Here we will build a very simple browser application with Centrifugo. It works in a way that users connect to Centrifugo over WebSocket, subscribe to channel and start receiving all messages published to that channel. In our case we will send a counter value to all channel subscribers to update it in all open browser tabs in real-time. First you need to install Centrifugo . Below in this example we will use binary file release for simplicity. We can generate minimal required configuration file with the following command: ./centrifugo genconfig It will generate config.json file in the same directory with content like this: { \"v3_use_offset\": true, \"token_hmac_secret_key\": \"46b38493-147e-4e3f-86e0-dc5ec54f5133\", \"admin_password\": \"ad0dff75-3131-4a02-8d64-9279b4f1c57b\", \"admin_secret\": \"583bc4b7-0fa5-4c4a-8566-16d3ce4ad401\", \"api_key\": \"aaaf202f-b5f8-4b34-bf88-f6c03a1ecda6\" } Now we can start server, and let's start it with built-in admin web interface: ./centrifugo --config=config.json --admin Now open http://localhost:8000 \u2013 and you should see Centrifugo admin web panel. Enter admin_password from configuration file to log in. Inside admin panel you should see that one Centrifugo node is running, and it does not have connected clients. Now let's create index.html file with our simple app: < html > < head > < title > Centrifugo quick start </ title > </ head > < body > < div id = \"counter\" > - </ div > < script src = \"https://cdn.jsdelivr.net/gh/centrifugal/centrifuge-js@2.6.2/dist/centrifuge.min.js\" ></ script > < script type = \"text/javascript\" > const container = document . getElementById ( 'counter' ) const centrifuge = new Centrifuge ( \"ws://localhost:8000/connection/websocket\" ); centrifuge . setToken ( \"<TOKEN>\" ); centrifuge . on ( 'connect' , function ( ctx ) { console . log ( \"connected\" , ctx ); }); centrifuge . on ( 'disconnect' , function ( ctx ) { console . log ( \"disconnected\" , ctx ); }); centrifuge . subscribe ( \"channel\" , function ( ctx ) { container . innerHTML = ctx . data . value ; document . title = ctx . data . value ; }); centrifuge . connect (); </ script > </ body > </ html > Note that we are using centrifuge-js 2.6.2 in this example, you better use its latest version for a moment of reading this. We create an instance of client providing it Centrifugo default WebSocket endpoint address, then we subscribe to channel channel and provide callback function to process real-time messages. Then we call connect method to create WebSocket connection. You need to open this file in a browser, for example on MacOS: open index.html Or just enter sth like file:///path/to/index.html to browser address bar. In real application you will serve your HTML files with a proper web server \u2013 but for this simple example we don't need it. Now if you look at browser developer tools or in Centrifugo logs you will notice that connection not successfully established: 2020-05-16 01:19:59 [INF] invalid connection token error=\"jwt: token format is not valid\" client=45a1b8f4-d6dc-4679-9927-93e41c14ad93 2020-05-16 01:19:59 [INF] disconnect after handling command client=45a1b8f4-d6dc-4679-9927-93e41c14ad93 command=\"id:1 params:\\\"{\\\\\\\"token\\\\\\\":\\\\\\\"<TOKEN>\\\\\\\"}\\\" \" reason=\"invalid token\" user= That's because client should provide valid JWT (JSON Web Token) to authenticate itself. This token must be generated on your backend and passed to client side. Since in our simple example we don't have application backend we can quickly generate example token for a user using centrifugo sub-command gentoken . Like this: ./centrifugo gentoken -u 123722 \u2013 where -u flag sets user ID. The output should be like: HMAC SHA-256 JWT for user 123722 with expiration TTL 168h0m0s: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM3MjIiLCJleHAiOjE1OTAxODYzMTZ9.YMJVJsQbK_p1fYFWkcoKBYr718AeavAk3MAYvxcMk0M \u2013 you will have another token value since this one based on randomly generated token_hmac_secret_key from configuration file we created in the beginning of this tutorial. Now we can copy generated HMAC SHA-256 JWT and paste it into centrifuge.setToken call instead of <TOKEN> placeholder in index.html file. I.e.: centrifuge.setToken(\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM3MjIiLCJleHAiOjE1OTAxODYzMTZ9.YMJVJsQbK_p1fYFWkcoKBYr718AeavAk3MAYvxcMk0M\"); That's it! Now if you reload your browser tab \u2013 connection will be successfully established and client will subscribe to channel. If you open developer tools and look at WebSocket frames panel you should see sth like this: OK, the last thing we need to do here is publish new counter value to channel and make sure our app works properly. We can do this over Centrifugo API sending HTTP request to default API endpoint http://localhost:8000/api , but let's do this over admin web panel first. Open Centrifugo admin web panel in another browser tab and go to Actions section. Select publish action, insert channel name that you want to publish to \u2013 in our case this is string channel and insert into data area JSON like this: { \"value\" : 1 } Click Submit button and check out application browser tab \u2013 counter value must be immediately received and displayed. Open several browser tabs with our app and make sure all tabs receive message as soon as you publish it. BTW, let's also look at how you can publish data to channel over Centrifugo API from a terminal using curl tool: curl --header \"Content-Type: application/json\" \\ --header \"Authorization: apikey aaaf202f-b5f8-4b34-bf88-f6c03a1ecda6\" \\ --request POST \\ --data '{\"method\": \"publish\", \"params\": {\"channel\": \"channel\", \"data\": {\"value\": 2}}}' \\ http://localhost:8000/api \u2013 where for Authorization header we set api_key value from Centrifugo config file generated above. We did it! We built the simplest app with Centrifugo and its Javascript client. It does not have backend, it's not very useful to be honest, but it should give you an insight on how to start working with Centrifugo server. Read more about Centrifugo server in next documentations chapters \u2013 it can do much-much more than we just showed here. Integration guide describes a process of idiomatic Centrifugo integration with your application backend.","title":"Quick start"},{"location":"quick_start/#more-examples","text":"Several more examples located on Github \u2013 check out this repo","title":"More examples"},{"location":"blog/","text":"Welcome to Centrifugo Dev Blog \u2764\ufe0f Here we are talking about real-time messaging topics \u2013 not only about Centrifugo server, but also about general related questions, about Centrifuge library, best practices on building real-time messaging servers, cool applications done with WebSocket technology etc. If you have an interesting post and want it to be published here \u2013 let us know in Centrifugo community channels.","title":"About this blog"},{"location":"blog/intro_centrifuge/","text":"An introduction to Centrifuge \u2013 real-time messaging with Go \u00b6 In this post I'll try to introduce Centrifuge - the heart of Centrifugo. Centrifuge is a real-time messaging library for the Go language. This post is going to be pretty long (looks like I am a huge fan of long reads) \u2013 so make sure you also have a drink (probably two) and let's go! How it's all started \u00b6 I wrote several blog posts before ( for example this one \u2013 yep, it's on Medium...) about an original motivation of Centrifugo server. Danger Centrifugo server is not the same as Centrifuge library for Go. It's a full-featured project built on top of Centrifuge library. Naming can be confusing, but it's not too hard once you spend some time with ecosystem. In short \u2013 Centrifugo was implemented to help traditional web frameworks dealing with many persistent connections (like WebSocket or SockJS HTTP transports). So frameworks like Django or Ruby on Rails, or frameworks from the PHP world could be used on a backend but still provide real-time messaging features like chats, multiplayer browser games, etc for users. With a little help from Centrifugo. Now there are cases when Centrifugo server used in conjunction even with a backend written in Go. While Go mostly has no problems dealing with many concurrent connections \u2013 Centrifugo provides some features beyond simple message passing between a client and a server. That makes it useful, especially since design is pretty non-obtrusive and fits well microservices world. Centrifugo is used in some well-known projects (like ManyChat, Yoola.io, Spot.im, Badoo etc). At the end of 2018, I released Centrifugo v2 based on a real-time messaging library for Go language \u2013 Centrifuge \u2013 the subject of this post. It was a pretty hard experience to decouple Centrifuge out of the monolithic Centrifugo server \u2013 I was unable to make all the things right immediately, so Centrifuge library API went through several iterations where I introduced backward-incompatible changes. All those changes targeted to make Centrifuge a more generic tool and remove opinionated or limiting parts. So what is Centrifuge? \u00b6 This is ... well, a framework to build real-time messaging applications with Go language. If you ever heard about socket.io \u2013 then you can think about Centrifuge as an analogue. I think the most popular applications these days are chats of different forms, but I want to emphasize that Centrifuge is not a framework to build chats \u2013 it's a generic instrument that can be used to create different sorts of real-time applications \u2013 real-time charts, multiplayer games. The obvious choice for real-time messaging transport to achieve fast and cross-platform bidirectional communication these days is WebSocket. Especially if you are targeting a browser environment. You mostly don't need to use WebSocket HTTP polyfills in 2021 (though there are still corner cases so Centrifuge supports SockJS polyfill). Centrifuge has its own custom protocol on top of plain WebSocket or SockJS frames. The reason why Centrifuge has its own protocol on top of underlying transport is that it provides several useful primitives to build real-time applications. The protocol described as strict Protobuf schema . It's possible to pass JSON or binary Protobuf-encoded data over the wire with Centrifuge. Note GRPC is very handy these days too (and can be used in a browser with a help of additional proxies), some developers prefer using it for real-time messaging apps \u2013 especially when one-way communication needed. It can be a bit better from integration perspective but more resource-consuming on server side and a bit trickier to deploy. Note Take a look at WebTransport \u2013 a brand-new spec for web browsers to allow fast communication between a client and a server on top of QUIC \u2013 it may be a good alternative to WebSocket in the future. This in a draft status at the moment, but it's already possible to play with in Chrome . Own protocol is one of the things that prove the framework status of Centrifuge. This dictates certain limits (for example, you can't just use an alternative message encoding) and makes developers use custom client connectors on a front-end side to communicate with a Centrifuge-based server (see more about connectors in ecosystem part). But protocol solves many practical tasks \u2013 and here we are going to look at real-time features it provides for a developer. Centrifuge Node \u00b6 To start working with Centrifuge you need to start Centrifuge server Node. Node is a core of Centrifuge \u2013 it has many useful methods \u2013 set event handlers, publish messages to channels, etc. We will look at some events and channels concept very soon. Also, Node abstracts away scalability aspects, so you don't need to think about how to scale WebSocket connections over different server instances and still have a way to deliver published messages to interested clients. For now, let's start a single instance of Node that will serve connections for us: node , err := centrifuge . New ( centrifuge . DefaultConfig ) if err != nil { log . Fatal ( err ) } if err := node . Run (); err != nil { log . Fatal ( err ) } It's also required to serve a WebSocket handler \u2013 this is possible just by registering centrifuge.WebsocketHandler in HTTP mux: wsHandler := centrifuge . NewWebsocketHandler ( node , centrifuge . WebsocketConfig {}) http . Handle ( \"/connection/websocket\" , wsHandler ) Now it's possible to connect to a server (using Centrifuge connector for a browser called centrifuge-js ): const centrifuge = new Centrifuge ( 'ws://localhost:8000/connection/websocket' ); centrifuge . connect (); Though connection will be rejected by the server since we also need to provide authentication details \u2013 Centrifuge expects explicitly provided connection Credentials to accept connection. Authentication \u00b6 Let's look at how we can tell Centrifuge details about connected user identity, so it could accept an incoming connection. There are two main ways to authenticate client connection in Centrifuge. The first one is over the native middleware mechanism. It's possible to wrap centrifuge.WebsocketHandler or centrifuge.SockjsHandler with middleware that checks user authentication and tells Centrifuge current user ID over context.Context : func auth ( h http . Handler ) http . Handler { return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { cred := & centrifuge . Credentials { UserID : \"42\" , } newCtx := centrifuge . SetCredentials ( r . Context (), cred ) r = r . WithContext ( newCtx ) h . ServeHTTP ( w , r ) }) } So WebsocketHandler can be registered this way (note that a handler now wrapped by auth middleware): wsHandler := centrifuge . NewWebsocketHandler ( node , centrifuge . WebsocketConfig {}) http . Handle ( \"/connection/websocket\" , auth ( wsHandler )) Another authentication way is a bit more generic \u2013 developers can authenticate connection based on custom token sent from a client inside first WebSocket/SockJS frame. This is called connect frame in terms of Centrifuge protocol. Any string token can be set \u2013 this opens a way to use JWT, Paceto, and any other kind of authentication tokens. For example see an authenticaton with JWT . Note BTW it's also possible to pass any information from client side with a first connect message from client to server and return custom information about server state to a client. This is out of post scope though. Nothing prevents you to integrate Centrifuge with OAuth2 or another framework session mechanism \u2013 like Gin for example . Channel subscriptions \u00b6 As soon as a client connected and successfully authenticated it can subscribe to channels. Channel (room or topic in other systems) is a lightweight and ephemeral entity in Centrifuge. Channel can have different features (we will look at some channel features below). Channels created automatically as soon as the first subscriber joins and destroyed as soon as the last subscriber left. The application can have many real-time features \u2013 even on one app screen. So sometimes client subscribes to several channels \u2013 each related to a specific real-time feature (for example one channel for chat updates, one channel likes notification stream, etc). Channel is just an ASCII string. A developer is responsible to find the best channel naming convention suitable for an application. Channel naming convention is an important aspect since in many cases developers want to authorize subscription to a channel on the server side \u2013 so only authorized users could listen to specific channel updates. Let's look at a basic subscription example on the client-side: centrifuge . subscribe ( 'example' , function ( msgCtx ) { console . log ( msgCtx ) }) On the server-side, you need to define subscribe event handler. If subscribe event handler not set then the connection won't be able to subscribe to channels at all. Subscribe event handler is where a developer may check permissions of the current connection to read channel updates. Here is a basic example of subscribe event handler that simply allows subscriptions to channel example for all authenticated connections and reject subscriptions to all other channels: node . OnConnect ( func ( client * centrifuge . Client ) { client . OnSubscribe ( func ( e centrifuge . SubscribeEvent , cb centrifuge . SubscribeCallback ) { if e . Channel != \"example\" { cb ( centrifuge . SubscribeReply {}, centrifuge . ErrorPermissionDenied ) return } cb ( centrifuge . SubscribeReply {}, nil ) }) }) You may notice a callback style of reacting to connection related things. While not being very idiomatic for Go it's very practical actually. The reason why we use callback style inside client event handlers is that it gives a developer possibility to control operation concurrency (i.e. process sth in separate goroutines or goroutine pool) and still control the order of events. See an example that demonstrates concurrency control in action. Now if some event published to a channel: // Here is how we can publish data to a channel. node . Publish ( \"example\" , [] byte ( `{\"input\": \"hello\"}` )) \u2013 data will be delivered to a subscribed client, and message will be printed to Javascript console. PUB/SUB in its usual form. Note Though Centrifuge protocol based on Protobuf schema in example above we published a JSON message into a channel. By default, we can only send JSON to connections since default protocol format is JSON. But we can switch to Protobuf-based binary protocol by connecting to ws://localhost:8000/connection/websocket?format=protobuf endpoint \u2013 then it's possible to send binary data to clients. Async message passing \u00b6 While Centrifuge mostly shines when you need channel semantics it's also possible to send any data to connection directly \u2013 to achieve bidirectional asynchronous communication, just what a native WebSocket provides. To send a message to a server one can use the send method on the client-side: centrifuge . send ({ \"input\" : \"hello\" }); On the server-side data will be available inside a message handler: client . OnMessage ( func ( e centrifuge . MessageEvent ) { log . Printf ( \"message from client: %s\" , e . Data ) }) And vice-versa, to send data to a client use Send method of centrifuge.Client : client . Send ([] byte ( `{\"input\": \"hello\"}` )) To listen to it on the client-side: centrifuge . on ( 'message' , function ( data ) { console . log ( data ); }); RPC \u00b6 RPC is a primitive for sending a request from a client to a server and waiting for a response (in this case all communication still happens via asynchronous message passing internally, but Centrifuge takes care of matching response data to request previously sent). On client side it's as simple as: const resp = await centrifuge . namedRPC ( 'my_method' , {}); On server side RPC event handler should be set to make calls available: client . OnRPC ( func ( e centrifuge . RPCEvent , cb centrifuge . RPCCallback ) { if e . Method == \"my_method\" { cb ( centrifuge . RPCReply { Data : [] byte ( `{\"result\": \"42\"}` )}, nil ) return } cb ( centrifuge . RPCReply {}, centrifuge . ErrorMethodNotFound ) }) Note, that it's possible to pass the name of RPC and depending on it and custom request params return different results to a client \u2013 just like a regular HTTP request but over asynchronous WebSocket (or SockJS) connection. Server-side subscriptions \u00b6 In many cases, a client is a source of knowledge which channels it wants to subscribe to on a specific application screen. But sometimes you want to control subscriptions to channels on a server-side. This is also possible in Centrifuge. It's possible to provide a slice of channels to subscribe connection to at the moment of connection establishment phase: node . OnConnecting ( func ( ctx context . Context , e centrifuge . ConnectEvent ) ( centrifuge . ConnectReply , error ) { return centrifuge . ConnectReply { Subscriptions : map [ string ] centrifuge . SubscribeOptions { \"example\" : {}, }, }, nil }) Note, that OnConnecting does not follow callback-style \u2013 this is because it can only happen once at the start of each connection \u2013 so there is no need to control operation concurrency. In this case on the client-side you will have access to messages published to channels by listening to on('publish') event: centrifuge . on ( 'publish' , function ( msgCtx ) { console . log ( msgCtx ); }); Also, centrifuge.Client has Subscribe and Unsubscribe methods so it's possible to subscribe/unsubscribe client to/from channel somewhere in the middle of its long WebSocket session. Windowed history in channel \u00b6 Every time a message published to a channel it's possible to provide custom history options. For example: node . Publish ( \"example\" , [] byte ( `{\"input\": \"hello\"}` ), centrifuge . WithHistory ( 300 , time . Minute ), ) In this case, Centrifuge will maintain a windowed Publication cache for a channel - or in other words, maintain a publication stream. This stream will have time retention (one minute in the example above) and the maximum size will be limited to the value provided during Publish (300 in the example above). Every message inside a history stream has an incremental offset field. Also, a stream has a field called epoch \u2013 this is a unique identifier of stream generation - thus client will have a possibility to distinguish situations where a stream is completely removed and there is no guarantee that no messages have been lost in between even if offset looks fine. Client protocol provides a possibility to paginate over a stream from a certain position with a limit: const streamPosition = { 'offset' : 0 , epoch : 'xyz' } resp = await sub . history ({ since : streamPosition , limit : 10 }); Iteration over history stream is a new feature which is just merged into Centrifuge master branch and can only be used from Javascript client at the moment. Also, Centrifuge has an automatic message recovery feature. Automatic recovery is very useful in scenarios when tons of persistent connections start reconnecting at once. I already described why this is useful in one of my previous posts about Websocket scalability. In short \u2013 since WebSocket connections are stateful then at the moment of mass reconnect they can create a very big spike in load on your main application database. Such mass reconnects are a usual thing in practice - for example when you reload your load balancers or re-deploying the Websocket server (new code version). Of course, recovery can also be useful for regular short network disconnects - when a user travels in the subway for example. But you always need a way to load an actual state from the main application database in case of an unsuccessful recovery. To enable automatic recovery you can provide the Recover flag in subscribe options: client . OnSubscribe ( func ( e centrifuge . SubscribeEvent , cb centrifuge . SubscribeCallback ) { cb ( centrifuge . SubscribeReply { Options : centrifuge . SubscribeOptions { Recover : true , }, }, nil ) }) Obviously, recovery will work only for channels where history stream maintained. The limitation in recovery is that all missed publications sent to client in one protocol frame \u2013 pagination is not supported during recovery process. This means that recovery is mostly effective for not too long offline time without tons of missed messages. Presence and presence stats \u00b6 Another cool thing Centrifuge exposes to developers is presence information for channels. Presence information contains a list of active channel subscribers. This is useful to show the online status of players in a game for example. Also, it's possible to turn on Join/Leave message feature inside channels: so each time connection subscribes to a channel all channel subscribers receive a Join message with client information (client ID, user ID). As soon as the client unsubscribes Leave message is sent to remaining channel subscribers with information who left a channel. Here is how to enable both presence and join/leave features for a subscription to channel: client . OnSubscribe ( func ( e centrifuge . SubscribeEvent , cb centrifuge . SubscribeCallback ) { cb ( centrifuge . SubscribeReply { Options : centrifuge . SubscribeOptions { Presence : true , JoinLeave : true , }, }, nil ) }) On a client-side then it's possible to call for the presence and setting event handler for join/leave messages. The important thing to be aware of when using Join/Leave messages is that this feature can dramatically increase CPU utilization and overall traffic in channels with a big number of active subscribers \u2013 since on every client connect/disconnect event such Join or Leave message must be sent to all subscribers. The advice here \u2013 avoid using Join/Leave messages or be ready to scale (Join/Leave messages scale well when adding more Centrifuge Nodes \u2013 more about scalability below). One more thing to remember is that presence information can also be pretty expensive to request in channels with many active subscribers \u2013 since it returns information about all connections \u2013 thus payload in response can be large. To help a bit with this situation Centrifuge has a presence stats client API method. Presence stats only contain two counters: the number of active connections in the channel and amount of unique users in the channel. If you still need to somehow process presence in rooms with a massive number of active subscribers \u2013 then I think you better do it in near real-time - for example with fast OLAP like ClickHouse . Scalability aspects \u00b6 To be fair it's not too hard to implement most of the features above inside one in-memory process. Yes, it takes time, but the code is mostly straightforward. When it comes to scalability things tend to be a bit harder. Centrifuge designed with the idea in mind that one machine is not enough to handle all application WebSocket connections. Connections should scale over application backend instances, and it should be simple to add more application nodes when the amount of users (connections) grows. Centrifuge abstracts scalability over the Node instance and two interfaces: Broker interface and PresenceManager interface. A broker is responsible for PUB/SUB and streaming semantics: type Broker interface { Run ( BrokerEventHandler ) error Subscribe ( ch string ) error Unsubscribe ( ch string ) error Publish ( ch string , data [] byte , opts PublishOptions ) ( StreamPosition , error ) PublishJoin ( ch string , info * ClientInfo ) error PublishLeave ( ch string , info * ClientInfo ) error PublishControl ( data [] byte , nodeID string ) error History ( ch string , filter HistoryFilter ) ([] * Publication , StreamPosition , error ) RemoveHistory ( ch string ) error } See full version with comments in source code. Every Centrifuge Node subscribes to channels via a broker. This provides a possibility to scale connections over many node instances \u2013 published messages will flow only to nodes with active channel subscribers. It's and important thing to combine PUB/SUB with history inside a Broker implementation to achieve an atomicity of saving message into history stream and publishing it to PUB/SUB with generated offset. PresenceManager is responsible for presence information management: type PresenceManager interface { Presence ( ch string ) ( map [ string ] * ClientInfo , error ) PresenceStats ( ch string ) ( PresenceStats , error ) AddPresence ( ch string , clientID string , info * ClientInfo , expire time . Duration ) error RemovePresence ( ch string , clientID string ) error } Full code with comments . Broker and PresenceManager together form an Engine interface: type Engine interface { Broker PresenceManager } By default, Centrifuge uses MemoryEngine that does not use any external services but limits developers to using only one Centrifuge Node (i.e. one server instance). Memory Engine is fast and can be suitable for some scenarios - even in production (with configured backup instance) \u2013 but as soon as the number of connections grows \u2013 you may need to load balance connections to different server instances. Here comes the Redis Engine. Redis Engine utilizes Redis for Broker and PresenceManager parts. History cache saved to Redis STREAM or Redis LIST data structures. For presence, Centrifuge uses a combination of HASH and ZSET structures. Centrifuge tries to fully utilize the connection between Node and Redis by using pipelining where possible and smart batching technique. All operations done in a single RTT with the help of Lua scripts loaded automatically to Redis on engine start. Redis is pretty fast and will allow your app to scale to some limits. When Redis starts being a bottleneck it's possible to shard data over different Redis instances. Client-side consistent sharding is built-in in Centrifuge and allows scaling further. It's also possible to achieve Redis's high availability with built-in Sentinel support. Redis Cluster supported too. So Redis Engine covers many options to communicate with Redis deployed in different ways. At Avito we served about 800k active connections in the messenger app with ease using a slightly adapted Centrifuge Redis Engine, so an approach proved to be working for rather big applications. We will look at some more concrete numbers below in the performance section. Both Broker and PresenceManager are pluggable, so it's possible to replace them with alternative implementations. Examples show how to use Nats server for at most once only PUB/SUB together with Centrifuge. Also, we have an example of full-featured Engine for Tarantool database \u2013 Tarantool Engine shows even better throughput for history and presence operations than Redis-based Engine (up to 10x for some ops). Order and delivery properties \u00b6 Since Centrifuge is a messaging system I also want to describe its order and message delivery guarantees. Message ordering in channels supported. As soon as you publish messages into channels one after another of course. Message delivery model is at most once by default. This is mostly comes from PUB/SUB model \u2013 message can be dropped on Centrifuge level if subscriber is offline or simply on broker level \u2013 since Redis PUB/SUB also works with at most once guarantee. Though if you maintain history stream inside a channel then things become a bit different. In this case you can tell Centrifuge to check client position inside stream. Since every publication has a unique incremental offset Centrifuge can track that client has correct offset inside a channel stream. If Centrifuge detects any missed messages it disconnects a client with special code \u2013 thus make it reconnect and recover messages from history stream. Since a message first saved to history stream and then published to PUB/SUB inside broker these mechanisms allow achieving at least once message delivery guarantee. Even if stream completely expired or dropped from broker memory Centrifuge will give a client a tip that messages could be lost \u2013 so client has a chance to restore state from a main application database. Ecosystem \u00b6 Here I want to be fair with my readers \u2013 Centrifuge is not ideal. This is a project maintained mostly by one person at the moment with all consequences. This hits an ecosystem a lot, can make some design choices opinionated or non-optimal. I mentioned in the first post that Centrifuge built on top of the custom protocol. The protocol is based on a strict Protobuf schema, works with JSON and binary data transfer, supports many features. But \u2013 this means that to connect to the Centrifuge-based server developers have to use custom connectors that can speak with Centrifuge over its custom protocol. The difficulty here is that protocol is asynchronous. Asynchronous protocols are harder to implement than synchronous ones. Multiplexing frames allows achieving good performance and fully utilize a single connection \u2013 but it hurts simplicity. At this moment Centrifuge has client connectors for: centrifuge-js - Javascript client for a browser, NodeJS and React Native centrifuge-go - for Go language centrifuge-mobile - for mobile development based on centrifuge-go and gomobile project centrifuge-swift - for iOS native development centrifuge-java - for Android native development and general Java centrifuge-dart - for Dart and Flutter Not all clients support all protocol features. Another drawback is that all clients do not have a persistent maintainer \u2013 I mostly maintain everything myself. Connectors can have non-idiomatic and pretty dumb code since I had no previous experience with mobile development, they lack proper tests and documentation. This is unfortunate. The good thing is that all connectors feel very similar, I am quickly releasing new versions when someone sends a pull request with improvements or bug fixes. So all connectors are alive. I maintain a feature matrix in connectors to let users understand what's supported. Actually feature support is pretty nice throughout all these connectors - there are only several things missing and not so much work required to make all connectors full-featured. But I really need help here. It will be a big mistake to not mention Centrifugo as a big plus for Centrifuge library ecosystem. Centrifugo is a server deployed in many projects throughout the world. Many features of Centrifuge library and its connectors have already been tested by Centrifugo users. One more thing to mention is that Centrifuge does not have v1 release. It still evolves \u2013 I believe that the most dramatic changes have already been made and backward compatibility issues will be minimal in the next releases \u2013 but can't say for sure. Performance \u00b6 I made a test stand in Kubernetes with one million connections. I can't call this a proper benchmark \u2013 since in a benchmark your main goal is to destroy a system, in my test I just achieved some reasonable numbers on limited hardware. These numbers should give a good insight into a possible throughput, latency, and estimate hardware requirements (at least approximately). Connections landed on different server pods, 5 Redis instances have been used to scale connections between pods. The detailed test stand description can be found in Centrifugo documentation . Some quick conclusions are: One connection costs about 30kb of RAM Redis broker CPU utilization increases linearly with more messages traveling around 1 million connections with 500k delivered messages per second with 200ms delivery latency in 99 percentile can be served with hardware amount equal to one modern physical server machine. The possible amount of messages can vary a lot depending on the number of channel subscribers though. Limitations \u00b6 Centrifuge does not allow subscribing on the same channel twice inside a single connection. It's not simple to add due to design decisions made \u2013 though there was no single user report about this in seven years of Centrifugo/Centrifuge history. Centrifuge does not support wildcard subscriptions. Not only because I never needed this myself but also due to some design choices made \u2013 so be aware of this. SockJS fallback does not support binary data - only JSON. If you want to use binary in your application then you can only use WebSocket with Centrifuge - there is no built-in fallback transport in this case. SockJS also requires sticky session support from your load balancer to emulate a stateful bidirectional connection with its HTTP fallback transports. Ideally, Centrifuge will go away from SockJS at some point, maybe when WebTransport becomes mature so users will have a choice between WebTransport or WebSocket. Websocket permessage-deflate compression supported (thanks to Gorilla WebSocket), but it can be pretty expensive in terms of CPU utilization and memory usage \u2013 the overhead depends on usage pattern, it's pretty hard to estimate in numbers. As said above you cannot only rely on Centrifuge for state recovery \u2013 it's still required to have a way to fully load application state from the main database. Also, I am not very happy with current error and disconnect handling throughout the connector ecosystem \u2013 this can be improved though, and I have some ideas for the future. Examples \u00b6 I am adding examples to _examples folder of Centrifuge repo. These examples completely cover Centrifuge API - including things not mentioned here. Check out the tips & tricks section of README \u2013 it contains some additional insights about an implementation. Conclusion \u00b6 I think Centrifuge could be a nice alternative to socket.io - with a better performance, main server implementation in Go language, and even more builtin features to build real-time apps. Centrifuge ecosystem definitely needs more work, especially in client connectors area, tutorials, community, stabilizing API, etc. Centrifuge fits pretty well proprietary application development where time matters and deadlines are close, so developers tend to choose a ready solution instead of writing their own. I believe Centrifuge can be a great time saver here. For Centrifugo server users Centrifuge package provides a way to write a more flexible server code adapted for business requirements but still use the same real-time core and have the same protocol features.","title":"An introduction to Centrifuge \u2013 real-time messaging with Go"},{"location":"blog/intro_centrifuge/#an-introduction-to-centrifuge-real-time-messaging-with-go","text":"In this post I'll try to introduce Centrifuge - the heart of Centrifugo. Centrifuge is a real-time messaging library for the Go language. This post is going to be pretty long (looks like I am a huge fan of long reads) \u2013 so make sure you also have a drink (probably two) and let's go!","title":"An introduction to Centrifuge \u2013 real-time messaging with Go"},{"location":"blog/intro_centrifuge/#how-its-all-started","text":"I wrote several blog posts before ( for example this one \u2013 yep, it's on Medium...) about an original motivation of Centrifugo server. Danger Centrifugo server is not the same as Centrifuge library for Go. It's a full-featured project built on top of Centrifuge library. Naming can be confusing, but it's not too hard once you spend some time with ecosystem. In short \u2013 Centrifugo was implemented to help traditional web frameworks dealing with many persistent connections (like WebSocket or SockJS HTTP transports). So frameworks like Django or Ruby on Rails, or frameworks from the PHP world could be used on a backend but still provide real-time messaging features like chats, multiplayer browser games, etc for users. With a little help from Centrifugo. Now there are cases when Centrifugo server used in conjunction even with a backend written in Go. While Go mostly has no problems dealing with many concurrent connections \u2013 Centrifugo provides some features beyond simple message passing between a client and a server. That makes it useful, especially since design is pretty non-obtrusive and fits well microservices world. Centrifugo is used in some well-known projects (like ManyChat, Yoola.io, Spot.im, Badoo etc). At the end of 2018, I released Centrifugo v2 based on a real-time messaging library for Go language \u2013 Centrifuge \u2013 the subject of this post. It was a pretty hard experience to decouple Centrifuge out of the monolithic Centrifugo server \u2013 I was unable to make all the things right immediately, so Centrifuge library API went through several iterations where I introduced backward-incompatible changes. All those changes targeted to make Centrifuge a more generic tool and remove opinionated or limiting parts.","title":"How it's all started"},{"location":"blog/intro_centrifuge/#so-what-is-centrifuge","text":"This is ... well, a framework to build real-time messaging applications with Go language. If you ever heard about socket.io \u2013 then you can think about Centrifuge as an analogue. I think the most popular applications these days are chats of different forms, but I want to emphasize that Centrifuge is not a framework to build chats \u2013 it's a generic instrument that can be used to create different sorts of real-time applications \u2013 real-time charts, multiplayer games. The obvious choice for real-time messaging transport to achieve fast and cross-platform bidirectional communication these days is WebSocket. Especially if you are targeting a browser environment. You mostly don't need to use WebSocket HTTP polyfills in 2021 (though there are still corner cases so Centrifuge supports SockJS polyfill). Centrifuge has its own custom protocol on top of plain WebSocket or SockJS frames. The reason why Centrifuge has its own protocol on top of underlying transport is that it provides several useful primitives to build real-time applications. The protocol described as strict Protobuf schema . It's possible to pass JSON or binary Protobuf-encoded data over the wire with Centrifuge. Note GRPC is very handy these days too (and can be used in a browser with a help of additional proxies), some developers prefer using it for real-time messaging apps \u2013 especially when one-way communication needed. It can be a bit better from integration perspective but more resource-consuming on server side and a bit trickier to deploy. Note Take a look at WebTransport \u2013 a brand-new spec for web browsers to allow fast communication between a client and a server on top of QUIC \u2013 it may be a good alternative to WebSocket in the future. This in a draft status at the moment, but it's already possible to play with in Chrome . Own protocol is one of the things that prove the framework status of Centrifuge. This dictates certain limits (for example, you can't just use an alternative message encoding) and makes developers use custom client connectors on a front-end side to communicate with a Centrifuge-based server (see more about connectors in ecosystem part). But protocol solves many practical tasks \u2013 and here we are going to look at real-time features it provides for a developer.","title":"So what is Centrifuge?"},{"location":"blog/intro_centrifuge/#centrifuge-node","text":"To start working with Centrifuge you need to start Centrifuge server Node. Node is a core of Centrifuge \u2013 it has many useful methods \u2013 set event handlers, publish messages to channels, etc. We will look at some events and channels concept very soon. Also, Node abstracts away scalability aspects, so you don't need to think about how to scale WebSocket connections over different server instances and still have a way to deliver published messages to interested clients. For now, let's start a single instance of Node that will serve connections for us: node , err := centrifuge . New ( centrifuge . DefaultConfig ) if err != nil { log . Fatal ( err ) } if err := node . Run (); err != nil { log . Fatal ( err ) } It's also required to serve a WebSocket handler \u2013 this is possible just by registering centrifuge.WebsocketHandler in HTTP mux: wsHandler := centrifuge . NewWebsocketHandler ( node , centrifuge . WebsocketConfig {}) http . Handle ( \"/connection/websocket\" , wsHandler ) Now it's possible to connect to a server (using Centrifuge connector for a browser called centrifuge-js ): const centrifuge = new Centrifuge ( 'ws://localhost:8000/connection/websocket' ); centrifuge . connect (); Though connection will be rejected by the server since we also need to provide authentication details \u2013 Centrifuge expects explicitly provided connection Credentials to accept connection.","title":"Centrifuge Node"},{"location":"blog/intro_centrifuge/#authentication","text":"Let's look at how we can tell Centrifuge details about connected user identity, so it could accept an incoming connection. There are two main ways to authenticate client connection in Centrifuge. The first one is over the native middleware mechanism. It's possible to wrap centrifuge.WebsocketHandler or centrifuge.SockjsHandler with middleware that checks user authentication and tells Centrifuge current user ID over context.Context : func auth ( h http . Handler ) http . Handler { return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { cred := & centrifuge . Credentials { UserID : \"42\" , } newCtx := centrifuge . SetCredentials ( r . Context (), cred ) r = r . WithContext ( newCtx ) h . ServeHTTP ( w , r ) }) } So WebsocketHandler can be registered this way (note that a handler now wrapped by auth middleware): wsHandler := centrifuge . NewWebsocketHandler ( node , centrifuge . WebsocketConfig {}) http . Handle ( \"/connection/websocket\" , auth ( wsHandler )) Another authentication way is a bit more generic \u2013 developers can authenticate connection based on custom token sent from a client inside first WebSocket/SockJS frame. This is called connect frame in terms of Centrifuge protocol. Any string token can be set \u2013 this opens a way to use JWT, Paceto, and any other kind of authentication tokens. For example see an authenticaton with JWT . Note BTW it's also possible to pass any information from client side with a first connect message from client to server and return custom information about server state to a client. This is out of post scope though. Nothing prevents you to integrate Centrifuge with OAuth2 or another framework session mechanism \u2013 like Gin for example .","title":"Authentication"},{"location":"blog/intro_centrifuge/#channel-subscriptions","text":"As soon as a client connected and successfully authenticated it can subscribe to channels. Channel (room or topic in other systems) is a lightweight and ephemeral entity in Centrifuge. Channel can have different features (we will look at some channel features below). Channels created automatically as soon as the first subscriber joins and destroyed as soon as the last subscriber left. The application can have many real-time features \u2013 even on one app screen. So sometimes client subscribes to several channels \u2013 each related to a specific real-time feature (for example one channel for chat updates, one channel likes notification stream, etc). Channel is just an ASCII string. A developer is responsible to find the best channel naming convention suitable for an application. Channel naming convention is an important aspect since in many cases developers want to authorize subscription to a channel on the server side \u2013 so only authorized users could listen to specific channel updates. Let's look at a basic subscription example on the client-side: centrifuge . subscribe ( 'example' , function ( msgCtx ) { console . log ( msgCtx ) }) On the server-side, you need to define subscribe event handler. If subscribe event handler not set then the connection won't be able to subscribe to channels at all. Subscribe event handler is where a developer may check permissions of the current connection to read channel updates. Here is a basic example of subscribe event handler that simply allows subscriptions to channel example for all authenticated connections and reject subscriptions to all other channels: node . OnConnect ( func ( client * centrifuge . Client ) { client . OnSubscribe ( func ( e centrifuge . SubscribeEvent , cb centrifuge . SubscribeCallback ) { if e . Channel != \"example\" { cb ( centrifuge . SubscribeReply {}, centrifuge . ErrorPermissionDenied ) return } cb ( centrifuge . SubscribeReply {}, nil ) }) }) You may notice a callback style of reacting to connection related things. While not being very idiomatic for Go it's very practical actually. The reason why we use callback style inside client event handlers is that it gives a developer possibility to control operation concurrency (i.e. process sth in separate goroutines or goroutine pool) and still control the order of events. See an example that demonstrates concurrency control in action. Now if some event published to a channel: // Here is how we can publish data to a channel. node . Publish ( \"example\" , [] byte ( `{\"input\": \"hello\"}` )) \u2013 data will be delivered to a subscribed client, and message will be printed to Javascript console. PUB/SUB in its usual form. Note Though Centrifuge protocol based on Protobuf schema in example above we published a JSON message into a channel. By default, we can only send JSON to connections since default protocol format is JSON. But we can switch to Protobuf-based binary protocol by connecting to ws://localhost:8000/connection/websocket?format=protobuf endpoint \u2013 then it's possible to send binary data to clients.","title":"Channel subscriptions"},{"location":"blog/intro_centrifuge/#async-message-passing","text":"While Centrifuge mostly shines when you need channel semantics it's also possible to send any data to connection directly \u2013 to achieve bidirectional asynchronous communication, just what a native WebSocket provides. To send a message to a server one can use the send method on the client-side: centrifuge . send ({ \"input\" : \"hello\" }); On the server-side data will be available inside a message handler: client . OnMessage ( func ( e centrifuge . MessageEvent ) { log . Printf ( \"message from client: %s\" , e . Data ) }) And vice-versa, to send data to a client use Send method of centrifuge.Client : client . Send ([] byte ( `{\"input\": \"hello\"}` )) To listen to it on the client-side: centrifuge . on ( 'message' , function ( data ) { console . log ( data ); });","title":"Async message passing"},{"location":"blog/intro_centrifuge/#rpc","text":"RPC is a primitive for sending a request from a client to a server and waiting for a response (in this case all communication still happens via asynchronous message passing internally, but Centrifuge takes care of matching response data to request previously sent). On client side it's as simple as: const resp = await centrifuge . namedRPC ( 'my_method' , {}); On server side RPC event handler should be set to make calls available: client . OnRPC ( func ( e centrifuge . RPCEvent , cb centrifuge . RPCCallback ) { if e . Method == \"my_method\" { cb ( centrifuge . RPCReply { Data : [] byte ( `{\"result\": \"42\"}` )}, nil ) return } cb ( centrifuge . RPCReply {}, centrifuge . ErrorMethodNotFound ) }) Note, that it's possible to pass the name of RPC and depending on it and custom request params return different results to a client \u2013 just like a regular HTTP request but over asynchronous WebSocket (or SockJS) connection.","title":"RPC"},{"location":"blog/intro_centrifuge/#server-side-subscriptions","text":"In many cases, a client is a source of knowledge which channels it wants to subscribe to on a specific application screen. But sometimes you want to control subscriptions to channels on a server-side. This is also possible in Centrifuge. It's possible to provide a slice of channels to subscribe connection to at the moment of connection establishment phase: node . OnConnecting ( func ( ctx context . Context , e centrifuge . ConnectEvent ) ( centrifuge . ConnectReply , error ) { return centrifuge . ConnectReply { Subscriptions : map [ string ] centrifuge . SubscribeOptions { \"example\" : {}, }, }, nil }) Note, that OnConnecting does not follow callback-style \u2013 this is because it can only happen once at the start of each connection \u2013 so there is no need to control operation concurrency. In this case on the client-side you will have access to messages published to channels by listening to on('publish') event: centrifuge . on ( 'publish' , function ( msgCtx ) { console . log ( msgCtx ); }); Also, centrifuge.Client has Subscribe and Unsubscribe methods so it's possible to subscribe/unsubscribe client to/from channel somewhere in the middle of its long WebSocket session.","title":"Server-side subscriptions"},{"location":"blog/intro_centrifuge/#windowed-history-in-channel","text":"Every time a message published to a channel it's possible to provide custom history options. For example: node . Publish ( \"example\" , [] byte ( `{\"input\": \"hello\"}` ), centrifuge . WithHistory ( 300 , time . Minute ), ) In this case, Centrifuge will maintain a windowed Publication cache for a channel - or in other words, maintain a publication stream. This stream will have time retention (one minute in the example above) and the maximum size will be limited to the value provided during Publish (300 in the example above). Every message inside a history stream has an incremental offset field. Also, a stream has a field called epoch \u2013 this is a unique identifier of stream generation - thus client will have a possibility to distinguish situations where a stream is completely removed and there is no guarantee that no messages have been lost in between even if offset looks fine. Client protocol provides a possibility to paginate over a stream from a certain position with a limit: const streamPosition = { 'offset' : 0 , epoch : 'xyz' } resp = await sub . history ({ since : streamPosition , limit : 10 }); Iteration over history stream is a new feature which is just merged into Centrifuge master branch and can only be used from Javascript client at the moment. Also, Centrifuge has an automatic message recovery feature. Automatic recovery is very useful in scenarios when tons of persistent connections start reconnecting at once. I already described why this is useful in one of my previous posts about Websocket scalability. In short \u2013 since WebSocket connections are stateful then at the moment of mass reconnect they can create a very big spike in load on your main application database. Such mass reconnects are a usual thing in practice - for example when you reload your load balancers or re-deploying the Websocket server (new code version). Of course, recovery can also be useful for regular short network disconnects - when a user travels in the subway for example. But you always need a way to load an actual state from the main application database in case of an unsuccessful recovery. To enable automatic recovery you can provide the Recover flag in subscribe options: client . OnSubscribe ( func ( e centrifuge . SubscribeEvent , cb centrifuge . SubscribeCallback ) { cb ( centrifuge . SubscribeReply { Options : centrifuge . SubscribeOptions { Recover : true , }, }, nil ) }) Obviously, recovery will work only for channels where history stream maintained. The limitation in recovery is that all missed publications sent to client in one protocol frame \u2013 pagination is not supported during recovery process. This means that recovery is mostly effective for not too long offline time without tons of missed messages.","title":"Windowed history in channel"},{"location":"blog/intro_centrifuge/#presence-and-presence-stats","text":"Another cool thing Centrifuge exposes to developers is presence information for channels. Presence information contains a list of active channel subscribers. This is useful to show the online status of players in a game for example. Also, it's possible to turn on Join/Leave message feature inside channels: so each time connection subscribes to a channel all channel subscribers receive a Join message with client information (client ID, user ID). As soon as the client unsubscribes Leave message is sent to remaining channel subscribers with information who left a channel. Here is how to enable both presence and join/leave features for a subscription to channel: client . OnSubscribe ( func ( e centrifuge . SubscribeEvent , cb centrifuge . SubscribeCallback ) { cb ( centrifuge . SubscribeReply { Options : centrifuge . SubscribeOptions { Presence : true , JoinLeave : true , }, }, nil ) }) On a client-side then it's possible to call for the presence and setting event handler for join/leave messages. The important thing to be aware of when using Join/Leave messages is that this feature can dramatically increase CPU utilization and overall traffic in channels with a big number of active subscribers \u2013 since on every client connect/disconnect event such Join or Leave message must be sent to all subscribers. The advice here \u2013 avoid using Join/Leave messages or be ready to scale (Join/Leave messages scale well when adding more Centrifuge Nodes \u2013 more about scalability below). One more thing to remember is that presence information can also be pretty expensive to request in channels with many active subscribers \u2013 since it returns information about all connections \u2013 thus payload in response can be large. To help a bit with this situation Centrifuge has a presence stats client API method. Presence stats only contain two counters: the number of active connections in the channel and amount of unique users in the channel. If you still need to somehow process presence in rooms with a massive number of active subscribers \u2013 then I think you better do it in near real-time - for example with fast OLAP like ClickHouse .","title":"Presence and presence stats"},{"location":"blog/intro_centrifuge/#scalability-aspects","text":"To be fair it's not too hard to implement most of the features above inside one in-memory process. Yes, it takes time, but the code is mostly straightforward. When it comes to scalability things tend to be a bit harder. Centrifuge designed with the idea in mind that one machine is not enough to handle all application WebSocket connections. Connections should scale over application backend instances, and it should be simple to add more application nodes when the amount of users (connections) grows. Centrifuge abstracts scalability over the Node instance and two interfaces: Broker interface and PresenceManager interface. A broker is responsible for PUB/SUB and streaming semantics: type Broker interface { Run ( BrokerEventHandler ) error Subscribe ( ch string ) error Unsubscribe ( ch string ) error Publish ( ch string , data [] byte , opts PublishOptions ) ( StreamPosition , error ) PublishJoin ( ch string , info * ClientInfo ) error PublishLeave ( ch string , info * ClientInfo ) error PublishControl ( data [] byte , nodeID string ) error History ( ch string , filter HistoryFilter ) ([] * Publication , StreamPosition , error ) RemoveHistory ( ch string ) error } See full version with comments in source code. Every Centrifuge Node subscribes to channels via a broker. This provides a possibility to scale connections over many node instances \u2013 published messages will flow only to nodes with active channel subscribers. It's and important thing to combine PUB/SUB with history inside a Broker implementation to achieve an atomicity of saving message into history stream and publishing it to PUB/SUB with generated offset. PresenceManager is responsible for presence information management: type PresenceManager interface { Presence ( ch string ) ( map [ string ] * ClientInfo , error ) PresenceStats ( ch string ) ( PresenceStats , error ) AddPresence ( ch string , clientID string , info * ClientInfo , expire time . Duration ) error RemovePresence ( ch string , clientID string ) error } Full code with comments . Broker and PresenceManager together form an Engine interface: type Engine interface { Broker PresenceManager } By default, Centrifuge uses MemoryEngine that does not use any external services but limits developers to using only one Centrifuge Node (i.e. one server instance). Memory Engine is fast and can be suitable for some scenarios - even in production (with configured backup instance) \u2013 but as soon as the number of connections grows \u2013 you may need to load balance connections to different server instances. Here comes the Redis Engine. Redis Engine utilizes Redis for Broker and PresenceManager parts. History cache saved to Redis STREAM or Redis LIST data structures. For presence, Centrifuge uses a combination of HASH and ZSET structures. Centrifuge tries to fully utilize the connection between Node and Redis by using pipelining where possible and smart batching technique. All operations done in a single RTT with the help of Lua scripts loaded automatically to Redis on engine start. Redis is pretty fast and will allow your app to scale to some limits. When Redis starts being a bottleneck it's possible to shard data over different Redis instances. Client-side consistent sharding is built-in in Centrifuge and allows scaling further. It's also possible to achieve Redis's high availability with built-in Sentinel support. Redis Cluster supported too. So Redis Engine covers many options to communicate with Redis deployed in different ways. At Avito we served about 800k active connections in the messenger app with ease using a slightly adapted Centrifuge Redis Engine, so an approach proved to be working for rather big applications. We will look at some more concrete numbers below in the performance section. Both Broker and PresenceManager are pluggable, so it's possible to replace them with alternative implementations. Examples show how to use Nats server for at most once only PUB/SUB together with Centrifuge. Also, we have an example of full-featured Engine for Tarantool database \u2013 Tarantool Engine shows even better throughput for history and presence operations than Redis-based Engine (up to 10x for some ops).","title":"Scalability aspects"},{"location":"blog/intro_centrifuge/#order-and-delivery-properties","text":"Since Centrifuge is a messaging system I also want to describe its order and message delivery guarantees. Message ordering in channels supported. As soon as you publish messages into channels one after another of course. Message delivery model is at most once by default. This is mostly comes from PUB/SUB model \u2013 message can be dropped on Centrifuge level if subscriber is offline or simply on broker level \u2013 since Redis PUB/SUB also works with at most once guarantee. Though if you maintain history stream inside a channel then things become a bit different. In this case you can tell Centrifuge to check client position inside stream. Since every publication has a unique incremental offset Centrifuge can track that client has correct offset inside a channel stream. If Centrifuge detects any missed messages it disconnects a client with special code \u2013 thus make it reconnect and recover messages from history stream. Since a message first saved to history stream and then published to PUB/SUB inside broker these mechanisms allow achieving at least once message delivery guarantee. Even if stream completely expired or dropped from broker memory Centrifuge will give a client a tip that messages could be lost \u2013 so client has a chance to restore state from a main application database.","title":"Order and delivery properties"},{"location":"blog/intro_centrifuge/#ecosystem","text":"Here I want to be fair with my readers \u2013 Centrifuge is not ideal. This is a project maintained mostly by one person at the moment with all consequences. This hits an ecosystem a lot, can make some design choices opinionated or non-optimal. I mentioned in the first post that Centrifuge built on top of the custom protocol. The protocol is based on a strict Protobuf schema, works with JSON and binary data transfer, supports many features. But \u2013 this means that to connect to the Centrifuge-based server developers have to use custom connectors that can speak with Centrifuge over its custom protocol. The difficulty here is that protocol is asynchronous. Asynchronous protocols are harder to implement than synchronous ones. Multiplexing frames allows achieving good performance and fully utilize a single connection \u2013 but it hurts simplicity. At this moment Centrifuge has client connectors for: centrifuge-js - Javascript client for a browser, NodeJS and React Native centrifuge-go - for Go language centrifuge-mobile - for mobile development based on centrifuge-go and gomobile project centrifuge-swift - for iOS native development centrifuge-java - for Android native development and general Java centrifuge-dart - for Dart and Flutter Not all clients support all protocol features. Another drawback is that all clients do not have a persistent maintainer \u2013 I mostly maintain everything myself. Connectors can have non-idiomatic and pretty dumb code since I had no previous experience with mobile development, they lack proper tests and documentation. This is unfortunate. The good thing is that all connectors feel very similar, I am quickly releasing new versions when someone sends a pull request with improvements or bug fixes. So all connectors are alive. I maintain a feature matrix in connectors to let users understand what's supported. Actually feature support is pretty nice throughout all these connectors - there are only several things missing and not so much work required to make all connectors full-featured. But I really need help here. It will be a big mistake to not mention Centrifugo as a big plus for Centrifuge library ecosystem. Centrifugo is a server deployed in many projects throughout the world. Many features of Centrifuge library and its connectors have already been tested by Centrifugo users. One more thing to mention is that Centrifuge does not have v1 release. It still evolves \u2013 I believe that the most dramatic changes have already been made and backward compatibility issues will be minimal in the next releases \u2013 but can't say for sure.","title":"Ecosystem"},{"location":"blog/intro_centrifuge/#performance","text":"I made a test stand in Kubernetes with one million connections. I can't call this a proper benchmark \u2013 since in a benchmark your main goal is to destroy a system, in my test I just achieved some reasonable numbers on limited hardware. These numbers should give a good insight into a possible throughput, latency, and estimate hardware requirements (at least approximately). Connections landed on different server pods, 5 Redis instances have been used to scale connections between pods. The detailed test stand description can be found in Centrifugo documentation . Some quick conclusions are: One connection costs about 30kb of RAM Redis broker CPU utilization increases linearly with more messages traveling around 1 million connections with 500k delivered messages per second with 200ms delivery latency in 99 percentile can be served with hardware amount equal to one modern physical server machine. The possible amount of messages can vary a lot depending on the number of channel subscribers though.","title":"Performance"},{"location":"blog/intro_centrifuge/#limitations","text":"Centrifuge does not allow subscribing on the same channel twice inside a single connection. It's not simple to add due to design decisions made \u2013 though there was no single user report about this in seven years of Centrifugo/Centrifuge history. Centrifuge does not support wildcard subscriptions. Not only because I never needed this myself but also due to some design choices made \u2013 so be aware of this. SockJS fallback does not support binary data - only JSON. If you want to use binary in your application then you can only use WebSocket with Centrifuge - there is no built-in fallback transport in this case. SockJS also requires sticky session support from your load balancer to emulate a stateful bidirectional connection with its HTTP fallback transports. Ideally, Centrifuge will go away from SockJS at some point, maybe when WebTransport becomes mature so users will have a choice between WebTransport or WebSocket. Websocket permessage-deflate compression supported (thanks to Gorilla WebSocket), but it can be pretty expensive in terms of CPU utilization and memory usage \u2013 the overhead depends on usage pattern, it's pretty hard to estimate in numbers. As said above you cannot only rely on Centrifuge for state recovery \u2013 it's still required to have a way to fully load application state from the main database. Also, I am not very happy with current error and disconnect handling throughout the connector ecosystem \u2013 this can be improved though, and I have some ideas for the future.","title":"Limitations"},{"location":"blog/intro_centrifuge/#examples","text":"I am adding examples to _examples folder of Centrifuge repo. These examples completely cover Centrifuge API - including things not mentioned here. Check out the tips & tricks section of README \u2013 it contains some additional insights about an implementation.","title":"Examples"},{"location":"blog/intro_centrifuge/#conclusion","text":"I think Centrifuge could be a nice alternative to socket.io - with a better performance, main server implementation in Go language, and even more builtin features to build real-time apps. Centrifuge ecosystem definitely needs more work, especially in client connectors area, tutorials, community, stabilizing API, etc. Centrifuge fits pretty well proprietary application development where time matters and deadlines are close, so developers tend to choose a ready solution instead of writing their own. I believe Centrifuge can be a great time saver here. For Centrifugo server users Centrifuge package provides a way to write a more flexible server code adapted for business requirements but still use the same real-time core and have the same protocol features.","title":"Conclusion"},{"location":"blog/quic_web_transport/","text":"Experimenting with QUIC and WebTransport in Go \u00b6 Overview \u00b6 UPDATE : WebTransport spec is still evolving. Some information here is out-of-date. For example the working group has no plan to implement both QuicTransport and HTTP3-based transports \u2013 only HTTP3 based WebTransport is going to be implemented. Maybe we will publish a follow-up of this post at some point. WebTransport is a new browser API offering low-latency, bidirectional, client-server messaging. If you have not heard about it before I suggest to first read a post called Experimenting with QuicTransport published recently on web.dev \u2013 it gives a nice overview to WebTransport and shows client-side code examples. Here we will concentrate on implementing server side. Some key points about WebTransport spec: WebTransport standard will provide a possibility to use streaming client-server communication using modern transports such as QUIC and HTTP/3 It can be a good alternative to WebSocket messaging, standard provides some capabilities that are not possible with current WebSocket spec: possibility to get rid of head-of-line blocking problems using individual streams for different data, the possibility to reuse a single connection to a server in different browser tabs WebTransport also defines an unreliable stream API using UDP datagrams (which is possible since QUIC is UDP-based) \u2013 which is what browsers did not have before without a rather complex WebRTC setup involving ICE, STUN, etc. This is sweet for in-browser real-time games. To help you figure out things here are links to current WebTransport specs: WebTransport overview \u2013 this spec gives an overview of WebTransport and provides requirements to transport layer WebTransport over QUIC \u2013 this spec describes QUIC-based transport for WebTransport WebTransport over HTTP/3 \u2013 this spec describes HTTP/3-based transport for WebTransport (actually HTTP/3 is a protocol defined on top of QUIC) At moment Chrome only implements trial possibility to try out WebTransport standard and only implements WebTransport over QUIC. Developers can initialize transport with code like this: const transport = new QuicTransport ( 'quic-transport://localhost:4433/path' ); In case of HTTP/3 transport one will use URL like 'https://localhost:4433/path' in transport constructor. All WebTransport underlying transports should support instantiation over URL \u2013 that's one of the spec requirements. I decided that this is a cool possibility to finally play with QUIC protocol and its Go implementation github.com/lucas-clemente/quic-go . Danger Please keep in mind that all things described in this post are work in progress. WebTransport drafts, Quic-Go library, even QUIC protocol itself are subjects to change. You should not use it in production yet. Experimenting with QuicTransport post contains links to a client example and companion Python server implementation . We will use a linked client example to connect to a server that runs on localhost and uses github.com/lucas-clemente/quic-go library. To make our example work we need to open client example in Chrome, and actually, at this moment we need to install Chrome Canary. The reason behind this is that the quic-go library supports QUIC draft-29 while Chrome < 85 implements QuicTransport over draft-27. If you read this post at a time when Chrome stable 85 already released then most probably you don't need to install Canary release and just use your stable Chrome. We also need to generate self-signed certificates since WebTransport only works with a TLS layer, and we should make Chrome trust our certificates. Let's prepare our client environment before writing a server and first install Chrome Canary. Install Chrome Canary \u00b6 Go to https://www.google.com/intl/en/chrome/canary/ , download and install Chrome Canary. We will use it to open client example . Note If you have Chrome >= 85 then most probably you can skip this step. Generate self-signed TLS certificates \u00b6 Since WebTransport based on modern network transports like QUIC and HTTP/3 security is a keystone. For our experiment we will create a self-signed TLS certificate using openssl . Make sure you have openssl installed: $ which openssl /usr/bin/openssl Then run: openssl genrsa -des3 -passout pass:x -out server.pass.key 2048 openssl rsa -passin pass:x -in server.pass.key -out server.key rm server.pass.key openssl req -new -key server.key -out server.csr Set localhost for Common Name when asked. The self-signed TLS certificate generated from the server.key private key and server.csr files: openssl x509 -req -sha256 -days 365 -in server.csr -signkey server.key -out server.crt After these manipulations you should have server.crt and server.key files in your working directory. To help you with process here is my console output during these steps (click to open): My console output generating self-signed certificates $ openssl genrsa -des3 -passout pass:x -out server.pass.key 2048 Generating RSA private key, 2048 bit long modulus ...........................................................................................+++ .....................+++ e is 65537 ( 0x10001 ) $ ls server.pass.key $ openssl rsa -passin pass:x -in server.pass.key -out server.key writing RSA key $ ls server.key server.pass.key $ rm server.pass.key $ openssl req -new -key server.key -out server.csr You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.' , the field will be left blank. ----- Country Name ( 2 letter code ) [] :RU State or Province Name ( full name ) [] : Locality Name ( eg, city ) [] : Organization Name ( eg, company ) [] : Organizational Unit Name ( eg, section ) [] : Common Name ( eg, fully qualified host name ) [] :localhost Email Address [] : Please enter the following 'extra' attributes to be sent with your certificate request A challenge password [] : $ openssl x509 -req -sha256 -days 365 -in server.csr -signkey server.key -out server.crt Signature ok subject = /C = RU/CN = localhost Getting Private key $ ls server.crt server.csr server.key Run client example \u00b6 Now the last step. What we need to do is run Chrome Canary with some flags that will allow it to trust our self-signed certificates. I suppose there is an alternative way making Chrome trust your certificates, but I have not tried it. First let's find out a fingerprint of our cert: openssl x509 -in server.crt -pubkey -noout | openssl pkey -pubin -outform der | openssl dgst -sha256 -binary | openssl enc -base64 In my case base64 fingerprint was pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M= , yours will be different. Then run Chrome Canary with some additional flags that will make it trust out certs (close other Chrome Canary instances before running it): $ /Applications/Google \\ Chrome \\ Canary.app/Contents/MacOS/Google \\ Chrome \\ Canary \\ --origin-to-force-quic-on = localhost:4433 \\ --ignore-certificate-errors-spki-list = pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M = This example is for MacOS, for your system see docs on how to run Chrome/Chromium with custom flags . Now you can open https://googlechrome.github.io/samples/quictransport/client.html URL in started browser and click Connect button. What? Connection not established? OK, this is fine since we need to run our server :) Writing a QUIC server \u00b6 Maybe in future we will have libraries that are specified to work with WebTransport over QUIC or HTTP/3, but for now we should implement server manually. As said above we will use github.com/lucas-clemente/quic-go library to do this. Server skeleton \u00b6 First, let's define a simple skeleton for our server: package main import ( \"errors\" \"log\" \"github.com/lucas-clemente/quic-go\" ) // Config for WebTransportServerQuic. type Config struct { // ListenAddr sets an address to bind server to. ListenAddr string // TLSCertPath defines a path to .crt cert file. TLSCertPath string // TLSKeyPath defines a path to .key cert file TLSKeyPath string // AllowedOrigins represents list of allowed origins to connect from. AllowedOrigins [] string } // WebTransportServerQuic can handle WebTransport QUIC connections according // to https://tools.ietf.org/html/draft-vvv-webtransport-quic-02. type WebTransportServerQuic struct { config Config } // NewWebTransportServerQuic creates new WebTransportServerQuic. func NewWebTransportServerQuic ( config Config ) * WebTransportServerQuic { return & WebTransportServerQuic { config : config , } } // Run server. func ( s * WebTransportServerQuic ) Run () error { return errors . New ( \"not implemented\" ) } func main () { server := NewWebTransportServerQuic ( Config { ListenAddr : \"0.0.0.0:4433\" , TLSCertPath : \"server.crt\" , TLSKeyPath : \"server.key\" , AllowedOrigins : [] string { \"localhost\" , \"googlechrome.github.io\" }, }) if err := server . Run (); err != nil { log . Fatal ( err ) } } Accept QUIC connections \u00b6 Let's concentrate on implementing Run method. We need to accept QUIC client connections. This can be done by creating quic.Listener instance and using its .Accept method to accept incoming client sessions. // Run server. func ( s * WebTransportServerQuic ) Run () error { listener , err := quic . ListenAddr ( s . config . ListenAddr , s . generateTLSConfig (), nil ) if err != nil { return err } for { sess , err := listener . Accept ( context . Background ()) if err != nil { return err } log . Printf ( \"session accepted: %s\" , sess . RemoteAddr (). String ()) go func () { defer func () { _ = sess . CloseWithError ( 0 , \"bye\" ) log . Println ( \"close session\" ) }() s . handleSession ( sess ) }() } } func ( s * WebTransportServerQuic ) handleSession ( sess quic . Session ) { // Not implemented yet. } An interesting thing to note is that QUIC allows closing connection with specific application-level integer code and custom string reason. Just like WebSocket if you worked with it. Also note, that we are starting our Listener with TLS configuration returned by s.generateTLSConfig() method. Let's take a closer look at how this method can be implemented. // https://tools.ietf.org/html/draft-vvv-webtransport-quic-02#section-3.1 const alpnQuicTransport = \"wq-vvv-01\" func ( s * WebTransportServerQuic ) generateTLSConfig () * tls . Config { cert , err := tls . LoadX509KeyPair ( s . config . TLSCertPath , s . config . TLSKeyPath ) if err != nil { log . Fatal ( err ) } return & tls . Config { Certificates : [] tls . Certificate { cert }, NextProtos : [] string { alpnQuicTransport }, } } Inside generateTLSConfig we load x509 certs from cert files generated above. WebTransport uses ALPN ( Application-Layer Protocol Negotiation to prevent handshakes with a server that does not support WebTransport spec. This is just a string wq-vvv-01 inside NextProtos slice of our *tls.Config . Connection Session handling \u00b6 At this moment if you run a server and open a client example in Chrome then click Connect button \u2013 you should see that connection successfully established in event log area: Now if you try to send data to a server nothing will happen. That's because we have not implemented reading data from session streams. Streams in QUIC provide a lightweight, ordered byte-stream abstraction to an application. Streams can be unidirectional or bidirectional. Streams can be short-lived, streams can also be long-lived and can last the entire duration of a connection. Client example provides three possible ways to communicate with a server: Send a datagram Open a unidirectional stream Open a bidirectional stream Unfortunately, quic-go library does not support sending UDP datagrams at this moment. To do this quic-go should implement one more draft called An Unreliable Datagram Extension to QUIC . There is already an ongoing pull request that implements it. This means that it's too early for us to experiment with unreliable UDP WebTransport client-server communication in Go. By the way, the interesting facts about UDP over QUIC are that QUIC congestion control mechanism will still apply and QUIC datagrams can support acknowledgements . Implementing a unidirectional stream is possible with quic-go since the library supports creating and accepting unidirectional streams, but I'll leave this for a reader (though we will need accepting one unidirectional stream for parsing client indication anyway \u2013 see below). Here we will only concentrate on implementing a server for a bidirectional case. We are in the Centrifugo blog, and this is the most interesting type of stream for me personally. Parsing client indication \u00b6 According to section-3.2 of Quic WebTransport spec in order to verify that the client's origin allowed connecting to the server, the user agent has to communicate the origin to the server. This is accomplished by sending a special message, called client indication, on stream 2, which is the first client-initiated unidirectional stream. Here we will implement this. In the beginning of our session handler we will accept a unidirectional stream initiated by a client. At moment spec defines two client indication keys: Origin and Path . In our case an origin value will be https://googlechrome.github.io and path will be /counter . Let's define some constants and structures: // client indication stream can not exceed 65535 bytes in length. // https://tools.ietf.org/html/draft-vvv-webtransport-quic-02#section-3.2 const maxClientIndicationLength = 65535 // define known client indication keys. type clientIndicationKey int16 const ( clientIndicationKeyOrigin clientIndicationKey = 0 clientIndicationKeyPath = 1 ) // ClientIndication container. type ClientIndication struct { // Origin client indication value. Origin string // Path client indication value. Path string } Now what we should do is accept unidirectional stream inside session handler: func ( s * WebTransportServerQuic ) handleSession ( sess quic . Session ) { stream , err := sess . AcceptUniStream ( context . Background ()) if err != nil { log . Println ( err ) return } log . Printf ( \"uni stream accepted, id: %d\" , stream . StreamID ()) indication , err := receiveClientIndication ( stream ) if err != nil { log . Println ( err ) return } log . Printf ( \"client indication: %+v\" , indication ) if err := s . validateClientIndication ( indication ); err != nil { log . Println ( err ) return } // this method blocks. if err := s . communicate ( sess ); err != nil { log . Println ( err ) } } func receiveClientIndication ( stream quic . ReceiveStream ) ( ClientIndication , error ) { return ClientIndication {}, errors . New ( \"not implemented yet\" ) } func ( s * WebTransportServerQuic ) validateClientIndication ( indication ClientIndication ) error { return errors . New ( \"not implemented yet\" ) } func ( s * WebTransportServerQuic ) communicate ( sess quic . Session ) error { return errors . New ( \"not implemented yet\" ) } As you can see to accept a unidirectional stream with data we can use .AcceptUniStream method of quic.Session . After accepting a stream we should read client indication data from it. According to spec it will contain a client indication in the following format: 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Key (16) | Length (16) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (*) ... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The code below parses client indication out of a stream data, we decode key-value pairs from uni stream until an end of stream (indicated by EOF): func receiveClientIndication ( stream quic . ReceiveStream ) ( ClientIndication , error ) { var clientIndication ClientIndication // read no more than maxClientIndicationLength bytes. reader := io . LimitReader ( stream , maxClientIndicationLength ) done := false for { if done { break } var key int16 err := binary . Read ( reader , binary . BigEndian , & key ) if err != nil { if err == io . EOF { done = true } else { return clientIndication , err } } var valueLength int16 err = binary . Read ( reader , binary . BigEndian , & valueLength ) if err != nil { return clientIndication , err } buf := make ([] byte , valueLength ) n , err := reader . Read ( buf ) if err != nil { if err == io . EOF { // still need to process indication value. done = true } else { return clientIndication , err } } if int16 ( n ) != valueLength { return clientIndication , errors . New ( \"read less than expected\" ) } value := string ( buf ) switch clientIndicationKey ( key ) { case clientIndicationKeyOrigin : clientIndication . Origin = value case clientIndicationKeyPath : clientIndication . Path = value default : log . Printf ( \"skip unknown client indication key: %d: %s\" , key , value ) } } return clientIndication , nil } We also validate Origin inside validateClientIndication method of our server: var errBadOrigin = errors . New ( \"bad origin\" ) func ( s * WebTransportServerQuic ) validateClientIndication ( indication ClientIndication ) error { u , err := url . Parse ( indication . Origin ) if err != nil { return errBadOrigin } if ! stringInSlice ( u . Host , s . config . AllowedOrigins ) { return errBadOrigin } return nil } func stringInSlice ( a string , list [] string ) bool { for _ , b := range list { if b == a { return true } } return false } Do you have stringInSlice function in every Go project? I do :) Communicating over bidirectional streams \u00b6 The final part here is accepting a bidirectional stream from a client, reading it, and sending responses back. Here we will just echo everything a client sends to a server back to a client. You can implement whatever bidirectional communication you want actually. Very similar to unidirectional case we can call .AcceptStream method of session to accept a bidirectional stream. func ( s * WebTransportServerQuic ) communicate ( sess quic . Session ) error { for { stream , err := sess . AcceptStream ( context . Background ()) if err != nil { return err } log . Printf ( \"stream accepted: %d\" , stream . StreamID ()) if _ , err := io . Copy ( stream , stream ); err != nil { return err } } } When you press Send button in client example it creates a bidirectional stream, sends data to it, then closes stream. Thus our code is sufficient. For a more complex communication that involves many concurrent streams you will have to write a more complex code that allows working with streams concurrently on server side. Full server example \u00b6 Full server code can be found in a Gist . Again \u2013 this is a toy example based on things that all work in progress. Conclusion \u00b6 WebTransport is an interesting technology that can open new possibilities in modern Web development. At this moment it's possible to play with it using QUIC transport \u2013 here we looked at how one can do that. Though we still have to wait a bit until all these things will be suitable for production usage. Also, even when ready we will still have to think about WebTransport fallback options \u2013 since wide adoption of browsers that support some new technology and infrastructure takes time. Actually WebTransport spec authors consider fallback options in design. This was mentioned in IETF slides ( PDF, 2.6MB ), but I have not found any additional information beyond that. Personally, I think the most exciting thing about WebTransport is the possibility to exchange UDP datagrams, which can help a lot to in-browser gaming. Unfortunately, we can't test it at this moment with Go (but it's already possible using Python as server as shown in the example ). WebTransport could be a nice candidate for a new Centrifugo transport next to WebSocket and SockJS \u2013 time will show.","title":"Experimenting with QUIC and WebTransport in Go"},{"location":"blog/quic_web_transport/#experimenting-with-quic-and-webtransport-in-go","text":"","title":"Experimenting with QUIC and WebTransport in Go"},{"location":"blog/quic_web_transport/#overview","text":"UPDATE : WebTransport spec is still evolving. Some information here is out-of-date. For example the working group has no plan to implement both QuicTransport and HTTP3-based transports \u2013 only HTTP3 based WebTransport is going to be implemented. Maybe we will publish a follow-up of this post at some point. WebTransport is a new browser API offering low-latency, bidirectional, client-server messaging. If you have not heard about it before I suggest to first read a post called Experimenting with QuicTransport published recently on web.dev \u2013 it gives a nice overview to WebTransport and shows client-side code examples. Here we will concentrate on implementing server side. Some key points about WebTransport spec: WebTransport standard will provide a possibility to use streaming client-server communication using modern transports such as QUIC and HTTP/3 It can be a good alternative to WebSocket messaging, standard provides some capabilities that are not possible with current WebSocket spec: possibility to get rid of head-of-line blocking problems using individual streams for different data, the possibility to reuse a single connection to a server in different browser tabs WebTransport also defines an unreliable stream API using UDP datagrams (which is possible since QUIC is UDP-based) \u2013 which is what browsers did not have before without a rather complex WebRTC setup involving ICE, STUN, etc. This is sweet for in-browser real-time games. To help you figure out things here are links to current WebTransport specs: WebTransport overview \u2013 this spec gives an overview of WebTransport and provides requirements to transport layer WebTransport over QUIC \u2013 this spec describes QUIC-based transport for WebTransport WebTransport over HTTP/3 \u2013 this spec describes HTTP/3-based transport for WebTransport (actually HTTP/3 is a protocol defined on top of QUIC) At moment Chrome only implements trial possibility to try out WebTransport standard and only implements WebTransport over QUIC. Developers can initialize transport with code like this: const transport = new QuicTransport ( 'quic-transport://localhost:4433/path' ); In case of HTTP/3 transport one will use URL like 'https://localhost:4433/path' in transport constructor. All WebTransport underlying transports should support instantiation over URL \u2013 that's one of the spec requirements. I decided that this is a cool possibility to finally play with QUIC protocol and its Go implementation github.com/lucas-clemente/quic-go . Danger Please keep in mind that all things described in this post are work in progress. WebTransport drafts, Quic-Go library, even QUIC protocol itself are subjects to change. You should not use it in production yet. Experimenting with QuicTransport post contains links to a client example and companion Python server implementation . We will use a linked client example to connect to a server that runs on localhost and uses github.com/lucas-clemente/quic-go library. To make our example work we need to open client example in Chrome, and actually, at this moment we need to install Chrome Canary. The reason behind this is that the quic-go library supports QUIC draft-29 while Chrome < 85 implements QuicTransport over draft-27. If you read this post at a time when Chrome stable 85 already released then most probably you don't need to install Canary release and just use your stable Chrome. We also need to generate self-signed certificates since WebTransport only works with a TLS layer, and we should make Chrome trust our certificates. Let's prepare our client environment before writing a server and first install Chrome Canary.","title":"Overview"},{"location":"blog/quic_web_transport/#install-chrome-canary","text":"Go to https://www.google.com/intl/en/chrome/canary/ , download and install Chrome Canary. We will use it to open client example . Note If you have Chrome >= 85 then most probably you can skip this step.","title":"Install Chrome Canary"},{"location":"blog/quic_web_transport/#generate-self-signed-tls-certificates","text":"Since WebTransport based on modern network transports like QUIC and HTTP/3 security is a keystone. For our experiment we will create a self-signed TLS certificate using openssl . Make sure you have openssl installed: $ which openssl /usr/bin/openssl Then run: openssl genrsa -des3 -passout pass:x -out server.pass.key 2048 openssl rsa -passin pass:x -in server.pass.key -out server.key rm server.pass.key openssl req -new -key server.key -out server.csr Set localhost for Common Name when asked. The self-signed TLS certificate generated from the server.key private key and server.csr files: openssl x509 -req -sha256 -days 365 -in server.csr -signkey server.key -out server.crt After these manipulations you should have server.crt and server.key files in your working directory. To help you with process here is my console output during these steps (click to open): My console output generating self-signed certificates $ openssl genrsa -des3 -passout pass:x -out server.pass.key 2048 Generating RSA private key, 2048 bit long modulus ...........................................................................................+++ .....................+++ e is 65537 ( 0x10001 ) $ ls server.pass.key $ openssl rsa -passin pass:x -in server.pass.key -out server.key writing RSA key $ ls server.key server.pass.key $ rm server.pass.key $ openssl req -new -key server.key -out server.csr You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.' , the field will be left blank. ----- Country Name ( 2 letter code ) [] :RU State or Province Name ( full name ) [] : Locality Name ( eg, city ) [] : Organization Name ( eg, company ) [] : Organizational Unit Name ( eg, section ) [] : Common Name ( eg, fully qualified host name ) [] :localhost Email Address [] : Please enter the following 'extra' attributes to be sent with your certificate request A challenge password [] : $ openssl x509 -req -sha256 -days 365 -in server.csr -signkey server.key -out server.crt Signature ok subject = /C = RU/CN = localhost Getting Private key $ ls server.crt server.csr server.key","title":"Generate self-signed TLS certificates"},{"location":"blog/quic_web_transport/#run-client-example","text":"Now the last step. What we need to do is run Chrome Canary with some flags that will allow it to trust our self-signed certificates. I suppose there is an alternative way making Chrome trust your certificates, but I have not tried it. First let's find out a fingerprint of our cert: openssl x509 -in server.crt -pubkey -noout | openssl pkey -pubin -outform der | openssl dgst -sha256 -binary | openssl enc -base64 In my case base64 fingerprint was pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M= , yours will be different. Then run Chrome Canary with some additional flags that will make it trust out certs (close other Chrome Canary instances before running it): $ /Applications/Google \\ Chrome \\ Canary.app/Contents/MacOS/Google \\ Chrome \\ Canary \\ --origin-to-force-quic-on = localhost:4433 \\ --ignore-certificate-errors-spki-list = pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M = This example is for MacOS, for your system see docs on how to run Chrome/Chromium with custom flags . Now you can open https://googlechrome.github.io/samples/quictransport/client.html URL in started browser and click Connect button. What? Connection not established? OK, this is fine since we need to run our server :)","title":"Run client example"},{"location":"blog/quic_web_transport/#writing-a-quic-server","text":"Maybe in future we will have libraries that are specified to work with WebTransport over QUIC or HTTP/3, but for now we should implement server manually. As said above we will use github.com/lucas-clemente/quic-go library to do this.","title":"Writing a QUIC server"},{"location":"blog/quic_web_transport/#server-skeleton","text":"First, let's define a simple skeleton for our server: package main import ( \"errors\" \"log\" \"github.com/lucas-clemente/quic-go\" ) // Config for WebTransportServerQuic. type Config struct { // ListenAddr sets an address to bind server to. ListenAddr string // TLSCertPath defines a path to .crt cert file. TLSCertPath string // TLSKeyPath defines a path to .key cert file TLSKeyPath string // AllowedOrigins represents list of allowed origins to connect from. AllowedOrigins [] string } // WebTransportServerQuic can handle WebTransport QUIC connections according // to https://tools.ietf.org/html/draft-vvv-webtransport-quic-02. type WebTransportServerQuic struct { config Config } // NewWebTransportServerQuic creates new WebTransportServerQuic. func NewWebTransportServerQuic ( config Config ) * WebTransportServerQuic { return & WebTransportServerQuic { config : config , } } // Run server. func ( s * WebTransportServerQuic ) Run () error { return errors . New ( \"not implemented\" ) } func main () { server := NewWebTransportServerQuic ( Config { ListenAddr : \"0.0.0.0:4433\" , TLSCertPath : \"server.crt\" , TLSKeyPath : \"server.key\" , AllowedOrigins : [] string { \"localhost\" , \"googlechrome.github.io\" }, }) if err := server . Run (); err != nil { log . Fatal ( err ) } }","title":"Server skeleton"},{"location":"blog/quic_web_transport/#accept-quic-connections","text":"Let's concentrate on implementing Run method. We need to accept QUIC client connections. This can be done by creating quic.Listener instance and using its .Accept method to accept incoming client sessions. // Run server. func ( s * WebTransportServerQuic ) Run () error { listener , err := quic . ListenAddr ( s . config . ListenAddr , s . generateTLSConfig (), nil ) if err != nil { return err } for { sess , err := listener . Accept ( context . Background ()) if err != nil { return err } log . Printf ( \"session accepted: %s\" , sess . RemoteAddr (). String ()) go func () { defer func () { _ = sess . CloseWithError ( 0 , \"bye\" ) log . Println ( \"close session\" ) }() s . handleSession ( sess ) }() } } func ( s * WebTransportServerQuic ) handleSession ( sess quic . Session ) { // Not implemented yet. } An interesting thing to note is that QUIC allows closing connection with specific application-level integer code and custom string reason. Just like WebSocket if you worked with it. Also note, that we are starting our Listener with TLS configuration returned by s.generateTLSConfig() method. Let's take a closer look at how this method can be implemented. // https://tools.ietf.org/html/draft-vvv-webtransport-quic-02#section-3.1 const alpnQuicTransport = \"wq-vvv-01\" func ( s * WebTransportServerQuic ) generateTLSConfig () * tls . Config { cert , err := tls . LoadX509KeyPair ( s . config . TLSCertPath , s . config . TLSKeyPath ) if err != nil { log . Fatal ( err ) } return & tls . Config { Certificates : [] tls . Certificate { cert }, NextProtos : [] string { alpnQuicTransport }, } } Inside generateTLSConfig we load x509 certs from cert files generated above. WebTransport uses ALPN ( Application-Layer Protocol Negotiation to prevent handshakes with a server that does not support WebTransport spec. This is just a string wq-vvv-01 inside NextProtos slice of our *tls.Config .","title":"Accept QUIC connections"},{"location":"blog/quic_web_transport/#connection-session-handling","text":"At this moment if you run a server and open a client example in Chrome then click Connect button \u2013 you should see that connection successfully established in event log area: Now if you try to send data to a server nothing will happen. That's because we have not implemented reading data from session streams. Streams in QUIC provide a lightweight, ordered byte-stream abstraction to an application. Streams can be unidirectional or bidirectional. Streams can be short-lived, streams can also be long-lived and can last the entire duration of a connection. Client example provides three possible ways to communicate with a server: Send a datagram Open a unidirectional stream Open a bidirectional stream Unfortunately, quic-go library does not support sending UDP datagrams at this moment. To do this quic-go should implement one more draft called An Unreliable Datagram Extension to QUIC . There is already an ongoing pull request that implements it. This means that it's too early for us to experiment with unreliable UDP WebTransport client-server communication in Go. By the way, the interesting facts about UDP over QUIC are that QUIC congestion control mechanism will still apply and QUIC datagrams can support acknowledgements . Implementing a unidirectional stream is possible with quic-go since the library supports creating and accepting unidirectional streams, but I'll leave this for a reader (though we will need accepting one unidirectional stream for parsing client indication anyway \u2013 see below). Here we will only concentrate on implementing a server for a bidirectional case. We are in the Centrifugo blog, and this is the most interesting type of stream for me personally.","title":"Connection Session handling"},{"location":"blog/quic_web_transport/#parsing-client-indication","text":"According to section-3.2 of Quic WebTransport spec in order to verify that the client's origin allowed connecting to the server, the user agent has to communicate the origin to the server. This is accomplished by sending a special message, called client indication, on stream 2, which is the first client-initiated unidirectional stream. Here we will implement this. In the beginning of our session handler we will accept a unidirectional stream initiated by a client. At moment spec defines two client indication keys: Origin and Path . In our case an origin value will be https://googlechrome.github.io and path will be /counter . Let's define some constants and structures: // client indication stream can not exceed 65535 bytes in length. // https://tools.ietf.org/html/draft-vvv-webtransport-quic-02#section-3.2 const maxClientIndicationLength = 65535 // define known client indication keys. type clientIndicationKey int16 const ( clientIndicationKeyOrigin clientIndicationKey = 0 clientIndicationKeyPath = 1 ) // ClientIndication container. type ClientIndication struct { // Origin client indication value. Origin string // Path client indication value. Path string } Now what we should do is accept unidirectional stream inside session handler: func ( s * WebTransportServerQuic ) handleSession ( sess quic . Session ) { stream , err := sess . AcceptUniStream ( context . Background ()) if err != nil { log . Println ( err ) return } log . Printf ( \"uni stream accepted, id: %d\" , stream . StreamID ()) indication , err := receiveClientIndication ( stream ) if err != nil { log . Println ( err ) return } log . Printf ( \"client indication: %+v\" , indication ) if err := s . validateClientIndication ( indication ); err != nil { log . Println ( err ) return } // this method blocks. if err := s . communicate ( sess ); err != nil { log . Println ( err ) } } func receiveClientIndication ( stream quic . ReceiveStream ) ( ClientIndication , error ) { return ClientIndication {}, errors . New ( \"not implemented yet\" ) } func ( s * WebTransportServerQuic ) validateClientIndication ( indication ClientIndication ) error { return errors . New ( \"not implemented yet\" ) } func ( s * WebTransportServerQuic ) communicate ( sess quic . Session ) error { return errors . New ( \"not implemented yet\" ) } As you can see to accept a unidirectional stream with data we can use .AcceptUniStream method of quic.Session . After accepting a stream we should read client indication data from it. According to spec it will contain a client indication in the following format: 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Key (16) | Length (16) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (*) ... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The code below parses client indication out of a stream data, we decode key-value pairs from uni stream until an end of stream (indicated by EOF): func receiveClientIndication ( stream quic . ReceiveStream ) ( ClientIndication , error ) { var clientIndication ClientIndication // read no more than maxClientIndicationLength bytes. reader := io . LimitReader ( stream , maxClientIndicationLength ) done := false for { if done { break } var key int16 err := binary . Read ( reader , binary . BigEndian , & key ) if err != nil { if err == io . EOF { done = true } else { return clientIndication , err } } var valueLength int16 err = binary . Read ( reader , binary . BigEndian , & valueLength ) if err != nil { return clientIndication , err } buf := make ([] byte , valueLength ) n , err := reader . Read ( buf ) if err != nil { if err == io . EOF { // still need to process indication value. done = true } else { return clientIndication , err } } if int16 ( n ) != valueLength { return clientIndication , errors . New ( \"read less than expected\" ) } value := string ( buf ) switch clientIndicationKey ( key ) { case clientIndicationKeyOrigin : clientIndication . Origin = value case clientIndicationKeyPath : clientIndication . Path = value default : log . Printf ( \"skip unknown client indication key: %d: %s\" , key , value ) } } return clientIndication , nil } We also validate Origin inside validateClientIndication method of our server: var errBadOrigin = errors . New ( \"bad origin\" ) func ( s * WebTransportServerQuic ) validateClientIndication ( indication ClientIndication ) error { u , err := url . Parse ( indication . Origin ) if err != nil { return errBadOrigin } if ! stringInSlice ( u . Host , s . config . AllowedOrigins ) { return errBadOrigin } return nil } func stringInSlice ( a string , list [] string ) bool { for _ , b := range list { if b == a { return true } } return false } Do you have stringInSlice function in every Go project? I do :)","title":"Parsing client indication"},{"location":"blog/quic_web_transport/#communicating-over-bidirectional-streams","text":"The final part here is accepting a bidirectional stream from a client, reading it, and sending responses back. Here we will just echo everything a client sends to a server back to a client. You can implement whatever bidirectional communication you want actually. Very similar to unidirectional case we can call .AcceptStream method of session to accept a bidirectional stream. func ( s * WebTransportServerQuic ) communicate ( sess quic . Session ) error { for { stream , err := sess . AcceptStream ( context . Background ()) if err != nil { return err } log . Printf ( \"stream accepted: %d\" , stream . StreamID ()) if _ , err := io . Copy ( stream , stream ); err != nil { return err } } } When you press Send button in client example it creates a bidirectional stream, sends data to it, then closes stream. Thus our code is sufficient. For a more complex communication that involves many concurrent streams you will have to write a more complex code that allows working with streams concurrently on server side.","title":"Communicating over bidirectional streams"},{"location":"blog/quic_web_transport/#full-server-example","text":"Full server code can be found in a Gist . Again \u2013 this is a toy example based on things that all work in progress.","title":"Full server example"},{"location":"blog/quic_web_transport/#conclusion","text":"WebTransport is an interesting technology that can open new possibilities in modern Web development. At this moment it's possible to play with it using QUIC transport \u2013 here we looked at how one can do that. Though we still have to wait a bit until all these things will be suitable for production usage. Also, even when ready we will still have to think about WebTransport fallback options \u2013 since wide adoption of browsers that support some new technology and infrastructure takes time. Actually WebTransport spec authors consider fallback options in design. This was mentioned in IETF slides ( PDF, 2.6MB ), but I have not found any additional information beyond that. Personally, I think the most exciting thing about WebTransport is the possibility to exchange UDP datagrams, which can help a lot to in-browser gaming. Unfortunately, we can't test it at this moment with Go (but it's already possible using Python as server as shown in the example ). WebTransport could be a nice candidate for a new Centrifugo transport next to WebSocket and SockJS \u2013 time will show.","title":"Conclusion"},{"location":"blog/scaling_websocket/","text":"Scaling WebSocket in Go and beyond \u00b6 I believe that in 2020 WebSocket is still an entertaining technology which is not so well-known and understood like HTTP. In this blog post I'd like to tell about state of WebSocket in Go language ecosystem, and a way we could write scalable WebSocket servers with Go and beyond Go. We won't talk a lot about WebSocket transport pros and cons \u2013 I'll provide links to other resources on this topic. Most advices here are generic enough and can be easily approximated to other programming languages. Also in this post we won't talk about ready to use solutions (if you are looking for it \u2013 check out Real-time Web Technologies guide by Phil Leggetter), just general considerations. There is not so much information about scaling WebSocket on the internet so if you are interested in WebSocket and real-time messaging technologies - keep on reading. If you don't know what WebSocket is \u2013 check out the following curious links: https://hpbn.co/websocket/ \u2013 a wonderful chapter of great book by Ilya Grigorik https://lucumr.pocoo.org/2012/9/24/websockets-101/ \u2013 valuable thoughts about WebSocket from Armin Ronacher As soon as you know WebSocket basics \u2013 we can proceed. WebSocket server tasks \u00b6 Speaking about scalable servers that work with many persistent WebSocket connections \u2013 I found several important tasks such a server should be able to do: Maintain many active connections Send many messages to clients Support WebSocket fallback to scale to every client Authenticate incoming connections and invalidate connections Survive massive reconnect of all clients without loosing messages Note Of course not all of these points equally important in various situations. Below we will look at some tips which relate to these points. WebSocket libraries \u00b6 In Go language ecosystem we have several libraries which can be used as a building block for a WebSocket server. Package golang.org/x/net/websocket is considered deprecated . The default choice in the community is gorilla/websocket library. Made by Gary Burd (who also gifted us an awesome Redigo package to communicate with Redis) \u2013 it's widely used, performs well, has a very good API \u2013 so in most cases you should go with it. Some people think that library not actively maintained at moment \u2013 but this is not quite true, it implements full WebSocket RFC, so actually it can be considered done. In 2018 my ex-colleague Sergey Kamardin open-sourced gobwas/ws library. It provides a bit lower-level API than gorilla/websocket thus allows reducing RAM usage per connection and has nice optimizations for WebSocket upgrade process. It does not support WebSocket permessage-deflate compression but otherwise a good alternative you can consider using. If you have not read Sergey's famous post A Million WebSockets and Go \u2013 make a bookmark! One more library is nhooyr/websocket . It's the youngest one and actively maintained. It compiles to WASM which can be a cool thing for someone. The API is a bit different from what gorilla/websocket offers, and one of the big advantages I see is that it solves a problem with a proper WebSocket closing handshake which is a bit hard to do right with Gorilla WebSocket . You can consider all listed libraries except one from x/net for your project. Take a library, follow its examples (make attention to goroutine-safety of various API operations). Personally I prefer Gorilla WebSocket at moment since it's feature-complete and battle tested by tons of projects around Go world. OS tuning \u00b6 OK, so you have chosen a library and built a server on top of it. As soon as you put it in production the interesting things start happening. Let's start with several OS specific key things you should do to prepare for many connections from WebSocket clients. Every connection will cost you an open file descriptor, so you should tune a maximum number of open file descriptors your process can use. An errors like too many open files raise due to OS limit on file descriptors which is usually 256-1024 by default (see with ulimit -n on Unix). A nice overview on how to do this on different systems can be found in Riak docs . Wanna more connections? Make this limit higher. Nice tip here is to limit a maximum number of connections your process can serve \u2013 making it less than known file descriptor limit: // ulimit -n == 65535 if conns . Len () >= 65500 { return errors . New ( \"connection limit reached\" ) } conns . Add ( conn ) \u2013 otherwise you have a risk to not even able to look at pprof when things go bad. And you always need monitoring of open file descriptors. You can also consider using netutil.LimitListener for this task, but don't forget to put pprof on another port with another HTTP server instance in this case. Keep attention on Ephemeral ports problem which is often happens between your load balancer and your WebSocket server. The problem arises due to the fact that each TCP connection uniquely identified in the OS by the 4-part-tuple: source ip | source port | destination ip | destination port On balancer/server boundary you are limited in 65536 possible variants by default. But actually due to some OS limits and sockets in TIME_WAIT state the number is even less. A very good explanation and how to deal with it can be found in Pusher blog . Your possible number of connections also limited by conntrack table. Netfilter framework which is part of iptables keeps information about all connections and has limited size for this information. See how to see its limits and instructions to increase in this article . One more thing you can do is tune your network stack for performance. Do this only if you understand that you need it. Maybe start with this gist , but don't optimize without full understanding why you are doing this. Sending many messages \u00b6 Now let's speak about sending many messages. The general tips follows. Make payload smaller . This is obvious \u2013 fewer data means more effective work on all layers. BTW WebSocket framing overhead is minimal and adds only 2-8 bytes to your payload. You can read detailed dedicated research in Dissecting WebSocket's Overhead article. You can reduce an amount of data traveling over network with permessage-deflate WebSocket extension, so your data will be compressed. Though using permessage-deflate is not always a good thing for server due to poor performance of flate , so you should be prepared for a CPU and RAM resource usage on server side. While Gorilla WebSocket has a lot of optimizations internally by reusing flate writers, overhead is still noticeable. The increase value heavily depends on your load profile. Make less system calls . Every syscall will have a constant overhead, and actually in WebSocket server under load you will mostly see read and write system calls in your CPU profiles. An advice here \u2013 try to use client-server protocol that supports message batching, so you can join individual messages together. Use effective message serialization protocol . Maybe use code generation for JSON to avoid extensive usage of reflect package done by Go std lib. Maybe use sth like gogo/protobuf package which allows to speedup Protobuf marshalling and unmarshalling. Unfortunately Gogo Protobuf is going through hard times at this moment. Try to serialize a message only once when sending to many subscribers. Have a way to scale to several machines - more power, more possible messages. We will talk about this very soon. WebSocket fallback transport \u00b6 Even in 2020 there are still users which cannot establish connection with WebSocket server. Actually the problem mostly appears with browsers. Some users still use old browsers. But they have a choice \u2013 install a newer browser. Still, there could also be users behind corporate proxies. Employees can have a trusted certificate installed on their machine so company proxy can re-encrypt even TLS traffic. Also, some browser extensions can block WebSocket traffic. One ready solution to this is Sockjs-Go library. This is a mature library that provides fallback transport for WebSocket. If client does not succeed with WebSocket connection establishment then client can use some of HTTP transports for client-server communication: EventSource aka Server-Sent Events , XHR-streaming, Long-Polling etc. The downside with those transports is that to achieve bidirectional communication you should use sticky sessions on your load balancer since SockJS keeps connection session state in process memory. We will talk about many instances of your WebSocket server very soon. You can implement WebSocket fallback yourself, this should be simple if you have a sliding window message stream on your backend which we will discuss very soon. Maybe look at GRPC , depending on application it could be better or worse than WebSocket \u2013 in general you can expect a better performance and less resource consumption from WebSocket for bidirectional communication case. My measurements for a bidirectional scenario showed 3x win for WebSocket (binary + GOGO protobuf) in terms of server CPU consumption and 4 times less RAM per connection. Though if you only need RPC then GRPC can be a better choice. But you need additional proxy to work with GRPC from a browser. Performance is not scalability \u00b6 You can optimize client-server protocol, tune your OS, but at some point you won't be able to use only one process on one server machine. You need to scale connections and work your server does over different server machines. Horizontal scaling is also good for a server high availability. Actually there are some sort of real-time applications where a single isolated process makes sense - for example multiplayer games where limited number of players play independent game rounds. As soon as you distribute connections over several machines you have to find a way to deliver a message to a certain user. The basic approach here is to publish messages to all server instances. This can work but this does not scale well. You need a sort of instance discovery to make this less painful. Here comes PUB/SUB, where you can connect WebSocket server instances over central PUB/SUB broker. Clients that establish connections with your WebSocket server subscribe to topics (channels) in a broker, and as soon as you publish a message to that topic it will be delivered to all active subscribers on WebSocket server instances. If server node does not have interested subscriber then it won't get a message from a broker thus you are getting effective network communication. Actually the main picture of this post illustrates exactly this architecture: Let's think about requirements for a broker for real-time messaging application. We want a broker: with reasonable performance and possibility to scale which maintains message order in topics can support millions of topics, where each topic should be ephemeral and lightweight \u2013 topics can be created when user comes to application and removed after user goes away possibility to keep a sliding window of messages inside channel to help us survive massive reconnect scenario (will talk about this later below, can be a separate part from broker actually) Personally when we talk about such brokers here are some options that come into my mind: RabbitMQ Kafka or Pulsar Nats or Nats-Streaming Tarantool Redis Sure there are more exist including libraries like ZeroMQ or nanomsg . Below I'll try to consider these solutions for the task of making scalable WebSocket server facing many user connections from Internet. If you are looking for unreliable at most once PUB/SUB then any of solutions mentioned above should be sufficient. Many real-time messaging apps are ok with at most once guarantee delivery. If you don't want to miss messages then things are a bit harder. Let's try to evaluate these options for a task where application has lots of different topics from which it wants to receive messages with at least once guarantee (having a personal topic per client is common thing in applications). A short analysis below can be a bit biased, but I believe thoughts are reasonable enough. I did not found enough information on the internet about scaling WebSocket beyond a single server process, so I'll try to fill the gap a little based on my personal knowledge without pretending to be absolutely objective in these considerations. In some posts on the internet about scaling WebSocket I saw advices to use RabbitMQ for PUB/SUB stuff in real-time messaging server. While this is a great messaging server, it does not like a high rate of queue bind and unbind type of load. It will work, but you will need to use a lot of server resources for not so big number of clients (imagine having millions of queues inside RabbitMQ). I have an example from my practice where RabbitMQ consumed about 70 CPU cores to serve real-time messages for 100k online connections. After replacing it with Redis keeping the same message delivery semantics we got only 0.3 CPU consumption on broker side. Kafka and Pulsar are great solutions, but not for this task I believe. The problem is again in dynamic ephemeral nature of our topics. Kafka also likes a more stable configuration of its topics. Keeping messages on disk can be an overkill for real-time messaging task. Also your consumers on Kafka server should pull from millions of different topics, not sure how well it performs, but my thoughts at moment - this should not perform very well. Kafka itself scales perfectly, you will definitely be able to achieve a goal but resource usage will be significant. Here is a post from Trello where they moved from RabbitMQ to Kafka for similar real-time messaging task and got about 5x resource usage improvements. Note also that the more partitions you have the more heavy failover process you get. Nats and Nats-Streaming. Raw Nats can only provide at most once guarantee. BTW recently Nats developers released native WebSocket support , so you can consider it for your application. Nats-Streaming server as broker will allow you to not lose messages. To be fair I don't have enough information about how well Nats-Streaming scales to millions of topics. An upcoming Jetstream which will be a part of Nats server can also be an interesting option \u2013 like Kafka it provides a persistent stream of messages for at least once delivery semantics. But again, it involves disk storage, a nice thing for backend microservices communication but can be an overkill for real-time messaging task. Sure Tarantool can fit to this task well too. It's fast, im-memory and flexible. Some possible problems with Tarantool are not so healthy state of its client libraries, complexity and the fact that it's heavily enterprise-oriented. You should invest enough time to benefit from it, but this can worth it actually. See an article on how to do a performant broker for WebSocket applications with Tarantool. Building PUB/SUB system on top of ZeroMQ will require you to build separate broker yourself. This could be an unnecessary complexity for your system. It's possible to implement PUB/SUB pattern with ZeroMQ and nanomsg without a central broker, but in this case messages without active subscribers on a server will be dropped on a consumer side thus all publications will travel to all server nodes. My personal choice at moment is Redis. While Redis PUB/SUB itself provides at most once guarantee , you can build at least once delivery on top of PUB/SUB and Redis data structures (though this can be challenging enough). Redis is very fast (especially when using pipelining protocol feature), and what is more important \u2013 very predictable . It gives you a good understanding of operation time complexity. You can shard topics over different Redis instances running in HA setup - with Sentinel or with Redis Cluster. It allows writing LUA procedures with some advanced logic which can be uploaded over client protocol thus feels like ordinary commands. You can use Redis to keep sliding window event stream which gives you access to missed messages from a certain position. We will talk about this later. OK, the end of opinionated thoughts here :) Depending on your choice the implementation of your system will vary and will have different properties \u2013 so try to evaluate possible solutions based on your application requirements. Anyway, whatever broker will be your choice, try to follow this rules to build effective PUB/SUB system: take into account message delivery guarantees of your system: at most once or at least once, ideally you should have an option to have both for different real-time features in your app make sure to use one or pool of connections between your server and a broker, don't create new connection per each client or topic that comes to your WebSocket server use effective serialization format between your WebSocket server and broker Massive reconnect \u00b6 Let's talk about one more problem that is unique for Websocket servers compared to HTTP. Your app can have thousands or millions of active WebSocket connections. In contract to stateless HTTP APIs your application is stateful. It uses push model. As soon as you deploying your WebSocket server or reload your load balancer (Nginx maybe) \u2013 connections got dropped and all that army of users start reconnecting. And this can be like an avalanche actually. How to survive? First of all - use exponential backoff strategies on client side. I.e. reconnect with intervals like 1, 2, 4, 8, 16 seconds with some random jitter. Turn on various rate limiting strategies on your WebSocket server, some of them should be turned on your backend load balancer level (like controlling TCP connection establishment rate), some are application specific (maybe limit an amount of requests from certain user). One more interesting technique to survive massive reconnect is using JWT (JSON Web Token) for authentication. I'll try to explain why this can be useful. As soon as your client start reconnecting you will have to authenticate each connection. In massive setups with many persistent connection this can be a very significant load on your Session backend. Since you need an extra request to your session storage for every client coming back. This can be a no problem for some infrastructures but can be really disastrous for others. JWT allows to reduce this spike in load on session storage since it can have all required authentication information inside its payload. When using JWT make sure you have chosen a reasonable JWT expiration time \u2013 expiration interval depends on your application nature and just one of trade-offs you should deal with as developer. Don't forget about making an effective connection between your WebSocket server and broker \u2013 as soon as all clients start reconnecting you should resubscribe your server nodes to all topics as fast as possible. Use techniques like smart batching at this moment. Let's look at a small piece of code that demonstrates this technique. Imagine we have a source channel from which we get items to process. We don\u2019t want to process items individually but in batch. For this we wait for first item coming from channel, then try to collect as many items from channel buffer as we want without blocking and timeouts involved. And then process slice of items we collected at once. For example build Redis pipeline from them and send to Redis in one connection write call. maxBatchSize := 50 for { select { case item := <- sourceCh : batch := [] string { item } loop : for len ( batch ) < maxBatchSize { select { case item := <- sourceCh : batch = append ( batch , item ) default : break loop } } // Do sth with collected batch of items. println ( len ( batch )) } } Look at a complete example in a Go playground: https://play.golang.org/p/u7SAGOLmDke . I also made a repo where I demonstrate how this technique together with Redis pipelining feature allows to fully utilize connection for a good performance https://github.com/FZambia/redigo-smart-batching . Another advice for those who run WebSocket services in Kubernetes. Learn how your ingress behaves \u2013 for example Nginx ingress can reload its configuration on every change inside Kubernetes services map resulting into closing all active WebSocket connections. Proxies like Envoy don't have this behaviour, so you can reduce number of mass disconnections in your system. You can also proxy WebSocket without using ingress at all over configured WebSocket service NodePort. Message event stream benefits \u00b6 Here comes a final part of this post. Maybe the most important one. Not only mass client re-connections could create a significant load on a session backend but also a huge load on your main application database. Why? Because WebSocket applications are stateful. Clients rely on a stream of messages coming from a backend to maintain its state actual. As soon as connection dropped client tries to reconnect. In some scenarios it also wants to restore its actual state. What if client reconnected after 3 seconds? How many state updates it could miss? Nobody knows. So to make sure state is actual client tries to get it from application database. This is again a significant spike in load on your main database in massive reconnect scenario. In can be really painful with many active connections. So what I think is nice to have for scenarios where we can't afford to miss messages (like in chat-like apps for example) is having effective and performant stream of messages inside each channel. Keep this stream in fast in-memory storage. This stream can have time retention and be limited in size (think about it as a sliding window of messages). I already mentioned that Redis can do this \u2013 it's possible to keep messages in Redis List or Redis Stream data structures. Other broker solutions could give you access to such a stream inside each channel out of the box. So as soon as client reconnects it can restore its state from fast in-memory event stream without even querying your database. Actually to survive mass reconnect scenario you don't need to keep such a stream for a long time \u2013 several minutes should be enough. You can even create your own Websocket fallback implementation (like Long-Polling) utilizing event stream with limited retention . Conclusion \u00b6 Hope advices given here will be useful for a reader and will help writing a more robust and more scalable real-time application backends. Centrifugo server and Centrifuge library for Go language have most of the mechanics described here including the last one \u2013 message stream for topics limited by size and retention period. Both also have techniques to prevent message loss due to at most once nature of Redis PUB/SUB giving at least once delivery guarantee inside message history window size and retention period.","title":"Scaling WebSocket in Go and beyond"},{"location":"blog/scaling_websocket/#scaling-websocket-in-go-and-beyond","text":"I believe that in 2020 WebSocket is still an entertaining technology which is not so well-known and understood like HTTP. In this blog post I'd like to tell about state of WebSocket in Go language ecosystem, and a way we could write scalable WebSocket servers with Go and beyond Go. We won't talk a lot about WebSocket transport pros and cons \u2013 I'll provide links to other resources on this topic. Most advices here are generic enough and can be easily approximated to other programming languages. Also in this post we won't talk about ready to use solutions (if you are looking for it \u2013 check out Real-time Web Technologies guide by Phil Leggetter), just general considerations. There is not so much information about scaling WebSocket on the internet so if you are interested in WebSocket and real-time messaging technologies - keep on reading. If you don't know what WebSocket is \u2013 check out the following curious links: https://hpbn.co/websocket/ \u2013 a wonderful chapter of great book by Ilya Grigorik https://lucumr.pocoo.org/2012/9/24/websockets-101/ \u2013 valuable thoughts about WebSocket from Armin Ronacher As soon as you know WebSocket basics \u2013 we can proceed.","title":"Scaling WebSocket in Go and beyond"},{"location":"blog/scaling_websocket/#websocket-server-tasks","text":"Speaking about scalable servers that work with many persistent WebSocket connections \u2013 I found several important tasks such a server should be able to do: Maintain many active connections Send many messages to clients Support WebSocket fallback to scale to every client Authenticate incoming connections and invalidate connections Survive massive reconnect of all clients without loosing messages Note Of course not all of these points equally important in various situations. Below we will look at some tips which relate to these points.","title":"WebSocket server tasks"},{"location":"blog/scaling_websocket/#websocket-libraries","text":"In Go language ecosystem we have several libraries which can be used as a building block for a WebSocket server. Package golang.org/x/net/websocket is considered deprecated . The default choice in the community is gorilla/websocket library. Made by Gary Burd (who also gifted us an awesome Redigo package to communicate with Redis) \u2013 it's widely used, performs well, has a very good API \u2013 so in most cases you should go with it. Some people think that library not actively maintained at moment \u2013 but this is not quite true, it implements full WebSocket RFC, so actually it can be considered done. In 2018 my ex-colleague Sergey Kamardin open-sourced gobwas/ws library. It provides a bit lower-level API than gorilla/websocket thus allows reducing RAM usage per connection and has nice optimizations for WebSocket upgrade process. It does not support WebSocket permessage-deflate compression but otherwise a good alternative you can consider using. If you have not read Sergey's famous post A Million WebSockets and Go \u2013 make a bookmark! One more library is nhooyr/websocket . It's the youngest one and actively maintained. It compiles to WASM which can be a cool thing for someone. The API is a bit different from what gorilla/websocket offers, and one of the big advantages I see is that it solves a problem with a proper WebSocket closing handshake which is a bit hard to do right with Gorilla WebSocket . You can consider all listed libraries except one from x/net for your project. Take a library, follow its examples (make attention to goroutine-safety of various API operations). Personally I prefer Gorilla WebSocket at moment since it's feature-complete and battle tested by tons of projects around Go world.","title":"WebSocket libraries"},{"location":"blog/scaling_websocket/#os-tuning","text":"OK, so you have chosen a library and built a server on top of it. As soon as you put it in production the interesting things start happening. Let's start with several OS specific key things you should do to prepare for many connections from WebSocket clients. Every connection will cost you an open file descriptor, so you should tune a maximum number of open file descriptors your process can use. An errors like too many open files raise due to OS limit on file descriptors which is usually 256-1024 by default (see with ulimit -n on Unix). A nice overview on how to do this on different systems can be found in Riak docs . Wanna more connections? Make this limit higher. Nice tip here is to limit a maximum number of connections your process can serve \u2013 making it less than known file descriptor limit: // ulimit -n == 65535 if conns . Len () >= 65500 { return errors . New ( \"connection limit reached\" ) } conns . Add ( conn ) \u2013 otherwise you have a risk to not even able to look at pprof when things go bad. And you always need monitoring of open file descriptors. You can also consider using netutil.LimitListener for this task, but don't forget to put pprof on another port with another HTTP server instance in this case. Keep attention on Ephemeral ports problem which is often happens between your load balancer and your WebSocket server. The problem arises due to the fact that each TCP connection uniquely identified in the OS by the 4-part-tuple: source ip | source port | destination ip | destination port On balancer/server boundary you are limited in 65536 possible variants by default. But actually due to some OS limits and sockets in TIME_WAIT state the number is even less. A very good explanation and how to deal with it can be found in Pusher blog . Your possible number of connections also limited by conntrack table. Netfilter framework which is part of iptables keeps information about all connections and has limited size for this information. See how to see its limits and instructions to increase in this article . One more thing you can do is tune your network stack for performance. Do this only if you understand that you need it. Maybe start with this gist , but don't optimize without full understanding why you are doing this.","title":"OS tuning"},{"location":"blog/scaling_websocket/#sending-many-messages","text":"Now let's speak about sending many messages. The general tips follows. Make payload smaller . This is obvious \u2013 fewer data means more effective work on all layers. BTW WebSocket framing overhead is minimal and adds only 2-8 bytes to your payload. You can read detailed dedicated research in Dissecting WebSocket's Overhead article. You can reduce an amount of data traveling over network with permessage-deflate WebSocket extension, so your data will be compressed. Though using permessage-deflate is not always a good thing for server due to poor performance of flate , so you should be prepared for a CPU and RAM resource usage on server side. While Gorilla WebSocket has a lot of optimizations internally by reusing flate writers, overhead is still noticeable. The increase value heavily depends on your load profile. Make less system calls . Every syscall will have a constant overhead, and actually in WebSocket server under load you will mostly see read and write system calls in your CPU profiles. An advice here \u2013 try to use client-server protocol that supports message batching, so you can join individual messages together. Use effective message serialization protocol . Maybe use code generation for JSON to avoid extensive usage of reflect package done by Go std lib. Maybe use sth like gogo/protobuf package which allows to speedup Protobuf marshalling and unmarshalling. Unfortunately Gogo Protobuf is going through hard times at this moment. Try to serialize a message only once when sending to many subscribers. Have a way to scale to several machines - more power, more possible messages. We will talk about this very soon.","title":"Sending many messages"},{"location":"blog/scaling_websocket/#websocket-fallback-transport","text":"Even in 2020 there are still users which cannot establish connection with WebSocket server. Actually the problem mostly appears with browsers. Some users still use old browsers. But they have a choice \u2013 install a newer browser. Still, there could also be users behind corporate proxies. Employees can have a trusted certificate installed on their machine so company proxy can re-encrypt even TLS traffic. Also, some browser extensions can block WebSocket traffic. One ready solution to this is Sockjs-Go library. This is a mature library that provides fallback transport for WebSocket. If client does not succeed with WebSocket connection establishment then client can use some of HTTP transports for client-server communication: EventSource aka Server-Sent Events , XHR-streaming, Long-Polling etc. The downside with those transports is that to achieve bidirectional communication you should use sticky sessions on your load balancer since SockJS keeps connection session state in process memory. We will talk about many instances of your WebSocket server very soon. You can implement WebSocket fallback yourself, this should be simple if you have a sliding window message stream on your backend which we will discuss very soon. Maybe look at GRPC , depending on application it could be better or worse than WebSocket \u2013 in general you can expect a better performance and less resource consumption from WebSocket for bidirectional communication case. My measurements for a bidirectional scenario showed 3x win for WebSocket (binary + GOGO protobuf) in terms of server CPU consumption and 4 times less RAM per connection. Though if you only need RPC then GRPC can be a better choice. But you need additional proxy to work with GRPC from a browser.","title":"WebSocket fallback transport"},{"location":"blog/scaling_websocket/#performance-is-not-scalability","text":"You can optimize client-server protocol, tune your OS, but at some point you won't be able to use only one process on one server machine. You need to scale connections and work your server does over different server machines. Horizontal scaling is also good for a server high availability. Actually there are some sort of real-time applications where a single isolated process makes sense - for example multiplayer games where limited number of players play independent game rounds. As soon as you distribute connections over several machines you have to find a way to deliver a message to a certain user. The basic approach here is to publish messages to all server instances. This can work but this does not scale well. You need a sort of instance discovery to make this less painful. Here comes PUB/SUB, where you can connect WebSocket server instances over central PUB/SUB broker. Clients that establish connections with your WebSocket server subscribe to topics (channels) in a broker, and as soon as you publish a message to that topic it will be delivered to all active subscribers on WebSocket server instances. If server node does not have interested subscriber then it won't get a message from a broker thus you are getting effective network communication. Actually the main picture of this post illustrates exactly this architecture: Let's think about requirements for a broker for real-time messaging application. We want a broker: with reasonable performance and possibility to scale which maintains message order in topics can support millions of topics, where each topic should be ephemeral and lightweight \u2013 topics can be created when user comes to application and removed after user goes away possibility to keep a sliding window of messages inside channel to help us survive massive reconnect scenario (will talk about this later below, can be a separate part from broker actually) Personally when we talk about such brokers here are some options that come into my mind: RabbitMQ Kafka or Pulsar Nats or Nats-Streaming Tarantool Redis Sure there are more exist including libraries like ZeroMQ or nanomsg . Below I'll try to consider these solutions for the task of making scalable WebSocket server facing many user connections from Internet. If you are looking for unreliable at most once PUB/SUB then any of solutions mentioned above should be sufficient. Many real-time messaging apps are ok with at most once guarantee delivery. If you don't want to miss messages then things are a bit harder. Let's try to evaluate these options for a task where application has lots of different topics from which it wants to receive messages with at least once guarantee (having a personal topic per client is common thing in applications). A short analysis below can be a bit biased, but I believe thoughts are reasonable enough. I did not found enough information on the internet about scaling WebSocket beyond a single server process, so I'll try to fill the gap a little based on my personal knowledge without pretending to be absolutely objective in these considerations. In some posts on the internet about scaling WebSocket I saw advices to use RabbitMQ for PUB/SUB stuff in real-time messaging server. While this is a great messaging server, it does not like a high rate of queue bind and unbind type of load. It will work, but you will need to use a lot of server resources for not so big number of clients (imagine having millions of queues inside RabbitMQ). I have an example from my practice where RabbitMQ consumed about 70 CPU cores to serve real-time messages for 100k online connections. After replacing it with Redis keeping the same message delivery semantics we got only 0.3 CPU consumption on broker side. Kafka and Pulsar are great solutions, but not for this task I believe. The problem is again in dynamic ephemeral nature of our topics. Kafka also likes a more stable configuration of its topics. Keeping messages on disk can be an overkill for real-time messaging task. Also your consumers on Kafka server should pull from millions of different topics, not sure how well it performs, but my thoughts at moment - this should not perform very well. Kafka itself scales perfectly, you will definitely be able to achieve a goal but resource usage will be significant. Here is a post from Trello where they moved from RabbitMQ to Kafka for similar real-time messaging task and got about 5x resource usage improvements. Note also that the more partitions you have the more heavy failover process you get. Nats and Nats-Streaming. Raw Nats can only provide at most once guarantee. BTW recently Nats developers released native WebSocket support , so you can consider it for your application. Nats-Streaming server as broker will allow you to not lose messages. To be fair I don't have enough information about how well Nats-Streaming scales to millions of topics. An upcoming Jetstream which will be a part of Nats server can also be an interesting option \u2013 like Kafka it provides a persistent stream of messages for at least once delivery semantics. But again, it involves disk storage, a nice thing for backend microservices communication but can be an overkill for real-time messaging task. Sure Tarantool can fit to this task well too. It's fast, im-memory and flexible. Some possible problems with Tarantool are not so healthy state of its client libraries, complexity and the fact that it's heavily enterprise-oriented. You should invest enough time to benefit from it, but this can worth it actually. See an article on how to do a performant broker for WebSocket applications with Tarantool. Building PUB/SUB system on top of ZeroMQ will require you to build separate broker yourself. This could be an unnecessary complexity for your system. It's possible to implement PUB/SUB pattern with ZeroMQ and nanomsg without a central broker, but in this case messages without active subscribers on a server will be dropped on a consumer side thus all publications will travel to all server nodes. My personal choice at moment is Redis. While Redis PUB/SUB itself provides at most once guarantee , you can build at least once delivery on top of PUB/SUB and Redis data structures (though this can be challenging enough). Redis is very fast (especially when using pipelining protocol feature), and what is more important \u2013 very predictable . It gives you a good understanding of operation time complexity. You can shard topics over different Redis instances running in HA setup - with Sentinel or with Redis Cluster. It allows writing LUA procedures with some advanced logic which can be uploaded over client protocol thus feels like ordinary commands. You can use Redis to keep sliding window event stream which gives you access to missed messages from a certain position. We will talk about this later. OK, the end of opinionated thoughts here :) Depending on your choice the implementation of your system will vary and will have different properties \u2013 so try to evaluate possible solutions based on your application requirements. Anyway, whatever broker will be your choice, try to follow this rules to build effective PUB/SUB system: take into account message delivery guarantees of your system: at most once or at least once, ideally you should have an option to have both for different real-time features in your app make sure to use one or pool of connections between your server and a broker, don't create new connection per each client or topic that comes to your WebSocket server use effective serialization format between your WebSocket server and broker","title":"Performance is not scalability"},{"location":"blog/scaling_websocket/#massive-reconnect","text":"Let's talk about one more problem that is unique for Websocket servers compared to HTTP. Your app can have thousands or millions of active WebSocket connections. In contract to stateless HTTP APIs your application is stateful. It uses push model. As soon as you deploying your WebSocket server or reload your load balancer (Nginx maybe) \u2013 connections got dropped and all that army of users start reconnecting. And this can be like an avalanche actually. How to survive? First of all - use exponential backoff strategies on client side. I.e. reconnect with intervals like 1, 2, 4, 8, 16 seconds with some random jitter. Turn on various rate limiting strategies on your WebSocket server, some of them should be turned on your backend load balancer level (like controlling TCP connection establishment rate), some are application specific (maybe limit an amount of requests from certain user). One more interesting technique to survive massive reconnect is using JWT (JSON Web Token) for authentication. I'll try to explain why this can be useful. As soon as your client start reconnecting you will have to authenticate each connection. In massive setups with many persistent connection this can be a very significant load on your Session backend. Since you need an extra request to your session storage for every client coming back. This can be a no problem for some infrastructures but can be really disastrous for others. JWT allows to reduce this spike in load on session storage since it can have all required authentication information inside its payload. When using JWT make sure you have chosen a reasonable JWT expiration time \u2013 expiration interval depends on your application nature and just one of trade-offs you should deal with as developer. Don't forget about making an effective connection between your WebSocket server and broker \u2013 as soon as all clients start reconnecting you should resubscribe your server nodes to all topics as fast as possible. Use techniques like smart batching at this moment. Let's look at a small piece of code that demonstrates this technique. Imagine we have a source channel from which we get items to process. We don\u2019t want to process items individually but in batch. For this we wait for first item coming from channel, then try to collect as many items from channel buffer as we want without blocking and timeouts involved. And then process slice of items we collected at once. For example build Redis pipeline from them and send to Redis in one connection write call. maxBatchSize := 50 for { select { case item := <- sourceCh : batch := [] string { item } loop : for len ( batch ) < maxBatchSize { select { case item := <- sourceCh : batch = append ( batch , item ) default : break loop } } // Do sth with collected batch of items. println ( len ( batch )) } } Look at a complete example in a Go playground: https://play.golang.org/p/u7SAGOLmDke . I also made a repo where I demonstrate how this technique together with Redis pipelining feature allows to fully utilize connection for a good performance https://github.com/FZambia/redigo-smart-batching . Another advice for those who run WebSocket services in Kubernetes. Learn how your ingress behaves \u2013 for example Nginx ingress can reload its configuration on every change inside Kubernetes services map resulting into closing all active WebSocket connections. Proxies like Envoy don't have this behaviour, so you can reduce number of mass disconnections in your system. You can also proxy WebSocket without using ingress at all over configured WebSocket service NodePort.","title":"Massive reconnect"},{"location":"blog/scaling_websocket/#message-event-stream-benefits","text":"Here comes a final part of this post. Maybe the most important one. Not only mass client re-connections could create a significant load on a session backend but also a huge load on your main application database. Why? Because WebSocket applications are stateful. Clients rely on a stream of messages coming from a backend to maintain its state actual. As soon as connection dropped client tries to reconnect. In some scenarios it also wants to restore its actual state. What if client reconnected after 3 seconds? How many state updates it could miss? Nobody knows. So to make sure state is actual client tries to get it from application database. This is again a significant spike in load on your main database in massive reconnect scenario. In can be really painful with many active connections. So what I think is nice to have for scenarios where we can't afford to miss messages (like in chat-like apps for example) is having effective and performant stream of messages inside each channel. Keep this stream in fast in-memory storage. This stream can have time retention and be limited in size (think about it as a sliding window of messages). I already mentioned that Redis can do this \u2013 it's possible to keep messages in Redis List or Redis Stream data structures. Other broker solutions could give you access to such a stream inside each channel out of the box. So as soon as client reconnects it can restore its state from fast in-memory event stream without even querying your database. Actually to survive mass reconnect scenario you don't need to keep such a stream for a long time \u2013 several minutes should be enough. You can even create your own Websocket fallback implementation (like Long-Polling) utilizing event stream with limited retention .","title":"Message event stream benefits"},{"location":"blog/scaling_websocket/#conclusion","text":"Hope advices given here will be useful for a reader and will help writing a more robust and more scalable real-time application backends. Centrifugo server and Centrifuge library for Go language have most of the mechanics described here including the last one \u2013 message stream for topics limited by size and retention period. Both also have techniques to prevent message loss due to at most once nature of Redis PUB/SUB giving at least once delivery guarantee inside message history window size and retention period.","title":"Conclusion"},{"location":"deploy/monitoring/","text":"Monitoring \u00b6 Centrifugo supports reporting metrics in Prometheus format and can automatically export metrics to Graphite. Prometheus \u00b6 To enable Prometheus endpoint start Centrifugo with prometheus option on: { ... \"prometheus\" : true } ./centrifugo --config=config.json This will enable /metrics endpoint so Centrifugo instance can be monitored by your Prometheus server. Graphite \u00b6 To enable automatic export to Graphite (via TCP): { \"graphite\" : true , \"graphite_host\" : \"localhost\" , \"graphite_port\" : 2003 } By default stats will be aggregated over 10 seconds interval inside Centrifugo and then pushed to Graphite over TCP connection. If you need to change this aggregation interval use graphite_interval option (in seconds, default 10 ). This option available since v2.1.0 Grafana dashboard \u00b6 Check out Centrifugo official Grafana dashboard for Prometheus storage. You can import that dashboard to your Grafana, point to Prometheus storage \u2013 and enjoy visualized metrics. Note, that dashboard requires Centrifugo >= v2.7.0 to work correctly.","title":"Monitoring"},{"location":"deploy/monitoring/#monitoring","text":"Centrifugo supports reporting metrics in Prometheus format and can automatically export metrics to Graphite.","title":"Monitoring"},{"location":"deploy/monitoring/#prometheus","text":"To enable Prometheus endpoint start Centrifugo with prometheus option on: { ... \"prometheus\" : true } ./centrifugo --config=config.json This will enable /metrics endpoint so Centrifugo instance can be monitored by your Prometheus server.","title":"Prometheus"},{"location":"deploy/monitoring/#graphite","text":"To enable automatic export to Graphite (via TCP): { \"graphite\" : true , \"graphite_host\" : \"localhost\" , \"graphite_port\" : 2003 } By default stats will be aggregated over 10 seconds interval inside Centrifugo and then pushed to Graphite over TCP connection. If you need to change this aggregation interval use graphite_interval option (in seconds, default 10 ). This option available since v2.1.0","title":"Graphite"},{"location":"deploy/monitoring/#grafana-dashboard","text":"Check out Centrifugo official Grafana dashboard for Prometheus storage. You can import that dashboard to your Grafana, point to Prometheus storage \u2013 and enjoy visualized metrics. Note, that dashboard requires Centrifugo >= v2.7.0 to work correctly.","title":"Grafana dashboard"},{"location":"deploy/nginx/","text":"Nginx configuration \u00b6 Although it's possible to use Centrifugo without any reverse proxy before it, it's still a good idea to keep Centrifugo behind mature reverse proxy to deal with edge cases when handling HTTP/Websocket connections from the wild. Also you probably want some sort of load balancing eventually between Centrifugo nodes so that proxy can be such a balancer too. In this section we will look at Nginx configuration to deploy Centrifugo. Minimal Nginx version \u2013 1.3.13 because it was the first version that can proxy Websocket connections. There are 2 ways: running Centrifugo server as separate service on its own domain or embed it to a location of your web site (for example to /centrifugo ). Separate domain for Centrifugo \u00b6 upstream centrifugo { # Enumerate all upstream servers here #sticky; ip_hash; server 127.0.0.1:8000; #server 127.0.0.1:8001; } map $http_upgrade $connection_upgrade { default upgrade; '' close; } #server { # listen 80; # server_name centrifugo.example.com; # rewrite ^(.*) https://$server_name$1 permanent; #} server { server_name centrifugo.example.com; listen 80; #listen 443; #ssl on; #ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; #ssl_certificate /etc/nginx/ssl/wildcard.example.com.crt; #ssl_certificate_key /etc/nginx/ssl/wildcard.example.com.key; #ssl_session_cache shared:SSL:10m;ssl_session_timeout 10m; include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; tcp_nopush on; tcp_nodelay on; gzip on; gzip_min_length 1000; gzip_proxied any; # Only retry if there was a communication error, not a timeout # on the Tornado server (to avoid propagating \"queries of death\" # to all frontends) proxy_next_upstream error; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header Host $http_host; location /connection { proxy_pass http://centrifugo; proxy_buffering off; keepalive_timeout 65; proxy_read_timeout 60s; proxy_http_version 1.1; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header Host $http_host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } location / { proxy_pass http://centrifugo; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } Embed to a location of web site \u00b6 upstream centrifugo { # Enumerate all the Tornado servers here #sticky; ip_hash; server 127.0.0.1:8000; #server 127.0.0.1:8001; } map $http_upgrade $connection_upgrade { default upgrade; '' close; } server { # ... your web site Nginx config location /centrifugo/ { rewrite ^/centrifugo/(.*) /$1 break; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_pass http://centrifugo; } location /centrifugo/connection { rewrite ^/centrifugo(.*) $1 break; proxy_next_upstream error; gzip on; gzip_min_length 1000; gzip_proxied any; proxy_buffering off; keepalive_timeout 65; proxy_pass http://centrifugo; proxy_read_timeout 60s; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header Host $http_host; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } } sticky \u00b6 You may be noticed commented sticky; directive in nginx upstream configuration. When using SockJS and client connects to Centrifugo - SockJS session created - and to communicate client must send all next requests to the same upstream backend. In this configuration we use ip_hash; directive to proxy clients with the same ip address to the same upstream backend. But ip_hash; is not the best choice in this case, because there could be situations where a lot of different browsers are coming with the same IP address (behind proxies) and the load balancing system won't be fair. Also fair load balancing does not work during development - when all clients connecting from localhost. So the best solution would be using something like nginx-sticky-module which uses setting a special cookie to track the upstream server for client. worker_connections \u00b6 You may also need to update worker_connections option of Nginx: events { worker_connections 40000; } Upstream keepalive \u00b6 See chapter about operating system tuning for more details.","title":"Nginx configuration"},{"location":"deploy/nginx/#nginx-configuration","text":"Although it's possible to use Centrifugo without any reverse proxy before it, it's still a good idea to keep Centrifugo behind mature reverse proxy to deal with edge cases when handling HTTP/Websocket connections from the wild. Also you probably want some sort of load balancing eventually between Centrifugo nodes so that proxy can be such a balancer too. In this section we will look at Nginx configuration to deploy Centrifugo. Minimal Nginx version \u2013 1.3.13 because it was the first version that can proxy Websocket connections. There are 2 ways: running Centrifugo server as separate service on its own domain or embed it to a location of your web site (for example to /centrifugo ).","title":"Nginx configuration"},{"location":"deploy/nginx/#separate-domain-for-centrifugo","text":"upstream centrifugo { # Enumerate all upstream servers here #sticky; ip_hash; server 127.0.0.1:8000; #server 127.0.0.1:8001; } map $http_upgrade $connection_upgrade { default upgrade; '' close; } #server { # listen 80; # server_name centrifugo.example.com; # rewrite ^(.*) https://$server_name$1 permanent; #} server { server_name centrifugo.example.com; listen 80; #listen 443; #ssl on; #ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; #ssl_certificate /etc/nginx/ssl/wildcard.example.com.crt; #ssl_certificate_key /etc/nginx/ssl/wildcard.example.com.key; #ssl_session_cache shared:SSL:10m;ssl_session_timeout 10m; include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; tcp_nopush on; tcp_nodelay on; gzip on; gzip_min_length 1000; gzip_proxied any; # Only retry if there was a communication error, not a timeout # on the Tornado server (to avoid propagating \"queries of death\" # to all frontends) proxy_next_upstream error; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header Host $http_host; location /connection { proxy_pass http://centrifugo; proxy_buffering off; keepalive_timeout 65; proxy_read_timeout 60s; proxy_http_version 1.1; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header Host $http_host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } location / { proxy_pass http://centrifugo; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } }","title":"Separate domain for Centrifugo"},{"location":"deploy/nginx/#embed-to-a-location-of-web-site","text":"upstream centrifugo { # Enumerate all the Tornado servers here #sticky; ip_hash; server 127.0.0.1:8000; #server 127.0.0.1:8001; } map $http_upgrade $connection_upgrade { default upgrade; '' close; } server { # ... your web site Nginx config location /centrifugo/ { rewrite ^/centrifugo/(.*) /$1 break; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_pass http://centrifugo; } location /centrifugo/connection { rewrite ^/centrifugo(.*) $1 break; proxy_next_upstream error; gzip on; gzip_min_length 1000; gzip_proxied any; proxy_buffering off; keepalive_timeout 65; proxy_pass http://centrifugo; proxy_read_timeout 60s; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header Host $http_host; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } }","title":"Embed to a location of web site"},{"location":"deploy/nginx/#sticky","text":"You may be noticed commented sticky; directive in nginx upstream configuration. When using SockJS and client connects to Centrifugo - SockJS session created - and to communicate client must send all next requests to the same upstream backend. In this configuration we use ip_hash; directive to proxy clients with the same ip address to the same upstream backend. But ip_hash; is not the best choice in this case, because there could be situations where a lot of different browsers are coming with the same IP address (behind proxies) and the load balancing system won't be fair. Also fair load balancing does not work during development - when all clients connecting from localhost. So the best solution would be using something like nginx-sticky-module which uses setting a special cookie to track the upstream server for client.","title":"sticky"},{"location":"deploy/nginx/#worker_connections","text":"You may also need to update worker_connections option of Nginx: events { worker_connections 40000; }","title":"worker_connections"},{"location":"deploy/nginx/#upstream-keepalive","text":"See chapter about operating system tuning for more details.","title":"Upstream keepalive"},{"location":"deploy/tls/","text":"TLS \u00b6 TLS/SSL layer is very important not only for securing your connections but also to increase a chance to establish Websocket connection. In most situations you will put TLS termination task on your reverse proxy/load balancing software such as Nginx . There are situations though when you want to serve secure connections by Centrifugo itself. There are two ways to do this: using TLS certificate cert and key files that you've got from your CA provider or using automatic certificate handling via ACME provider (only Let's Encrypt at this moment). Using crt and key files \u00b6 In first way you already have cert and key files. For development you can create self-signed certificate - see this instruction as example. Then to start Centrifugo use the following command: ./centrifugo --config=config.json --tls --tls_key=server.key --tls_cert=server.crt Or just use configuration file: { ... \"tls\" : true , \"tls_key\" : \"server.key\" , \"tls_cert\" : \"server.crt\" } And run: ./centrifugo --config=config.json Automatic certificates \u00b6 For automatic certificates from Let's Encrypt add into configuration file: { ... \"tls_autocert\": true, \"tls_autocert_host_whitelist\": \"www.example.com\", \"tls_autocert_cache_dir\": \"/tmp/certs\", \"tls_autocert_email\": \"user@example.com\", \"tls_autocert_http\": true, \"tls_autocert_http_addr\": \":80\" } tls_autocert (boolean) says Centrifugo that you want automatic certificate handling using ACME provider. tls_autocert_host_whitelist (string) is a string with your app domain address. This can be comma-separated list. It's optional but recommended for extra security. tls_autocert_cache_dir (string) is a path to a folder to cache issued certificate files. This is optional but will increase performance. tls_autocert_email (string) is optional - it's an email address ACME provider will send notifications about problems with your certificates. tls_autocert_http (boolean) is an option to handle http_01 ACME challenge on non-TLS port. tls_autocert_http_addr (string) can be used to set address for handling http_01 ACME challenge (default is :80 ) When configured correctly and your domain is valid ( localhost will not work) - certificates will be retrieved on first request to Centrifugo. Also Let's Encrypt certificates will be automatically renewed. There are tho options that allow Centrifugo to support TLS client connections from older browsers such as Chrome 49 on Windows XP and IE8 on XP: tls_autocert_force_rsa - this is a boolean option, by default false . When enabled it forces autocert manager generate certificates with 2048-bit RSA keys. tls_autocert_server_name - string option, allows to set server name for client handshake hello. This can be useful to deal with old browsers without SNI support - see comment grpc_api_tls_disable boolean flag allows to disable TLS for GRPC API server but keep it on for HTTP endpoints. Custom TLS for GRPC API \u00b6 Starting from Centrifugo v2.2.5 you can provide custom certificate files to configure TLS for GRPC API server in custom way. grpc_api_tls boolean flag enables TLS for GRPC API server, requires an X509 certificate and a key file grpc_api_tls_cert string provides a path to an X509 certificate file for GRPC API server grpc_api_tls_key string provides a path to an X509 certificate key for GRPC API server","title":"TLS"},{"location":"deploy/tls/#tls","text":"TLS/SSL layer is very important not only for securing your connections but also to increase a chance to establish Websocket connection. In most situations you will put TLS termination task on your reverse proxy/load balancing software such as Nginx . There are situations though when you want to serve secure connections by Centrifugo itself. There are two ways to do this: using TLS certificate cert and key files that you've got from your CA provider or using automatic certificate handling via ACME provider (only Let's Encrypt at this moment).","title":"TLS"},{"location":"deploy/tls/#using-crt-and-key-files","text":"In first way you already have cert and key files. For development you can create self-signed certificate - see this instruction as example. Then to start Centrifugo use the following command: ./centrifugo --config=config.json --tls --tls_key=server.key --tls_cert=server.crt Or just use configuration file: { ... \"tls\" : true , \"tls_key\" : \"server.key\" , \"tls_cert\" : \"server.crt\" } And run: ./centrifugo --config=config.json","title":"Using crt and key files"},{"location":"deploy/tls/#automatic-certificates","text":"For automatic certificates from Let's Encrypt add into configuration file: { ... \"tls_autocert\": true, \"tls_autocert_host_whitelist\": \"www.example.com\", \"tls_autocert_cache_dir\": \"/tmp/certs\", \"tls_autocert_email\": \"user@example.com\", \"tls_autocert_http\": true, \"tls_autocert_http_addr\": \":80\" } tls_autocert (boolean) says Centrifugo that you want automatic certificate handling using ACME provider. tls_autocert_host_whitelist (string) is a string with your app domain address. This can be comma-separated list. It's optional but recommended for extra security. tls_autocert_cache_dir (string) is a path to a folder to cache issued certificate files. This is optional but will increase performance. tls_autocert_email (string) is optional - it's an email address ACME provider will send notifications about problems with your certificates. tls_autocert_http (boolean) is an option to handle http_01 ACME challenge on non-TLS port. tls_autocert_http_addr (string) can be used to set address for handling http_01 ACME challenge (default is :80 ) When configured correctly and your domain is valid ( localhost will not work) - certificates will be retrieved on first request to Centrifugo. Also Let's Encrypt certificates will be automatically renewed. There are tho options that allow Centrifugo to support TLS client connections from older browsers such as Chrome 49 on Windows XP and IE8 on XP: tls_autocert_force_rsa - this is a boolean option, by default false . When enabled it forces autocert manager generate certificates with 2048-bit RSA keys. tls_autocert_server_name - string option, allows to set server name for client handshake hello. This can be useful to deal with old browsers without SNI support - see comment grpc_api_tls_disable boolean flag allows to disable TLS for GRPC API server but keep it on for HTTP endpoints.","title":"Automatic certificates"},{"location":"deploy/tls/#custom-tls-for-grpc-api","text":"Starting from Centrifugo v2.2.5 you can provide custom certificate files to configure TLS for GRPC API server in custom way. grpc_api_tls boolean flag enables TLS for GRPC API server, requires an X509 certificate and a key file grpc_api_tls_cert string provides a path to an X509 certificate file for GRPC API server grpc_api_tls_key string provides a path to an X509 certificate key for GRPC API server","title":"Custom TLS for GRPC API"},{"location":"deploy/tuning/","text":"Tuning operating system \u00b6 As Centrifugo/Centrifuge deals with lots of persistent connections your operating system must be ready for it. open files limit \u00b6 First of all you should increase a max number of open files your processes can open. To get you current open files limit run: ulimit -n The result shows approximately how many clients your server can handle. See this document to get more info on how to increase this number. If you install Centrifugo using RPM from repo then it automatically sets max open files limit to 65536. You may also need to increase max open files for Nginx. lots of sockets in TIME_WAIT state. \u00b6 Look how many socket descriptors in TIME_WAIT state. netstat -an |grep TIME_WAIT | grep CENTRIFUGO_PID | wc -l Under load when lots of connections and disconnection happen lots of used socket descriptors can stay in TIME_WAIT state. Those descriptors can not be reused for a while. So you can get various errors when using Centrifugo. For example something like (99: Cannot assign requested address) while connecting to upstream in Nginx error log and 502 on client side. In this case there are several advices that can help. Nice article about TIME_WAIT sockets: http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html There is a perfect article about operating system tuning for lots of connections: https://engineering.gosquared.com/optimising-nginx-node-js-and-networking-for-heavy-workloads . To summarize: Increase ip_local_port_range If you are using Nginx set keepalive directive in upstream. upstream centrifugo { #sticky; ip_hash; server 127.0.0.1:8000; keepalive 512; } And finally if the problem is not gone away consider trying to enable net.ipv4.tcp_tw_reuse","title":"OS tuning"},{"location":"deploy/tuning/#tuning-operating-system","text":"As Centrifugo/Centrifuge deals with lots of persistent connections your operating system must be ready for it.","title":"Tuning operating system"},{"location":"deploy/tuning/#open-files-limit","text":"First of all you should increase a max number of open files your processes can open. To get you current open files limit run: ulimit -n The result shows approximately how many clients your server can handle. See this document to get more info on how to increase this number. If you install Centrifugo using RPM from repo then it automatically sets max open files limit to 65536. You may also need to increase max open files for Nginx.","title":"open files limit"},{"location":"deploy/tuning/#lots-of-sockets-in-time_wait-state","text":"Look how many socket descriptors in TIME_WAIT state. netstat -an |grep TIME_WAIT | grep CENTRIFUGO_PID | wc -l Under load when lots of connections and disconnection happen lots of used socket descriptors can stay in TIME_WAIT state. Those descriptors can not be reused for a while. So you can get various errors when using Centrifugo. For example something like (99: Cannot assign requested address) while connecting to upstream in Nginx error log and 502 on client side. In this case there are several advices that can help. Nice article about TIME_WAIT sockets: http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html There is a perfect article about operating system tuning for lots of connections: https://engineering.gosquared.com/optimising-nginx-node-js-and-networking-for-heavy-workloads . To summarize: Increase ip_local_port_range If you are using Nginx set keepalive directive in upstream. upstream centrifugo { #sticky; ip_hash; server 127.0.0.1:8000; keepalive 512; } And finally if the problem is not gone away consider trying to enable net.ipv4.tcp_tw_reuse","title":"lots of sockets in TIME_WAIT state."},{"location":"libraries/api/","text":"HTTP API clients \u00b6 If you look at server API docs you will find that sending API request to Centrifugo is a very simple task to do in any programming language - this is just a POST request with JSON payload in body and Authorization header. See more in special chapter in server section. We have several official client libraries for different languages so you don't have to construct proper HTTP requests manually: cent for Python phpcent for PHP gocent for Go rubycent for Ruby ( not available for Centrifugo v2 yet ) jscent for NodeJS ( not available for Centrifugo v2 yet ) Also there are libraries supported by community: laravel-centrifugo for Laravel framework crystalcent for Crystal language CentrifugoBundle for Symfony framework Also, keep in mind that Centrifugo has GRPC API so you can automatically generate client API code for your language.","title":"API libraries"},{"location":"libraries/api/#http-api-clients","text":"If you look at server API docs you will find that sending API request to Centrifugo is a very simple task to do in any programming language - this is just a POST request with JSON payload in body and Authorization header. See more in special chapter in server section. We have several official client libraries for different languages so you don't have to construct proper HTTP requests manually: cent for Python phpcent for PHP gocent for Go rubycent for Ruby ( not available for Centrifugo v2 yet ) jscent for NodeJS ( not available for Centrifugo v2 yet ) Also there are libraries supported by community: laravel-centrifugo for Laravel framework crystalcent for Crystal language CentrifugoBundle for Symfony framework Also, keep in mind that Centrifugo has GRPC API so you can automatically generate client API code for your language.","title":"HTTP API clients"},{"location":"libraries/client/","text":"Client libraries \u00b6 These libraries allow your users to connect to Centrifugo from application frontend. centrifuge-js \u2013 for browser, NodeJS and React Native centrifuge-go - for Go language centrifuge-mobile - for iOS/Android with centrifuge-go as basis and gomobile centrifuge-dart - for Dart and Flutter centrifuge-swift \u2013 for native iOS development centrifuge-java \u2013 for native Android development and general Java","title":"Client libraries"},{"location":"libraries/client/#client-libraries","text":"These libraries allow your users to connect to Centrifugo from application frontend. centrifuge-js \u2013 for browser, NodeJS and React Native centrifuge-go - for Go language centrifuge-mobile - for iOS/Android with centrifuge-go as basis and gomobile centrifuge-dart - for Dart and Flutter centrifuge-swift \u2013 for native iOS development centrifuge-java \u2013 for native Android development and general Java","title":"Client libraries"},{"location":"misc/benchmark/","text":"Benchmark \u00b6 In order to get an understanding about possible hardware requirements for reasonably massive Centrifugo setup we made a test stand inside Kubernetes. Our goal was to run server based on Centrifuge library (the core of Centrifugo server) with one million WebSocket connections and send many messages to connected clients. While sending many messages we have been looking at delivery time latency. In fact we will see that about 30 million messages per minute (500k messages per second) will be delivered to connected clients and latency won't be larger than 200ms in 99 percentile. Server nodes have been run on machines with the following configuration: CPU Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz Linux Debian 4.9.65-3+deb9u1 (2017-12-23) x86_64 GNU/Linux Some sysctl values: fs.file-max = 3276750 fs.nr_open = 1048576 net.ipv4.tcp_mem = 3086496 4115330 6172992 net.ipv4.tcp_rmem = 8192 8388608 16777216 net.ipv4.tcp_wmem = 4096 4194394 16777216 net.core.rmem_max = 33554432 net.core.wmem_max = 33554432 Kubernetes used these machines as its nodes. We started 20 Centrifuge-based server pods. Our clients connected to server pods using Centrifuge Protobuf protocol. To scale horizontally we used Redis Engine and sharded it to 5 different Redis instances (each Redis instance consumes 1 CPU max). To achieve many client connections we used 100 Kubernetes pods each generating about 10k client connections to server. Here are some numbers we achieved: 1 million WebSocket connections Each connection subscribed to 2 channels: one personal channel and one group channel (with 10 subscribers in it), i.e. we had about 1.1 million active channels at each moment. 28 million messages per minute (about 500k per second) delivered to clients 200k per minute constant connect/disconnect rate to simulate real-life situation where clients connect/disconnect from server 200ms delivery latency in 99 percentile The size of each published message was about 100 bytes And here are some numbers about final resource usage on server side (we don't actually interested in client side resource usage here): 40 CPU total for server nodes when load achieved values claimed above (20 pods, ~2 CPU each) 27 GB of RAM used mostly to handle 1 mln WebSocket connections, i.e. about 30kb RAM per connection 0.32 CPU usage on every Redis instance 100 mbit/sec rx \u0438 150 mbit/sec tx of network used on each server pod The picture that demonstrates experiment (better to open image in new tab): This also demonstrates that to handle one million of WebSocket connections without many messages sent to clients you need about 10 CPU total for server nodes and about 5% of CPU on each of Redis instances. In this case CPU mostly spent on connect/disconnect flow, ping/pong frames, subscriptions to channels. If we enable history and history message recovery features we see an increased Redis CPU usage: 64% instead of 32% on the same workload. Other resources usage is pretty the same. The results mean that one can theoretically achieve the comparable numbers on single modern server machine. But numbers can vary a lot in case of different load scenarios. In this benchmark we looked at basic use case where we only connect many clients and send Publications to them. There are many features in Centrifuge library and in Centrifugo not covered by this artificial experiment. Also note that though benchmark was made for Centrifuge library for Centrifugo you can expect similar results. Read and write buffer sizes of websocket connections were set to 512 kb on server side (sizes of buffers affect memory usage), with Centrifugo this means that to reproduce the same configuration you need to set: { ... \"websocket_read_buffer_size\" : 512 , \"websocket_write_buffer_size\" : 512 }","title":"Benchmark"},{"location":"misc/benchmark/#benchmark","text":"In order to get an understanding about possible hardware requirements for reasonably massive Centrifugo setup we made a test stand inside Kubernetes. Our goal was to run server based on Centrifuge library (the core of Centrifugo server) with one million WebSocket connections and send many messages to connected clients. While sending many messages we have been looking at delivery time latency. In fact we will see that about 30 million messages per minute (500k messages per second) will be delivered to connected clients and latency won't be larger than 200ms in 99 percentile. Server nodes have been run on machines with the following configuration: CPU Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz Linux Debian 4.9.65-3+deb9u1 (2017-12-23) x86_64 GNU/Linux Some sysctl values: fs.file-max = 3276750 fs.nr_open = 1048576 net.ipv4.tcp_mem = 3086496 4115330 6172992 net.ipv4.tcp_rmem = 8192 8388608 16777216 net.ipv4.tcp_wmem = 4096 4194394 16777216 net.core.rmem_max = 33554432 net.core.wmem_max = 33554432 Kubernetes used these machines as its nodes. We started 20 Centrifuge-based server pods. Our clients connected to server pods using Centrifuge Protobuf protocol. To scale horizontally we used Redis Engine and sharded it to 5 different Redis instances (each Redis instance consumes 1 CPU max). To achieve many client connections we used 100 Kubernetes pods each generating about 10k client connections to server. Here are some numbers we achieved: 1 million WebSocket connections Each connection subscribed to 2 channels: one personal channel and one group channel (with 10 subscribers in it), i.e. we had about 1.1 million active channels at each moment. 28 million messages per minute (about 500k per second) delivered to clients 200k per minute constant connect/disconnect rate to simulate real-life situation where clients connect/disconnect from server 200ms delivery latency in 99 percentile The size of each published message was about 100 bytes And here are some numbers about final resource usage on server side (we don't actually interested in client side resource usage here): 40 CPU total for server nodes when load achieved values claimed above (20 pods, ~2 CPU each) 27 GB of RAM used mostly to handle 1 mln WebSocket connections, i.e. about 30kb RAM per connection 0.32 CPU usage on every Redis instance 100 mbit/sec rx \u0438 150 mbit/sec tx of network used on each server pod The picture that demonstrates experiment (better to open image in new tab): This also demonstrates that to handle one million of WebSocket connections without many messages sent to clients you need about 10 CPU total for server nodes and about 5% of CPU on each of Redis instances. In this case CPU mostly spent on connect/disconnect flow, ping/pong frames, subscriptions to channels. If we enable history and history message recovery features we see an increased Redis CPU usage: 64% instead of 32% on the same workload. Other resources usage is pretty the same. The results mean that one can theoretically achieve the comparable numbers on single modern server machine. But numbers can vary a lot in case of different load scenarios. In this benchmark we looked at basic use case where we only connect many clients and send Publications to them. There are many features in Centrifuge library and in Centrifugo not covered by this artificial experiment. Also note that though benchmark was made for Centrifuge library for Centrifugo you can expect similar results. Read and write buffer sizes of websocket connections were set to 512 kb on server side (sizes of buffers affect memory usage), with Centrifugo this means that to reproduce the same configuration you need to set: { ... \"websocket_read_buffer_size\" : 512 , \"websocket_write_buffer_size\" : 512 }","title":"Benchmark"},{"location":"misc/insecure_modes/","text":"Insecure modes \u00b6 This chapter describes several insecure options that enable several insecure modes in Centrifugo. Insecure client connection \u00b6 The boolean option client_insecure (default false ) allows to connect to Centrifugo without JWT token. This means there is no user authentication involved. This mode can be useful to demo projects based on Centrifugo, personal projects or real-time application prototyping. Insecure API mode \u00b6 This mode can be enabled using boolean option api_insecure (default false ). When on there is no need to provide API key in HTTP requests. When using this mode everyone that has access to /api endpoint can send any command to server. Enabling this option can be reasonable if /api endpoint protected by firewall rules. The option is also useful in development to simplify sending API commands to Centrifugo using CURL for example without specifying Authorization header in requests. Insecure admin mode \u00b6 This mode can be enabled using boolean option admin_insecure (default false ). When on there is no authentication in admin web interface. Again - this is not secure but can be justified if you protected admin interface by firewall rules or you want to use basic authentication for Centrifugo admin interface.","title":"Insecure modes"},{"location":"misc/insecure_modes/#insecure-modes","text":"This chapter describes several insecure options that enable several insecure modes in Centrifugo.","title":"Insecure modes"},{"location":"misc/insecure_modes/#insecure-client-connection","text":"The boolean option client_insecure (default false ) allows to connect to Centrifugo without JWT token. This means there is no user authentication involved. This mode can be useful to demo projects based on Centrifugo, personal projects or real-time application prototyping.","title":"Insecure client connection"},{"location":"misc/insecure_modes/#insecure-api-mode","text":"This mode can be enabled using boolean option api_insecure (default false ). When on there is no need to provide API key in HTTP requests. When using this mode everyone that has access to /api endpoint can send any command to server. Enabling this option can be reasonable if /api endpoint protected by firewall rules. The option is also useful in development to simplify sending API commands to Centrifugo using CURL for example without specifying Authorization header in requests.","title":"Insecure API mode"},{"location":"misc/insecure_modes/#insecure-admin-mode","text":"This mode can be enabled using boolean option admin_insecure (default false ). When on there is no authentication in admin web interface. Again - this is not secure but can be justified if you protected admin interface by firewall rules or you want to use basic authentication for Centrifugo admin interface.","title":"Insecure admin mode"},{"location":"misc/migrate/","text":"Migration notes from Centrifugo v1 \u00b6 In version 2 of Centrifugo many things changed in backwards incompatible way comparing to version 1. This document aims to help Centrifugo v1 users to migrate their projects to version 2 (if they want to). New client protocol and client libraries \u00b6 In Centrifugo v2 internal client-server protocol changed meaning that old client library version won't work with new server. So first step in migrating - update client libraries to new version with Centrifugo v2 support. While refactoring client's API changed a bit so you have to adapt your code to those changes. For the moment of this writing we have no native mobile libraries for Centrifugo v2. So if you are using centrifuge-ios or centrifuge-android then you can't migrate to v2 until those libraries will be ported. Migrate communication with API \u00b6 Centrifugo v2 simplified communication with API - requests should not be signed with secret key anymore thus you can simply integrate your backend with Centrifugo without using any of our helper libraries - just send JSON API command as POST request to api endpoint. Don't forget to use api key and protect API endpoint with TLS (more information in server API description document). Centrifugo v1 could process messages published in Redis queue. In v2 this possibility was removed because this technique is not good in terms of error handling and non-deterministic delay before message will be processed by Centrifugo node worker. Migrate to using HTTP or GRPC API. Use JWT instead of hand-crafted connection token \u00b6 In Centrifugo v2 you must use JWT instead of hand-crafted tokens of v1. This means that you need to download JWT library for your language (there are plenty of them \u2013 see jwt.io) and build connection token with it. See dedicated docs chapter to see how token can be built. All connection information will be passed inside this single token string. This means you only need to pass one string to your frontend. No need to pass user , timestamp , info anymore. This also means that you will have less problems with escaping features of template engines - because JWT is safe base64 string. Connection expiration (connection check mechanism) now based on exp claim of JWT \u2013 you don't need to enable it globally in configuration. Use JWT instead of hand-crafted signature for private subscriptions \u00b6 Read chapter about private subscriptions to find how you should now use JWT for private channel subscriptions. Channel options changed \u00b6 Channel option recover now called history_recover . There is no watch channel option anymore - in Centrifugo v2 admin websocket connection was removed as it made code base much more overhelmed for almost nothing. SockJS endpoint changed \u00b6 It's now /connection/sockjs instead of /connection New way to export metrics \u00b6 Centrifugo is now uses Prometheus primitives internally so if you are using Prometheus you can simply configure it to monitor Centrifugo. Also Centrifugo is able to automatically convert and export metrics to Graphite. See special Monitoring chapter in server docs. Previously you have to periodically call stats command and export metrics manually. This is gone in Centrifugo v2. Options renamed \u00b6 Some of advanced options have been renamed \u2013 if you are using advanced configuration then refer to documentation to find actual option names. No client limited channels anymore \u00b6 That was a pretty useless feature of Centrifugo v1. New reserved symbols in channel name \u00b6 Symbols * and / in channel name are now reserved for Centrifugo future needs - please do not use it in channels. Centrifugo v1 repos \u00b6 Here some links for those who still use Centrifugo v1 Centrifugo v1 source code Centrifugo v1 documentation centrifuge-js v1 centrifuge-go centrifuge-mobile examples","title":"Migrate from Centrifugo v1"},{"location":"misc/migrate/#migration-notes-from-centrifugo-v1","text":"In version 2 of Centrifugo many things changed in backwards incompatible way comparing to version 1. This document aims to help Centrifugo v1 users to migrate their projects to version 2 (if they want to).","title":"Migration notes from Centrifugo v1"},{"location":"misc/migrate/#new-client-protocol-and-client-libraries","text":"In Centrifugo v2 internal client-server protocol changed meaning that old client library version won't work with new server. So first step in migrating - update client libraries to new version with Centrifugo v2 support. While refactoring client's API changed a bit so you have to adapt your code to those changes. For the moment of this writing we have no native mobile libraries for Centrifugo v2. So if you are using centrifuge-ios or centrifuge-android then you can't migrate to v2 until those libraries will be ported.","title":"New client protocol and client libraries"},{"location":"misc/migrate/#migrate-communication-with-api","text":"Centrifugo v2 simplified communication with API - requests should not be signed with secret key anymore thus you can simply integrate your backend with Centrifugo without using any of our helper libraries - just send JSON API command as POST request to api endpoint. Don't forget to use api key and protect API endpoint with TLS (more information in server API description document). Centrifugo v1 could process messages published in Redis queue. In v2 this possibility was removed because this technique is not good in terms of error handling and non-deterministic delay before message will be processed by Centrifugo node worker. Migrate to using HTTP or GRPC API.","title":"Migrate communication with API"},{"location":"misc/migrate/#use-jwt-instead-of-hand-crafted-connection-token","text":"In Centrifugo v2 you must use JWT instead of hand-crafted tokens of v1. This means that you need to download JWT library for your language (there are plenty of them \u2013 see jwt.io) and build connection token with it. See dedicated docs chapter to see how token can be built. All connection information will be passed inside this single token string. This means you only need to pass one string to your frontend. No need to pass user , timestamp , info anymore. This also means that you will have less problems with escaping features of template engines - because JWT is safe base64 string. Connection expiration (connection check mechanism) now based on exp claim of JWT \u2013 you don't need to enable it globally in configuration.","title":"Use JWT instead of hand-crafted connection token"},{"location":"misc/migrate/#use-jwt-instead-of-hand-crafted-signature-for-private-subscriptions","text":"Read chapter about private subscriptions to find how you should now use JWT for private channel subscriptions.","title":"Use JWT instead of hand-crafted signature for private subscriptions"},{"location":"misc/migrate/#channel-options-changed","text":"Channel option recover now called history_recover . There is no watch channel option anymore - in Centrifugo v2 admin websocket connection was removed as it made code base much more overhelmed for almost nothing.","title":"Channel options changed"},{"location":"misc/migrate/#sockjs-endpoint-changed","text":"It's now /connection/sockjs instead of /connection","title":"SockJS endpoint changed"},{"location":"misc/migrate/#new-way-to-export-metrics","text":"Centrifugo is now uses Prometheus primitives internally so if you are using Prometheus you can simply configure it to monitor Centrifugo. Also Centrifugo is able to automatically convert and export metrics to Graphite. See special Monitoring chapter in server docs. Previously you have to periodically call stats command and export metrics manually. This is gone in Centrifugo v2.","title":"New way to export metrics"},{"location":"misc/migrate/#options-renamed","text":"Some of advanced options have been renamed \u2013 if you are using advanced configuration then refer to documentation to find actual option names.","title":"Options renamed"},{"location":"misc/migrate/#no-client-limited-channels-anymore","text":"That was a pretty useless feature of Centrifugo v1.","title":"No client limited channels anymore"},{"location":"misc/migrate/#new-reserved-symbols-in-channel-name","text":"Symbols * and / in channel name are now reserved for Centrifugo future needs - please do not use it in channels.","title":"New reserved symbols in channel name"},{"location":"misc/migrate/#centrifugo-v1-repos","text":"Here some links for those who still use Centrifugo v1 Centrifugo v1 source code Centrifugo v1 documentation centrifuge-js v1 centrifuge-go centrifuge-mobile examples","title":"Centrifugo v1 repos"},{"location":"pro/","text":"Centrifugo PRO \u00b6 Centrifugo becomes more popular and is used in many projects over the world. Since it's rather big project I need more and more time to maintain it healthy, improve client libraries and introduce new features. I am considering to create a PRO version of Centrifugo. It may include some additional features on top of open-source Centrifugo version. This version will have some model of monetization, I am still evaluating whether it's reasonable to have and will be in demand. An alternative to PRO version is our Centrifugal OpenCollective organization \u2013 personally I prefer this way of becoming sustainable since it does not involve creating custom closed-source version of Centrifugo. Please contact me (see email address in my GitHub profile ) if you are interested in having additional features mentioned below and have any ideas on how to keep Centrifugo development sustainable. Real-time connection analytics with Clickhouse \u00b6 This feature will allow exporting information about connections, subscriptions and client operations to ClickHouse thus providing real-time analytics with seconds delay. ClickHouse is fast and simple to operate with, and it allows effective data keeping for a window of time. With analytics, one will be able to inspect the state of a system in detail with a connection resolution. This adds a greater observability, also the possibility to do data analysis and various reports. User operation throttling \u00b6 Throttle any operation per user ID using token bucket algorithm and sharded Redis (or sharded Redis Cluster). Throttle connect, subscribe, publish, history, presence, RPC operations. You can also throttle RPC by method. If user exceeded configured limit for an operation it will receive a special error in response. User active status \u00b6 Centrifugo has presence feature for channels. It works well (for channels with reasonably small number of active subscribers though), but sometimes you need a bit different functionality. What if all you want is get specific user active status based on its recent activity in app? You can create a personal channel with presence enabled for each user. It will show that user connected to a server. But this won't show whether user did some actions in your app or just left it open while not actually using it. User active status feature will allow calling a special RPC method from client side when your user makes some useful action in application (clicks on buttons, uses mouse \u2013 which means that user really uses your app at moment, not just connected to a server in background, and of course you still can call this RPC periodically), this RPC call will set user's last active time value in Redis (again with sharding and Cluster support). On backend side you will have access to a bulk API to get active status of particular users effectively. So you can get last time user was active in your app. Information about active status will be kept in Redis for a configured time interval, then expire. This feature can be useful for chat applications when you need to get online/activity status for a list of buddies. BTW it's already possible to implement without Centrifugo (we have this as advice in FAQ) but builtin possibility seems a nice thing to have.","title":"About"},{"location":"pro/#centrifugo-pro","text":"Centrifugo becomes more popular and is used in many projects over the world. Since it's rather big project I need more and more time to maintain it healthy, improve client libraries and introduce new features. I am considering to create a PRO version of Centrifugo. It may include some additional features on top of open-source Centrifugo version. This version will have some model of monetization, I am still evaluating whether it's reasonable to have and will be in demand. An alternative to PRO version is our Centrifugal OpenCollective organization \u2013 personally I prefer this way of becoming sustainable since it does not involve creating custom closed-source version of Centrifugo. Please contact me (see email address in my GitHub profile ) if you are interested in having additional features mentioned below and have any ideas on how to keep Centrifugo development sustainable.","title":"Centrifugo PRO"},{"location":"pro/#real-time-connection-analytics-with-clickhouse","text":"This feature will allow exporting information about connections, subscriptions and client operations to ClickHouse thus providing real-time analytics with seconds delay. ClickHouse is fast and simple to operate with, and it allows effective data keeping for a window of time. With analytics, one will be able to inspect the state of a system in detail with a connection resolution. This adds a greater observability, also the possibility to do data analysis and various reports.","title":"Real-time connection analytics with Clickhouse"},{"location":"pro/#user-operation-throttling","text":"Throttle any operation per user ID using token bucket algorithm and sharded Redis (or sharded Redis Cluster). Throttle connect, subscribe, publish, history, presence, RPC operations. You can also throttle RPC by method. If user exceeded configured limit for an operation it will receive a special error in response.","title":"User operation throttling"},{"location":"pro/#user-active-status","text":"Centrifugo has presence feature for channels. It works well (for channels with reasonably small number of active subscribers though), but sometimes you need a bit different functionality. What if all you want is get specific user active status based on its recent activity in app? You can create a personal channel with presence enabled for each user. It will show that user connected to a server. But this won't show whether user did some actions in your app or just left it open while not actually using it. User active status feature will allow calling a special RPC method from client side when your user makes some useful action in application (clicks on buttons, uses mouse \u2013 which means that user really uses your app at moment, not just connected to a server in background, and of course you still can call this RPC periodically), this RPC call will set user's last active time value in Redis (again with sharding and Cluster support). On backend side you will have access to a bulk API to get active status of particular users effectively. So you can get last time user was active in your app. Information about active status will be kept in Redis for a configured time interval, then expire. This feature can be useful for chat applications when you need to get online/activity status for a list of buddies. BTW it's already possible to implement without Centrifugo (we have this as advice in FAQ) but builtin possibility seems a nice thing to have.","title":"User active status"},{"location":"server/admin/","text":"Admin web interface \u00b6 Centrifugo comes with builtin admin web interface. It can: show general information and statistics from server nodes call publish , broadcast , unsubscribe , disconnect , history , presence , presence_stats , channels , info server API commands. For publish command Ace JSON editor helps to write JSON to send into channel. To enable admin interface you must run centrifugo with --admin and provide some security options in configuration file. centrifugo --config = config.json --admin Also you must set two options in config: admin_password and admin_secret : { ... , \"admin_password\" : \"<PASSWORD>\" , \"admin_secret\" : \"<SECRET>\" } admin_password \u2013 this is a password to log into admin web interface admin_secret - this is a secret key for authentication token set on successful login. Make both strong and keep in secret. After setting this in config go to http://localhost:8000 (by default) - and you should see web interface. Although there is password based authentication a good advice is to protect web interface by firewall rules in production. If you don't want to use embedded web interface you can specify path to your own custom web interface directory: { ... , \"admin_password\" : \"<PASSWORD>\" , \"admin_secret\" : \"<SECRET>\" , \"admin_web_path\" : \"<PATH>\" } This can be useful if you want to modify official web interface code in some way. There is also an option to run Centrifugo in insecure admin mode - in this case you don't need to set admin_password and admin_secret in config \u2013 in web interface you will be logged in automatically without any password. Note that this is only an option for production if you protected admin web interface with firewall rules. Otherwise anyone in internet will have full access to admin functionality described above. To start Centrifugo with admin web interface in insecure admin mode run: centrifugo --config=config.json --admin --admin_insecure","title":"Admin web interface"},{"location":"server/admin/#admin-web-interface","text":"Centrifugo comes with builtin admin web interface. It can: show general information and statistics from server nodes call publish , broadcast , unsubscribe , disconnect , history , presence , presence_stats , channels , info server API commands. For publish command Ace JSON editor helps to write JSON to send into channel. To enable admin interface you must run centrifugo with --admin and provide some security options in configuration file. centrifugo --config = config.json --admin Also you must set two options in config: admin_password and admin_secret : { ... , \"admin_password\" : \"<PASSWORD>\" , \"admin_secret\" : \"<SECRET>\" } admin_password \u2013 this is a password to log into admin web interface admin_secret - this is a secret key for authentication token set on successful login. Make both strong and keep in secret. After setting this in config go to http://localhost:8000 (by default) - and you should see web interface. Although there is password based authentication a good advice is to protect web interface by firewall rules in production. If you don't want to use embedded web interface you can specify path to your own custom web interface directory: { ... , \"admin_password\" : \"<PASSWORD>\" , \"admin_secret\" : \"<SECRET>\" , \"admin_web_path\" : \"<PATH>\" } This can be useful if you want to modify official web interface code in some way. There is also an option to run Centrifugo in insecure admin mode - in this case you don't need to set admin_password and admin_secret in config \u2013 in web interface you will be logged in automatically without any password. Note that this is only an option for production if you protected admin web interface with firewall rules. Otherwise anyone in internet will have full access to admin functionality described above. To start Centrifugo with admin web interface in insecure admin mode run: centrifugo --config=config.json --admin --admin_insecure","title":"Admin web interface"},{"location":"server/authentication/","text":"Authentication \u00b6 When you are using centrifuge library from Go language you can implement any user authentication using middleware. In Centrifugo case you need to tell a server who is connecting in well-known predefined way. This chapter describes a mechanism of authenticating user over JSON Web Token (JWT). Note If you prefer to avoid using JWT then look at the proxy feature . It allows proxying connection request from Centrifugo to your backend for authentication details. Upon connecting to Centrifugo client must provide connection JWT with several predefined credential claims. If you've never heard about JWT before - refer to jwt.io page. At moment the only supported JWT algorithms are HMAC, RSA and ECDSA - i.e. HS256, HS384, HS512, RSA256, RSA384, RSA512, EC256, EC384, EC512. This can be extended later. RSA algorithm is available since v2.3.0 release. ECDSA algorithm is available since v2.8.2 release. We will use Javascript Centrifugo client here for example snippets for client side and PyJWT Python library to generate connection token on backend side. To add HMAC secret key to Centrifugo add token_hmac_secret_key to configuration file: { \"token_hmac_secret_key\" : \"<YOUR-SECRET-STRING-HERE>\" , ... } To add RSA public key (must be PEM encoded string) add token_rsa_public_key option, ex: { \"token_rsa_public_key\" : \"-----BEGIN PUBLIC KEY-----\\nMFwwDQYJKoZ...\" , ... } To add ECDSA public key (must be PEM encoded string) add token_ecdsa_public_key option, ex: { \"token_ecdsa_public_key\" : \"-----BEGIN PUBLIC KEY-----\\nxyz23adf...\" , ... } Claims \u00b6 Centrifugo uses the following claims in a JWT: sub , exp , info and b64info . What do they mean? Let's describe in detail. sub \u00b6 This is a standard JWT claim which must contain an ID of current application user ( as string ). If your user not currently authenticated in your application, but you want to let him connect to Centrifugo anyway \u2013 you can use empty string as user ID in this sub claim. This is called anonymous access. In this case anonymous option must be enabled in Centrifugo configuration for channels that client will subscribe to. exp \u00b6 This is a UNIX timestamp seconds when token will expire. This is standard JWT claim - all JWT libraries for different languages provide an API to set it. If exp claim not provided then Centrifugo won't expire any connections. When provided special algorithm will find connections with exp in the past and activate connection refresh mechanism. Refresh mechanism allows connection to survive and be prolonged. In case of refresh failure client connection will be eventually closed by Centrifugo and won't be accepted until new valid and actual credentials provided in connection token. You can use connection expiration mechanism in cases when you don't want users of your app to be subscribed on channels after being banned/deactivated in application. Or to protect your users from a token leakage (providing a reasonably short time of expiration). Choose exp value wisely, you don't need small values because refresh mechanism will hit your application often with refresh requests. But setting this value too large can lead to non very fast user connection deactivation. This is a trade off. Read more about connection expiration in a special chapter. info \u00b6 This claim is optional - this is additional information about client connection that can be provided for Centrifugo. This information will be included in presence information, join/leave events and in channel publication message if it was published from client side. b64info \u00b6 If you are using binary protobuf protocol you may want info to be custom bytes. Use this field in this case. This field contains a base64 representation of your bytes. After receiving Centrifugo will decode base64 back to bytes and will embed result into various places described above. channels \u00b6 New in v2.4.0 An optional array of strings with server-side channels. See more details about server-side subscriptions . Examples \u00b6 Let's look how to generate connection HS256 JWT in Python: Simplest token \u00b6 import jwt token = jwt . encode ({ \"sub\" : \"42\" }, \"secret\" ) . decode () print ( token ) Note that we use the value of secret from Centrifugo config here (in this case secret value is just secret ). The only two who must know secret key is your application backend which generates JWT and Centrifugo itself. You should never show secret key to your users. Then you can pass this token to your client side and use it when connecting to Centrifugo: var centrifuge = new Centrifuge ( \"ws://localhost:8000/connection/websocket\" ); centrifuge . setToken ( token ); centrifuge . connect (); Token with expiration \u00b6 Token that will be valid for 5 minutes: import jwt import time claims = { \"sub\" : \"42\" , \"exp\" : int ( time . time ()) + 5 * 60 } token = jwt . encode ( claims , \"secret\" , algorithm = \"HS256\" ) . decode () print ( token ) Token with additional connection info \u00b6 import jwt claims = { \"sub\" : \"42\" , \"info\" : { \"name\" : \"Alexander Emelin\" }} token = jwt . encode ( claims , \"secret\" , algorithm = \"HS256\" ) . decode () print ( token ) Investigating problems with JWT \u00b6 You can use jwt.io site to investigate contents of your tokens. Also server logs usually contain some useful information. JSON Web Key support \u00b6 Starting from v2.8.2 Centrifugo supports JSON Web Key (JWK) spec . This means that it's possible to improve JWT security by providing an endpoint to Centrifugo from where to load JWK (by looking at kid header of JWT). A mechanism can be enabled by providing token_jwks_public_endpoint string option to Centrifugo (HTTP address). As soon as token_jwks_public_endpoint set all tokens will be verified using JSON Web Key Set loaded from JWKS endpoint. This makes it impossible to use non-JWK based tokens to connect and subscribe to private channels. At the moment Centrifugo caches keys loaded from an endpoint for one hour. Centrifugo will load keys from JWKS endpoint by issuing GET HTTP request with 1 second timeout and one retry in case of failure (not configurable at the moment). Only RSA algorithm supported. JWKS support enabled both for connection and private channel subscription tokens.","title":"Authentication"},{"location":"server/authentication/#authentication","text":"When you are using centrifuge library from Go language you can implement any user authentication using middleware. In Centrifugo case you need to tell a server who is connecting in well-known predefined way. This chapter describes a mechanism of authenticating user over JSON Web Token (JWT). Note If you prefer to avoid using JWT then look at the proxy feature . It allows proxying connection request from Centrifugo to your backend for authentication details. Upon connecting to Centrifugo client must provide connection JWT with several predefined credential claims. If you've never heard about JWT before - refer to jwt.io page. At moment the only supported JWT algorithms are HMAC, RSA and ECDSA - i.e. HS256, HS384, HS512, RSA256, RSA384, RSA512, EC256, EC384, EC512. This can be extended later. RSA algorithm is available since v2.3.0 release. ECDSA algorithm is available since v2.8.2 release. We will use Javascript Centrifugo client here for example snippets for client side and PyJWT Python library to generate connection token on backend side. To add HMAC secret key to Centrifugo add token_hmac_secret_key to configuration file: { \"token_hmac_secret_key\" : \"<YOUR-SECRET-STRING-HERE>\" , ... } To add RSA public key (must be PEM encoded string) add token_rsa_public_key option, ex: { \"token_rsa_public_key\" : \"-----BEGIN PUBLIC KEY-----\\nMFwwDQYJKoZ...\" , ... } To add ECDSA public key (must be PEM encoded string) add token_ecdsa_public_key option, ex: { \"token_ecdsa_public_key\" : \"-----BEGIN PUBLIC KEY-----\\nxyz23adf...\" , ... }","title":"Authentication"},{"location":"server/authentication/#claims","text":"Centrifugo uses the following claims in a JWT: sub , exp , info and b64info . What do they mean? Let's describe in detail.","title":"Claims"},{"location":"server/authentication/#sub","text":"This is a standard JWT claim which must contain an ID of current application user ( as string ). If your user not currently authenticated in your application, but you want to let him connect to Centrifugo anyway \u2013 you can use empty string as user ID in this sub claim. This is called anonymous access. In this case anonymous option must be enabled in Centrifugo configuration for channels that client will subscribe to.","title":"sub"},{"location":"server/authentication/#exp","text":"This is a UNIX timestamp seconds when token will expire. This is standard JWT claim - all JWT libraries for different languages provide an API to set it. If exp claim not provided then Centrifugo won't expire any connections. When provided special algorithm will find connections with exp in the past and activate connection refresh mechanism. Refresh mechanism allows connection to survive and be prolonged. In case of refresh failure client connection will be eventually closed by Centrifugo and won't be accepted until new valid and actual credentials provided in connection token. You can use connection expiration mechanism in cases when you don't want users of your app to be subscribed on channels after being banned/deactivated in application. Or to protect your users from a token leakage (providing a reasonably short time of expiration). Choose exp value wisely, you don't need small values because refresh mechanism will hit your application often with refresh requests. But setting this value too large can lead to non very fast user connection deactivation. This is a trade off. Read more about connection expiration in a special chapter.","title":"exp"},{"location":"server/authentication/#info","text":"This claim is optional - this is additional information about client connection that can be provided for Centrifugo. This information will be included in presence information, join/leave events and in channel publication message if it was published from client side.","title":"info"},{"location":"server/authentication/#b64info","text":"If you are using binary protobuf protocol you may want info to be custom bytes. Use this field in this case. This field contains a base64 representation of your bytes. After receiving Centrifugo will decode base64 back to bytes and will embed result into various places described above.","title":"b64info"},{"location":"server/authentication/#channels","text":"New in v2.4.0 An optional array of strings with server-side channels. See more details about server-side subscriptions .","title":"channels"},{"location":"server/authentication/#examples","text":"Let's look how to generate connection HS256 JWT in Python:","title":"Examples"},{"location":"server/authentication/#simplest-token","text":"import jwt token = jwt . encode ({ \"sub\" : \"42\" }, \"secret\" ) . decode () print ( token ) Note that we use the value of secret from Centrifugo config here (in this case secret value is just secret ). The only two who must know secret key is your application backend which generates JWT and Centrifugo itself. You should never show secret key to your users. Then you can pass this token to your client side and use it when connecting to Centrifugo: var centrifuge = new Centrifuge ( \"ws://localhost:8000/connection/websocket\" ); centrifuge . setToken ( token ); centrifuge . connect ();","title":"Simplest token"},{"location":"server/authentication/#token-with-expiration","text":"Token that will be valid for 5 minutes: import jwt import time claims = { \"sub\" : \"42\" , \"exp\" : int ( time . time ()) + 5 * 60 } token = jwt . encode ( claims , \"secret\" , algorithm = \"HS256\" ) . decode () print ( token )","title":"Token with expiration"},{"location":"server/authentication/#token-with-additional-connection-info","text":"import jwt claims = { \"sub\" : \"42\" , \"info\" : { \"name\" : \"Alexander Emelin\" }} token = jwt . encode ( claims , \"secret\" , algorithm = \"HS256\" ) . decode () print ( token )","title":"Token with additional connection info"},{"location":"server/authentication/#investigating-problems-with-jwt","text":"You can use jwt.io site to investigate contents of your tokens. Also server logs usually contain some useful information.","title":"Investigating problems with JWT"},{"location":"server/authentication/#json-web-key-support","text":"Starting from v2.8.2 Centrifugo supports JSON Web Key (JWK) spec . This means that it's possible to improve JWT security by providing an endpoint to Centrifugo from where to load JWK (by looking at kid header of JWT). A mechanism can be enabled by providing token_jwks_public_endpoint string option to Centrifugo (HTTP address). As soon as token_jwks_public_endpoint set all tokens will be verified using JSON Web Key Set loaded from JWKS endpoint. This makes it impossible to use non-JWK based tokens to connect and subscribe to private channels. At the moment Centrifugo caches keys loaded from an endpoint for one hour. Centrifugo will load keys from JWKS endpoint by issuing GET HTTP request with 1 second timeout and one retry in case of failure (not configurable at the moment). Only RSA algorithm supported. JWKS support enabled both for connection and private channel subscription tokens.","title":"JSON Web Key support"},{"location":"server/channels/","text":"Channels \u00b6 Channel is a route for publication messages. Clients can be subscribed to a channel to receive messages published to this channel \u2013 new publications, join/leave events (if enabled for a channel namespace) etc. Channel subscriber can also ask for channel presence or channel history information (if enabled for a channel namespace). Channel is just a string - news , comments are valid channel names. Though this string has some predefined rules as we will see below. Channel is an ephemeral entity \u2013 you don't need to create it explicitly . Channel created automatically by Centrifugo as soon as first client subscribes to it. As soon as last subscriber leaves channel - it's automatically cleaned up. Channel name rules \u00b6 Only ASCII symbols must be used in channel string . Channel name length limited by 255 characters by default (can be changed via configuration file option channel_max_length ). Several symbols in channel names reserved for Centrifugo internal needs: : \u2013 for namespace channel boundary (see below) $ \u2013 for private channel prefix (see below) # \u2013 for user channel boundary (see below) * \u2013 for future Centrifugo needs & \u2013 for future Centrifugo needs / \u2013 for future Centrifugo needs namespace boundary ( : ) \u00b6 : \u2013 is a channel namespace boundary. Namespaces used to set custom options to a group of channels. Each channel belonging to the same namespace will have the same channel options. Read more about available channel options below. If channel is public:chat - then Centrifugo will apply options to this channel from channel namespace with name public . private channel prefix ( $ ) \u00b6 If channel starts with $ then it is considered private . Subscription on a private channel must be properly signed by your backend. Use private channels if you pass sensitive data inside channel and want to control access permissions on your backend. For example $secrets is a private channel, $public:chat - is a private channel that belongs namespace public . Subscription request to private channels requires additional JWT from your backend. Read detailed chapter about private channels . If you need a personal channel for a single user (or maybe channel for short and stable set of users) then consider using user-limited channel (see below) as a simpler alternative which does not require additional subscription token from your backend. user channel boundary ( # ) \u00b6 # \u2013 is a user channel boundary. This is a separator to create personal channels for users (we call this user-limited channels ) without need to provide subscription token. For example if channel is news#42 then only user with ID 42 can subscribe on this channel (Centrifugo knows user ID because clients provide it in connection credentials with connection JWT). Moreover, you can provide several user IDs in channel name separated by a comma: dialog#42,43 \u2013 in this case only user with ID 42 and user with ID 43 will be able to subscribe on this channel. This is useful for channels with static list of allowed users, for example for single user personal messages channel, for dialog channel between certainly defined users. As soon as you need dynamic user access to channel this channel type does not suit well. Channel options \u00b6 Let's look at configuration options related to channels. es published into that channel. The following options will affect channel behaviour. publish \u00b6 publish (boolean, default false ) \u2013 allow clients to publish messages into channels directly (from client side). Your application will never receive those messages. In idiomatic case all messages must be published to Centrifugo by your application backend using Centrifugo API. But this option can be useful when you want to build something without backend-side validation and saving into database. This option can also be useful for demos and prototyping real-time ideas. By default it's false . subscribe_to_publish \u00b6 subscribe_to_publish (boolean, default false ) - when publish option enabled client can publish into channel without being subscribed to it. This option enables automatic check that client subscribed on channel before allowing client to publish into channel. anonymous \u00b6 anonymous (boolean, default false ) \u2013 this option enables anonymous access (with empty sub claim in connection token). In most situations your application works with authenticated users so every user has its own unique id. But if you provide real-time features for public access you may need unauthorized access to some channels. Turn on this option and use empty string as user ID. presence \u00b6 presence (boolean, default false ) \u2013 enable/disable presence information. Presence is an information about clients currently subscribed on channel. By default this option is off so no presence information will be available for channels. presence_disable_for_client \u00b6 presence_disable_for_client (boolean, default false , available since v2.2.3) \u2013 allows making presence calls available only for server side API. By default presence information is available for both client and server side APIs. join_leave \u00b6 join_leave (boolean, default false ) \u2013 enable/disable sending join(leave) messages when client subscribes on a channel (unsubscribes from channel). history_size \u00b6 history_size (integer, default 0 ) \u2013 history size (amount of messages) for channels. As Centrifugo keeps all history messages in memory it's very important to limit maximum amount of messages in channel history to reasonable value. history_size defines maximum amount of messages that Centrifugo will keep for each channel in namespace during history lifetime (see below). By default history size is 0 - this means that channels will have no history messages at all. history_lifetime \u00b6 history_lifetime (integer, default 0 ) \u2013 interval in seconds how long to keep channel history messages. As all history is storing in memory it is also very important to get rid of old history data for unused (inactive for a long time) channels. By default history lifetime is 0 \u2013 this means that channels will have no history messages at all. So to turn on keeping history messages you should wisely configure both history_size and history_lifetime options . history_recover \u00b6 history_recover (boolean, default false ) \u2013 when enabled Centrifugo will try to recover missed publications after a client reconnects for some reason (bad internet connection for example). Also when recovery feature is on Centrifugo tries to compensate at most once delivery of PUB/SUB messages checking client position inside stream, so you get at least once delivery guarantee in history retention period and history window size. By default, this feature is off. This option must be used in conjunction with reasonably configured message history for channel i.e. history_size and history_lifetime must be set (because Centrifugo uses channel history to recover messages). Also note that not all real-time events require this feature turned on so think wisely when you need this. When this option turned on your application should be designed in a way to tolerate duplicate messages coming from channel (currently Centrifugo returns recovered publications in order and without duplicates but this is implementation detail that can be theoretically changed in future). See more details about how recovery works in special chapter . history_disable_for_client \u00b6 history_disable_for_client (boolean, default false , available since v2.2.3) \u2013 allows making history available only for a server side API. By default false \u2013 i.e. history calls are available for both client and server side APIs. History recovery mechanism if enabled will continue to work for clients anyway even if history_disable_for_client is on. server_side \u00b6 server_side (boolean, default false , available since v2.4.0) \u2013 when enabled then all client-side subscription requests to channels in namespace will be rejected with PermissionDenied error. proxy_subscribe \u00b6 proxy_subscribe (boolean, default false , available since v2.6.0) \u2013 turns on subscribe proxy, more info in proxy chapter proxy_publish \u00b6 proxy_publish (boolean, default false , available since v2.6.0) \u2013 turns on publish proxy, more info in proxy chapter Channel options config example \u00b6 Let's look how to set some of these options in a config: { \"v3_use_offset\" : true , \"token_hmac_secret_key\" : \"my-secret-key\" , \"api_key\" : \"secret-api-key\" , \"anonymous\" : true , \"publish\" : true , \"subscribe_to_publish\" : true , \"presence\" : true , \"join_leave\" : true , \"history_size\" : 10 , \"history_lifetime\" : 300 , \"history_recover\" : true } Channel namespaces \u00b6 The last channel specific option is namespaces . namespaces are optional and if set must be an array of namespace objects. Namespace allows to configure custom options for channels starting with namespace name. This provides a great control over channel behaviour so you have a flexible way to define different channel options for different real-time features in your app. Namespace has a name, and the same channel options (with same defaults) as described above. name - unique namespace name (name must consist of letters, numbers, underscores or hyphens and be more than 2 symbols length i.e. satisfy regexp ^[-a-zA-Z0-9_]{2,}$ ). If you want to use namespace options for a channel - you must include namespace name into channel name with : as separator: public:messages gossips:messages Where public and gossips are namespace names from project namespaces . All things together here is an example of config.json which includes some top-level channel options set and has 2 additional channel namespaces configured: { \"v3_use_offset\" : true , \"token_hmac_secret_key\" : \"very-long-secret-key\" , \"api_key\" : \"secret-api-key\" , \"anonymous\" : true , \"publish\" : true , \"presence\" : true , \"join_leave\" : true , \"history_size\" : 10 , \"history_lifetime\" : 30 , \"namespaces\" : [ { \"name\" : \"public\" , \"publish\" : true , \"anonymous\" : true , \"history_size\" : 10 , \"history_lifetime\" : 300 , \"history_recover\" : true }, { \"name\" : \"gossips\" , \"presence\" : true , \"join_leave\" : true } ] } Channel news will use globally defined channel options. Channel public:news will use public namespace's options. Channel gossips:news will use gossips namespace's options. Channel namespaces also work with private channels and user-limited channels . For example, if you have namespace called dialogs then private channel can be constructed as $dialogs:gossips , user-limited channel can be constructed as dialogs:dialog#1,2 . There is no inheritance in channel options and namespaces \u2013 for example you defined presence: true on a top level of configuration and then defined namespace \u2013 that namespace won't have presence enabled - you must enable it for namespace explicitly. Setting namespaces over env \u00b6 While setting most options in Centrifugo over env is pretty straightforward setting namespaces is a bit special: CENTRIFUGO_NAMESPACES='[{\"name\": \"ns1\"}, {\"name\": \"ns2\"}]' ./centrifugo I.e. CENTRIFUGO_NAMESPACES environment variable should be a valid JSON string that represents namespaces array.","title":"Channels"},{"location":"server/channels/#channels","text":"Channel is a route for publication messages. Clients can be subscribed to a channel to receive messages published to this channel \u2013 new publications, join/leave events (if enabled for a channel namespace) etc. Channel subscriber can also ask for channel presence or channel history information (if enabled for a channel namespace). Channel is just a string - news , comments are valid channel names. Though this string has some predefined rules as we will see below. Channel is an ephemeral entity \u2013 you don't need to create it explicitly . Channel created automatically by Centrifugo as soon as first client subscribes to it. As soon as last subscriber leaves channel - it's automatically cleaned up.","title":"Channels"},{"location":"server/channels/#channel-name-rules","text":"Only ASCII symbols must be used in channel string . Channel name length limited by 255 characters by default (can be changed via configuration file option channel_max_length ). Several symbols in channel names reserved for Centrifugo internal needs: : \u2013 for namespace channel boundary (see below) $ \u2013 for private channel prefix (see below) # \u2013 for user channel boundary (see below) * \u2013 for future Centrifugo needs & \u2013 for future Centrifugo needs / \u2013 for future Centrifugo needs","title":"Channel name rules"},{"location":"server/channels/#namespace-boundary","text":": \u2013 is a channel namespace boundary. Namespaces used to set custom options to a group of channels. Each channel belonging to the same namespace will have the same channel options. Read more about available channel options below. If channel is public:chat - then Centrifugo will apply options to this channel from channel namespace with name public .","title":"namespace boundary (:)"},{"location":"server/channels/#private-channel-prefix","text":"If channel starts with $ then it is considered private . Subscription on a private channel must be properly signed by your backend. Use private channels if you pass sensitive data inside channel and want to control access permissions on your backend. For example $secrets is a private channel, $public:chat - is a private channel that belongs namespace public . Subscription request to private channels requires additional JWT from your backend. Read detailed chapter about private channels . If you need a personal channel for a single user (or maybe channel for short and stable set of users) then consider using user-limited channel (see below) as a simpler alternative which does not require additional subscription token from your backend.","title":"private channel prefix ($)"},{"location":"server/channels/#user-channel-boundary","text":"# \u2013 is a user channel boundary. This is a separator to create personal channels for users (we call this user-limited channels ) without need to provide subscription token. For example if channel is news#42 then only user with ID 42 can subscribe on this channel (Centrifugo knows user ID because clients provide it in connection credentials with connection JWT). Moreover, you can provide several user IDs in channel name separated by a comma: dialog#42,43 \u2013 in this case only user with ID 42 and user with ID 43 will be able to subscribe on this channel. This is useful for channels with static list of allowed users, for example for single user personal messages channel, for dialog channel between certainly defined users. As soon as you need dynamic user access to channel this channel type does not suit well.","title":"user channel boundary (#)"},{"location":"server/channels/#channel-options","text":"Let's look at configuration options related to channels. es published into that channel. The following options will affect channel behaviour.","title":"Channel options"},{"location":"server/channels/#publish","text":"publish (boolean, default false ) \u2013 allow clients to publish messages into channels directly (from client side). Your application will never receive those messages. In idiomatic case all messages must be published to Centrifugo by your application backend using Centrifugo API. But this option can be useful when you want to build something without backend-side validation and saving into database. This option can also be useful for demos and prototyping real-time ideas. By default it's false .","title":"publish"},{"location":"server/channels/#subscribe_to_publish","text":"subscribe_to_publish (boolean, default false ) - when publish option enabled client can publish into channel without being subscribed to it. This option enables automatic check that client subscribed on channel before allowing client to publish into channel.","title":"subscribe_to_publish"},{"location":"server/channels/#anonymous","text":"anonymous (boolean, default false ) \u2013 this option enables anonymous access (with empty sub claim in connection token). In most situations your application works with authenticated users so every user has its own unique id. But if you provide real-time features for public access you may need unauthorized access to some channels. Turn on this option and use empty string as user ID.","title":"anonymous"},{"location":"server/channels/#presence","text":"presence (boolean, default false ) \u2013 enable/disable presence information. Presence is an information about clients currently subscribed on channel. By default this option is off so no presence information will be available for channels.","title":"presence"},{"location":"server/channels/#presence_disable_for_client","text":"presence_disable_for_client (boolean, default false , available since v2.2.3) \u2013 allows making presence calls available only for server side API. By default presence information is available for both client and server side APIs.","title":"presence_disable_for_client"},{"location":"server/channels/#join_leave","text":"join_leave (boolean, default false ) \u2013 enable/disable sending join(leave) messages when client subscribes on a channel (unsubscribes from channel).","title":"join_leave"},{"location":"server/channels/#history_size","text":"history_size (integer, default 0 ) \u2013 history size (amount of messages) for channels. As Centrifugo keeps all history messages in memory it's very important to limit maximum amount of messages in channel history to reasonable value. history_size defines maximum amount of messages that Centrifugo will keep for each channel in namespace during history lifetime (see below). By default history size is 0 - this means that channels will have no history messages at all.","title":"history_size"},{"location":"server/channels/#history_lifetime","text":"history_lifetime (integer, default 0 ) \u2013 interval in seconds how long to keep channel history messages. As all history is storing in memory it is also very important to get rid of old history data for unused (inactive for a long time) channels. By default history lifetime is 0 \u2013 this means that channels will have no history messages at all. So to turn on keeping history messages you should wisely configure both history_size and history_lifetime options .","title":"history_lifetime"},{"location":"server/channels/#history_recover","text":"history_recover (boolean, default false ) \u2013 when enabled Centrifugo will try to recover missed publications after a client reconnects for some reason (bad internet connection for example). Also when recovery feature is on Centrifugo tries to compensate at most once delivery of PUB/SUB messages checking client position inside stream, so you get at least once delivery guarantee in history retention period and history window size. By default, this feature is off. This option must be used in conjunction with reasonably configured message history for channel i.e. history_size and history_lifetime must be set (because Centrifugo uses channel history to recover messages). Also note that not all real-time events require this feature turned on so think wisely when you need this. When this option turned on your application should be designed in a way to tolerate duplicate messages coming from channel (currently Centrifugo returns recovered publications in order and without duplicates but this is implementation detail that can be theoretically changed in future). See more details about how recovery works in special chapter .","title":"history_recover"},{"location":"server/channels/#history_disable_for_client","text":"history_disable_for_client (boolean, default false , available since v2.2.3) \u2013 allows making history available only for a server side API. By default false \u2013 i.e. history calls are available for both client and server side APIs. History recovery mechanism if enabled will continue to work for clients anyway even if history_disable_for_client is on.","title":"history_disable_for_client"},{"location":"server/channels/#server_side","text":"server_side (boolean, default false , available since v2.4.0) \u2013 when enabled then all client-side subscription requests to channels in namespace will be rejected with PermissionDenied error.","title":"server_side"},{"location":"server/channels/#proxy_subscribe","text":"proxy_subscribe (boolean, default false , available since v2.6.0) \u2013 turns on subscribe proxy, more info in proxy chapter","title":"proxy_subscribe"},{"location":"server/channels/#proxy_publish","text":"proxy_publish (boolean, default false , available since v2.6.0) \u2013 turns on publish proxy, more info in proxy chapter","title":"proxy_publish"},{"location":"server/channels/#channel-options-config-example","text":"Let's look how to set some of these options in a config: { \"v3_use_offset\" : true , \"token_hmac_secret_key\" : \"my-secret-key\" , \"api_key\" : \"secret-api-key\" , \"anonymous\" : true , \"publish\" : true , \"subscribe_to_publish\" : true , \"presence\" : true , \"join_leave\" : true , \"history_size\" : 10 , \"history_lifetime\" : 300 , \"history_recover\" : true }","title":"Channel options config example"},{"location":"server/channels/#channel-namespaces","text":"The last channel specific option is namespaces . namespaces are optional and if set must be an array of namespace objects. Namespace allows to configure custom options for channels starting with namespace name. This provides a great control over channel behaviour so you have a flexible way to define different channel options for different real-time features in your app. Namespace has a name, and the same channel options (with same defaults) as described above. name - unique namespace name (name must consist of letters, numbers, underscores or hyphens and be more than 2 symbols length i.e. satisfy regexp ^[-a-zA-Z0-9_]{2,}$ ). If you want to use namespace options for a channel - you must include namespace name into channel name with : as separator: public:messages gossips:messages Where public and gossips are namespace names from project namespaces . All things together here is an example of config.json which includes some top-level channel options set and has 2 additional channel namespaces configured: { \"v3_use_offset\" : true , \"token_hmac_secret_key\" : \"very-long-secret-key\" , \"api_key\" : \"secret-api-key\" , \"anonymous\" : true , \"publish\" : true , \"presence\" : true , \"join_leave\" : true , \"history_size\" : 10 , \"history_lifetime\" : 30 , \"namespaces\" : [ { \"name\" : \"public\" , \"publish\" : true , \"anonymous\" : true , \"history_size\" : 10 , \"history_lifetime\" : 300 , \"history_recover\" : true }, { \"name\" : \"gossips\" , \"presence\" : true , \"join_leave\" : true } ] } Channel news will use globally defined channel options. Channel public:news will use public namespace's options. Channel gossips:news will use gossips namespace's options. Channel namespaces also work with private channels and user-limited channels . For example, if you have namespace called dialogs then private channel can be constructed as $dialogs:gossips , user-limited channel can be constructed as dialogs:dialog#1,2 . There is no inheritance in channel options and namespaces \u2013 for example you defined presence: true on a top level of configuration and then defined namespace \u2013 that namespace won't have presence enabled - you must enable it for namespace explicitly.","title":"Channel namespaces"},{"location":"server/channels/#setting-namespaces-over-env","text":"While setting most options in Centrifugo over env is pretty straightforward setting namespaces is a bit special: CENTRIFUGO_NAMESPACES='[{\"name\": \"ns1\"}, {\"name\": \"ns2\"}]' ./centrifugo I.e. CENTRIFUGO_NAMESPACES environment variable should be a valid JSON string that represents namespaces array.","title":"Setting namespaces over env"},{"location":"server/client_api/","text":"Client API \u00b6 This chapter describes client Centrifugo API \u2013 i.e. primitives to communicate with a server from an application front-end (i.e. browser or mobile device). This is a formal description \u2013 refer to each specific client implementation for concrete method names and possibilities. See full list of Centrifugo client connectors . If you are looking for a detailed information about client-server protocol internals then client protocol description chapter can help. We use Javascript client centrifuge-js for examples here. Connect \u00b6 Each Centrifugo client allows connecting to a server. const centrifuge = new Centrifuge ( 'ws://localhost:8000/connection/websocket' ); centrifuge . connect (); In most cases you will need to pass JWT token for authentication, so the example above transforms to: const centrifuge = new Centrifuge ( 'ws://localhost:8000/connection/websocket' ); centrifuge . setToken ( '<USER-JWT-TOKEN>' ) centrifuge . connect (); See authentication chapter for more information on how to generate connection JWT. If you are using connect proxy then you may go without setting JWT. Disconnect \u00b6 After connecting you can disconnect from a server at any moment. centrifuge . disconnect (); Connection lifecycle events \u00b6 All client implementations allow setting handlers on connect and disconnect events. For example: centrifuge . on ( 'connect' , function ( connectCtx ){ console . log ( 'connected' , connectCtx ) }); centrifuge . on ( 'disconnect' , function ( disconnectCtx ){ console . log ( 'disconnected' , disconnectCtx ) }); Subscribe \u00b6 Another core functionality of client API is possibility to subscribe on a channel to receive all messages published to that channel. centrifuge . subscribe ( 'channel' , function ( messageCtx ) { console . log ( messageCtx ); }) Client can subscribe to different channels . Subscribe method returns Subscription object. It's also possible to react on different Subscription events: join and leave events, subscribe success and subscribe error events, unsubscribe event. In idiomatic case messages published to channels from application backend over Centrifugo server API . Though it's not always true. Centrifugo also provides message recovery feature to restore missed publications in channels. Publications can be missed due to temporary disconnects (bad network) or server reloads. Recovery happens automatically on reconnect (due to bad network or server reloads) as soon as recovery in channel properly configured . Client keeps last seen Publication offset and restores new publications since known offset. If recovery failed then client implementation provides flag inside subscribe event to let your application know that some publications missed \u2013 so you may need to load state from scratch from application backend. Not all Centrifugo clients implement recovery feature \u2013 refer to specific client implementation docs. More details about recovery in a dedicated chapter . RPC \u00b6 Client can send RPC to a server. RPC is a call which is not related to channels at all. It's just a way to call server method from client side over WebSocket or SockJS connection. RPC is only available when RPC proxy configured. const rpcRequest = { 'key' : 'value' }; const data = await centrifuge . namedRPC ( 'example_method' , rpcRequest ); History \u00b6 Once subscribed client can call publication history inside channel (only for channels where history configured ) to get last publications in channel: const resp = await subscription . history (); Presence and presence stats \u00b6 Once subscribed client can call presence and presence stats information inside channel (only for channels where presence configured ): For presence (full information about active subscribers in channel): const resp = await subscription . presence (); For presence stats (just a number of clients and unique users in channel): const resp = await subscription . presenceStats (); Server-side subscriptions \u00b6 To handle publications coming from server-side subscriptions client API allows listening publications simply on Centrifuge client instance: centrifuge . on ( 'publish' , function ( messageCtx ) { console . log ( messageCtx ); }); It's also possible to react on different server-side Subscription events: join and leave events, subscribe success, unsubscribe event. There is no subscribe error event here since subscription initiated on a server side.","title":"Client API"},{"location":"server/client_api/#client-api","text":"This chapter describes client Centrifugo API \u2013 i.e. primitives to communicate with a server from an application front-end (i.e. browser or mobile device). This is a formal description \u2013 refer to each specific client implementation for concrete method names and possibilities. See full list of Centrifugo client connectors . If you are looking for a detailed information about client-server protocol internals then client protocol description chapter can help. We use Javascript client centrifuge-js for examples here.","title":"Client API"},{"location":"server/client_api/#connect","text":"Each Centrifugo client allows connecting to a server. const centrifuge = new Centrifuge ( 'ws://localhost:8000/connection/websocket' ); centrifuge . connect (); In most cases you will need to pass JWT token for authentication, so the example above transforms to: const centrifuge = new Centrifuge ( 'ws://localhost:8000/connection/websocket' ); centrifuge . setToken ( '<USER-JWT-TOKEN>' ) centrifuge . connect (); See authentication chapter for more information on how to generate connection JWT. If you are using connect proxy then you may go without setting JWT.","title":"Connect"},{"location":"server/client_api/#disconnect","text":"After connecting you can disconnect from a server at any moment. centrifuge . disconnect ();","title":"Disconnect"},{"location":"server/client_api/#connection-lifecycle-events","text":"All client implementations allow setting handlers on connect and disconnect events. For example: centrifuge . on ( 'connect' , function ( connectCtx ){ console . log ( 'connected' , connectCtx ) }); centrifuge . on ( 'disconnect' , function ( disconnectCtx ){ console . log ( 'disconnected' , disconnectCtx ) });","title":"Connection lifecycle events"},{"location":"server/client_api/#subscribe","text":"Another core functionality of client API is possibility to subscribe on a channel to receive all messages published to that channel. centrifuge . subscribe ( 'channel' , function ( messageCtx ) { console . log ( messageCtx ); }) Client can subscribe to different channels . Subscribe method returns Subscription object. It's also possible to react on different Subscription events: join and leave events, subscribe success and subscribe error events, unsubscribe event. In idiomatic case messages published to channels from application backend over Centrifugo server API . Though it's not always true. Centrifugo also provides message recovery feature to restore missed publications in channels. Publications can be missed due to temporary disconnects (bad network) or server reloads. Recovery happens automatically on reconnect (due to bad network or server reloads) as soon as recovery in channel properly configured . Client keeps last seen Publication offset and restores new publications since known offset. If recovery failed then client implementation provides flag inside subscribe event to let your application know that some publications missed \u2013 so you may need to load state from scratch from application backend. Not all Centrifugo clients implement recovery feature \u2013 refer to specific client implementation docs. More details about recovery in a dedicated chapter .","title":"Subscribe"},{"location":"server/client_api/#rpc","text":"Client can send RPC to a server. RPC is a call which is not related to channels at all. It's just a way to call server method from client side over WebSocket or SockJS connection. RPC is only available when RPC proxy configured. const rpcRequest = { 'key' : 'value' }; const data = await centrifuge . namedRPC ( 'example_method' , rpcRequest );","title":"RPC"},{"location":"server/client_api/#history","text":"Once subscribed client can call publication history inside channel (only for channels where history configured ) to get last publications in channel: const resp = await subscription . history ();","title":"History"},{"location":"server/client_api/#presence-and-presence-stats","text":"Once subscribed client can call presence and presence stats information inside channel (only for channels where presence configured ): For presence (full information about active subscribers in channel): const resp = await subscription . presence (); For presence stats (just a number of clients and unique users in channel): const resp = await subscription . presenceStats ();","title":"Presence and presence stats"},{"location":"server/client_api/#server-side-subscriptions","text":"To handle publications coming from server-side subscriptions client API allows listening publications simply on Centrifuge client instance: centrifuge . on ( 'publish' , function ( messageCtx ) { console . log ( messageCtx ); }); It's also possible to react on different server-side Subscription events: join and leave events, subscribe success, unsubscribe event. There is no subscribe error event here since subscription initiated on a server side.","title":"Server-side subscriptions"},{"location":"server/commands/","text":"Console commands \u00b6 Here is a list of console commands that come with Centrifugo executable. version command \u00b6 To show Centrifugo version and exit run: centrifugo version checkconfig command \u00b6 Centrifugo has special command to check configuration file checkconfig : centrifugo checkconfig --config = config.json If any errors found during validation \u2013 program will exit with error message and exit code 1. genconfig command \u00b6 Another command is genconfig : centrifugo genconfig -c config.json It will automatically generate the minimal required configuration file. If any errors happen \u2013 program will exit with error message and exit code 1. gentoken command \u00b6 Another command is gentoken : centrifugo gentoken -c config.json -u 28282 It will automatically generate HMAC SHA-256 based token for user with ID 28282 (which expires in 1 week). You can change token TTL with -t flag (number of seconds): centrifugo gentoken -c config.json -u 28282 -t 3600 This way generated token will be valid for 1 hour. If any errors happen \u2013 program will exit with error message and exit code 1. checktoken command \u00b6 One more command is checktoken : centrifugo checktoken -c config.json <TOKEN> It will validate your connection JWT, so you can test it before using while developing application. If any errors happen or validation failed \u2013 program will exit with error message and exit code 1.","title":"Console commands"},{"location":"server/commands/#console-commands","text":"Here is a list of console commands that come with Centrifugo executable.","title":"Console commands"},{"location":"server/commands/#version-command","text":"To show Centrifugo version and exit run: centrifugo version","title":"version command"},{"location":"server/commands/#checkconfig-command","text":"Centrifugo has special command to check configuration file checkconfig : centrifugo checkconfig --config = config.json If any errors found during validation \u2013 program will exit with error message and exit code 1.","title":"checkconfig command"},{"location":"server/commands/#genconfig-command","text":"Another command is genconfig : centrifugo genconfig -c config.json It will automatically generate the minimal required configuration file. If any errors happen \u2013 program will exit with error message and exit code 1.","title":"genconfig command"},{"location":"server/commands/#gentoken-command","text":"Another command is gentoken : centrifugo gentoken -c config.json -u 28282 It will automatically generate HMAC SHA-256 based token for user with ID 28282 (which expires in 1 week). You can change token TTL with -t flag (number of seconds): centrifugo gentoken -c config.json -u 28282 -t 3600 This way generated token will be valid for 1 hour. If any errors happen \u2013 program will exit with error message and exit code 1.","title":"gentoken command"},{"location":"server/commands/#checktoken-command","text":"One more command is checktoken : centrifugo checktoken -c config.json <TOKEN> It will validate your connection JWT, so you can test it before using while developing application. If any errors happen or validation failed \u2013 program will exit with error message and exit code 1.","title":"checktoken command"},{"location":"server/configuration/","text":"Configuration \u00b6 Here we will look at how Centrifugo can be configured. Configuration ways \u00b6 Centrifugo can be configured in several ways: over command-line flags, see centrifugo -h for available flags, command-line flags limited to most frequently used over configuration file, configuration file supports all options mentioned in this documentation over OS environment variables, all Centrifugo options can be set over env in format CENTRIFUGO_<OPTION_NAME> (mostly straightforward except namespaces - see how to set namespaces via env ) The basic way to start with Centrifugo is run centrifugo genconfig command which will generate config.json configuration file with some options (in a current directory), so you can then run Centrifugo: centrifugo -c config.json Below while describing configuration file format we will look at the meaning of the required options. Config file formats \u00b6 Centrifugo supports different configuration file formats. JSON config format \u00b6 Centrifugo requires configuration file on start. As was mentioned earlier it must be a file with valid JSON. This is a minimal Centrifugo configuration file: { \"v3_use_offset\" : true , \"token_hmac_secret_key\" : \"<YOUR-SECRET-STRING-HERE>\" , \"api_key\" : \"<YOUR-API-KEY-HERE>\" , } The only two fields required are token_hmac_secret_key and api_key . token_hmac_secret_key used to check JWT signature (more about JWT in authentication chapter ). API key used for Centrifugo API endpoint authorization, see more in chapter about server HTTP API . Keep both values in secret and never reveal to clients. The option v3_use_offset turns on using latest client-server protocol offset field ( will be used by default in Centrifugo v3 so better to use it from start ). TOML config format \u00b6 Centrifugo also supports TOML format for configuration file: centrifugo --config=config.toml Where config.toml contains: v3_use_offset = true token_hmac_secret_key = \"<YOUR-SECRET-STRING-HERE>\" api_key = \"<YOUR-API-KEY-HERE>\" log_level = \"debug\" I.e. the same configuration as JSON file above with one extra option to define logging level. YAML config format \u00b6 YAML config also supported. config.yaml : v3_use_offset: true token_hmac_secret_key: \"<YOUR-SECRET-STRING-HERE>\" api_key: \"<YOUR-API-KEY-HERE>\" log_level: debug With YAML remember to use spaces, not tabs when writing configuration file. Important options \u00b6 Some of the most important options you can configure when running Centrifugo: address \u2013 bind your Centrifugo to specific interface address (by default \"\" ) port \u2013 port to bind Centrifugo to (by default 8000 ) engine \u2013 engine to use - memory or redis (by default memory ). Read more about engines in special chapter . Note that some options can be set via command-line. Command-line options are more valuable when set than configuration file's options. See description of viper \u2013 to see more details about configuration options priority. Advanced options \u00b6 Centrifugo has some options for which default values make sense for most applications. In many case you don't need (and you really should not) change them. This chapter is about such options. client_channel_limit \u00b6 Default: 128 Sets maximum number of different channel subscriptions single client can have. channel_max_length \u00b6 Default: 255 Sets maximum length of channel name. client_user_connection_limit \u00b6 Default: 0 Maximum number of connections from user (with known user ID) to Centrifugo node. By default, unlimited. The important thing to emphasize is that client_user_connection_limit works only per one Centrifugo node and exists mostly to protect Centrifugo from many connections from a single user \u2013 but not for business logic limitations. This means that if you will scale nodes \u2013 say run 10 Centrifugo nodes \u2013 then a user will be able to create 10 connections (one to each node). client_request_max_size \u00b6 Default: 65536 Maximum allowed size of request from client in bytes. client_queue_max_size \u00b6 Default: 10485760 Maximum client message queue size in bytes to close slow reader connections. By default - 10mb. client_anonymous \u00b6 Default: false Enable a mode when all clients can connect to Centrifugo without JWT connection token. In this case all connections without token will be treated as anonymous (i.e. with empty user ID) and only can subscribe to channels with anonymous option enabled. client_concurrency \u00b6 Available since Centrifugo v2.8.0 Default: 0 client_concurrency when set tells Centrifugo that commands from client must be processed concurrently. By default, concurrency disabled \u2013 Centrifugo processes commands received from a client one by one. This means that if a client issues two RPC requests to a server then Centrifugo will process the first one, then the second one. If the first RPC call is slow then the client will wait for the second RPC response much longer than it could (even if second RPC is very fast). If you set client_concurrency to some value greater than 1 then commands will be processed concurrently (in parallel) in separate goroutines (with maximum concurrency level capped by client_concurrency value). Thus, this option can effectively reduce the latency of individual requests. Since separate goroutines involved in processing this mode adds some performance and memory overhead \u2013 though it should be pretty negligible in most cases. This option applies to all commands from a client (including subscribe, publish, presence, etc). sockjs_heartbeat_delay \u00b6 Default: 25 Interval in seconds how often to send SockJS h-frames to client. websocket_compression \u00b6 Default: false Enable websocket compression, see chapter about websocket transport for more details. gomaxprocs \u00b6 Default: 0 By default, Centrifugo runs on all available CPU cores. If you want to limit amount of cores Centrifugo can utilize in one moment use this option. Advanced endpoint configuration. \u00b6 After you started Centrifugo you have several endpoints available. As soon as you have not provided any extra options you have 3 endpoints by default. Default endpoints. \u00b6 The main endpoint is raw Websocket endpoint to serve client connections that use pure Websocket protocol: ws://localhost:8000/connection/websocket Then there is SockJS endpoint - it's needed to serve client connections that use SockJS library: http://localhost:8000/connection/sockjs And finally you have API endpoint to publish messages to channels (and execute other available API commands): http://localhost:8000/api By default, all endpoints work on port 8000 . You can change it using port option: { \"port\": 9000 } In production setup you will have your domain name in endpoint addresses above instead of localhost . Also if your Centrifugo will be behind proxy or load balancer software you most probably won't have ports in your endpoint addresses. What will always be the same as shown above are URL paths: /connection/sockjs , /connection/websocket , /api . Let's look at possibilities to tweak available endpoints. Admin endpoints. \u00b6 First is enabling admin endpoints: { ... \"admin\": true, \"admin_password\": \"password\", \"admin_secret\": \"secret\" } This makes the following endpoint available: http://localhost:8000 At this address you will see admin web interface. You can log into it using admin_password value shown above. Debug endpoints. \u00b6 Next, when Centrifugo started in debug mode some extra debug endpoints become available. To start in debug mode add debug option to config: { ... \"debug\": true } And endpoint: http://localhost:8000/debug/pprof/ \u2013 will show you useful info about internal state of Centrifugo instance. This info is especially helpful when troubleshooting. See wiki page for more info. Health check endpoint \u00b6 New in v2.1.0 Use health boolean option (by default false ) to enable healthcheck endpoint which will be available on path /health . Also available over command-line flag: ./centrifugo -c config.json --health Custom internal ports \u00b6 We strongly recommend to not expose API, admin, debug and prometheus endpoints to Internet. The following Centrifugo endpoints are considered internal: API endpoint ( /api ) - for HTTP API requests Admin web interface endpoints ( / , /admin/auth , /admin/api ) - used by web interface Prometheus endpoint ( /metrics ) - used for exposing server metrics in Prometheus format Health check endpoint ( /health ) - used to do health checks Debug endpoints ( /debug/pprof ) - used to inspect internal server state It's a good practice to protect those endpoints with firewall. For example, you can do this in location section of Nginx configuration. Though sometimes you don't have access to per-location configuration in your proxy/load balancer software. For example when using Amazon ELB. In this case you can change ports on which your internal endpoints work. To run internal endpoints on custom port use internal_port option: { ... \"internal_port\": 9000 } So admin web interface will work on address: http://localhost:9000 Also debug page will be available on new custom port too: http://localhost:9000/debug/pprof/ The same for API and prometheus endpoint. Disable default endpoints \u00b6 These options available since v2.4.0 To disable websocket endpoint set websocket_disable boolean option to true . To disable SockJS endpoint set sockjs_disable boolean option to true . To disable API endpoint set api_disable boolean option to true . Customize handler endpoints \u00b6 Starting from Centrifugo v2.2.5 it's possible to customize server HTTP handler endpoints. To do this Centrifugo supports several options: admin_handler_prefix (default \"\" ) - to control Admin panel URL prefix websocket_handler_prefix (default \"/connection/websocket\" ) - to control WebSocket URL prefix sockjs_handler_prefix (default \"/connection/sockjs\" ) - to control SockJS URL prefix api_handler_prefix (default \"/api\" ) - to control HTTP API URL prefix prometheus_handler_prefix (default \"/metrics\" ) - to control Prometheus URL prefix health_handler_prefix (default \"/health\" ) - to control health check URL prefix Signal handling \u00b6 You can send HUP signal to Centrifugo to reload a configuration: kill -HUP <PID> Though at moment this will only reload token secrets and channel options (top-level and namespaces) . Centrifugo tries to gracefully shutdown client connections when SIGINT or SIGTERM signals received. By default, maximum graceful shutdown period is 30 seconds but can be changed using shutdown_timeout (integer, in seconds) configuration option.","title":"Configuration"},{"location":"server/configuration/#configuration","text":"Here we will look at how Centrifugo can be configured.","title":"Configuration"},{"location":"server/configuration/#configuration-ways","text":"Centrifugo can be configured in several ways: over command-line flags, see centrifugo -h for available flags, command-line flags limited to most frequently used over configuration file, configuration file supports all options mentioned in this documentation over OS environment variables, all Centrifugo options can be set over env in format CENTRIFUGO_<OPTION_NAME> (mostly straightforward except namespaces - see how to set namespaces via env ) The basic way to start with Centrifugo is run centrifugo genconfig command which will generate config.json configuration file with some options (in a current directory), so you can then run Centrifugo: centrifugo -c config.json Below while describing configuration file format we will look at the meaning of the required options.","title":"Configuration ways"},{"location":"server/configuration/#config-file-formats","text":"Centrifugo supports different configuration file formats.","title":"Config file formats"},{"location":"server/configuration/#json-config-format","text":"Centrifugo requires configuration file on start. As was mentioned earlier it must be a file with valid JSON. This is a minimal Centrifugo configuration file: { \"v3_use_offset\" : true , \"token_hmac_secret_key\" : \"<YOUR-SECRET-STRING-HERE>\" , \"api_key\" : \"<YOUR-API-KEY-HERE>\" , } The only two fields required are token_hmac_secret_key and api_key . token_hmac_secret_key used to check JWT signature (more about JWT in authentication chapter ). API key used for Centrifugo API endpoint authorization, see more in chapter about server HTTP API . Keep both values in secret and never reveal to clients. The option v3_use_offset turns on using latest client-server protocol offset field ( will be used by default in Centrifugo v3 so better to use it from start ).","title":"JSON config format"},{"location":"server/configuration/#toml-config-format","text":"Centrifugo also supports TOML format for configuration file: centrifugo --config=config.toml Where config.toml contains: v3_use_offset = true token_hmac_secret_key = \"<YOUR-SECRET-STRING-HERE>\" api_key = \"<YOUR-API-KEY-HERE>\" log_level = \"debug\" I.e. the same configuration as JSON file above with one extra option to define logging level.","title":"TOML config format"},{"location":"server/configuration/#yaml-config-format","text":"YAML config also supported. config.yaml : v3_use_offset: true token_hmac_secret_key: \"<YOUR-SECRET-STRING-HERE>\" api_key: \"<YOUR-API-KEY-HERE>\" log_level: debug With YAML remember to use spaces, not tabs when writing configuration file.","title":"YAML config format"},{"location":"server/configuration/#important-options","text":"Some of the most important options you can configure when running Centrifugo: address \u2013 bind your Centrifugo to specific interface address (by default \"\" ) port \u2013 port to bind Centrifugo to (by default 8000 ) engine \u2013 engine to use - memory or redis (by default memory ). Read more about engines in special chapter . Note that some options can be set via command-line. Command-line options are more valuable when set than configuration file's options. See description of viper \u2013 to see more details about configuration options priority.","title":"Important options"},{"location":"server/configuration/#advanced-options","text":"Centrifugo has some options for which default values make sense for most applications. In many case you don't need (and you really should not) change them. This chapter is about such options.","title":"Advanced options"},{"location":"server/configuration/#client_channel_limit","text":"Default: 128 Sets maximum number of different channel subscriptions single client can have.","title":"client_channel_limit"},{"location":"server/configuration/#channel_max_length","text":"Default: 255 Sets maximum length of channel name.","title":"channel_max_length"},{"location":"server/configuration/#client_user_connection_limit","text":"Default: 0 Maximum number of connections from user (with known user ID) to Centrifugo node. By default, unlimited. The important thing to emphasize is that client_user_connection_limit works only per one Centrifugo node and exists mostly to protect Centrifugo from many connections from a single user \u2013 but not for business logic limitations. This means that if you will scale nodes \u2013 say run 10 Centrifugo nodes \u2013 then a user will be able to create 10 connections (one to each node).","title":"client_user_connection_limit"},{"location":"server/configuration/#client_request_max_size","text":"Default: 65536 Maximum allowed size of request from client in bytes.","title":"client_request_max_size"},{"location":"server/configuration/#client_queue_max_size","text":"Default: 10485760 Maximum client message queue size in bytes to close slow reader connections. By default - 10mb.","title":"client_queue_max_size"},{"location":"server/configuration/#client_anonymous","text":"Default: false Enable a mode when all clients can connect to Centrifugo without JWT connection token. In this case all connections without token will be treated as anonymous (i.e. with empty user ID) and only can subscribe to channels with anonymous option enabled.","title":"client_anonymous"},{"location":"server/configuration/#client_concurrency","text":"Available since Centrifugo v2.8.0 Default: 0 client_concurrency when set tells Centrifugo that commands from client must be processed concurrently. By default, concurrency disabled \u2013 Centrifugo processes commands received from a client one by one. This means that if a client issues two RPC requests to a server then Centrifugo will process the first one, then the second one. If the first RPC call is slow then the client will wait for the second RPC response much longer than it could (even if second RPC is very fast). If you set client_concurrency to some value greater than 1 then commands will be processed concurrently (in parallel) in separate goroutines (with maximum concurrency level capped by client_concurrency value). Thus, this option can effectively reduce the latency of individual requests. Since separate goroutines involved in processing this mode adds some performance and memory overhead \u2013 though it should be pretty negligible in most cases. This option applies to all commands from a client (including subscribe, publish, presence, etc).","title":"client_concurrency"},{"location":"server/configuration/#sockjs_heartbeat_delay","text":"Default: 25 Interval in seconds how often to send SockJS h-frames to client.","title":"sockjs_heartbeat_delay"},{"location":"server/configuration/#websocket_compression","text":"Default: false Enable websocket compression, see chapter about websocket transport for more details.","title":"websocket_compression"},{"location":"server/configuration/#gomaxprocs","text":"Default: 0 By default, Centrifugo runs on all available CPU cores. If you want to limit amount of cores Centrifugo can utilize in one moment use this option.","title":"gomaxprocs"},{"location":"server/configuration/#advanced-endpoint-configuration","text":"After you started Centrifugo you have several endpoints available. As soon as you have not provided any extra options you have 3 endpoints by default.","title":"Advanced endpoint configuration."},{"location":"server/configuration/#default-endpoints","text":"The main endpoint is raw Websocket endpoint to serve client connections that use pure Websocket protocol: ws://localhost:8000/connection/websocket Then there is SockJS endpoint - it's needed to serve client connections that use SockJS library: http://localhost:8000/connection/sockjs And finally you have API endpoint to publish messages to channels (and execute other available API commands): http://localhost:8000/api By default, all endpoints work on port 8000 . You can change it using port option: { \"port\": 9000 } In production setup you will have your domain name in endpoint addresses above instead of localhost . Also if your Centrifugo will be behind proxy or load balancer software you most probably won't have ports in your endpoint addresses. What will always be the same as shown above are URL paths: /connection/sockjs , /connection/websocket , /api . Let's look at possibilities to tweak available endpoints.","title":"Default endpoints."},{"location":"server/configuration/#admin-endpoints","text":"First is enabling admin endpoints: { ... \"admin\": true, \"admin_password\": \"password\", \"admin_secret\": \"secret\" } This makes the following endpoint available: http://localhost:8000 At this address you will see admin web interface. You can log into it using admin_password value shown above.","title":"Admin endpoints."},{"location":"server/configuration/#debug-endpoints","text":"Next, when Centrifugo started in debug mode some extra debug endpoints become available. To start in debug mode add debug option to config: { ... \"debug\": true } And endpoint: http://localhost:8000/debug/pprof/ \u2013 will show you useful info about internal state of Centrifugo instance. This info is especially helpful when troubleshooting. See wiki page for more info.","title":"Debug endpoints."},{"location":"server/configuration/#health-check-endpoint","text":"New in v2.1.0 Use health boolean option (by default false ) to enable healthcheck endpoint which will be available on path /health . Also available over command-line flag: ./centrifugo -c config.json --health","title":"Health check endpoint"},{"location":"server/configuration/#custom-internal-ports","text":"We strongly recommend to not expose API, admin, debug and prometheus endpoints to Internet. The following Centrifugo endpoints are considered internal: API endpoint ( /api ) - for HTTP API requests Admin web interface endpoints ( / , /admin/auth , /admin/api ) - used by web interface Prometheus endpoint ( /metrics ) - used for exposing server metrics in Prometheus format Health check endpoint ( /health ) - used to do health checks Debug endpoints ( /debug/pprof ) - used to inspect internal server state It's a good practice to protect those endpoints with firewall. For example, you can do this in location section of Nginx configuration. Though sometimes you don't have access to per-location configuration in your proxy/load balancer software. For example when using Amazon ELB. In this case you can change ports on which your internal endpoints work. To run internal endpoints on custom port use internal_port option: { ... \"internal_port\": 9000 } So admin web interface will work on address: http://localhost:9000 Also debug page will be available on new custom port too: http://localhost:9000/debug/pprof/ The same for API and prometheus endpoint.","title":"Custom internal ports"},{"location":"server/configuration/#disable-default-endpoints","text":"These options available since v2.4.0 To disable websocket endpoint set websocket_disable boolean option to true . To disable SockJS endpoint set sockjs_disable boolean option to true . To disable API endpoint set api_disable boolean option to true .","title":"Disable default endpoints"},{"location":"server/configuration/#customize-handler-endpoints","text":"Starting from Centrifugo v2.2.5 it's possible to customize server HTTP handler endpoints. To do this Centrifugo supports several options: admin_handler_prefix (default \"\" ) - to control Admin panel URL prefix websocket_handler_prefix (default \"/connection/websocket\" ) - to control WebSocket URL prefix sockjs_handler_prefix (default \"/connection/sockjs\" ) - to control SockJS URL prefix api_handler_prefix (default \"/api\" ) - to control HTTP API URL prefix prometheus_handler_prefix (default \"/metrics\" ) - to control Prometheus URL prefix health_handler_prefix (default \"/health\" ) - to control health check URL prefix","title":"Customize handler endpoints"},{"location":"server/configuration/#signal-handling","text":"You can send HUP signal to Centrifugo to reload a configuration: kill -HUP <PID> Though at moment this will only reload token secrets and channel options (top-level and namespaces) . Centrifugo tries to gracefully shutdown client connections when SIGINT or SIGTERM signals received. By default, maximum graceful shutdown period is 30 seconds but can be changed using shutdown_timeout (integer, in seconds) configuration option.","title":"Signal handling"},{"location":"server/connection_expiration/","text":"Connection expiration \u00b6 In authentication chapter we mentioned exp claim in connection token that allows to expire client connection at some point of time. In this chapter we will look at details on what happens when Centrifugo detects that connection is going to expire. So first you should do is enable client expiration mechanism in Centrifugo providing connection token with expiration: import jwt import time token = jwt . encode ({ \"sub\" : \"42\" , \"exp\" : int ( time . time ()) + 10 * 60 }, \"secret\" ) . decode () print ( token ) Let's suppose that you set exp field to timestamp that will expire in 10 minutes and client connected to Centrifugo with this token. During 10 mins connection will be kept by Centrifugo. When this time passed Centrifugo gives connection some time (configured, 25 seconds by default) to refresh its credentials and provide new valid token with new exp . When client first connects to Centrifugo it receives ttl value in connect reply. That ttl value contains number of seconds after which client must send refresh command with new credentials to Centrifugo. Centrifugo clients must handle this ttl field and automatically start refresh process. For example Javascript browser client will send AJAX POST request to your application when it's time to refresh credentials. By default this request goes to /centrifuge/refresh url endpoint. In response your server must return JSON with new connection token: { \"token\" : token } So you must just return the same connection token for your user when rendering page initially. But with actual valid exp . Javascript client will then send them to Centrifugo server and connection will be refreshed for a time you set in exp . In this case you know which user want to refresh its connection because this is just a general request to your app - so your session mechanism will tell you about the user. If you don't want to refresh connection for this user - just return 403 Forbidden on refresh request to your application backend. Javascript client also has options to hook into refresh mechanism to implement your custom way of refreshing. Other Centrifugo clients also should have hooks to refresh credentials but depending on client API for this can be different - see specific client docs.","title":"Connection expiration"},{"location":"server/connection_expiration/#connection-expiration","text":"In authentication chapter we mentioned exp claim in connection token that allows to expire client connection at some point of time. In this chapter we will look at details on what happens when Centrifugo detects that connection is going to expire. So first you should do is enable client expiration mechanism in Centrifugo providing connection token with expiration: import jwt import time token = jwt . encode ({ \"sub\" : \"42\" , \"exp\" : int ( time . time ()) + 10 * 60 }, \"secret\" ) . decode () print ( token ) Let's suppose that you set exp field to timestamp that will expire in 10 minutes and client connected to Centrifugo with this token. During 10 mins connection will be kept by Centrifugo. When this time passed Centrifugo gives connection some time (configured, 25 seconds by default) to refresh its credentials and provide new valid token with new exp . When client first connects to Centrifugo it receives ttl value in connect reply. That ttl value contains number of seconds after which client must send refresh command with new credentials to Centrifugo. Centrifugo clients must handle this ttl field and automatically start refresh process. For example Javascript browser client will send AJAX POST request to your application when it's time to refresh credentials. By default this request goes to /centrifuge/refresh url endpoint. In response your server must return JSON with new connection token: { \"token\" : token } So you must just return the same connection token for your user when rendering page initially. But with actual valid exp . Javascript client will then send them to Centrifugo server and connection will be refreshed for a time you set in exp . In this case you know which user want to refresh its connection because this is just a general request to your app - so your session mechanism will tell you about the user. If you don't want to refresh connection for this user - just return 403 Forbidden on refresh request to your application backend. Javascript client also has options to hook into refresh mechanism to implement your custom way of refreshing. Other Centrifugo clients also should have hooks to refresh credentials but depending on client API for this can be different - see specific client docs.","title":"Connection expiration"},{"location":"server/engines/","text":"Engines \u00b6 Memory engine Redis engine Nats broker Engine in Centrifugo is responsible for publishing messages between nodes, handle PUB/SUB broker subscriptions, save/retrieve presence and history data. By default, Centrifugo uses Memory engine. There is also Redis engine available. The difference between them - with Memory engine you can start only one node of Centrifugo, while Redis engine allows running several nodes on different machines and they will be connected via Redis, will know about each other due to Redis and will also keep history and presence data in Redis instead of Centrifugo node process memory so this data can be accessed from each node. To set engine you can use engine configuration option. Available values are memory and redis . Default value is memory . For example to work with Redis engine: centrifugo --config=config.json --engine=redis Or just set engine in config: { ... \"engine\" : \"redis\" } Memory engine \u00b6 Supports only one node. Nice choice to start with. Supports all features keeping everything in Centrifugo node process memory. You don't need to install Redis when using this engine. Advantages: fast does not require separate Redis setup Disadvantages: does not allow scaling nodes (actually you still can scale Centrifugo with Memory engine but you have to publish data into each Centrifugo node and you won't have consistent state of presence) does not persist message history in channels between Centrifugo restarts Several configuration options related to Memory engine: memory_history_meta_ttl (int, default 0 ) - sets a time in seconds of history stream metadata expiration. Stream metadata is an information about current offset number in channel and epoch value. By default, metadata for channels does not expire. Though in some cases \u2013 when channels created for \u0430 short time and then not used anymore \u2013 created metadata can stay in memory while not actually useful. For example, you can have a personal user channel but after using your app for a while user left it forever. In long-term perspective this can be an unwanted memory leak. Setting a reasonable value to this option (usually much bigger than history retention period) can help. In this case unused channel metadata will eventually expire. Available since v2.5.0 Redis engine \u00b6 Allows scaling Centrifugo nodes to different machines. Nodes will use Redis as message broker. Redis engine keeps presence and history data in Redis, uses Redis PUB/SUB for internal node communication. Minimal Redis version is 3.2.0 Several configuration options related to Redis engine: redis_host (string, default \"127.0.0.1\" ) - Redis server host redis_port (int, default 6379 ) - Redis server port redis_url (string, default \"\" ) - optional Redis connection URL redis_password (string, default \"\" ) - Redis password redis_db (int, default 0 ) - number of Redis db to use redis_tls (boolean, default false ) - enable Redis TLS connection (new in v2.0.2) redis_tls_skip_verify (boolean, default false ) - disable Redis TLS host verification (new in v2.0.2) redis_sentinels (string, default \"\" ) - comma separated list of Sentinels for HA redis_master_name (string, default \"\" ) - name of Redis master Sentinel monitors redis_prefix (string, default \"centrifugo\" ) \u2013 custom prefix to use for channels and keys in Redis redis_history_meta_ttl (int, default 0 ) - sets a time in seconds of history stream metadata expiration in Redis Engine. Meta key in Redis is a HASH that contains current offset number in channel and epoch value. By default, metadata for channels does not expire. Though in some cases \u2013 when channels created for \u0430 short time and then not used anymore \u2013 created stream metadata can stay in memory while not actually useful. For example, you can have a personal user channel but after using your app for a while user left it forever. In long-term perspective this can be an unwanted memory leak. Setting a reasonable value to this option (usually much bigger than history retention period) can help. In this case unused channel metadata will eventually expire. Available since v2.3.0 redis_streams (boolean, default false ) \u2013 turns on using Redis Streams instead of List data structure for keeping history All of these options can be set over configuration file. Some of them can be set over command-line arguments (see centrifugo -h output). Let's describe a bit more redis_url option. redis_url allows to set Redis connection parameters in a form of URL in format redis://:password@hostname:port/db_number . When redis_url set Centrifugo will use URL instead of values provided in redis_host , redis_port , redis_password , redis_db options. Scaling with Redis tutorial \u00b6 Let's see how to start several Centrifugo nodes using Redis engine. We will start 3 Centrifugo nodes and all those nodes will be connected via Redis. First, you should have Redis running. As soon as it's running - we can launch 3 Centrifugo instances. Open your terminal and start first one: centrifugo --config=config.json --port=8000 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 If your Redis on the same machine and runs on its default port you can omit redis_host and redis_port options in command above. Then open another terminal and start another Centrifugo instance: centrifugo --config=config.json --port=8001 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 Note that we use another port number ( 8001 ) as port 8000 already busy by our first Centrifugo instance. If you are starting Centrifugo instances on different machines then you most probably can use the same port number ( 8000 or whatever you want) for all instances. And finally let's start third instance: centrifugo --config=config.json --port=8002 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 Now you have 3 Centrifugo instances running on ports 8000, 8001, 8002 and clients can connect to any of them. You can also send API requests to any of those nodes \u2013 as all nodes connected over Redis PUB/SUB message will be delivered to all interested clients on all nodes. To load balance clients between nodes you can use Nginx \u2013 you can find its configuration here in documentation. Redis Sentinel for high availability \u00b6 Centrifugo supports official way to add high availability to Redis - Redis Sentinel . For this you only need to utilize 2 Redis Engine options: redis_master_name and redis_sentinels . redis_master_name - is a name of master your Sentinels monitor. redis_sentinels - comma-separated addresses of Sentinel servers. At least one known server required. redis_sentinel_password \u2013 optional string password for your Sentinel, works with Redis Sentinel >= 5.0.1 (available since Centrifugo v2.6.0) So you can start Centrifugo which will use Sentinels to discover redis master instance like this: centrifugo --config=config.json --engine=redis --redis_master_name=mymaster --redis_sentinels=\":26379\" Sentinel configuration files can look like this: port 26379 sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 10000 sentinel failover-timeout mymaster 60000 You can find how to properly setup Sentinels in official documentation . Note that when your redis master instance down there will be small downtime interval until Sentinels discover a problem and come to quorum decision about new master. The length of this period depends on Sentinel configuration. Haproxy instead of Sentinel configuration \u00b6 Alternatively you can use Haproxy between Centrifugo and Redis to let it properly balance traffic to Redis master. In this case you still need to configure Sentinels but you can omit Sentinel specifics from Centrifugo configuration and just use Redis address as in simple non-HA case. For example you can use something like this in Haproxy config: listen redis server redis-01 127.0.0.1:6380 check port 6380 check inter 2s weight 1 inter 2s downinter 5s rise 10 fall 2 server redis-02 127.0.0.1:6381 check port 6381 check inter 2s weight 1 inter 2s downinter 5s rise 10 fall 2 backup bind *:16379 mode tcp option tcpka option tcplog option tcp-check tcp-check send PING\\r\\n tcp-check expect string +PONG tcp-check send info\\ replication\\r\\n tcp-check expect string role:master tcp-check send QUIT\\r\\n tcp-check expect string +OK balance roundrobin And then just point Centrifugo to this Haproxy: centrifugo --config=config.json --engine=redis --redis_host=localhost --redis_port=16379 Redis sharding \u00b6 Centrifugo has a built-in Redis sharding support. This resolves situation when Redis becoming a bottleneck on large Centrifugo setup. Redis is single-threaded server, it's very fast but it's power is not infinite so when your Redis approaches 100% CPU usage then sharding feature can help your application to scale. At moment Centrifugo supports simple comma-based approach to configuring Redis shards. Let's just look on examples. To start Centrifugo with 2 Redis shards on localhost running on port 6379 and port 6380: centrifugo --config=config.json --engine=redis --redis_port=6379,6380 To start Centrifugo with Redis instances on different hosts: centrifugo --config=config.json --engine=redis --redis_host=192.168.1.34,192.168.1.35 If you also need to customize AUTH password, Redis DB number then you can use redis_url option. Note, that due to how Redis PUB/SUB work it's not possible (and it's pretty useless anyway) to run shards in one Redis instances using different Redis DB numbers. When sharding enabled Centrifugo will spread channels and history/presence keys over configured Redis instances using consistent hashing algorithm. At moment we use Jump consistent hash algorithm (see paper and implementation ) Redis cluster \u00b6 Redis cluster supported since Centrifugo v2.5.0 Danger Redis Cluster integration does not support channels API command due to Redis cluster limitations. Other Centrifugo features should work. Running Centrifugo with Redis cluster is simple and can be achieved using redis_cluster_addrs option. This is an array of strings. Each element of array is a comma-separated Redis cluster seed nodes. For example: { ... \"redis_cluster_addrs\" : [ \"localhost:30001,localhost:30002,localhost:30003\" ] } Actually you don't need to list all Redis cluster nodes in config \u2013 only several working nodes is enough to start. To set the same over environment variable: CENTRIFUGO_REDIS_CLUSTER_ADDRS = \"localhost:30001\" CENTRIFUGO_ENGINE = redis ./centrifugo If you need to shard data between several Redis clusters then simply add one more string with seed nodes of another cluster to this array: { ... \"redis_cluster_addrs\" : [ \"localhost:30001,localhost:30002,localhost:30003\" , \"localhost:30101,localhost:30102,localhost:30103\" ] } Sharding between different Redis clusters can make sense due to the fact how PUB/SUB works in Redis cluster. It does not scale linearly when adding nodes as all PUB/SUB messages got copied to every cluster node. See this discussion for more information on topic. To spread data between different Redis clusters Centrifugo uses the same consistent hashing algorithm described above (i.e. Jump ). To reproduce the same over environment variable use space to separate different clusters: CENTRIFUGO_REDIS_CLUSTER_ADDRS = \"localhost:30001,localhost:30002 localhost:30101,localhost:30102\" CENTRIFUGO_ENGINE = redis ./centrifugo Redis Streams \u00b6 Since Centrifugo v2.5.0 it's possible to use Redis Stream data structure to keep Publication history inside channels. Redis streams can help to reduce number of memory allocations Centrifugo does during message recovery process upon client reconnect inside large history streams. This can be critical for massive Centrifugo deployments that utilize recovery feature. To turn on using Redis streams use boolean option redis_streams , default false . Redis Streams can become default data structure to keep Publication history in Centrifugo v3. KeyDB \u00b6 Centrifugo Redis engine seamlessly works with KeyDB . KeyDB server is compatible with Redis and provides several additional features beyond. Though we can't give any promises about compatibility with KeyDB in future Centrifugo releases - while KeyDB is fully compatible with Redis things should work fine. That's why we consider this as EXPERIMENTAL feature. Use KeyDB instead of Redis only if you are really sure you need it. Nothing stops you from running several Redis instances per each core you have, configure sharding and obtain even better performance that KeyDB can provide (due to lack of synchronization between threads in Redis). In order to run Centrifugo with KeyDB all you need to do is use redis engine option and run KeyDB server instead of Redis. Nats broker \u00b6 Starting from Centrifugo v2.6.0 it's possible to scale with Nats PUB/SUB server. Keep in mind, that Nats called a broker here, not an Engine \u2013 Nats integration only implements PUB/SUB part of Engine, so carefully read limitations below. Known limitations: Nats integration works only for unreliable at most once PUB/SUB . This means that history, presence and message recovery Centrifugo features won't be available. Nats wildcard channel subscriptions with symbols * and > not supported . First start Nats server: $ nats-server [3569] 2020/07/08 20:28:44.324269 [INF] Starting nats-server version 2.1.7 [3569] 2020/07/08 20:28:44.324400 [INF] Git commit [not set] [3569] 2020/07/08 20:28:44.325600 [INF] Listening for client connections on 0.0.0.0:4222 [3569] 2020/07/08 20:28:44.325612 [INF] Server id is NDAM7GEHUXAKS5SGMA3QE6ZSO4IQUJP6EL3G2E2LJYREVMAMIOBE7JT4 [3569] 2020/07/08 20:28:44.325617 [INF] Server is ready Then start Centrifugo with broker option: centrifugo --broker = nats --config = config.json And one more Centrifugo on another port (of course in real life you will start another Centrifugo on another machine): centrifugo --broker = nats --config = config.json --port = 8001 Now you can scale connections over Centrifugo instances, instances will be connected over Nats server. Available options: nats_url - connection url in format nats://derek:pass@localhost:4222 , by default nats://127.0.0.1:4222 . nats_prefix - prefix for channels used by Centrifugo inside Nats. By default, centrifugo . nats_dial_timeout - timeout for dialing to Nats in seconds, default 1 . nats_write_timeout - write (and flush) timeout on a connection to Nats in seconds, default 1 . It's theoretically possible to use Redis Engine together with Nats broker for presence information. If you are interested in this \u2013 please write to our community chat rooms.","title":"Engines"},{"location":"server/engines/#engines","text":"Memory engine Redis engine Nats broker Engine in Centrifugo is responsible for publishing messages between nodes, handle PUB/SUB broker subscriptions, save/retrieve presence and history data. By default, Centrifugo uses Memory engine. There is also Redis engine available. The difference between them - with Memory engine you can start only one node of Centrifugo, while Redis engine allows running several nodes on different machines and they will be connected via Redis, will know about each other due to Redis and will also keep history and presence data in Redis instead of Centrifugo node process memory so this data can be accessed from each node. To set engine you can use engine configuration option. Available values are memory and redis . Default value is memory . For example to work with Redis engine: centrifugo --config=config.json --engine=redis Or just set engine in config: { ... \"engine\" : \"redis\" }","title":"Engines"},{"location":"server/engines/#memory-engine","text":"Supports only one node. Nice choice to start with. Supports all features keeping everything in Centrifugo node process memory. You don't need to install Redis when using this engine. Advantages: fast does not require separate Redis setup Disadvantages: does not allow scaling nodes (actually you still can scale Centrifugo with Memory engine but you have to publish data into each Centrifugo node and you won't have consistent state of presence) does not persist message history in channels between Centrifugo restarts Several configuration options related to Memory engine: memory_history_meta_ttl (int, default 0 ) - sets a time in seconds of history stream metadata expiration. Stream metadata is an information about current offset number in channel and epoch value. By default, metadata for channels does not expire. Though in some cases \u2013 when channels created for \u0430 short time and then not used anymore \u2013 created metadata can stay in memory while not actually useful. For example, you can have a personal user channel but after using your app for a while user left it forever. In long-term perspective this can be an unwanted memory leak. Setting a reasonable value to this option (usually much bigger than history retention period) can help. In this case unused channel metadata will eventually expire. Available since v2.5.0","title":"Memory engine"},{"location":"server/engines/#redis-engine","text":"Allows scaling Centrifugo nodes to different machines. Nodes will use Redis as message broker. Redis engine keeps presence and history data in Redis, uses Redis PUB/SUB for internal node communication. Minimal Redis version is 3.2.0 Several configuration options related to Redis engine: redis_host (string, default \"127.0.0.1\" ) - Redis server host redis_port (int, default 6379 ) - Redis server port redis_url (string, default \"\" ) - optional Redis connection URL redis_password (string, default \"\" ) - Redis password redis_db (int, default 0 ) - number of Redis db to use redis_tls (boolean, default false ) - enable Redis TLS connection (new in v2.0.2) redis_tls_skip_verify (boolean, default false ) - disable Redis TLS host verification (new in v2.0.2) redis_sentinels (string, default \"\" ) - comma separated list of Sentinels for HA redis_master_name (string, default \"\" ) - name of Redis master Sentinel monitors redis_prefix (string, default \"centrifugo\" ) \u2013 custom prefix to use for channels and keys in Redis redis_history_meta_ttl (int, default 0 ) - sets a time in seconds of history stream metadata expiration in Redis Engine. Meta key in Redis is a HASH that contains current offset number in channel and epoch value. By default, metadata for channels does not expire. Though in some cases \u2013 when channels created for \u0430 short time and then not used anymore \u2013 created stream metadata can stay in memory while not actually useful. For example, you can have a personal user channel but after using your app for a while user left it forever. In long-term perspective this can be an unwanted memory leak. Setting a reasonable value to this option (usually much bigger than history retention period) can help. In this case unused channel metadata will eventually expire. Available since v2.3.0 redis_streams (boolean, default false ) \u2013 turns on using Redis Streams instead of List data structure for keeping history All of these options can be set over configuration file. Some of them can be set over command-line arguments (see centrifugo -h output). Let's describe a bit more redis_url option. redis_url allows to set Redis connection parameters in a form of URL in format redis://:password@hostname:port/db_number . When redis_url set Centrifugo will use URL instead of values provided in redis_host , redis_port , redis_password , redis_db options.","title":"Redis engine"},{"location":"server/engines/#scaling-with-redis-tutorial","text":"Let's see how to start several Centrifugo nodes using Redis engine. We will start 3 Centrifugo nodes and all those nodes will be connected via Redis. First, you should have Redis running. As soon as it's running - we can launch 3 Centrifugo instances. Open your terminal and start first one: centrifugo --config=config.json --port=8000 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 If your Redis on the same machine and runs on its default port you can omit redis_host and redis_port options in command above. Then open another terminal and start another Centrifugo instance: centrifugo --config=config.json --port=8001 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 Note that we use another port number ( 8001 ) as port 8000 already busy by our first Centrifugo instance. If you are starting Centrifugo instances on different machines then you most probably can use the same port number ( 8000 or whatever you want) for all instances. And finally let's start third instance: centrifugo --config=config.json --port=8002 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 Now you have 3 Centrifugo instances running on ports 8000, 8001, 8002 and clients can connect to any of them. You can also send API requests to any of those nodes \u2013 as all nodes connected over Redis PUB/SUB message will be delivered to all interested clients on all nodes. To load balance clients between nodes you can use Nginx \u2013 you can find its configuration here in documentation.","title":"Scaling with Redis tutorial"},{"location":"server/engines/#redis-sentinel-for-high-availability","text":"Centrifugo supports official way to add high availability to Redis - Redis Sentinel . For this you only need to utilize 2 Redis Engine options: redis_master_name and redis_sentinels . redis_master_name - is a name of master your Sentinels monitor. redis_sentinels - comma-separated addresses of Sentinel servers. At least one known server required. redis_sentinel_password \u2013 optional string password for your Sentinel, works with Redis Sentinel >= 5.0.1 (available since Centrifugo v2.6.0) So you can start Centrifugo which will use Sentinels to discover redis master instance like this: centrifugo --config=config.json --engine=redis --redis_master_name=mymaster --redis_sentinels=\":26379\" Sentinel configuration files can look like this: port 26379 sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 10000 sentinel failover-timeout mymaster 60000 You can find how to properly setup Sentinels in official documentation . Note that when your redis master instance down there will be small downtime interval until Sentinels discover a problem and come to quorum decision about new master. The length of this period depends on Sentinel configuration.","title":"Redis Sentinel for high availability"},{"location":"server/engines/#haproxy-instead-of-sentinel-configuration","text":"Alternatively you can use Haproxy between Centrifugo and Redis to let it properly balance traffic to Redis master. In this case you still need to configure Sentinels but you can omit Sentinel specifics from Centrifugo configuration and just use Redis address as in simple non-HA case. For example you can use something like this in Haproxy config: listen redis server redis-01 127.0.0.1:6380 check port 6380 check inter 2s weight 1 inter 2s downinter 5s rise 10 fall 2 server redis-02 127.0.0.1:6381 check port 6381 check inter 2s weight 1 inter 2s downinter 5s rise 10 fall 2 backup bind *:16379 mode tcp option tcpka option tcplog option tcp-check tcp-check send PING\\r\\n tcp-check expect string +PONG tcp-check send info\\ replication\\r\\n tcp-check expect string role:master tcp-check send QUIT\\r\\n tcp-check expect string +OK balance roundrobin And then just point Centrifugo to this Haproxy: centrifugo --config=config.json --engine=redis --redis_host=localhost --redis_port=16379","title":"Haproxy instead of Sentinel configuration"},{"location":"server/engines/#redis-sharding","text":"Centrifugo has a built-in Redis sharding support. This resolves situation when Redis becoming a bottleneck on large Centrifugo setup. Redis is single-threaded server, it's very fast but it's power is not infinite so when your Redis approaches 100% CPU usage then sharding feature can help your application to scale. At moment Centrifugo supports simple comma-based approach to configuring Redis shards. Let's just look on examples. To start Centrifugo with 2 Redis shards on localhost running on port 6379 and port 6380: centrifugo --config=config.json --engine=redis --redis_port=6379,6380 To start Centrifugo with Redis instances on different hosts: centrifugo --config=config.json --engine=redis --redis_host=192.168.1.34,192.168.1.35 If you also need to customize AUTH password, Redis DB number then you can use redis_url option. Note, that due to how Redis PUB/SUB work it's not possible (and it's pretty useless anyway) to run shards in one Redis instances using different Redis DB numbers. When sharding enabled Centrifugo will spread channels and history/presence keys over configured Redis instances using consistent hashing algorithm. At moment we use Jump consistent hash algorithm (see paper and implementation )","title":"Redis sharding"},{"location":"server/engines/#redis-cluster","text":"Redis cluster supported since Centrifugo v2.5.0 Danger Redis Cluster integration does not support channels API command due to Redis cluster limitations. Other Centrifugo features should work. Running Centrifugo with Redis cluster is simple and can be achieved using redis_cluster_addrs option. This is an array of strings. Each element of array is a comma-separated Redis cluster seed nodes. For example: { ... \"redis_cluster_addrs\" : [ \"localhost:30001,localhost:30002,localhost:30003\" ] } Actually you don't need to list all Redis cluster nodes in config \u2013 only several working nodes is enough to start. To set the same over environment variable: CENTRIFUGO_REDIS_CLUSTER_ADDRS = \"localhost:30001\" CENTRIFUGO_ENGINE = redis ./centrifugo If you need to shard data between several Redis clusters then simply add one more string with seed nodes of another cluster to this array: { ... \"redis_cluster_addrs\" : [ \"localhost:30001,localhost:30002,localhost:30003\" , \"localhost:30101,localhost:30102,localhost:30103\" ] } Sharding between different Redis clusters can make sense due to the fact how PUB/SUB works in Redis cluster. It does not scale linearly when adding nodes as all PUB/SUB messages got copied to every cluster node. See this discussion for more information on topic. To spread data between different Redis clusters Centrifugo uses the same consistent hashing algorithm described above (i.e. Jump ). To reproduce the same over environment variable use space to separate different clusters: CENTRIFUGO_REDIS_CLUSTER_ADDRS = \"localhost:30001,localhost:30002 localhost:30101,localhost:30102\" CENTRIFUGO_ENGINE = redis ./centrifugo","title":"Redis cluster"},{"location":"server/engines/#redis-streams","text":"Since Centrifugo v2.5.0 it's possible to use Redis Stream data structure to keep Publication history inside channels. Redis streams can help to reduce number of memory allocations Centrifugo does during message recovery process upon client reconnect inside large history streams. This can be critical for massive Centrifugo deployments that utilize recovery feature. To turn on using Redis streams use boolean option redis_streams , default false . Redis Streams can become default data structure to keep Publication history in Centrifugo v3.","title":"Redis Streams"},{"location":"server/engines/#keydb","text":"Centrifugo Redis engine seamlessly works with KeyDB . KeyDB server is compatible with Redis and provides several additional features beyond. Though we can't give any promises about compatibility with KeyDB in future Centrifugo releases - while KeyDB is fully compatible with Redis things should work fine. That's why we consider this as EXPERIMENTAL feature. Use KeyDB instead of Redis only if you are really sure you need it. Nothing stops you from running several Redis instances per each core you have, configure sharding and obtain even better performance that KeyDB can provide (due to lack of synchronization between threads in Redis). In order to run Centrifugo with KeyDB all you need to do is use redis engine option and run KeyDB server instead of Redis.","title":"KeyDB"},{"location":"server/engines/#nats-broker","text":"Starting from Centrifugo v2.6.0 it's possible to scale with Nats PUB/SUB server. Keep in mind, that Nats called a broker here, not an Engine \u2013 Nats integration only implements PUB/SUB part of Engine, so carefully read limitations below. Known limitations: Nats integration works only for unreliable at most once PUB/SUB . This means that history, presence and message recovery Centrifugo features won't be available. Nats wildcard channel subscriptions with symbols * and > not supported . First start Nats server: $ nats-server [3569] 2020/07/08 20:28:44.324269 [INF] Starting nats-server version 2.1.7 [3569] 2020/07/08 20:28:44.324400 [INF] Git commit [not set] [3569] 2020/07/08 20:28:44.325600 [INF] Listening for client connections on 0.0.0.0:4222 [3569] 2020/07/08 20:28:44.325612 [INF] Server id is NDAM7GEHUXAKS5SGMA3QE6ZSO4IQUJP6EL3G2E2LJYREVMAMIOBE7JT4 [3569] 2020/07/08 20:28:44.325617 [INF] Server is ready Then start Centrifugo with broker option: centrifugo --broker = nats --config = config.json And one more Centrifugo on another port (of course in real life you will start another Centrifugo on another machine): centrifugo --broker = nats --config = config.json --port = 8001 Now you can scale connections over Centrifugo instances, instances will be connected over Nats server. Available options: nats_url - connection url in format nats://derek:pass@localhost:4222 , by default nats://127.0.0.1:4222 . nats_prefix - prefix for channels used by Centrifugo inside Nats. By default, centrifugo . nats_dial_timeout - timeout for dialing to Nats in seconds, default 1 . nats_write_timeout - write (and flush) timeout on a connection to Nats in seconds, default 1 . It's theoretically possible to use Redis Engine together with Nats broker for presence information. If you are interested in this \u2013 please write to our community chat rooms.","title":"Nats broker"},{"location":"server/grpc_api/","text":"Server GRPC API \u00b6 Centrifugo also supports GRPC API. With GRPC it's possible to communicate with Centrifugo using more compact binary representation of commands and use the power of HTTP/2 which is the transport behind GRPC. GRPC API is also useful if you want to publish binary data to Centrifugo channels. You can enable GRPC API in Centrifugo using grpc_api option: ./centrifugo --config=config.json --grpc_api As always in Centrifugo you can just add grpc_api option to configuration file: { ... \"grpc_api\" : true } By default, GRPC will be served on port 10000 but you can change it using grpc_api_port option. Now as soon as Centrifugo started you can send GRPC commands to it. To do this get our API Protocol Buffer definitions from this file . Then see GRPC docs specific to your language to find out how to generate client code from definitions and use generated code to communicate with Centrifugo. Example for Python \u00b6 For example for Python you need to run sth like this according to GRPC docs: python -m grpc_tools.protoc -I../../protos --python_out=. --grpc_python_out=. api.proto As soon as you run command you will have 2 generated files: api_pb2.py and api_pb2_grpc.py . Now all you need is to write simple program that uses generated code and sends GRPC requests to Centrifugo: import grpc import api_pb2_grpc as api_grpc import api_pb2 as api_pb channel = grpc . insecure_channel ( 'localhost:10000' ) stub = api_grpc . CentrifugoStub ( channel ) try : resp = stub . Info ( api_pb . InfoRequest ()) except grpc . RpcError as err : # GRPC level error. print ( err . code (), err . details ()) else : if resp . error . code : # Centrifugo server level error. print ( resp . error . code , resp . error . message ) else : print ( resp . result ) Note that you need to explicitly handle Centrifugo API level error which is not transformed automatically into GRPC protocol level error. Example for Go \u00b6 Here is a simple example on how to run Centrifugo with GRPC Go client. You need protoc and protoc-gen-go installed. First start Centrifugo itself: centrifugo --config config.json --grpc_api In another terminal tab: cd ~ mkdir centrifugo_grpc_example cd centrifugo_grpc_example/ wget https://raw.githubusercontent.com/centrifugal/centrifugo/master/misc/proto/api.proto -O api.proto protoc api.proto --go_out = plugins = grpc,import_path = main:./ touch main.go Put the following code to main.go file (created on last step above): package main import ( \"context\" \"log\" \"time\" \"google.golang.org/grpc\" ) func main () { conn , err := grpc . Dial ( \"localhost:10000\" , grpc . WithInsecure ()) if err != nil { log . Fatalln ( err ) } defer conn . Close () client := NewCentrifugoClient ( conn ) for { resp , err := client . Publish ( context . Background (), & PublishRequest { Channel : \"chat:index\" , Data : [] byte ( `{\"input\": \"hello from GRPC\"}` ), }) if err != nil { log . Printf ( \"Transport level error: %v\" , err ) } else { if resp . GetError () != nil { respError := resp . GetError () log . Printf ( \"Error %d (%s)\" , respError . Code , respError . Message ) } else { log . Println ( \"Successfully published\" ) } } time . Sleep ( time . Second ) } } Then run: GO111MODULE = on go run *.go The program starts and periodically publishes the same payload into chat:index channel. API key authorization \u00b6 Available since v2.6.1. You can also set grpc_api_key (string) in Centrifugo configuration to protect GRPC API with key. In this case you should set per RPC metadata with key authorization and value apikey <KEY> . For example in Go language: package main import ( \"context\" \"log\" \"time\" \"google.golang.org/grpc\" ) type keyAuth struct { key string } func ( t keyAuth ) GetRequestMetadata ( ctx context . Context , uri ... string ) ( map [ string ] string , error ) { return map [ string ] string { \"authorization\" : \"apikey \" + t . key , }, nil } func ( t keyAuth ) RequireTransportSecurity () bool { return false } func main () { conn , err := grpc . Dial ( \"localhost:10000\" , grpc . WithInsecure (), grpc . WithPerRPCCredentials ( keyAuth { \"xxx\" })) if err != nil { log . Fatalln ( err ) } defer conn . Close () client := NewCentrifugoClient ( conn ) for { resp , err := client . Publish ( context . Background (), & PublishRequest { Channel : \"chat:index\" , Data : [] byte ( `{\"input\": \"hello from GRPC\"}` ), }) if err != nil { log . Printf ( \"Transport level error: %v\" , err ) } else { if resp . GetError () != nil { respError := resp . GetError () log . Printf ( \"Error %d (%s)\" , respError . Code , respError . Message ) } else { log . Println ( \"Successfully published\" ) } } time . Sleep ( time . Second ) } } For other languages refer to GRPC docs.","title":"Server GRPC API"},{"location":"server/grpc_api/#server-grpc-api","text":"Centrifugo also supports GRPC API. With GRPC it's possible to communicate with Centrifugo using more compact binary representation of commands and use the power of HTTP/2 which is the transport behind GRPC. GRPC API is also useful if you want to publish binary data to Centrifugo channels. You can enable GRPC API in Centrifugo using grpc_api option: ./centrifugo --config=config.json --grpc_api As always in Centrifugo you can just add grpc_api option to configuration file: { ... \"grpc_api\" : true } By default, GRPC will be served on port 10000 but you can change it using grpc_api_port option. Now as soon as Centrifugo started you can send GRPC commands to it. To do this get our API Protocol Buffer definitions from this file . Then see GRPC docs specific to your language to find out how to generate client code from definitions and use generated code to communicate with Centrifugo.","title":"Server GRPC API"},{"location":"server/grpc_api/#example-for-python","text":"For example for Python you need to run sth like this according to GRPC docs: python -m grpc_tools.protoc -I../../protos --python_out=. --grpc_python_out=. api.proto As soon as you run command you will have 2 generated files: api_pb2.py and api_pb2_grpc.py . Now all you need is to write simple program that uses generated code and sends GRPC requests to Centrifugo: import grpc import api_pb2_grpc as api_grpc import api_pb2 as api_pb channel = grpc . insecure_channel ( 'localhost:10000' ) stub = api_grpc . CentrifugoStub ( channel ) try : resp = stub . Info ( api_pb . InfoRequest ()) except grpc . RpcError as err : # GRPC level error. print ( err . code (), err . details ()) else : if resp . error . code : # Centrifugo server level error. print ( resp . error . code , resp . error . message ) else : print ( resp . result ) Note that you need to explicitly handle Centrifugo API level error which is not transformed automatically into GRPC protocol level error.","title":"Example for Python"},{"location":"server/grpc_api/#example-for-go","text":"Here is a simple example on how to run Centrifugo with GRPC Go client. You need protoc and protoc-gen-go installed. First start Centrifugo itself: centrifugo --config config.json --grpc_api In another terminal tab: cd ~ mkdir centrifugo_grpc_example cd centrifugo_grpc_example/ wget https://raw.githubusercontent.com/centrifugal/centrifugo/master/misc/proto/api.proto -O api.proto protoc api.proto --go_out = plugins = grpc,import_path = main:./ touch main.go Put the following code to main.go file (created on last step above): package main import ( \"context\" \"log\" \"time\" \"google.golang.org/grpc\" ) func main () { conn , err := grpc . Dial ( \"localhost:10000\" , grpc . WithInsecure ()) if err != nil { log . Fatalln ( err ) } defer conn . Close () client := NewCentrifugoClient ( conn ) for { resp , err := client . Publish ( context . Background (), & PublishRequest { Channel : \"chat:index\" , Data : [] byte ( `{\"input\": \"hello from GRPC\"}` ), }) if err != nil { log . Printf ( \"Transport level error: %v\" , err ) } else { if resp . GetError () != nil { respError := resp . GetError () log . Printf ( \"Error %d (%s)\" , respError . Code , respError . Message ) } else { log . Println ( \"Successfully published\" ) } } time . Sleep ( time . Second ) } } Then run: GO111MODULE = on go run *.go The program starts and periodically publishes the same payload into chat:index channel.","title":"Example for Go"},{"location":"server/grpc_api/#api-key-authorization","text":"Available since v2.6.1. You can also set grpc_api_key (string) in Centrifugo configuration to protect GRPC API with key. In this case you should set per RPC metadata with key authorization and value apikey <KEY> . For example in Go language: package main import ( \"context\" \"log\" \"time\" \"google.golang.org/grpc\" ) type keyAuth struct { key string } func ( t keyAuth ) GetRequestMetadata ( ctx context . Context , uri ... string ) ( map [ string ] string , error ) { return map [ string ] string { \"authorization\" : \"apikey \" + t . key , }, nil } func ( t keyAuth ) RequireTransportSecurity () bool { return false } func main () { conn , err := grpc . Dial ( \"localhost:10000\" , grpc . WithInsecure (), grpc . WithPerRPCCredentials ( keyAuth { \"xxx\" })) if err != nil { log . Fatalln ( err ) } defer conn . Close () client := NewCentrifugoClient ( conn ) for { resp , err := client . Publish ( context . Background (), & PublishRequest { Channel : \"chat:index\" , Data : [] byte ( `{\"input\": \"hello from GRPC\"}` ), }) if err != nil { log . Printf ( \"Transport level error: %v\" , err ) } else { if resp . GetError () != nil { respError := resp . GetError () log . Printf ( \"Error %d (%s)\" , respError . Code , respError . Message ) } else { log . Println ( \"Successfully published\" ) } } time . Sleep ( time . Second ) } } For other languages refer to GRPC docs.","title":"API key authorization"},{"location":"server/http_api/","text":"Server HTTP API \u00b6 HTTP API is a way to send commands to Centrifugo. For example, server API allows publishing messages to channels. Server HTTP API works on /api endpoint. It has very simple request format: this is a HTTP POST request with application/json Content-Type and with JSON command body. In most cases though you can just use one of our available HTTP API libraries . In this chapter we will make an API method overview. API protected by api_key set in Centrifugo configuration. I.e. api_key must be added to config, like: { ... \"api_key\" : \"<YOUR API KEY>\" } This API key must be set in request Authorization header in this way: Authorization: apikey <KEY> Starting from Centrifugo v2.2.7 it's also possible to pass API key over URL query param. This solves some edge cases where it's not possible to use Authorization header. Simply add ?api_key=<YOUR API KEY> query param to API endpoint. Keep in mind that passing API key in Authorization header is a recommended way. It's possible to disable API key check on Centrifugo side using api_insecure configuration option. Be sure to protect API endpoint by firewall rules in this case to prevent anyone in internet to send commands over your unprotected Centrifugo API. API key auth is not very safe for man-in-the-middle so recommended way is running Centrifugo with TLS (we are in 2018 in the end). Command is a JSON object with two properties: method and params . method is a name of command you want to call. params is an object with command arguments. There are several commands available. Let's investigate each of available server API commands. publish \u00b6 Publish command allows publishing data into a channel. It looks like this: { \"method\" : \"publish\" , \"params\" : { \"channel\" : \"chat\" , \"data\" : { \"text\" : \"hello\" } } } Let's apply all information said above and send publish command to Centrifugo. We will send request using requests library for Python. import json import requests command = { \"method\" : \"publish\" , \"params\" : { \"channel\" : \"docs\" , \"data\" : { \"content\" : \"1\" } } } api_key = \"YOUR_API_KEY\" data = json . dumps ( command ) headers = { 'Content-type' : 'application/json' , 'Authorization' : 'apikey ' + api_key } resp = requests . post ( \"https://centrifuge.example.com/api\" , data = data , headers = headers ) print ( resp . json ()) The same using httpie console tool: $ echo '{\"method\": \"publish\", \"params\": {\"channel\": \"chat\", \"data\": {\"text\": \"hello\"}}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" -vvv POST /api HTTP/1.1 Accept: application/json, */* Accept-Encoding: gzip, deflate Authorization: apikey KEY Connection: keep-alive Content-Length: 80 Content-Type: application/json Host: localhost:8000 User-Agent: HTTPie/0.9.8 { \"method\" : \"publish\" , \"params\" : { \"channel\" : \"chat\" , \"data\" : { \"text\" : \"hello\" } } } HTTP/1.1 200 OK Content-Length: 3 Content-Type: application/json Date: Thu, 17 May 2018 22 :01:42 GMT {} In case of error response object will contain error field: $ echo '{\"method\": \"publish\", \"params\": {\"channel\": \"unknown:chat\", \"data\": {\"text\": \"hello\"}}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 55 Content-Type: application/json Date: Thu, 17 May 2018 22 :03:09 GMT { \"error\" : { \"code\" : 102 , \"message\" : \"namespace not found\" } } error object contains error code and message - this also the same for other commands described below. publish command is the main command you need. Again - remember that we have client API libraries that can help you avoid some boilerplate we just wrote and help to properly handle error responses from Centrifugo. Let's look at other available commands: broadcast \u00b6 Similar to publish but allows to send the same data into many channels. { \"method\" : \"broadcast\" , \"params\" : { \"channels\" : [ \"CHANNEL_1\" , \"CHANNEL_2\" ], \"data\" : { \"text\" : \"hello\" } } } unsubscribe \u00b6 unsubscribe allows unsubscribing user from a channel. params is an object with two keys: channel and user (user ID you want to unsubscribe) { \"method\" : \"unsubscribe\" , \"params\" : { \"channel\" : \"CHANNEL NAME\" , \"user\" : \"USER ID\" } } disconnect \u00b6 disconnect allows disconnecting user by ID. params in an object with user key. { \"method\" : \"disconnect\" , \"params\" : { \"user\" : \"USER ID\" } } presence \u00b6 presence allows getting channel presence information (all clients currently subscribed on this channel). params is an object with channel key. { \"method\" : \"presence\" , \"params\" : { \"channel\" : \"chat\" } } Example: fz@centrifugo: echo '{\"method\": \"presence\", \"params\": {\"channel\": \"chat\"}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 127 Content-Type: application/json Date: Thu, 17 May 2018 22 :13:17 GMT { \"result\" : { \"presence\" : { \"c54313b2-0442-499a-a70c-051f8588020f\" : { \"client\" : \"c54313b2-0442-499a-a70c-051f8588020f\" , \"user\" : \"42\" } , \"adad13b1-0442-499a-a70c-051f858802da\" : { \"client\" : \"adad13b1-0442-499a-a70c-051f858802da\" , \"user\" : \"42\" } } } } presence_stats \u00b6 presence_stats allows getting short channel presence information. { \"method\" : \"presence_stats\" , \"params\" : { \"channel\" : \"chat\" } } Example: $ echo '{\"method\": \"presence_stats\", \"params\": {\"channel\": \"public:chat\"}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 43 Content-Type: application/json Date: Thu, 17 May 2018 22 :09:44 GMT { \"result\" : { \"num_clients\" : 0 , \"num_users\" : 0 } } history \u00b6 history allows getting channel history information (list of last messages published into channel). params is an object with channel key: { \"method\" : \"history\" , \"params\" : { \"channel\" : \"chat\" } } Example: $ echo '{\"method\": \"history\", \"params\": {\"channel\": \"public:chat\"}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 87 Content-Type: application/json Date: Thu, 17 May 2018 22 :14:10 GMT { \"result\" : { \"publications\" : [ { \"data\" : { \"text\" : \"hello\" } , \"uid\" : \"BWcn14OTBrqUhTXyjNg0fg\" } , { \"data\" : { \"text\" : \"hi!\" } , \"uid\" : \"Ascn14OTBrq14OXyjNg0hg\" } ] } } channels \u00b6 channels allows getting list of active (with one or more subscribers) channels. { \"method\" : \"channels\" , \"params\" : {} } Example: $ echo '{\"method\": \"channels\", \"params\": {}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 27 Content-Type: application/json Date: Thu, 17 May 2018 22 :08:31 GMT { \"result\" : { \"channels\" : [ \"chat\" ] } } Keep in mind that since channels API command returns all active channels it can be really heavy for massive deployments. At moment there is no way to paginate over channels list and we don't know a case where this could be useful and not error prone. At the moment we mostly suppose that channels command will be used in development process and in not very massive Centrifugo setups (with no more than 10k channels). Also channels command considered optional in engine implementations. A better and scalable approach could be real-time analytics approach described here . info \u00b6 info method allows getting information about running Centrifugo nodes. { \"method\" : \"info\" , \"params\" : {} } Example: $ echo '{\"method\": \"info\", \"params\": {}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 184 Content-Type: application/json Date: Thu, 17 May 2018 22 :07:58 GMT { \"result\" : { \"nodes\" : [ { \"name\" : \"Alexanders-MacBook-Pro.local_8000\" , \"num_channels\" : 0 , \"num_clients\" : 0 , \"num_users\" : 0 , \"uid\" : \"f844a2ed-5edf-4815-b83c-271974003db9\" , \"uptime\" : 0 , \"version\" : \"\" } ] } } Command pipelining \u00b6 It's possible to combine several commands into one request to Centrifugo. To do this use JSON streaming format. This can improve server throughput and reduce traffic travelling around.","title":"Server HTTP API"},{"location":"server/http_api/#server-http-api","text":"HTTP API is a way to send commands to Centrifugo. For example, server API allows publishing messages to channels. Server HTTP API works on /api endpoint. It has very simple request format: this is a HTTP POST request with application/json Content-Type and with JSON command body. In most cases though you can just use one of our available HTTP API libraries . In this chapter we will make an API method overview. API protected by api_key set in Centrifugo configuration. I.e. api_key must be added to config, like: { ... \"api_key\" : \"<YOUR API KEY>\" } This API key must be set in request Authorization header in this way: Authorization: apikey <KEY> Starting from Centrifugo v2.2.7 it's also possible to pass API key over URL query param. This solves some edge cases where it's not possible to use Authorization header. Simply add ?api_key=<YOUR API KEY> query param to API endpoint. Keep in mind that passing API key in Authorization header is a recommended way. It's possible to disable API key check on Centrifugo side using api_insecure configuration option. Be sure to protect API endpoint by firewall rules in this case to prevent anyone in internet to send commands over your unprotected Centrifugo API. API key auth is not very safe for man-in-the-middle so recommended way is running Centrifugo with TLS (we are in 2018 in the end). Command is a JSON object with two properties: method and params . method is a name of command you want to call. params is an object with command arguments. There are several commands available. Let's investigate each of available server API commands.","title":"Server HTTP API"},{"location":"server/http_api/#publish","text":"Publish command allows publishing data into a channel. It looks like this: { \"method\" : \"publish\" , \"params\" : { \"channel\" : \"chat\" , \"data\" : { \"text\" : \"hello\" } } } Let's apply all information said above and send publish command to Centrifugo. We will send request using requests library for Python. import json import requests command = { \"method\" : \"publish\" , \"params\" : { \"channel\" : \"docs\" , \"data\" : { \"content\" : \"1\" } } } api_key = \"YOUR_API_KEY\" data = json . dumps ( command ) headers = { 'Content-type' : 'application/json' , 'Authorization' : 'apikey ' + api_key } resp = requests . post ( \"https://centrifuge.example.com/api\" , data = data , headers = headers ) print ( resp . json ()) The same using httpie console tool: $ echo '{\"method\": \"publish\", \"params\": {\"channel\": \"chat\", \"data\": {\"text\": \"hello\"}}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" -vvv POST /api HTTP/1.1 Accept: application/json, */* Accept-Encoding: gzip, deflate Authorization: apikey KEY Connection: keep-alive Content-Length: 80 Content-Type: application/json Host: localhost:8000 User-Agent: HTTPie/0.9.8 { \"method\" : \"publish\" , \"params\" : { \"channel\" : \"chat\" , \"data\" : { \"text\" : \"hello\" } } } HTTP/1.1 200 OK Content-Length: 3 Content-Type: application/json Date: Thu, 17 May 2018 22 :01:42 GMT {} In case of error response object will contain error field: $ echo '{\"method\": \"publish\", \"params\": {\"channel\": \"unknown:chat\", \"data\": {\"text\": \"hello\"}}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 55 Content-Type: application/json Date: Thu, 17 May 2018 22 :03:09 GMT { \"error\" : { \"code\" : 102 , \"message\" : \"namespace not found\" } } error object contains error code and message - this also the same for other commands described below. publish command is the main command you need. Again - remember that we have client API libraries that can help you avoid some boilerplate we just wrote and help to properly handle error responses from Centrifugo. Let's look at other available commands:","title":"publish"},{"location":"server/http_api/#broadcast","text":"Similar to publish but allows to send the same data into many channels. { \"method\" : \"broadcast\" , \"params\" : { \"channels\" : [ \"CHANNEL_1\" , \"CHANNEL_2\" ], \"data\" : { \"text\" : \"hello\" } } }","title":"broadcast"},{"location":"server/http_api/#unsubscribe","text":"unsubscribe allows unsubscribing user from a channel. params is an object with two keys: channel and user (user ID you want to unsubscribe) { \"method\" : \"unsubscribe\" , \"params\" : { \"channel\" : \"CHANNEL NAME\" , \"user\" : \"USER ID\" } }","title":"unsubscribe"},{"location":"server/http_api/#disconnect","text":"disconnect allows disconnecting user by ID. params in an object with user key. { \"method\" : \"disconnect\" , \"params\" : { \"user\" : \"USER ID\" } }","title":"disconnect"},{"location":"server/http_api/#presence","text":"presence allows getting channel presence information (all clients currently subscribed on this channel). params is an object with channel key. { \"method\" : \"presence\" , \"params\" : { \"channel\" : \"chat\" } } Example: fz@centrifugo: echo '{\"method\": \"presence\", \"params\": {\"channel\": \"chat\"}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 127 Content-Type: application/json Date: Thu, 17 May 2018 22 :13:17 GMT { \"result\" : { \"presence\" : { \"c54313b2-0442-499a-a70c-051f8588020f\" : { \"client\" : \"c54313b2-0442-499a-a70c-051f8588020f\" , \"user\" : \"42\" } , \"adad13b1-0442-499a-a70c-051f858802da\" : { \"client\" : \"adad13b1-0442-499a-a70c-051f858802da\" , \"user\" : \"42\" } } } }","title":"presence"},{"location":"server/http_api/#presence_stats","text":"presence_stats allows getting short channel presence information. { \"method\" : \"presence_stats\" , \"params\" : { \"channel\" : \"chat\" } } Example: $ echo '{\"method\": \"presence_stats\", \"params\": {\"channel\": \"public:chat\"}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 43 Content-Type: application/json Date: Thu, 17 May 2018 22 :09:44 GMT { \"result\" : { \"num_clients\" : 0 , \"num_users\" : 0 } }","title":"presence_stats"},{"location":"server/http_api/#history","text":"history allows getting channel history information (list of last messages published into channel). params is an object with channel key: { \"method\" : \"history\" , \"params\" : { \"channel\" : \"chat\" } } Example: $ echo '{\"method\": \"history\", \"params\": {\"channel\": \"public:chat\"}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 87 Content-Type: application/json Date: Thu, 17 May 2018 22 :14:10 GMT { \"result\" : { \"publications\" : [ { \"data\" : { \"text\" : \"hello\" } , \"uid\" : \"BWcn14OTBrqUhTXyjNg0fg\" } , { \"data\" : { \"text\" : \"hi!\" } , \"uid\" : \"Ascn14OTBrq14OXyjNg0hg\" } ] } }","title":"history"},{"location":"server/http_api/#channels","text":"channels allows getting list of active (with one or more subscribers) channels. { \"method\" : \"channels\" , \"params\" : {} } Example: $ echo '{\"method\": \"channels\", \"params\": {}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 27 Content-Type: application/json Date: Thu, 17 May 2018 22 :08:31 GMT { \"result\" : { \"channels\" : [ \"chat\" ] } } Keep in mind that since channels API command returns all active channels it can be really heavy for massive deployments. At moment there is no way to paginate over channels list and we don't know a case where this could be useful and not error prone. At the moment we mostly suppose that channels command will be used in development process and in not very massive Centrifugo setups (with no more than 10k channels). Also channels command considered optional in engine implementations. A better and scalable approach could be real-time analytics approach described here .","title":"channels"},{"location":"server/http_api/#info","text":"info method allows getting information about running Centrifugo nodes. { \"method\" : \"info\" , \"params\" : {} } Example: $ echo '{\"method\": \"info\", \"params\": {}}' | http \"localhost:8000/api\" Authorization: \"apikey KEY\" HTTP/1.1 200 OK Content-Length: 184 Content-Type: application/json Date: Thu, 17 May 2018 22 :07:58 GMT { \"result\" : { \"nodes\" : [ { \"name\" : \"Alexanders-MacBook-Pro.local_8000\" , \"num_channels\" : 0 , \"num_clients\" : 0 , \"num_users\" : 0 , \"uid\" : \"f844a2ed-5edf-4815-b83c-271974003db9\" , \"uptime\" : 0 , \"version\" : \"\" } ] } }","title":"info"},{"location":"server/http_api/#command-pipelining","text":"It's possible to combine several commands into one request to Centrifugo. To do this use JSON streaming format. This can improve server throughput and reduce traffic travelling around.","title":"Command pipelining"},{"location":"server/install/","text":"Server overview and installation \u00b6 Centrifugo server written in Go language. It's an open-source software, the source code is available on Github . Centrifugo is built around Centrifuge library for Go language. That library defines custom protocol and message types which must be sent over various transports (Websocket, SockJS). Server clients use that protocol internally and provide simple API to features - making persistent connection, subscribing on channels, calling RPC commands and more. Server documentation covers a lot of server concepts in detail. Here we start with ways to install Centrifugo on your system. Install from binary release \u00b6 Binary releases available on Github. Download latest release for your operating system, unpack it and you are done. Centrifugo is pre-built for: Linux 64-bit (linux_amd64) Linux 32-bit (linux_386) MacOS (darwin_amd64) Windows (windows_amd64) FreeBSD (freebsd_amd64) ARM v6 (linux_armv6) Archives contain a single statically compiled binary centrifugo file which is ready to run: ./centrifugo -h See version of Centrifugo: ./centrifugo version Centrifugo server node requires configuration file with some secret keys. If you are new to Centrifugo then there is genconfig command which generates minimal required configuration file: ./centrifugo genconfig It generates secret keys automatically and creates configuration file config.json in a current directory (by default) so you can finally run Centrifugo instance: ./centrifugo --config = config.json We will talk about a configuration in detail in next sections. You can also put or symlink centrifugo into your bin OS directory and run it from anywhere: centrifugo --config = config.json Docker image \u00b6 Centrifugo server has docker image available on Docker Hub . docker pull centrifugo/centrifugo Run: docker run --ulimit nofile = 65536 :65536 -v /host/dir/with/config/file:/centrifugo -p 8000 :8000 centrifugo/centrifugo centrifugo -c config.json Note that docker allows setting nofile limits in command-line arguments which is pretty important to handle lots of simultaneous persistent connections and not run out of open file limit (each connection requires one file descriptor). See also OS tuning chapter . Docker-compose example \u00b6 Create configuration file config.json : { \"v3_use_offset\" : true , \"token_hmac_secret_key\" : \"my_secret\" , \"api_key\" : \"my_api_key\" , \"admin_password\" : \"password\" , \"admin_secret\" : \"secret\" , \"admin\" : true } Create docker-compose.yml : centrifugo: container_name: centrifugo image: centrifugo/centrifugo:latest volumes: - ./config.json:/centrifugo/config.json command: centrifugo -c config.json ports: - 8000:8000 ulimits: nofile: soft: 65535 hard: 65535 Run with: docker-compose up Kubernetes Helm chart \u00b6 Official Kubernetes Helm chart available and located on Github . Follow instructions in repository README to bootstrap Centrifugo inside your Kubernetes cluster. RPM and DEB packages for Linux \u00b6 Every time we make new Centrifugo release we upload rpm and deb packages for popular linux distributions on packagecloud.io . At moment, we support versions of the following distributions: 64-bit Debian 8 Jessie 64-bit Debian 9 Stretch 64-bit Debian 10 Buster 64-bit Ubuntu 16.04 Xenial 64-bit Ubuntu 18.04 Bionic 64-bit Ubuntu 20.04 Focal Fossa 64-bit Centos 7 64-bit Centos 8 See full list of available packages and installation instructions . Centrifugo also works on 32-bit architecture, but we don't support packaging for it since 64-bit is more convenient for servers today. With brew on MacOS \u00b6 If you are developing on MacOS then you can install Centrifugo over brew : brew tap centrifugal/centrifugo brew install centrifugo Build from source \u00b6 You need Go language installed: git clone https://github.com/centrifugal/centrifugo.git cd centrifugo go build ./centrifugo Centrifugo vendors dependencies at the moment, if you want to build using vendored deps run: go build -mod vendor ./centrifugo","title":"Installation"},{"location":"server/install/#server-overview-and-installation","text":"Centrifugo server written in Go language. It's an open-source software, the source code is available on Github . Centrifugo is built around Centrifuge library for Go language. That library defines custom protocol and message types which must be sent over various transports (Websocket, SockJS). Server clients use that protocol internally and provide simple API to features - making persistent connection, subscribing on channels, calling RPC commands and more. Server documentation covers a lot of server concepts in detail. Here we start with ways to install Centrifugo on your system.","title":"Server overview and installation"},{"location":"server/install/#install-from-binary-release","text":"Binary releases available on Github. Download latest release for your operating system, unpack it and you are done. Centrifugo is pre-built for: Linux 64-bit (linux_amd64) Linux 32-bit (linux_386) MacOS (darwin_amd64) Windows (windows_amd64) FreeBSD (freebsd_amd64) ARM v6 (linux_armv6) Archives contain a single statically compiled binary centrifugo file which is ready to run: ./centrifugo -h See version of Centrifugo: ./centrifugo version Centrifugo server node requires configuration file with some secret keys. If you are new to Centrifugo then there is genconfig command which generates minimal required configuration file: ./centrifugo genconfig It generates secret keys automatically and creates configuration file config.json in a current directory (by default) so you can finally run Centrifugo instance: ./centrifugo --config = config.json We will talk about a configuration in detail in next sections. You can also put or symlink centrifugo into your bin OS directory and run it from anywhere: centrifugo --config = config.json","title":"Install from binary release"},{"location":"server/install/#docker-image","text":"Centrifugo server has docker image available on Docker Hub . docker pull centrifugo/centrifugo Run: docker run --ulimit nofile = 65536 :65536 -v /host/dir/with/config/file:/centrifugo -p 8000 :8000 centrifugo/centrifugo centrifugo -c config.json Note that docker allows setting nofile limits in command-line arguments which is pretty important to handle lots of simultaneous persistent connections and not run out of open file limit (each connection requires one file descriptor). See also OS tuning chapter .","title":"Docker image"},{"location":"server/install/#docker-compose-example","text":"Create configuration file config.json : { \"v3_use_offset\" : true , \"token_hmac_secret_key\" : \"my_secret\" , \"api_key\" : \"my_api_key\" , \"admin_password\" : \"password\" , \"admin_secret\" : \"secret\" , \"admin\" : true } Create docker-compose.yml : centrifugo: container_name: centrifugo image: centrifugo/centrifugo:latest volumes: - ./config.json:/centrifugo/config.json command: centrifugo -c config.json ports: - 8000:8000 ulimits: nofile: soft: 65535 hard: 65535 Run with: docker-compose up","title":"Docker-compose example"},{"location":"server/install/#kubernetes-helm-chart","text":"Official Kubernetes Helm chart available and located on Github . Follow instructions in repository README to bootstrap Centrifugo inside your Kubernetes cluster.","title":"Kubernetes Helm chart"},{"location":"server/install/#rpm-and-deb-packages-for-linux","text":"Every time we make new Centrifugo release we upload rpm and deb packages for popular linux distributions on packagecloud.io . At moment, we support versions of the following distributions: 64-bit Debian 8 Jessie 64-bit Debian 9 Stretch 64-bit Debian 10 Buster 64-bit Ubuntu 16.04 Xenial 64-bit Ubuntu 18.04 Bionic 64-bit Ubuntu 20.04 Focal Fossa 64-bit Centos 7 64-bit Centos 8 See full list of available packages and installation instructions . Centrifugo also works on 32-bit architecture, but we don't support packaging for it since 64-bit is more convenient for servers today.","title":"RPM and DEB packages for Linux"},{"location":"server/install/#with-brew-on-macos","text":"If you are developing on MacOS then you can install Centrifugo over brew : brew tap centrifugal/centrifugo brew install centrifugo","title":"With brew on MacOS"},{"location":"server/install/#build-from-source","text":"You need Go language installed: git clone https://github.com/centrifugal/centrifugo.git cd centrifugo go build ./centrifugo Centrifugo vendors dependencies at the moment, if you want to build using vendored deps run: go build -mod vendor ./centrifugo","title":"Build from source"},{"location":"server/private_channels/","text":"Private channels \u00b6 In channels chapter we mentioned private channels. This chapter has more information about private channel mechanism in Centrifugo. All channels starting with $ considered private. In this case your backend should additionally provide token for every subscription request to such a channel . This way you can control subscription permissions and only allow certain users to subscribe to a channel. The way how this token obtained varies depending on client implementation. For example in Javascript client AJAX POST request automatically sent to /centrifuge/subscribe endpoint on every private channel subscription attempt. Other client libraries can provide a hook for your custom code that will obtain private channel subscription token from application backend. Private channel subscription token is also JWT (like connection token described in authentication chapter ). But it has different claims. Note Connection token and private channel subscription token are different entities. Though both are JWT, and you can generate them using any JWT library. Note Even when authorizing subscription to private channel with private subscription JWT you should set a proper connection JWT for a client as it provides user authentication details to Centrifugo. Note When you need to use namespace for private channel then the name of namespace should be written after $ symbol, i.e. if you have namespace name chat then private channel which belongs to that namespace must be written as sth like $chat:stream . Supported JWT algorithms for private subscription tokens match algorithms to create connection JWT. Claims \u00b6 Private channel subscription token claims are: client , channel , info , b64info , exp and eto . What do they mean? Let's describe in detail. client \u00b6 Required. Client ID which wants to subscribe on a channel ( string ). Note Centrifugo server sets a unique client ID for each incoming connection. This client ID regenerated on every reconnect. You must use this client ID for private channel subscription token. If you are using centrifuge-js library then Client ID and Subscription Channels will be automaticaly added to POST request. In other cases refer to specific client documentation (in most cases you will have client ID in private subscription event context) channel \u00b6 Required. Channel that client tries to subscribe to ( string ). info \u00b6 Optional. Additional information for connection inside this channel ( valid JSON ). b64info \u00b6 Optional. Additional information for connection inside this channel in base64 format ( string ). exp \u00b6 Optional. This is standard JWT claim that allows to set private channel subscription token expiration time. At moment if subscription token expires client connection will be closed and client will try to reconnect. In most cases you don't need this and should prefer using exp of connection token to deactivate connection. But if you need more granular per-channel control this may fit your needs. Once exp set in token every subscription token must be periodically refreshed. Refer to specific client documentation in order to see how to refresh subscription tokens. eto \u00b6 Optional. An eto boolean flag can be used to indicate that Centrifugo must only check token expiration but not turn on Subscription expiration checks on server side. This allows to implement one-time subcription tokens. Example \u00b6 So to generate subscription token you can use something like this in Python (assuming client ID is XXX and private channel is $gossips ): import jwt token = jwt . encode ({ \"client\" : \"XXX\" , \"channel\" : \"$gossips\" }, \"secret\" , algorithm = \"HS256\" ) . decode () print ( token ) Where \"secret\" is the token_hmac_secret_key from Centrifugo configuration (we use HMAC tokens in this example which relies on shared secret key, for RSA or ECDSA tokens you need to use private key known only by your backend).","title":"Private channels"},{"location":"server/private_channels/#private-channels","text":"In channels chapter we mentioned private channels. This chapter has more information about private channel mechanism in Centrifugo. All channels starting with $ considered private. In this case your backend should additionally provide token for every subscription request to such a channel . This way you can control subscription permissions and only allow certain users to subscribe to a channel. The way how this token obtained varies depending on client implementation. For example in Javascript client AJAX POST request automatically sent to /centrifuge/subscribe endpoint on every private channel subscription attempt. Other client libraries can provide a hook for your custom code that will obtain private channel subscription token from application backend. Private channel subscription token is also JWT (like connection token described in authentication chapter ). But it has different claims. Note Connection token and private channel subscription token are different entities. Though both are JWT, and you can generate them using any JWT library. Note Even when authorizing subscription to private channel with private subscription JWT you should set a proper connection JWT for a client as it provides user authentication details to Centrifugo. Note When you need to use namespace for private channel then the name of namespace should be written after $ symbol, i.e. if you have namespace name chat then private channel which belongs to that namespace must be written as sth like $chat:stream . Supported JWT algorithms for private subscription tokens match algorithms to create connection JWT.","title":"Private channels"},{"location":"server/private_channels/#claims","text":"Private channel subscription token claims are: client , channel , info , b64info , exp and eto . What do they mean? Let's describe in detail.","title":"Claims"},{"location":"server/private_channels/#client","text":"Required. Client ID which wants to subscribe on a channel ( string ). Note Centrifugo server sets a unique client ID for each incoming connection. This client ID regenerated on every reconnect. You must use this client ID for private channel subscription token. If you are using centrifuge-js library then Client ID and Subscription Channels will be automaticaly added to POST request. In other cases refer to specific client documentation (in most cases you will have client ID in private subscription event context)","title":"client"},{"location":"server/private_channels/#channel","text":"Required. Channel that client tries to subscribe to ( string ).","title":"channel"},{"location":"server/private_channels/#info","text":"Optional. Additional information for connection inside this channel ( valid JSON ).","title":"info"},{"location":"server/private_channels/#b64info","text":"Optional. Additional information for connection inside this channel in base64 format ( string ).","title":"b64info"},{"location":"server/private_channels/#exp","text":"Optional. This is standard JWT claim that allows to set private channel subscription token expiration time. At moment if subscription token expires client connection will be closed and client will try to reconnect. In most cases you don't need this and should prefer using exp of connection token to deactivate connection. But if you need more granular per-channel control this may fit your needs. Once exp set in token every subscription token must be periodically refreshed. Refer to specific client documentation in order to see how to refresh subscription tokens.","title":"exp"},{"location":"server/private_channels/#eto","text":"Optional. An eto boolean flag can be used to indicate that Centrifugo must only check token expiration but not turn on Subscription expiration checks on server side. This allows to implement one-time subcription tokens.","title":"eto"},{"location":"server/private_channels/#example","text":"So to generate subscription token you can use something like this in Python (assuming client ID is XXX and private channel is $gossips ): import jwt token = jwt . encode ({ \"client\" : \"XXX\" , \"channel\" : \"$gossips\" }, \"secret\" , algorithm = \"HS256\" ) . decode () print ( token ) Where \"secret\" is the token_hmac_secret_key from Centrifugo configuration (we use HMAC tokens in this example which relies on shared secret key, for RSA or ECDSA tokens you need to use private key known only by your backend).","title":"Example"},{"location":"server/proxy/","text":"Proxy calls to app backend \u00b6 It's possible to proxy some client connection events over HTTP to application backend and react to them in a way you need. For example, you can authenticate connection via request from Centrifugo to your app backend, refresh client sessions and answer to RPC calls sent by client over WebSocket or SockJS connections. Proxy request structure \u00b6 All proxy calls are HTTP POST requests that will be sent from Centrifugo to configured endpoints with a configured timeout. These requests will have some headers copied from original client request (see details below) and include JSON body which varies depending on call type (for example data sent by client in RPC call etc, see more details about JSON bodies below). Proxy headers \u00b6 By default, the following headers from original client request will be copied to proxied request: Origin (Centrifugo >= v2.3.1) User-Agent Cookie Authorization X-Real-Ip X-Forwarded-For X-Request-Id It's possible to add extra headers using proxy_extra_http_headers configuration option (available since v2.3.1). This is an array of strings in configuration file, ex: { ... \"proxy_extra_http_headers\" : [ \"X-B3-TraceId\" , \"X-B3-SpanId\" ] } Alternatively you can set extra headers via environment variable (space separated): export CENTRIFUGO_PROXY_EXTRA_HTTP_HEADERS=\"X-B3-TraceId X-B3-SpanId\" ./centrifugo Since v2.5.1 Centrifugo also forces Content-Type header to be application/json in all proxy HTTP requests since it sends body in JSON format to application backend. Connect proxy \u00b6 With the following options in configuration file: { ... \"proxy_connect_endpoint\" : \"http://localhost:3000/centrifugo/connect\" , \"proxy_connect_timeout\" : 1 } \u2013 connection requests without JWT set will be proxied to proxy_connect_endpoint URL endpoint. On your backend side you can authenticate incoming connection and return client credentials to Centrifugo in response to proxied request. This means you don't need to generate JWT token and pass it to client side and can rely on cookie while authenticating user. Centrifugo should work on same domain in this case so your site cookie could be passed to Centrifugo . This also means that every new connection from user will result in HTTP POST request to your application backend. While with JWT token you usually generate it once on application page reload, if client reconnects due to Centrifugo restart or internet connection loss it uses the same JWT it had before thus usually no additional requests generated during reconnect process (until JWT expired). Payload example that will be sent to app backend when client without token wants to establish connection with Centrifugo and proxy_connect_endpoint is set to non-empty URL string: { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" } Request fields: client is a unique client ID generated by Centrifugo for each incoming connection transport is transport name ( websocket or sockjs at moment) protocol is a protocol type used by client ( json or protobuf at moment) encoding is a protocol encoding type used ( json or binary at moment) name is an optional name of client (this field will only be set if provided by a client on connect), Centrifugo >= 2.6.2 version is an optional version of client (this field will only be set if provided by a client on connect), Centrifugo >= 2.6.2 Response expected: { \"result\" : { \"user\" : \"56\" }} Result fields you can set: user (string) is user ID (calculated on app backend based on request cookie header for example). Return it as empty string for accepting unauthenticated request expire_at (optional integer) is a timestamp when connection must be considered expired. If not set or set to 0 connection won't expire at all info (optional JSON) is a connection info JSON b64info (optional string) is a binary connection info encoded in base64 format, will be decoded to raw bytes on Centrifugo before using in messages data (optional JSON) is a custom data to send to client in connect command response. Supported since v2.3.1 b64data (optional string) is a custom data to send to client in connect command response for binary connections, will be decoded to raw bytes on Centrifugo side before sending to client. Supported since v2.3.1 channels (optional array of strings) - allows to provide a list of server-side channels to subscribe connection to. See more details about server-side subscriptions . Supported since v2.4.0 proxy_connect_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend. Here is the simplest example of connect handler in Tornado Python framework (note that in real system you need to authenticate user on your backend side, here we just return \"56\" as user ID): class CentrifugoConnectHandler ( tornado . web . RequestHandler ): def check_xsrf_cookie ( self ): pass def post ( self ): self . set_header ( 'Content-Type' , 'application/json; charset=\"utf-8\"' ) data = json . dumps ({ 'result' : { 'user' : '56' } }) self . write ( data ) def main (): options . parse_command_line () app = tornado . web . Application ([ ( r '/centrifugo/connect' , CentrifugoConnectHandler ), ]) app . listen ( 3000 ) tornado . ioloop . IOLoop . instance () . start () if __name__ == '__main__' : main () This example should help you to implement similar HTTP handler in any language/framework you are using on backend side. Refresh proxy \u00b6 With the following options in configuration file: { ... \"proxy_refresh_endpoint\" : \"http://localhost:3000/centrifugo/refresh\" , \"proxy_refresh_timeout\" : 1 } \u2013 Centrifugo will call proxy_refresh_endpoint when it's time to refresh connection. Centrifugo itself will ask your backend about connection validity instead of refresh workflow on client side. Payload sent to app backend in refresh request (when connection is going to expire): { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" , \"user\" : \"56\" } Request fields: client , transport , protocol , encoding are the same as described for connect request payload user is a connection user ID obtained during authentication process Response expected: { \"result\" : { \"expire_at\" : 1565436268 }} Result fields: expired (boolean) is a flag to mark connection as expired - client will be diconnected expire_at (integer) is a next timestamp when connection must be considered expired info (optional JSON) is a connection info JSON b64info (optional string) is a binary connection info encoded in base64 format proxy_refresh_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend. RPC proxy \u00b6 With the following option in configuration file: { ... \"proxy_rpc_endpoint\" : \"http://localhost:3000/centrifugo/connect\" , \"proxy_rpc_timeout\" : 1 } RPC calls over client connection will be proxied to proxy_rpc_endpoint . This allows developer to utilize WebSocket (or SockJS) connection in bidirectional way. Payload sent to app backend in RPC request: { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" , \"user\" : \"56\" , \"method\" : \"getCurrentPrice\" , \"data\" :{ \"params\" : { \"object_id\" : 12 }} } Request fields: client , transport , protocol , encoding are the same as described for connect request payload user is a connection user ID obtained during authentication process method is an RPC method string, if client does not use named RPC call then method will be omitted (available since v2.6.0) data is an RPC custom data sent by client b64data will be set instead of data field for connections that use binary payload encoding Response expected: { \"result\" : { \"data\" : { \"answer\" : \"2019\" }}} Result fields: data (JSON) is and RPC response - any valid JSON is supported b64data string can be set instead of data for binary response encoded in base64 format proxy_rpc_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend. See below on how to return a custom error. Subscribe proxy \u00b6 Available since Centrifugo v2.6.0 With the following option in configuration file: { ... \"proxy_subscribe_endpoint\" : \"http://localhost:3000/centrifugo/subscribe\" , \"proxy_subscribe_timeout\" : 1 } \u2013 subscribe requests sent over client connection will be proxied to proxy_subscribe_endpoint . This allows you to check access of client to a channel. Danger Subscribe proxy does not proxy private and user-limited channels at the moment . That's because those are already quite secure (user-limited channels check current user ID, private channels require subscription token). In some cases you may use subscribe proxy as a replacement for private channels actually: if you prefer to check permissions using proxy to backend mechanism \u2013 just stop using $ prefixes in channels, properly configure subscribe proxy and validate subscriptions upon proxy from Centrifugo to your backend (issued each time user tries to subscribe on a channel for which subscribe proxy enabled). Unlike proxy types described above subscribe proxy must be enabled per channel namespace. This means that every namespace (including global one) has a boolean option proxy_subscribe that enables subscribe proxy for channels in a namespace. So to enable subscribe proxy for channels without namespace define proxy_subscribe on a top configuration level: { ... \"proxy_subscribe_endpoint\" : \"http://localhost:3000/centrifugo/subscribe\" , \"proxy_subscribe_timeout\" : 1 , \"proxy_subscribe\" : true } Or for channels in namespace sun : { ... \"proxy_subscribe_endpoint\" : \"http://localhost:3000/centrifugo/subscribe\" , \"proxy_subscribe_timeout\" : 1 , \"namespaces\" : [{ \"name\" : \"sun\" , \"proxy_subscribe\" : true }] } Payload sent to app backend in subscribe request: { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" , \"user\" : \"56\" , \"channel\" : \"chat:index\" } Request fields: client , transport , protocol , encoding are the same as described for connect request payload user is a connection user ID obtained during authentication process channel is a string channel client wants to publish to. Response expected: { \"result\" : {}} Result fields: info (optional JSON) is a channel info JSON b64info (optional string) is a binary connection channel info encoded in base64 format, will be decoded to raw bytes on Centrifugo before using See below on how to return an error in case you don't want to allow subscribing. proxy_subscribe_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend. Publish proxy \u00b6 Available since Centrifugo v2.6.0 With the following option in configuration file: { ... \"proxy_publish_endpoint\" : \"http://localhost:3000/centrifugo/publish\" , \"proxy_publish_timeout\" : 1 } \u2013 publish calls sent by a client will be proxied to proxy_publish_endpoint . This request happens BEFORE a message actually published to a channel, so your backend can validate whether client can publish data to a channel. An important thing here is that publication to channel can fail after your backend successfully validated publish request (for example publish to Redis by Centrifugo returned an error). In this case your backend won't know about error happened but this error will propagate to client side. Like subscribe proxy publish proxy must be enabled per channel namespace. This means that every namespace (including global one) has a boolean option proxy_publish that enables publish proxy for channels in namespace. All other namespace options will be taken into account before making proxy request, so you also need to turn on publish option too. So to enable publish proxy for channels without namespace define proxy_publish and publish on a top configuration level: { ... \"proxy_publish_endpoint\" : \"http://localhost:3000/centrifugo/publish\" , \"proxy_publish_timeout\" : 1 , \"publish\" : true , \"proxy_publish\" : true } Or for channels in namespace sun : { ... \"proxy_publish_endpoint\" : \"http://localhost:3000/centrifugo/publish\" , \"proxy_publish_timeout\" : 1 , \"namespaces\" : [{ \"name\" : \"sun\" , \"publish\" : true , \"proxy_publish\" : true }] } Keep in mind that this will only work if publish channel option is on for a channel namespace (or for global top-level namespace). Payload sent to app backend in publish request: { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" , \"user\" : \"56\" , \"channel\" : \"chat:index\" , \"data\" :{ \"input\" : \"hello\" } } Request fields: client , transport , protocol , encoding are the same as described for connect request payload user is a connection user ID obtained during authentication process data is an RPC data sent by client b64data will be set instead of data field for connections that use binary payload encoding channel is a string channel client wants to publish to. Response expected: { \"result\" : {}} Result fields: no fields at moment. See below on how to return an error in case you don't want to allow publishing. proxy_publish_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend. Return custom error \u00b6 Application backend can return JSON object that contain an error to return it to client: { \"error\" : { \"code\" : 1000 , \"message\" : \"custom error\" } } Application should use error codes >= 1000 , error codes in range 0-999 are reserved by Centrifugo internal protocol. Error code field is uint32 internally. This does not apply to response on refresh request as there is no sense in returning an error (will not reach client anyway). proxy_rpc_timeout (float, in seconds) controls timeout of HTTP POST request sent to app backend. Return custom disconnect \u00b6 Application backend can return JSON object that contain an custom disconnect object to disconnect client in custom way: { \"disconnect\" : { \"code\" : 4000 , \"reconnect\" : false , \"reason\" : \"custom disconnect\" } } Application should use numbers in range 4000-4999 for custom disconnect codes . Code is uint32 internally. Numbers below 4000 are reserved by Centrifugo internal protocol. Keep in mind that due to WebSocket protocol limitations and Centrifugo internal protocol needs you need to keep disconnect reason string no longer than 32 symbols . This does not apply to response on refresh request as there is no way to control disconnect at moment - client will always be disconnected with expired disconnect reason.","title":"Proxy to backend"},{"location":"server/proxy/#proxy-calls-to-app-backend","text":"It's possible to proxy some client connection events over HTTP to application backend and react to them in a way you need. For example, you can authenticate connection via request from Centrifugo to your app backend, refresh client sessions and answer to RPC calls sent by client over WebSocket or SockJS connections.","title":"Proxy calls to app backend"},{"location":"server/proxy/#proxy-request-structure","text":"All proxy calls are HTTP POST requests that will be sent from Centrifugo to configured endpoints with a configured timeout. These requests will have some headers copied from original client request (see details below) and include JSON body which varies depending on call type (for example data sent by client in RPC call etc, see more details about JSON bodies below).","title":"Proxy request structure"},{"location":"server/proxy/#proxy-headers","text":"By default, the following headers from original client request will be copied to proxied request: Origin (Centrifugo >= v2.3.1) User-Agent Cookie Authorization X-Real-Ip X-Forwarded-For X-Request-Id It's possible to add extra headers using proxy_extra_http_headers configuration option (available since v2.3.1). This is an array of strings in configuration file, ex: { ... \"proxy_extra_http_headers\" : [ \"X-B3-TraceId\" , \"X-B3-SpanId\" ] } Alternatively you can set extra headers via environment variable (space separated): export CENTRIFUGO_PROXY_EXTRA_HTTP_HEADERS=\"X-B3-TraceId X-B3-SpanId\" ./centrifugo Since v2.5.1 Centrifugo also forces Content-Type header to be application/json in all proxy HTTP requests since it sends body in JSON format to application backend.","title":"Proxy headers"},{"location":"server/proxy/#connect-proxy","text":"With the following options in configuration file: { ... \"proxy_connect_endpoint\" : \"http://localhost:3000/centrifugo/connect\" , \"proxy_connect_timeout\" : 1 } \u2013 connection requests without JWT set will be proxied to proxy_connect_endpoint URL endpoint. On your backend side you can authenticate incoming connection and return client credentials to Centrifugo in response to proxied request. This means you don't need to generate JWT token and pass it to client side and can rely on cookie while authenticating user. Centrifugo should work on same domain in this case so your site cookie could be passed to Centrifugo . This also means that every new connection from user will result in HTTP POST request to your application backend. While with JWT token you usually generate it once on application page reload, if client reconnects due to Centrifugo restart or internet connection loss it uses the same JWT it had before thus usually no additional requests generated during reconnect process (until JWT expired). Payload example that will be sent to app backend when client without token wants to establish connection with Centrifugo and proxy_connect_endpoint is set to non-empty URL string: { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" } Request fields: client is a unique client ID generated by Centrifugo for each incoming connection transport is transport name ( websocket or sockjs at moment) protocol is a protocol type used by client ( json or protobuf at moment) encoding is a protocol encoding type used ( json or binary at moment) name is an optional name of client (this field will only be set if provided by a client on connect), Centrifugo >= 2.6.2 version is an optional version of client (this field will only be set if provided by a client on connect), Centrifugo >= 2.6.2 Response expected: { \"result\" : { \"user\" : \"56\" }} Result fields you can set: user (string) is user ID (calculated on app backend based on request cookie header for example). Return it as empty string for accepting unauthenticated request expire_at (optional integer) is a timestamp when connection must be considered expired. If not set or set to 0 connection won't expire at all info (optional JSON) is a connection info JSON b64info (optional string) is a binary connection info encoded in base64 format, will be decoded to raw bytes on Centrifugo before using in messages data (optional JSON) is a custom data to send to client in connect command response. Supported since v2.3.1 b64data (optional string) is a custom data to send to client in connect command response for binary connections, will be decoded to raw bytes on Centrifugo side before sending to client. Supported since v2.3.1 channels (optional array of strings) - allows to provide a list of server-side channels to subscribe connection to. See more details about server-side subscriptions . Supported since v2.4.0 proxy_connect_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend. Here is the simplest example of connect handler in Tornado Python framework (note that in real system you need to authenticate user on your backend side, here we just return \"56\" as user ID): class CentrifugoConnectHandler ( tornado . web . RequestHandler ): def check_xsrf_cookie ( self ): pass def post ( self ): self . set_header ( 'Content-Type' , 'application/json; charset=\"utf-8\"' ) data = json . dumps ({ 'result' : { 'user' : '56' } }) self . write ( data ) def main (): options . parse_command_line () app = tornado . web . Application ([ ( r '/centrifugo/connect' , CentrifugoConnectHandler ), ]) app . listen ( 3000 ) tornado . ioloop . IOLoop . instance () . start () if __name__ == '__main__' : main () This example should help you to implement similar HTTP handler in any language/framework you are using on backend side.","title":"Connect proxy"},{"location":"server/proxy/#refresh-proxy","text":"With the following options in configuration file: { ... \"proxy_refresh_endpoint\" : \"http://localhost:3000/centrifugo/refresh\" , \"proxy_refresh_timeout\" : 1 } \u2013 Centrifugo will call proxy_refresh_endpoint when it's time to refresh connection. Centrifugo itself will ask your backend about connection validity instead of refresh workflow on client side. Payload sent to app backend in refresh request (when connection is going to expire): { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" , \"user\" : \"56\" } Request fields: client , transport , protocol , encoding are the same as described for connect request payload user is a connection user ID obtained during authentication process Response expected: { \"result\" : { \"expire_at\" : 1565436268 }} Result fields: expired (boolean) is a flag to mark connection as expired - client will be diconnected expire_at (integer) is a next timestamp when connection must be considered expired info (optional JSON) is a connection info JSON b64info (optional string) is a binary connection info encoded in base64 format proxy_refresh_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend.","title":"Refresh proxy"},{"location":"server/proxy/#rpc-proxy","text":"With the following option in configuration file: { ... \"proxy_rpc_endpoint\" : \"http://localhost:3000/centrifugo/connect\" , \"proxy_rpc_timeout\" : 1 } RPC calls over client connection will be proxied to proxy_rpc_endpoint . This allows developer to utilize WebSocket (or SockJS) connection in bidirectional way. Payload sent to app backend in RPC request: { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" , \"user\" : \"56\" , \"method\" : \"getCurrentPrice\" , \"data\" :{ \"params\" : { \"object_id\" : 12 }} } Request fields: client , transport , protocol , encoding are the same as described for connect request payload user is a connection user ID obtained during authentication process method is an RPC method string, if client does not use named RPC call then method will be omitted (available since v2.6.0) data is an RPC custom data sent by client b64data will be set instead of data field for connections that use binary payload encoding Response expected: { \"result\" : { \"data\" : { \"answer\" : \"2019\" }}} Result fields: data (JSON) is and RPC response - any valid JSON is supported b64data string can be set instead of data for binary response encoded in base64 format proxy_rpc_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend. See below on how to return a custom error.","title":"RPC proxy"},{"location":"server/proxy/#subscribe-proxy","text":"Available since Centrifugo v2.6.0 With the following option in configuration file: { ... \"proxy_subscribe_endpoint\" : \"http://localhost:3000/centrifugo/subscribe\" , \"proxy_subscribe_timeout\" : 1 } \u2013 subscribe requests sent over client connection will be proxied to proxy_subscribe_endpoint . This allows you to check access of client to a channel. Danger Subscribe proxy does not proxy private and user-limited channels at the moment . That's because those are already quite secure (user-limited channels check current user ID, private channels require subscription token). In some cases you may use subscribe proxy as a replacement for private channels actually: if you prefer to check permissions using proxy to backend mechanism \u2013 just stop using $ prefixes in channels, properly configure subscribe proxy and validate subscriptions upon proxy from Centrifugo to your backend (issued each time user tries to subscribe on a channel for which subscribe proxy enabled). Unlike proxy types described above subscribe proxy must be enabled per channel namespace. This means that every namespace (including global one) has a boolean option proxy_subscribe that enables subscribe proxy for channels in a namespace. So to enable subscribe proxy for channels without namespace define proxy_subscribe on a top configuration level: { ... \"proxy_subscribe_endpoint\" : \"http://localhost:3000/centrifugo/subscribe\" , \"proxy_subscribe_timeout\" : 1 , \"proxy_subscribe\" : true } Or for channels in namespace sun : { ... \"proxy_subscribe_endpoint\" : \"http://localhost:3000/centrifugo/subscribe\" , \"proxy_subscribe_timeout\" : 1 , \"namespaces\" : [{ \"name\" : \"sun\" , \"proxy_subscribe\" : true }] } Payload sent to app backend in subscribe request: { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" , \"user\" : \"56\" , \"channel\" : \"chat:index\" } Request fields: client , transport , protocol , encoding are the same as described for connect request payload user is a connection user ID obtained during authentication process channel is a string channel client wants to publish to. Response expected: { \"result\" : {}} Result fields: info (optional JSON) is a channel info JSON b64info (optional string) is a binary connection channel info encoded in base64 format, will be decoded to raw bytes on Centrifugo before using See below on how to return an error in case you don't want to allow subscribing. proxy_subscribe_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend.","title":"Subscribe proxy"},{"location":"server/proxy/#publish-proxy","text":"Available since Centrifugo v2.6.0 With the following option in configuration file: { ... \"proxy_publish_endpoint\" : \"http://localhost:3000/centrifugo/publish\" , \"proxy_publish_timeout\" : 1 } \u2013 publish calls sent by a client will be proxied to proxy_publish_endpoint . This request happens BEFORE a message actually published to a channel, so your backend can validate whether client can publish data to a channel. An important thing here is that publication to channel can fail after your backend successfully validated publish request (for example publish to Redis by Centrifugo returned an error). In this case your backend won't know about error happened but this error will propagate to client side. Like subscribe proxy publish proxy must be enabled per channel namespace. This means that every namespace (including global one) has a boolean option proxy_publish that enables publish proxy for channels in namespace. All other namespace options will be taken into account before making proxy request, so you also need to turn on publish option too. So to enable publish proxy for channels without namespace define proxy_publish and publish on a top configuration level: { ... \"proxy_publish_endpoint\" : \"http://localhost:3000/centrifugo/publish\" , \"proxy_publish_timeout\" : 1 , \"publish\" : true , \"proxy_publish\" : true } Or for channels in namespace sun : { ... \"proxy_publish_endpoint\" : \"http://localhost:3000/centrifugo/publish\" , \"proxy_publish_timeout\" : 1 , \"namespaces\" : [{ \"name\" : \"sun\" , \"publish\" : true , \"proxy_publish\" : true }] } Keep in mind that this will only work if publish channel option is on for a channel namespace (or for global top-level namespace). Payload sent to app backend in publish request: { \"client\" : \"9336a229-2400-4ebc-8c50-0a643d22e8a0\" , \"transport\" : \"websocket\" , \"protocol\" : \"json\" , \"encoding\" : \"json\" , \"user\" : \"56\" , \"channel\" : \"chat:index\" , \"data\" :{ \"input\" : \"hello\" } } Request fields: client , transport , protocol , encoding are the same as described for connect request payload user is a connection user ID obtained during authentication process data is an RPC data sent by client b64data will be set instead of data field for connections that use binary payload encoding channel is a string channel client wants to publish to. Response expected: { \"result\" : {}} Result fields: no fields at moment. See below on how to return an error in case you don't want to allow publishing. proxy_publish_timeout (float, in seconds) config option controls timeout of HTTP POST request sent to app backend.","title":"Publish proxy"},{"location":"server/proxy/#return-custom-error","text":"Application backend can return JSON object that contain an error to return it to client: { \"error\" : { \"code\" : 1000 , \"message\" : \"custom error\" } } Application should use error codes >= 1000 , error codes in range 0-999 are reserved by Centrifugo internal protocol. Error code field is uint32 internally. This does not apply to response on refresh request as there is no sense in returning an error (will not reach client anyway). proxy_rpc_timeout (float, in seconds) controls timeout of HTTP POST request sent to app backend.","title":"Return custom error"},{"location":"server/proxy/#return-custom-disconnect","text":"Application backend can return JSON object that contain an custom disconnect object to disconnect client in custom way: { \"disconnect\" : { \"code\" : 4000 , \"reconnect\" : false , \"reason\" : \"custom disconnect\" } } Application should use numbers in range 4000-4999 for custom disconnect codes . Code is uint32 internally. Numbers below 4000 are reserved by Centrifugo internal protocol. Keep in mind that due to WebSocket protocol limitations and Centrifugo internal protocol needs you need to keep disconnect reason string no longer than 32 symbols . This does not apply to response on refresh request as there is no way to control disconnect at moment - client will always be disconnected with expired disconnect reason.","title":"Return custom disconnect"},{"location":"server/server_subs/","text":"Server-side subscriptions \u00b6 Starting from v2.4.0 Centrifugo supports server-side subscriptions. Overview \u00b6 Before v2.4.0 only client could initiate subscription to channel calling Subscribe method. While this is actually the most flexible approach as client side usually knows well which channels it needs to consume in concrete moment \u2013 in some situations all you need is to subscribe your connections to several channels on server side at the moment of connection establishement. So client effectively starts receiving publications from those channels without explicitly call Subscribe method. You can set a list of channels for connection in two ways at moment: over connection JWT using channels claim, which is an array of strings over connect proxy returning channels field in result (also an array of strings) On client side you need to listen for publications from server-side channels using top-level client event handler. At this moment server-side subscriptions only supported by centrifuge-js client. With it all you need to do on client side is sth like this: var centrifuge = new Centrifuge ( address ); centrifuge . on ( 'publish' , function ( ctx ) { const channel = ctx . channel ; const payload = JSON . stringify ( ctx . data ); console . log ( 'Publication from server-side channel' , channel , payload ); }); centrifuge . connect (); I.e. listen for publications without any usage of subscription objects. You can look at channel publication relates to using field in callback context as shown in example. In future this mechanism will be supported by all our clients . Hopefully with community help this will happen very soon. Server-side subscription limitations \u00b6 Such subscriptions do not fit well for dynamic subscriptions \u2013 as Centrifugo does not have subscribe server API at moment. Also the same rules about best practices of working with channels and client-side subscriptions equally applicable to server-side subscription. Automatic personal channel subscription \u00b6 v2.4.0 also introduced some sugar on top of server-side subscriptions. It's possible to automatically subscribe user to personal server-side channel. To enable this you need to enable user_subscribe_to_personal boolean option (by default false ). As soon as you do this every connection with non-empty user ID will be automatically subscribed to personal user-limited channel. Anonymous users with empty user ID won't be subscribed to any channel. For example, if you set this option and user with ID 87334 connects to Centrifugo it will be automatically subscribed to channel #87334 and you can process personal publications on client side in the same way as shown above. As you can see by default generated personal channel name belongs to default namespace (i.e. no explicit namespace used). To set custom namespace name use user_personal_channel_namespace option (string, default \"\" ) \u2013 i.e. the name of namespace from configured configuration namespaces array. In this case if you set user_personal_channel_namespace to personal for example \u2013 then the automatically generated personal channel will be personal:#87334 \u2013 user will be automatically subscribed to it on connect and you can use this channel name to publish personal notifications to online user. Maintain single user connection \u00b6 Available since v2.8.0 Usage of personal channel subscription also opens a road to enable one more feature: maintaining only a single connection for each user globally around all Centrifugo nodes. user_personal_single_connection boolean option (default false ) turns on a mode in which Centrifugo will try to maintain only a single connection for each user in the same moment. As soon as the user establishes a connection other connections from the same user will be closed with connection limit reason (client won't try to automatically reconnect). This feature works with a help of presence information inside a personal channel. So presence should be turned on in a personal channel . Example config: { \"v3_use_offset\": true, \"user_subscribe_to_personal\": true, \"user_personal_single_connection\": true, \"user_personal_channel_namespace\": \"personal\", \"namespaces\": [ { \"name\": \"personal\", \"presence\": true } ] } Note Centrifugo can't guarantee that other user connections will be closed \u2013 since Disconnect messages distributed around Centrifugo nodes with at most once guarantee. So don't add critical business logic based on this feature to your application. Though this should work just fine most of the time if the connection between Centrifugo node and PUB/SUB broker is OK. Mark namespace as server-side \u00b6 v2.4.0 also introduced a new channel namespace boolean option called server_side (default false ). When on then all client-side subscription requests to channels in namespace will be rejected with PermissionDenied error.","title":"Server-side subscriptions"},{"location":"server/server_subs/#server-side-subscriptions","text":"Starting from v2.4.0 Centrifugo supports server-side subscriptions.","title":"Server-side subscriptions"},{"location":"server/server_subs/#overview","text":"Before v2.4.0 only client could initiate subscription to channel calling Subscribe method. While this is actually the most flexible approach as client side usually knows well which channels it needs to consume in concrete moment \u2013 in some situations all you need is to subscribe your connections to several channels on server side at the moment of connection establishement. So client effectively starts receiving publications from those channels without explicitly call Subscribe method. You can set a list of channels for connection in two ways at moment: over connection JWT using channels claim, which is an array of strings over connect proxy returning channels field in result (also an array of strings) On client side you need to listen for publications from server-side channels using top-level client event handler. At this moment server-side subscriptions only supported by centrifuge-js client. With it all you need to do on client side is sth like this: var centrifuge = new Centrifuge ( address ); centrifuge . on ( 'publish' , function ( ctx ) { const channel = ctx . channel ; const payload = JSON . stringify ( ctx . data ); console . log ( 'Publication from server-side channel' , channel , payload ); }); centrifuge . connect (); I.e. listen for publications without any usage of subscription objects. You can look at channel publication relates to using field in callback context as shown in example. In future this mechanism will be supported by all our clients . Hopefully with community help this will happen very soon.","title":"Overview"},{"location":"server/server_subs/#server-side-subscription-limitations","text":"Such subscriptions do not fit well for dynamic subscriptions \u2013 as Centrifugo does not have subscribe server API at moment. Also the same rules about best practices of working with channels and client-side subscriptions equally applicable to server-side subscription.","title":"Server-side subscription limitations"},{"location":"server/server_subs/#automatic-personal-channel-subscription","text":"v2.4.0 also introduced some sugar on top of server-side subscriptions. It's possible to automatically subscribe user to personal server-side channel. To enable this you need to enable user_subscribe_to_personal boolean option (by default false ). As soon as you do this every connection with non-empty user ID will be automatically subscribed to personal user-limited channel. Anonymous users with empty user ID won't be subscribed to any channel. For example, if you set this option and user with ID 87334 connects to Centrifugo it will be automatically subscribed to channel #87334 and you can process personal publications on client side in the same way as shown above. As you can see by default generated personal channel name belongs to default namespace (i.e. no explicit namespace used). To set custom namespace name use user_personal_channel_namespace option (string, default \"\" ) \u2013 i.e. the name of namespace from configured configuration namespaces array. In this case if you set user_personal_channel_namespace to personal for example \u2013 then the automatically generated personal channel will be personal:#87334 \u2013 user will be automatically subscribed to it on connect and you can use this channel name to publish personal notifications to online user.","title":"Automatic personal channel subscription"},{"location":"server/server_subs/#maintain-single-user-connection","text":"Available since v2.8.0 Usage of personal channel subscription also opens a road to enable one more feature: maintaining only a single connection for each user globally around all Centrifugo nodes. user_personal_single_connection boolean option (default false ) turns on a mode in which Centrifugo will try to maintain only a single connection for each user in the same moment. As soon as the user establishes a connection other connections from the same user will be closed with connection limit reason (client won't try to automatically reconnect). This feature works with a help of presence information inside a personal channel. So presence should be turned on in a personal channel . Example config: { \"v3_use_offset\": true, \"user_subscribe_to_personal\": true, \"user_personal_single_connection\": true, \"user_personal_channel_namespace\": \"personal\", \"namespaces\": [ { \"name\": \"personal\", \"presence\": true } ] } Note Centrifugo can't guarantee that other user connections will be closed \u2013 since Disconnect messages distributed around Centrifugo nodes with at most once guarantee. So don't add critical business logic based on this feature to your application. Though this should work just fine most of the time if the connection between Centrifugo node and PUB/SUB broker is OK.","title":"Maintain single user connection"},{"location":"server/server_subs/#mark-namespace-as-server-side","text":"v2.4.0 also introduced a new channel namespace boolean option called server_side (default false ). When on then all client-side subscription requests to channels in namespace will be rejected with PermissionDenied error.","title":"Mark namespace as server-side"},{"location":"transports/","text":"This section describes client-server transports that Centrifugo supports and its specifics. Client-server transports used to connect to Centrifugo from a frontend of your application. At moment Centrifugo supports the following client-server transports: Websocket \u2013 with JSON or binary protobuf protocol. SockJS \u2013 only supports JSON protocol Having both of these transport means that it's possible to connect to Centrifugo from everywhere. Since Centrifugo has its own protocol for client-server communication (for authentication, subscriptions, publishing messages to channels, calling RPC etc) transports above wrapped by our client libraries . Keep in mind that if you are planning to use non-JSON binary data between a client and server then you can only use WebSocket transport. See how to achieve binary passing with protobuf format.","title":"Overview"},{"location":"transports/protobuf/","text":"Protobuf binary protocol \u00b6 In most cases you will use Centrifugo with JSON protocol which is used by default. It consists of simple human-readable frames that can be easily inspected. Also it's a very simple task to publish JSON encoded data to HTTP API endpoint. You may want to use binary Protobuf client protocol if: you want less traffic on wire as Protobuf is very compact you want maximum performance as Protobuf encoding/decoding is very efficient you can sacrifice human-readable JSON for your application Binary protobuf protocol only works for raw Websocket connections (as SockJS can't deal with binary). With most clients to use binary you just need to provide query parameter format to Websocket URL, so final URL look like: wss://centrifugo.example.com/connection/websocket?format=protobuf After doing this Centrifugo will use binary frames to pass data between client and server. Your application specific payload can be random bytes. Note You still can continue to encode your application specific data as JSON when using Protobuf protocol thus have a possibility to coexist with clients that use JSON protocol on the same Centrifugo installation inside the same channels.","title":"Protobuf protocol"},{"location":"transports/protobuf/#protobuf-binary-protocol","text":"In most cases you will use Centrifugo with JSON protocol which is used by default. It consists of simple human-readable frames that can be easily inspected. Also it's a very simple task to publish JSON encoded data to HTTP API endpoint. You may want to use binary Protobuf client protocol if: you want less traffic on wire as Protobuf is very compact you want maximum performance as Protobuf encoding/decoding is very efficient you can sacrifice human-readable JSON for your application Binary protobuf protocol only works for raw Websocket connections (as SockJS can't deal with binary). With most clients to use binary you just need to provide query parameter format to Websocket URL, so final URL look like: wss://centrifugo.example.com/connection/websocket?format=protobuf After doing this Centrifugo will use binary frames to pass data between client and server. Your application specific payload can be random bytes. Note You still can continue to encode your application specific data as JSON when using Protobuf protocol thus have a possibility to coexist with clients that use JSON protocol on the same Centrifugo installation inside the same channels.","title":"Protobuf binary protocol"},{"location":"transports/protocol/","text":"Client protocol \u00b6 This chapter describes internal client-server protocol in details to help developers build new client libraries and understand how existing client libraries work. Note that you can always look at existing client implementations in case of any questions. Not all clients support all available server features though. Client implementation feature matrix \u00b6 First we will look at list of features client library should support. Depending on client implementation some features can be not implemented. If you an author of client library you can use this list as checklist. Our current client feature matrix looks like this: connect to server (both Centrifugo and Centrifuge-based) using JSON protocol format connect to server (both Centrifugo and Centrifuge-based) using Protobuf protocol format connect to server with token (JWT in Centrifugo case, any string token in Centrifuge library case) connect to server with custom headers (not available in a browser) automatic reconnect in case of dial problems (network) an exponential backoff for reconnect process possibility to set handlers for connect and disconnect events extract and expose disconnect reason subscribe on a channel and provide a way to handle asynchronous Publications coming from a channel handle Join and Leave messages from a channel handle Unsubscribe notifications publish method of Subscription unsubscribe method of Subscription presence method of Subscription presence stats method of Subscription history method of Subscription send asynchronous messages to server handle asynchronous messages from server send RPC requests to server publish to channel without being subscribed subscribe to private (token-protected) channels with token connection token refresh mechanism private channel subscription token refresh client protocol level ping/pong to find broken connection automatic reconnect in case of connect or subscribe command timeouts handle connection expired error handle subscription expired error server-side subscriptions message recovery mechanism Below I'll try to describe most of these points in detail. This document describes protocol specifics for Websocket transport which supports binary and text formats to transfer data. As Centrifugo and Centrifuge library for Go have various types of messages it serializes protocol messages using JSON or Protobuf formats. Note SockJS works almost the same way as JSON websocket described here but has its own extra framing on top of Centrifuge protocol messages. SockJS can only work with JSON - it's not possible to transfer binary data over it. SockJS is only needed as fallback to Websocket in web browsers. Top level framing \u00b6 Centrifuge protocol defined in Protobuf schema . That schema is a source of truth and all protocol description below describes messages from that schema. Client sends Command to server. Server sends Reply to client. All communication between client and server is a bidirectional exchange of Command and Reply messages. One request from client to server and one response from server to client can have more than one Command or Reply . This allows reducing number of system calls for writing and reading data. When JSON format used then many Command can be sent from client to server in JSON streaming line-delimited format. I.e. each individual Command encoded to JSON and then commands joined together using new line symbol \\n : {\"id\": 1, \"method\": \"subscribe\", \"params\": {\"channel\": \"ch1\"}} {\"id\": 2, \"method\": \"subscribe\", \"params\": {\"channel\": \"ch2\"}} For example here is how we do this in Javascript client when JSON format used: function encodeCommands ( commands ) { const encodedCommands = []; for ( const i in commands ) { if ( commands . hasOwnProperty ( i )) { encodedCommands . push ( JSON . stringify ( commands [ i ])); } } return encodedCommands . join ( '\\n' ); } Note This doc will use JSON format for examples because it's human-readable. Everything said here for JSON is also true for Protobuf encoded case. The only difference is how several individual Command or server Reply joined into one request \u2013 see details below. Note Method represented as a ENUM in protobuf schema and can be sent as integer value. Though it's possible to send it as string in JSON case \u2013 this was made to make JSON protocol human-friendly. When Protobuf format used then many Command can be sent from client to server in length-delimited format where each individual Command marshaled to bytes prepended by varint length. See existing client implementations for encoding example. The same rules relate to many Reply in one response from server to client. Line-delimited JSON and varint-length prefixed Protobuf also used there. For example here is how we read server response and extracting individual replies in Javascript client when JSON format used: function decodeReplies ( data ) { const replies = []; const encodedReplies = data . split ( '\\n' ); for ( const i in encodedReplies ) { if ( encodedReplies . hasOwnProperty ( i )) { if ( ! encodedReplies [ i ]) { continue ; } const reply = JSON . parse ( encodedReplies [ i ]); replies . push ( reply ); } } return replies ; } For Protobuf case see existing client implementations for decoding example. As you can see each Command has id field. This is an incremental uint32 field. This field will be echoed in a server replies to commands so client could match a certain Reply to Command sent before. This is important since Websocket is an asynchronous protocol where server and client both send messages at any moment and there is no builtin request-response matching. Having id allows matching a reply with a command send before. So you can expect something like this in response after sending commands to server: {\"id\": 1, \"result\": {}} {\"id\": 2, \"result\": {}} Besides id Reply from server to client have two important fields: result and error . result contains useful payload object which is different for various Reply messages. error contains error description if Command processing resulted in some error on a server. error is optional and if Reply does not have error then it means that Command processed successfully and client can parse result object appropriately. error looks like this in JSON case: { \"code\" : 100 , \"message\" : \"internal server error\" } We will talk more about error handling below. The special type of Reply is asynchronous Reply . Such replies have no id field set (or id can be equal to zero). Async replies can come to client in any moment - not as reaction to issued Command but as message from server to client in arbitrary time. For example this can be a message published into channel. Centrifuge library defines several command types client can issue. A well-written client must be aware of all those commands and client workflow. Communication with Centrifuge/Centrifugo server starts with issuing connect command. Connect \u00b6 First of all client must dial with a server and then send connect Command to it. Default Websocket endpoint in Centrifugo is: ws://centrifugo.example.com/connection/websocket In case of using TLS: wss://centrifugo.example.com/connection/websocket After a successful dial to WebSocket endpoint client must send connect command to server to authorize itself. connect command looks like: { \"id\" : 1 , \"method\" : \"connect\" , \"params\" : { \"token\" : \"JWT\" , \"data\" : {} } } Where params fields: optional string token - connection token. Can be ommited if token-based auth not used. data - can contain custom connect data, for example it can contain client settings. In response to connect command server sends a connect reply. It looks this way: { \"id\" : 1 , \"result\" :{ \"client\" : \"421bf374-dd01-4f82-9def-8c31697e956f\" , \"version\" : \"2.0.0\" } } result has some fields: string client - unique client connection ID server issued to this connection string version - server version optional bool expires - whether a server will expire connection at some point optional int32 ttl - time in seconds until connection expires Subscribe \u00b6 As soon as client successfully connected and got unique connection ID it is ready to subscribe on channels. To do this it must send subscribe command to server: { \"id\" : 2 , \"method\" : \"subscribe\" , \"params\" : { \"channel\" : \"ch1\" } } Fields that can be set in params are: string channel - channel to subscribe In response to subscribe a client receives reply like: { \"id\" : 2 , \"result\" : {} } result can have the following fields that relate to subscription expiration: optional bool expires - indicates whether subscription expires or not. optional uint32 ttl - number of seconds until subscription expire. Also several fields that relate to message recovery: optional bool recoverable - means that messages can be recovered in this subscription. optional uint64 offset - current publication offset inside channel optional string epoch - current epoch inside channel optional array publications - this is an array of missed publications in channel. When received client must call general publication event handler for each message in this array. optional bool recovered - this flag set to true when server thinks that all missed publications successfully recovered and send in subscribe reply (in publications array) and false otherwise. See more about meaning of recovery related fields in special doc chapter . After a client received a successful reply on subscribe command it will receive asynchronous reply messages published to this channel. Messages can be of several types: Publication message Join message Leave message Unsub message Message message Sub message See more about asynchronous messages below. Unsubscribe \u00b6 When client wants to unsubscribe from a channel and therefore stop receiving asynchronous subscription messages from connection related to channel it must call unsubscribe command: { \"id\" : 3 , \"method\" : \"unsubscribe\" , \"params\" : { \"channel\" : \"ch1\" } } Actually server response does not mean a lot for a client - it must immediately remove channel subscription from internal implementation data structures and ignore all messages related to channel. Refresh \u00b6 It's possible to turn on client connection expiration mechanism on a server. While enabled server will keep track of connections whose time of life is close to the end (connection lifetime set on connection authentication phase). In this case connection will be closed. Client can prevent closing connection refreshing its connection credentials. To do this it must send refresh command to server. refresh command is similar to connect : { \"id\" : 4 , \"method\" : \"refresh\" , \"params\" : { \"token\" : \"<refreshed token>\" } } The tip whether a connection must be refreshed by a client comes in reply to connect command shown above - fields expires and ttl . When client connection expire mechanism is on the value of field expires in connect reply is true . In this case client implementation should look at ttl value which is seconds left until connection will be considered expired. Client must send refresh command after this ttl seconds. Server gives client a configured window to refresh token after ttl passed and then closes connection if client have not updated its token. When connecting with already expired token an error will be returned (with code 109 ). In this case client should refresh its token and reconnect with exponential backoff. RPC-like calls: publish, history, presence \u00b6 The mechanics of these calls is simple - client sends command and expects response from server. publish command allows to publish a message into a channel from a client. Note To publish from client publish option in server configuration must be set to true history allows asking a server for channel history if enabled. presence allows asking a server for channel presence information if enabled. Asynchronous server-to-client messages \u00b6 There are several types of asynchronous messages that can come from server to client. All of them relate to current client subscriptions. The most important message is Publication : { \"result\" :{ \"channel\" : \"ch1\" , \"data\" :{ \"data\" :{ \"input\" : \"1\" }, \"info\" :{ \"user\" : \"2694\" , \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \"conn_info\" :{ \"name\" : \"Alexander\" }, \"chan_info\" :{} } } } } Publication is a message published into channel. Note that there is no id field in this message - this symptom allows to distinguish it from Reply to Command . Next message is Join message: { \"result\" :{ \"type\" : 1 , \"channel\" : \"ch1\" , \"data\" :{ \"info\" :{ \"user\" : \"2694\" , \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \"conn_info\" :{ \"name\" : \"Alexander\" }, \"chan_info\" :{} } } } } Join messages sent when someone joined (subscribed on) channel. Note To enable Join and Leave messages join_leave option must be enabled on server globally or for channel namespace. Leave messages sent when someone left (unsubscribed from) channel. { \"result\" :{ \"type\" : 2 , \"channel\" : \"ch1\" , \"data\" :{ \"info\" :{ \"user\" : \"2694\" , \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \"conn_info\" :{ \"name\" : \"Alexander\" }, \"chan_info\" :{} } } } } Finally Unsub message that means that server unsubscribed current client from a channel: { \"result\" :{ \"type\" : 3 , \"channel\" : \"ch1\" , \"data\" :{} } } It's possible to distinguish between different types of asynchronous messages looking at type field (for Publication this field not set or 0 ). Ping Pong \u00b6 To maintain connection alive and detect broken connections client must periodically send ping commands to server and expect replies to it. Ping command looks like: { \"id\" : 32 , \"method\" : \"ping\" } Server just echoes this command back. When client does not receive ping reply for some time it must consider connection broken and try to reconnect. Recommended ping interval is 25 seconds, recommended period to wait for pong is 1-5 seconds. Though those numbers can vary. Handle disconnects \u00b6 Client should handle disconnect advices from server. In websocket case disconnect advice is sent in reason field of CLOSE Websocket frame. Reason contains string which is disconnect object encoded into JSON (even in case of Protobuf scenario). That objects looks like: { \"reason\" : \"shutdown\" , \"reconnect\" : true } It contains string reason of connection closing and advice to reconnect or not. Client should take this reconnect advice into account. In case of network problems and random disconnect from server without well known reason client should always try to reconnect with exponential intervals. Handle errors \u00b6 This section contains advices to error handling in client implementations. Errors can happen during various operations and can be handled in special way in context of some commands to tolerate network and server problems. Errors during connect must result in full client reconnect with exponential backoff strategy. The special case is error with code 110 which signals that connection token already expired. As we said above client should update its connection JWT before connecting to server again. Errors during subscribe must result in full client reconnect in case of internal error (code 100 ). And be sent to subscribe error event handler of subscription if received error is persistent. Persistent errors are errors like permission denied , bad request , namespace not found etc. Persistent errors in most situation mean a mistake from developers side. The special corner case is client-side timeout during subscribe operation. As protocol is asynchronous it's possible in this case that server will eventually subscribe client on channel but client will think that it's not subscribed. It's possible to retry subscription request and tolerate already subscribed (code 105 ) error as expected. But the simplest solution is to reconnect entirely as this is simpler and gives client a chance to connect to working server instance. Errors during rpc-like operations can be just returned to caller - i.e. user javascript code. Calls like history and presence are idempotent. You should be accurate with unidempotent operations like publish - in case of client timeout it's possible to send the same message into channel twice if retry publish after timeout - so users of libraries must care about this case \u2013 making sure they have some protection from displaying message twice on client side (maybe some sort of unique key in payload). Client implementation advices \u00b6 Here are some advices about client public API. Examples here are in Javascript language. This is just an attempt to help in developing a client - but rules here is not obligatorily the best way to implement client. Create client instance: const centrifuge = new Centrifuge ( \"ws://localhost:8000/connection/websocket\" , {}); Set connection token (in case of using Centrifugo): centrifuge . setToken ( \"XXX\" ) Connect to server: centrifuge . connect (); 2 event handlers can be set to centrifuge object: connect and disconnect centrifuge . on ( 'connect' , function ( context ) { console . log ( context ); }); centrifuge . on ( 'disconnect' , function ( context ) { console . log ( context ); }); Client created in disconnected state with reconnect attribute set to true and reconnecting flag set to false . After connect() called state goes to connecting . It's only possible to connect from disconnected state. Every time connect() called reconnect flag of client must be set to true . After each failed connect attempt state must be set to disconnected , disconnect event must be emitted (only if reconnecting flag is false ), and then reconnecting flag must be set to true (if client should continue reconnecting) to not emit disconnect event again after next in a row connect attempt failure. In case of failure next connection attempt must be scheduled automatically with backoff strategy. On successful connect reconnecting flag must be set to false , backoff retry must be resetted and connect event must be emitted. When connection lost then the same set of actions as when connect failed must be performed. Client must allow to subscribe on channels: var subscription = centrifuge . subscribe ( \"channel\" , eventHandlers ); Subscription object created and control immediately returned to caller - subscribing must be performed asynchronously. This is required because client can automatically reconnect later so event-based model better suites for subscriptions. Subscription should support several event handlers: handler for publication received from channel join message handler leave message handler error handler subscribe success event handler unsubscribe event handler Every time client connects to server it must restore all subscriptions. Every time client disconnects from server it must call unsubscribe handlers for all active subscriptions and then emit disconnect event. Client must periodically (once in 25 secs, configurable) send ping messages to server. If pong has not beed received in 5 secs (configurable) then client must disconnect from server and try to reconnect with backoff strategy. Client can automatically batch several requests into one frame to server and also must be able to handle several replies received from server in one frame. Server side subscriptions (SSS) \u00b6 It's also possible to subscribe connection to channels on server side. In this case we call this server-side subscription. Client should only handle asynchronous messages coming from a server without need to create subscriptions on client side. SSS should be kept separate from client-side subs SSS requires new event handlers on top-level of Client - Subscribe, Publish, Join, Leave, Unsubscribe, event handlers will be called with event context similar to client-side subs case but with channel field Connect Reply contains SSS set by a server on connect, on reconnect client has a chance to recover missed Publications Server side subscription can happen at any moment - Sub Push will be sent to client Message recovery \u00b6 Client should automatically recover messages after being disconnected due to network problems and set appropriate fields in subscribe event context. Two important fields in onSubscribeSuccess event context are isRecovered and isResubscribe . First field let user know what server thinks about subscription state - were all messages recovered or not. The second field must only be true if resubscribe was caused by temporary network connection lost. If user initiated resubscribe himself (calling unsubscribe method and then subscribe method) then recover workflow should not be used and isResubscribe must be false . Disconnect code and reason \u00b6 In case of Websocket it is sent by server in CLOSE Websocket frame. This is a string containing JSON object with fields: reason (string) and reconnect (bool). Client should give users access to these fields in disconnect event and automatically follow reconnect advice. Additional notes \u00b6 Centrifugo and Centrifuge-based server do not allow one client connection to subscribe on the same channel twice. In this case client will receive already subscribed error in reply to subscribe command.","title":"Client protocol"},{"location":"transports/protocol/#client-protocol","text":"This chapter describes internal client-server protocol in details to help developers build new client libraries and understand how existing client libraries work. Note that you can always look at existing client implementations in case of any questions. Not all clients support all available server features though.","title":"Client protocol"},{"location":"transports/protocol/#client-implementation-feature-matrix","text":"First we will look at list of features client library should support. Depending on client implementation some features can be not implemented. If you an author of client library you can use this list as checklist. Our current client feature matrix looks like this: connect to server (both Centrifugo and Centrifuge-based) using JSON protocol format connect to server (both Centrifugo and Centrifuge-based) using Protobuf protocol format connect to server with token (JWT in Centrifugo case, any string token in Centrifuge library case) connect to server with custom headers (not available in a browser) automatic reconnect in case of dial problems (network) an exponential backoff for reconnect process possibility to set handlers for connect and disconnect events extract and expose disconnect reason subscribe on a channel and provide a way to handle asynchronous Publications coming from a channel handle Join and Leave messages from a channel handle Unsubscribe notifications publish method of Subscription unsubscribe method of Subscription presence method of Subscription presence stats method of Subscription history method of Subscription send asynchronous messages to server handle asynchronous messages from server send RPC requests to server publish to channel without being subscribed subscribe to private (token-protected) channels with token connection token refresh mechanism private channel subscription token refresh client protocol level ping/pong to find broken connection automatic reconnect in case of connect or subscribe command timeouts handle connection expired error handle subscription expired error server-side subscriptions message recovery mechanism Below I'll try to describe most of these points in detail. This document describes protocol specifics for Websocket transport which supports binary and text formats to transfer data. As Centrifugo and Centrifuge library for Go have various types of messages it serializes protocol messages using JSON or Protobuf formats. Note SockJS works almost the same way as JSON websocket described here but has its own extra framing on top of Centrifuge protocol messages. SockJS can only work with JSON - it's not possible to transfer binary data over it. SockJS is only needed as fallback to Websocket in web browsers.","title":"Client implementation feature matrix"},{"location":"transports/protocol/#top-level-framing","text":"Centrifuge protocol defined in Protobuf schema . That schema is a source of truth and all protocol description below describes messages from that schema. Client sends Command to server. Server sends Reply to client. All communication between client and server is a bidirectional exchange of Command and Reply messages. One request from client to server and one response from server to client can have more than one Command or Reply . This allows reducing number of system calls for writing and reading data. When JSON format used then many Command can be sent from client to server in JSON streaming line-delimited format. I.e. each individual Command encoded to JSON and then commands joined together using new line symbol \\n : {\"id\": 1, \"method\": \"subscribe\", \"params\": {\"channel\": \"ch1\"}} {\"id\": 2, \"method\": \"subscribe\", \"params\": {\"channel\": \"ch2\"}} For example here is how we do this in Javascript client when JSON format used: function encodeCommands ( commands ) { const encodedCommands = []; for ( const i in commands ) { if ( commands . hasOwnProperty ( i )) { encodedCommands . push ( JSON . stringify ( commands [ i ])); } } return encodedCommands . join ( '\\n' ); } Note This doc will use JSON format for examples because it's human-readable. Everything said here for JSON is also true for Protobuf encoded case. The only difference is how several individual Command or server Reply joined into one request \u2013 see details below. Note Method represented as a ENUM in protobuf schema and can be sent as integer value. Though it's possible to send it as string in JSON case \u2013 this was made to make JSON protocol human-friendly. When Protobuf format used then many Command can be sent from client to server in length-delimited format where each individual Command marshaled to bytes prepended by varint length. See existing client implementations for encoding example. The same rules relate to many Reply in one response from server to client. Line-delimited JSON and varint-length prefixed Protobuf also used there. For example here is how we read server response and extracting individual replies in Javascript client when JSON format used: function decodeReplies ( data ) { const replies = []; const encodedReplies = data . split ( '\\n' ); for ( const i in encodedReplies ) { if ( encodedReplies . hasOwnProperty ( i )) { if ( ! encodedReplies [ i ]) { continue ; } const reply = JSON . parse ( encodedReplies [ i ]); replies . push ( reply ); } } return replies ; } For Protobuf case see existing client implementations for decoding example. As you can see each Command has id field. This is an incremental uint32 field. This field will be echoed in a server replies to commands so client could match a certain Reply to Command sent before. This is important since Websocket is an asynchronous protocol where server and client both send messages at any moment and there is no builtin request-response matching. Having id allows matching a reply with a command send before. So you can expect something like this in response after sending commands to server: {\"id\": 1, \"result\": {}} {\"id\": 2, \"result\": {}} Besides id Reply from server to client have two important fields: result and error . result contains useful payload object which is different for various Reply messages. error contains error description if Command processing resulted in some error on a server. error is optional and if Reply does not have error then it means that Command processed successfully and client can parse result object appropriately. error looks like this in JSON case: { \"code\" : 100 , \"message\" : \"internal server error\" } We will talk more about error handling below. The special type of Reply is asynchronous Reply . Such replies have no id field set (or id can be equal to zero). Async replies can come to client in any moment - not as reaction to issued Command but as message from server to client in arbitrary time. For example this can be a message published into channel. Centrifuge library defines several command types client can issue. A well-written client must be aware of all those commands and client workflow. Communication with Centrifuge/Centrifugo server starts with issuing connect command.","title":"Top level framing"},{"location":"transports/protocol/#connect","text":"First of all client must dial with a server and then send connect Command to it. Default Websocket endpoint in Centrifugo is: ws://centrifugo.example.com/connection/websocket In case of using TLS: wss://centrifugo.example.com/connection/websocket After a successful dial to WebSocket endpoint client must send connect command to server to authorize itself. connect command looks like: { \"id\" : 1 , \"method\" : \"connect\" , \"params\" : { \"token\" : \"JWT\" , \"data\" : {} } } Where params fields: optional string token - connection token. Can be ommited if token-based auth not used. data - can contain custom connect data, for example it can contain client settings. In response to connect command server sends a connect reply. It looks this way: { \"id\" : 1 , \"result\" :{ \"client\" : \"421bf374-dd01-4f82-9def-8c31697e956f\" , \"version\" : \"2.0.0\" } } result has some fields: string client - unique client connection ID server issued to this connection string version - server version optional bool expires - whether a server will expire connection at some point optional int32 ttl - time in seconds until connection expires","title":"Connect"},{"location":"transports/protocol/#subscribe","text":"As soon as client successfully connected and got unique connection ID it is ready to subscribe on channels. To do this it must send subscribe command to server: { \"id\" : 2 , \"method\" : \"subscribe\" , \"params\" : { \"channel\" : \"ch1\" } } Fields that can be set in params are: string channel - channel to subscribe In response to subscribe a client receives reply like: { \"id\" : 2 , \"result\" : {} } result can have the following fields that relate to subscription expiration: optional bool expires - indicates whether subscription expires or not. optional uint32 ttl - number of seconds until subscription expire. Also several fields that relate to message recovery: optional bool recoverable - means that messages can be recovered in this subscription. optional uint64 offset - current publication offset inside channel optional string epoch - current epoch inside channel optional array publications - this is an array of missed publications in channel. When received client must call general publication event handler for each message in this array. optional bool recovered - this flag set to true when server thinks that all missed publications successfully recovered and send in subscribe reply (in publications array) and false otherwise. See more about meaning of recovery related fields in special doc chapter . After a client received a successful reply on subscribe command it will receive asynchronous reply messages published to this channel. Messages can be of several types: Publication message Join message Leave message Unsub message Message message Sub message See more about asynchronous messages below.","title":"Subscribe"},{"location":"transports/protocol/#unsubscribe","text":"When client wants to unsubscribe from a channel and therefore stop receiving asynchronous subscription messages from connection related to channel it must call unsubscribe command: { \"id\" : 3 , \"method\" : \"unsubscribe\" , \"params\" : { \"channel\" : \"ch1\" } } Actually server response does not mean a lot for a client - it must immediately remove channel subscription from internal implementation data structures and ignore all messages related to channel.","title":"Unsubscribe"},{"location":"transports/protocol/#refresh","text":"It's possible to turn on client connection expiration mechanism on a server. While enabled server will keep track of connections whose time of life is close to the end (connection lifetime set on connection authentication phase). In this case connection will be closed. Client can prevent closing connection refreshing its connection credentials. To do this it must send refresh command to server. refresh command is similar to connect : { \"id\" : 4 , \"method\" : \"refresh\" , \"params\" : { \"token\" : \"<refreshed token>\" } } The tip whether a connection must be refreshed by a client comes in reply to connect command shown above - fields expires and ttl . When client connection expire mechanism is on the value of field expires in connect reply is true . In this case client implementation should look at ttl value which is seconds left until connection will be considered expired. Client must send refresh command after this ttl seconds. Server gives client a configured window to refresh token after ttl passed and then closes connection if client have not updated its token. When connecting with already expired token an error will be returned (with code 109 ). In this case client should refresh its token and reconnect with exponential backoff.","title":"Refresh"},{"location":"transports/protocol/#rpc-like-calls-publish-history-presence","text":"The mechanics of these calls is simple - client sends command and expects response from server. publish command allows to publish a message into a channel from a client. Note To publish from client publish option in server configuration must be set to true history allows asking a server for channel history if enabled. presence allows asking a server for channel presence information if enabled.","title":"RPC-like calls: publish, history, presence"},{"location":"transports/protocol/#asynchronous-server-to-client-messages","text":"There are several types of asynchronous messages that can come from server to client. All of them relate to current client subscriptions. The most important message is Publication : { \"result\" :{ \"channel\" : \"ch1\" , \"data\" :{ \"data\" :{ \"input\" : \"1\" }, \"info\" :{ \"user\" : \"2694\" , \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \"conn_info\" :{ \"name\" : \"Alexander\" }, \"chan_info\" :{} } } } } Publication is a message published into channel. Note that there is no id field in this message - this symptom allows to distinguish it from Reply to Command . Next message is Join message: { \"result\" :{ \"type\" : 1 , \"channel\" : \"ch1\" , \"data\" :{ \"info\" :{ \"user\" : \"2694\" , \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \"conn_info\" :{ \"name\" : \"Alexander\" }, \"chan_info\" :{} } } } } Join messages sent when someone joined (subscribed on) channel. Note To enable Join and Leave messages join_leave option must be enabled on server globally or for channel namespace. Leave messages sent when someone left (unsubscribed from) channel. { \"result\" :{ \"type\" : 2 , \"channel\" : \"ch1\" , \"data\" :{ \"info\" :{ \"user\" : \"2694\" , \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \"conn_info\" :{ \"name\" : \"Alexander\" }, \"chan_info\" :{} } } } } Finally Unsub message that means that server unsubscribed current client from a channel: { \"result\" :{ \"type\" : 3 , \"channel\" : \"ch1\" , \"data\" :{} } } It's possible to distinguish between different types of asynchronous messages looking at type field (for Publication this field not set or 0 ).","title":"Asynchronous server-to-client messages"},{"location":"transports/protocol/#ping-pong","text":"To maintain connection alive and detect broken connections client must periodically send ping commands to server and expect replies to it. Ping command looks like: { \"id\" : 32 , \"method\" : \"ping\" } Server just echoes this command back. When client does not receive ping reply for some time it must consider connection broken and try to reconnect. Recommended ping interval is 25 seconds, recommended period to wait for pong is 1-5 seconds. Though those numbers can vary.","title":"Ping Pong"},{"location":"transports/protocol/#handle-disconnects","text":"Client should handle disconnect advices from server. In websocket case disconnect advice is sent in reason field of CLOSE Websocket frame. Reason contains string which is disconnect object encoded into JSON (even in case of Protobuf scenario). That objects looks like: { \"reason\" : \"shutdown\" , \"reconnect\" : true } It contains string reason of connection closing and advice to reconnect or not. Client should take this reconnect advice into account. In case of network problems and random disconnect from server without well known reason client should always try to reconnect with exponential intervals.","title":"Handle disconnects"},{"location":"transports/protocol/#handle-errors","text":"This section contains advices to error handling in client implementations. Errors can happen during various operations and can be handled in special way in context of some commands to tolerate network and server problems. Errors during connect must result in full client reconnect with exponential backoff strategy. The special case is error with code 110 which signals that connection token already expired. As we said above client should update its connection JWT before connecting to server again. Errors during subscribe must result in full client reconnect in case of internal error (code 100 ). And be sent to subscribe error event handler of subscription if received error is persistent. Persistent errors are errors like permission denied , bad request , namespace not found etc. Persistent errors in most situation mean a mistake from developers side. The special corner case is client-side timeout during subscribe operation. As protocol is asynchronous it's possible in this case that server will eventually subscribe client on channel but client will think that it's not subscribed. It's possible to retry subscription request and tolerate already subscribed (code 105 ) error as expected. But the simplest solution is to reconnect entirely as this is simpler and gives client a chance to connect to working server instance. Errors during rpc-like operations can be just returned to caller - i.e. user javascript code. Calls like history and presence are idempotent. You should be accurate with unidempotent operations like publish - in case of client timeout it's possible to send the same message into channel twice if retry publish after timeout - so users of libraries must care about this case \u2013 making sure they have some protection from displaying message twice on client side (maybe some sort of unique key in payload).","title":"Handle errors"},{"location":"transports/protocol/#client-implementation-advices","text":"Here are some advices about client public API. Examples here are in Javascript language. This is just an attempt to help in developing a client - but rules here is not obligatorily the best way to implement client. Create client instance: const centrifuge = new Centrifuge ( \"ws://localhost:8000/connection/websocket\" , {}); Set connection token (in case of using Centrifugo): centrifuge . setToken ( \"XXX\" ) Connect to server: centrifuge . connect (); 2 event handlers can be set to centrifuge object: connect and disconnect centrifuge . on ( 'connect' , function ( context ) { console . log ( context ); }); centrifuge . on ( 'disconnect' , function ( context ) { console . log ( context ); }); Client created in disconnected state with reconnect attribute set to true and reconnecting flag set to false . After connect() called state goes to connecting . It's only possible to connect from disconnected state. Every time connect() called reconnect flag of client must be set to true . After each failed connect attempt state must be set to disconnected , disconnect event must be emitted (only if reconnecting flag is false ), and then reconnecting flag must be set to true (if client should continue reconnecting) to not emit disconnect event again after next in a row connect attempt failure. In case of failure next connection attempt must be scheduled automatically with backoff strategy. On successful connect reconnecting flag must be set to false , backoff retry must be resetted and connect event must be emitted. When connection lost then the same set of actions as when connect failed must be performed. Client must allow to subscribe on channels: var subscription = centrifuge . subscribe ( \"channel\" , eventHandlers ); Subscription object created and control immediately returned to caller - subscribing must be performed asynchronously. This is required because client can automatically reconnect later so event-based model better suites for subscriptions. Subscription should support several event handlers: handler for publication received from channel join message handler leave message handler error handler subscribe success event handler unsubscribe event handler Every time client connects to server it must restore all subscriptions. Every time client disconnects from server it must call unsubscribe handlers for all active subscriptions and then emit disconnect event. Client must periodically (once in 25 secs, configurable) send ping messages to server. If pong has not beed received in 5 secs (configurable) then client must disconnect from server and try to reconnect with backoff strategy. Client can automatically batch several requests into one frame to server and also must be able to handle several replies received from server in one frame.","title":"Client implementation advices"},{"location":"transports/protocol/#server-side-subscriptions-sss","text":"It's also possible to subscribe connection to channels on server side. In this case we call this server-side subscription. Client should only handle asynchronous messages coming from a server without need to create subscriptions on client side. SSS should be kept separate from client-side subs SSS requires new event handlers on top-level of Client - Subscribe, Publish, Join, Leave, Unsubscribe, event handlers will be called with event context similar to client-side subs case but with channel field Connect Reply contains SSS set by a server on connect, on reconnect client has a chance to recover missed Publications Server side subscription can happen at any moment - Sub Push will be sent to client","title":"Server side subscriptions (SSS)"},{"location":"transports/protocol/#message-recovery","text":"Client should automatically recover messages after being disconnected due to network problems and set appropriate fields in subscribe event context. Two important fields in onSubscribeSuccess event context are isRecovered and isResubscribe . First field let user know what server thinks about subscription state - were all messages recovered or not. The second field must only be true if resubscribe was caused by temporary network connection lost. If user initiated resubscribe himself (calling unsubscribe method and then subscribe method) then recover workflow should not be used and isResubscribe must be false .","title":"Message recovery"},{"location":"transports/protocol/#disconnect-code-and-reason","text":"In case of Websocket it is sent by server in CLOSE Websocket frame. This is a string containing JSON object with fields: reason (string) and reconnect (bool). Client should give users access to these fields in disconnect event and automatically follow reconnect advice.","title":"Disconnect code and reason"},{"location":"transports/protocol/#additional-notes","text":"Centrifugo and Centrifuge-based server do not allow one client connection to subscribe on the same channel twice. In this case client will receive already subscribed error in reply to subscribe command.","title":"Additional notes"},{"location":"transports/recovery/","text":"How message recovery works \u00b6 This description uses offset field available since Centrifugo v2.5.0 which replaced two uint32 fields seq and gen in client protocol schema. This means that here we describe a case when Centrifugo config contains v3_use_offset option enabled: { ... \"v3_use_offset\" : true } Note For seq and gen recovery works in similar way, but we have two uint32 fields instead of single uint64 offset . One of the most interesting features of Centrifugo is message recovery after short network disconnects. This mechanism allows client to automatically get missed publications on successful resubscribe to channel after being disconnected for a while. In general, you would query your application backend for actual state on every client reconnect - but message recovery feature allows Centrifugo to deal with this and restore missed publications from history cache thus radically reducing load on your application backend and your main database in some scenarios. Danger Message recovery protocol feature designed to be used together with reasonably small Publication stream size as all missed publications sent towards client in one protocol frame on resubscribe to channel. Thus, it mostly suitable for short-time disconnects. It helps a lot to survive reconnect storm when many clients reconnect at one moment (balancer reload, network glitch) - but it's not a good idea to recover a long list of missed messages after clients being offline for a long time. To enable recovery mechanism for channels set history_recover boolean configuration option to true on the configuration file top-level or for a channel namespace. When subscribing on channels Centrifugo will return missed publications to client in subscribe Reply , also it will return special recovered boolean flag to indicate whether all missed publications successfully recovered after disconnect or not. Centrifugo recovery model based on two fields in protocol: offset and epoch . All fields managed automatically by Centrifugo client libraries, but it's good to know how recovery works under the hood. Once history_recover option enabled every publication will have incremental (inside channel) offset field. This field has uint64 type. Another field is string epoch . It exists to handle cases when history storage has been restarted while client was in disconnected state so publication numeration in a channel started from scratch. For example at moment Memory engine does not persist publication sequences on disk so every restart will start numeration from scratch, after each restart new epoch field generated, and we can understand in recovery process that client could miss messages thus returning correct recovered flag in subscribe Reply . This also applies to Redis engine \u2013 if you do not use AOF with fsync then sequences can be lost after Redis restart. When using Redis engine you need to use fully in-memory model strategy or AOF with fsync to guarantee reliability of recovered flag sent by Centrifugo. When server receives subscribe command with boolean flag recover set to true and offset , epoch set to values last seen by a client (see SubscribeRequest type in protocol definitions ) it can try to find all missed publications from history cache. Recovered publications will be passed to client in subscribe Reply in correct order, and your publication handler will be automatically called to process each missed message. You can also manually implement your own recovery algorithm on top of basic PUB/SUB possibilities that Centrifugo provides. As we said above you can simply ask your backend for an actual state after every client reconnect completely bypassing recovery mechanism described here.","title":"Message recovery"},{"location":"transports/recovery/#how-message-recovery-works","text":"This description uses offset field available since Centrifugo v2.5.0 which replaced two uint32 fields seq and gen in client protocol schema. This means that here we describe a case when Centrifugo config contains v3_use_offset option enabled: { ... \"v3_use_offset\" : true } Note For seq and gen recovery works in similar way, but we have two uint32 fields instead of single uint64 offset . One of the most interesting features of Centrifugo is message recovery after short network disconnects. This mechanism allows client to automatically get missed publications on successful resubscribe to channel after being disconnected for a while. In general, you would query your application backend for actual state on every client reconnect - but message recovery feature allows Centrifugo to deal with this and restore missed publications from history cache thus radically reducing load on your application backend and your main database in some scenarios. Danger Message recovery protocol feature designed to be used together with reasonably small Publication stream size as all missed publications sent towards client in one protocol frame on resubscribe to channel. Thus, it mostly suitable for short-time disconnects. It helps a lot to survive reconnect storm when many clients reconnect at one moment (balancer reload, network glitch) - but it's not a good idea to recover a long list of missed messages after clients being offline for a long time. To enable recovery mechanism for channels set history_recover boolean configuration option to true on the configuration file top-level or for a channel namespace. When subscribing on channels Centrifugo will return missed publications to client in subscribe Reply , also it will return special recovered boolean flag to indicate whether all missed publications successfully recovered after disconnect or not. Centrifugo recovery model based on two fields in protocol: offset and epoch . All fields managed automatically by Centrifugo client libraries, but it's good to know how recovery works under the hood. Once history_recover option enabled every publication will have incremental (inside channel) offset field. This field has uint64 type. Another field is string epoch . It exists to handle cases when history storage has been restarted while client was in disconnected state so publication numeration in a channel started from scratch. For example at moment Memory engine does not persist publication sequences on disk so every restart will start numeration from scratch, after each restart new epoch field generated, and we can understand in recovery process that client could miss messages thus returning correct recovered flag in subscribe Reply . This also applies to Redis engine \u2013 if you do not use AOF with fsync then sequences can be lost after Redis restart. When using Redis engine you need to use fully in-memory model strategy or AOF with fsync to guarantee reliability of recovered flag sent by Centrifugo. When server receives subscribe command with boolean flag recover set to true and offset , epoch set to values last seen by a client (see SubscribeRequest type in protocol definitions ) it can try to find all missed publications from history cache. Recovered publications will be passed to client in subscribe Reply in correct order, and your publication handler will be automatically called to process each missed message. You can also manually implement your own recovery algorithm on top of basic PUB/SUB possibilities that Centrifugo provides. As we said above you can simply ask your backend for an actual state after every client reconnect completely bypassing recovery mechanism described here.","title":"How message recovery works"},{"location":"transports/sockjs/","text":"SockJS \u00b6 SockJS is a polyfill browser library which provides HTTP-based fallback transports in case when it's not possible to establish Websocket connection. This can happen in old client browsers or because of some proxy behind client and server that cuts of Websocket traffic. You can find more information on SockJS project Github page . If you have a requirement to work everywhere SockJS is the solution. SockJS will automatically choose best fallback transport if Websocket connection failed for some reason. Some of the fallback transports are: Eventsource (SSE) XHR-streaming Long-polling And more (see SockJS docs ) SockJS connection endpoint in Centrifugo is /connection/sockjs . There are two caveats when using SockJS . First is that you need to use sticky sessions mechanism if you have many Centrifugo nodes running . This mechanism usually supported by load balancers (for example Nginx). Sticky sessions mean that all requests from the same client will come to the same Centrifugo node. This is necessary because SockJS maintains connection session in process memory thus allowing bidirectional communication between a client and a server. Sticky mechanism not required if you only use one Centrifugo node on a backend. See how enable sticky sessions in Nginx in deploy section of this doc. Second \u2013 SockJS does not support binary data, so you are limited in using JSON with it .","title":"SockJS"},{"location":"transports/sockjs/#sockjs","text":"SockJS is a polyfill browser library which provides HTTP-based fallback transports in case when it's not possible to establish Websocket connection. This can happen in old client browsers or because of some proxy behind client and server that cuts of Websocket traffic. You can find more information on SockJS project Github page . If you have a requirement to work everywhere SockJS is the solution. SockJS will automatically choose best fallback transport if Websocket connection failed for some reason. Some of the fallback transports are: Eventsource (SSE) XHR-streaming Long-polling And more (see SockJS docs ) SockJS connection endpoint in Centrifugo is /connection/sockjs . There are two caveats when using SockJS . First is that you need to use sticky sessions mechanism if you have many Centrifugo nodes running . This mechanism usually supported by load balancers (for example Nginx). Sticky sessions mean that all requests from the same client will come to the same Centrifugo node. This is necessary because SockJS maintains connection session in process memory thus allowing bidirectional communication between a client and a server. Sticky mechanism not required if you only use one Centrifugo node on a backend. See how enable sticky sessions in Nginx in deploy section of this doc. Second \u2013 SockJS does not support binary data, so you are limited in using JSON with it .","title":"SockJS"},{"location":"transports/websocket/","text":"Websocket \u00b6 Websocket is the main transport in Centrifugo. It's a very efficient low-overhead protocol on top of TCP. The biggest advantage is that Websocket works out of the box in all modern browsers and almost all programming languages have Websocket implementations. This makes Websocket a pretty universal transport that can even be used to connect to Centrifugo from web apps and mobile apps and other environments. Websocket connection endpoint in Centrifugo is /connection/websocket . If you want to use Protobuf binary protocol then you need to connect to /connection/websocket?format=protobuf Websocket compression \u00b6 An experimental feature for raw websocket endpoint - permessage-deflate compression for websocket messages. Btw look at great article about websocket compression. We consider this experimental because this websocket compression is experimental in Gorilla Websocket library that Centrifugo uses internally. Websocket compression can reduce an amount of traffic travelling over the wire. But keep in mind that enabling websocket compression will result in much slower Centrifugo performance and more memory usage \u2013 depending on your message rate this can be very noticeable. To enable websocket compression for raw websocket endpoint set websocket_compression: true in configuration file. After this clients that support permessage-deflate will negotiate compression with server automatically. Note that enabling compression does not mean that every connection will use it - this depends on client support for this feature. Another option is websocket_compression_min_size . Default 0. This is a minimal size of message in bytes for which we use deflate compression when writing it to client's connection. Default value 0 means that we will compress all messages when websocket_compression enabled and compression support negotiated with client. It's also possible to control websocket compression level defined at compress/flate By default when compression with a client negotiated Centrifugo uses compression level 1 (BestSpeed). If you want to set custom compression level use websocket_compression_level configuration option. If you have a few writes then websocket_use_write_buffer_pool (boolean, default false ) option can reduce memory usage of Centrifugo a bit as there won't be separate write buffer binded to each WebSocket connection.","title":"Websocket"},{"location":"transports/websocket/#websocket","text":"Websocket is the main transport in Centrifugo. It's a very efficient low-overhead protocol on top of TCP. The biggest advantage is that Websocket works out of the box in all modern browsers and almost all programming languages have Websocket implementations. This makes Websocket a pretty universal transport that can even be used to connect to Centrifugo from web apps and mobile apps and other environments. Websocket connection endpoint in Centrifugo is /connection/websocket . If you want to use Protobuf binary protocol then you need to connect to /connection/websocket?format=protobuf","title":"Websocket"},{"location":"transports/websocket/#websocket-compression","text":"An experimental feature for raw websocket endpoint - permessage-deflate compression for websocket messages. Btw look at great article about websocket compression. We consider this experimental because this websocket compression is experimental in Gorilla Websocket library that Centrifugo uses internally. Websocket compression can reduce an amount of traffic travelling over the wire. But keep in mind that enabling websocket compression will result in much slower Centrifugo performance and more memory usage \u2013 depending on your message rate this can be very noticeable. To enable websocket compression for raw websocket endpoint set websocket_compression: true in configuration file. After this clients that support permessage-deflate will negotiate compression with server automatically. Note that enabling compression does not mean that every connection will use it - this depends on client support for this feature. Another option is websocket_compression_min_size . Default 0. This is a minimal size of message in bytes for which we use deflate compression when writing it to client's connection. Default value 0 means that we will compress all messages when websocket_compression enabled and compression support negotiated with client. It's also possible to control websocket compression level defined at compress/flate By default when compression with a client negotiated Centrifugo uses compression level 1 (BestSpeed). If you want to set custom compression level use websocket_compression_level configuration option. If you have a few writes then websocket_use_write_buffer_pool (boolean, default false ) option can reduce memory usage of Centrifugo a bit as there won't be separate write buffer binded to each WebSocket connection.","title":"Websocket compression"}]}