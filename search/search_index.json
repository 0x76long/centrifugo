{
    "docs": [
        {
            "location": "/",
            "text": "Centrifugo overview\n\u00b6\n\n\nThis is a work in progress documentation for Centrifugo v2\n\n\nFirst of all we have chat on Gitter \u2013 welcome!\n\n\n\n\nCentrifugo is a language-agnostic real-time messaging server. Language-agnostic means that it does not matter which programming language your application uses on frontend or backend sides - Centrifugo can work in conjunction with any. Real-time messages are messages that delivered to your clients almost immediately after some event happened - think live comments, chats, real-time charts, dynamic counters.\n\n\nThere are several main transports Centrifugo supports at moment:\n\n\n\n\nWebsocket (JSON or binary Protobuf)\n\n\nSockJS (library that tries to establish Websocket connection first and then falls back to HTTP transports automatically in case of problems with Websocket connection)\n\n\n\n\nMotivation of project\n\u00b6\n\n\nCentrifugo was originally born to help applications written in language or framework without builtin concurency support to introduce real-time updates. For example frameworks like Django, Flask, Yii, Laravel, Ruby on Rails etc has poor support of working with many persistent connections. Centrifugo aims to help with this and continue to write backend in your favorite language and favorite framework. It also has some features that can simplify your life as a developer even if you are writing backend in asynchronous concurrent language.\n\n\nConcepts\n\u00b6\n\n\nCentrifugo is language-agnostic real-time server. It is running as standalone server and takes care of handling persistent connections from your frontend application users. Your application backend and frontend can be written in any programming language. Your clients connect to Centrifugo from frontend using connection credentials provided by your application backend, subscribe on channels. As soon as some event happens your application backend can publish message with event into channel using Centrifugo API. And that message will be delivered to all clients currently subscribed on channel. Here is a simplified scheme:",
            "title": "Getting Started"
        },
        {
            "location": "/#centrifugo-overview",
            "text": "This is a work in progress documentation for Centrifugo v2  First of all we have chat on Gitter \u2013 welcome!   Centrifugo is a language-agnostic real-time messaging server. Language-agnostic means that it does not matter which programming language your application uses on frontend or backend sides - Centrifugo can work in conjunction with any. Real-time messages are messages that delivered to your clients almost immediately after some event happened - think live comments, chats, real-time charts, dynamic counters.  There are several main transports Centrifugo supports at moment:   Websocket (JSON or binary Protobuf)  SockJS (library that tries to establish Websocket connection first and then falls back to HTTP transports automatically in case of problems with Websocket connection)",
            "title": "Centrifugo overview"
        },
        {
            "location": "/#motivation-of-project",
            "text": "Centrifugo was originally born to help applications written in language or framework without builtin concurency support to introduce real-time updates. For example frameworks like Django, Flask, Yii, Laravel, Ruby on Rails etc has poor support of working with many persistent connections. Centrifugo aims to help with this and continue to write backend in your favorite language and favorite framework. It also has some features that can simplify your life as a developer even if you are writing backend in asynchronous concurrent language.",
            "title": "Motivation of project"
        },
        {
            "location": "/#concepts",
            "text": "Centrifugo is language-agnostic real-time server. It is running as standalone server and takes care of handling persistent connections from your frontend application users. Your application backend and frontend can be written in any programming language. Your clients connect to Centrifugo from frontend using connection credentials provided by your application backend, subscribe on channels. As soon as some event happens your application backend can publish message with event into channel using Centrifugo API. And that message will be delivered to all clients currently subscribed on channel. Here is a simplified scheme:",
            "title": "Concepts"
        },
        {
            "location": "/server/",
            "text": "Server overview\n\u00b6\n\n\nCentrifugo server is written in Go language. It's an open-source software, the source code is available \non Github\n.\n\n\nCentrifugo is built around \ncentrifuge\n library for Go language. That library defines custom protocol and message types which must be sent over various transports (Websocket, SockJS). Server clients use that protocol internally and provide simple API to features - making persistent connection, subscribing on channels, calling RPC commands and more.\n\n\nThis documentation chapter covers some server concepts in detail. This is documentation for Centrifugo server but many things said here are also valid for centrifuge library as it's a core of Centrifugo server.",
            "title": "Overview"
        },
        {
            "location": "/server/#server-overview",
            "text": "Centrifugo server is written in Go language. It's an open-source software, the source code is available  on Github .  Centrifugo is built around  centrifuge  library for Go language. That library defines custom protocol and message types which must be sent over various transports (Websocket, SockJS). Server clients use that protocol internally and provide simple API to features - making persistent connection, subscribing on channels, calling RPC commands and more.  This documentation chapter covers some server concepts in detail. This is documentation for Centrifugo server but many things said here are also valid for centrifuge library as it's a core of Centrifugo server.",
            "title": "Server overview"
        },
        {
            "location": "/server/install/",
            "text": "Install and quick start\n\u00b6\n\n\nGo is a perfect language - it gives developers an opportunity to have single binary executable file for application and cross-compile application on all target operating systems for distribution. This means that all you need to get Centrifugo \u2013 \ndownload latest release\n for you operating system, unpack it and you are done!\n\n\nNow you can see help information for Centrifugo:\n\n\n./centrifugo -h\n\n\n\n\nCentrifugo server node requires configuration file with secret key. If you are new to Centrifugo then there is \ngenconfig\n command which generates minimal required configuration file:\n\n\n./centrifugo genconfig\n\n\n\n\nIt generates secret key automatically and creates configuration file \nconfig.json\n in current directory (by default) so you can finally run Centrifugo instance:\n\n\n./centrifugo --config\n=\nconfig.json\n\n\n\n\nWe will talk about configuration in detail in next sections.\n\n\nYou can also put or symlink \ncentrifugo\n into your \nbin\n OS directory and run it from anywhere:\n\n\ncentrifugo --config\n=\nconfig.json\n\n\n\n\nIn production you will need to daemonize Centrifugo. We have prebuilt \nrpm\n and \ndeb\n packages for\nmost popular Linux distributions and Docker image. See \nDeploy\n section for more information.",
            "title": "Installation"
        },
        {
            "location": "/server/install/#install-and-quick-start",
            "text": "Go is a perfect language - it gives developers an opportunity to have single binary executable file for application and cross-compile application on all target operating systems for distribution. This means that all you need to get Centrifugo \u2013  download latest release  for you operating system, unpack it and you are done!  Now you can see help information for Centrifugo:  ./centrifugo -h  Centrifugo server node requires configuration file with secret key. If you are new to Centrifugo then there is  genconfig  command which generates minimal required configuration file:  ./centrifugo genconfig  It generates secret key automatically and creates configuration file  config.json  in current directory (by default) so you can finally run Centrifugo instance:  ./centrifugo --config = config.json  We will talk about configuration in detail in next sections.  You can also put or symlink  centrifugo  into your  bin  OS directory and run it from anywhere:  centrifugo --config = config.json  In production you will need to daemonize Centrifugo. We have prebuilt  rpm  and  deb  packages for\nmost popular Linux distributions and Docker image. See  Deploy  section for more information.",
            "title": "Install and quick start"
        },
        {
            "location": "/server/configuration/",
            "text": "Configuration\n\u00b6\n\n\nCentrifugo expects JSON, TOML or YAML as format of configuration file. Thanks to brilliant Go library for application configuration - \nviper\n.\n\n\nFirst let's look at all available command-line options:\n\n\ncentrifugo -h\n\n\n\n\nYou should see something like this as output:\n\n\nCentrifugo \u2013 real-time messaging server\n\nUsage:\n   [flags]\n   [command]\n\nAvailable Commands:\n  checkconfig Check configuration file\n  genconfig   Generate simple configuration file to start with\n  help        Help about any command\n  version     Centrifugo version information\n\nFlags:\n  -a, --address string             interface address to listen on\n      --admin                      enable admin web interface\n      --admin_insecure             use insecure admin mode \u2013 no auth required for admin socket\n      --api_insecure               use insecure API mode\n      --client_insecure            start in insecure client mode\n  -c, --config string              path to config file (default \"config.json\")\n      --debug                      enable debug endpoints\n  -e, --engine string              engine to use: memory or redis (default \"memory\")\n      --grpc_api                   enable GRPC API server\n  -h, --help                       help for this command\n      --internal_port string       custom port for internal endpoints\n      --log_file string            optional log file - if not specified logs go to STDOUT\n      --log_level string           set the log level: debug, info, error, fatal or none (default \"info\")\n  -n, --name string                unique node name\n      --pid_file string            optional path to create PID file\n  -p, --port string                port to bind HTTP server to (default \"8000\")\n      --prometheus                 enable Prometheus metrics endpoint\n      --redis_db string            Redis database (Redis engine) (default \"0\")\n      --redis_host string          Redis host (Redis engine) (default \"127.0.0.1\")\n      --redis_master_name string   name of Redis master Sentinel monitors (Redis engine)\n      --redis_password string      Redis auth password (Redis engine)\n      --redis_port string          Redis port (Redis engine) (default \"6379\")\n      --redis_sentinels string     comma-separated list of Sentinel addresses (Redis engine)\n      --redis_url string           Redis connection URL in format redis://:password@hostname:port/db (Redis engine)\n      --tls                        enable TLS, requires an X509 certificate and a key file\n      --tls_cert string            path to an X509 certificate file\n      --tls_key string             path to an X509 certificate key\n\nUse \" [command] --help\" for more information about a command.\n\n\n\n\nversion\n\u00b6\n\n\nTo show version and exit run:\n\n\ncentrifugo version\n\n\n\n\nJSON file\n\u00b6\n\n\nCentrifugo requires configuration file on start. As was mentioned earlier it must be a file with valid JSON.\n\n\nThis is a minimal Centrifugo configuration file:\n\n\n{\n\n  \n\"secret\"\n:\n \n\"secret\"\n\n\n}\n\n\n\n\n\nThe only field that is required is \nsecret\n. Secret used to create HMAC signs. Keep it strong and in secret!\n\n\nTOML file\n\u00b6\n\n\nCentrifugo also supports TOML format for configuration file:\n\n\ncentrifugo --config=config.toml\n\n\n\n\nWhere \nconfig.toml\n contains:\n\n\nsecret = \"secret\"\nlog_level = \"debug\"\n\n\n\n\nI.e. the same configuration as JSON file above. We will talk about what is \nnamespaces\n field soon.\n\n\nYAML file\n\u00b6\n\n\nAnd YAML config also supported. \nconfig.yaml\n:\n\n\nsecret\n:\n \nsecret\n\n\nlog_level\n:\n \ndebug\n\n\n\n\n\nWith YAML remember to use spaces, not tabs when writing configuration file.\n\n\ncheckconfig command\n\u00b6\n\n\nCentrifugo has special command to check configuration file \ncheckconfig\n:\n\n\ncentrifugo checkconfig --config\n=\nconfig.json\n\n\n\n\nIf any errors found during validation \u2013 program will exit with error message and exit code 1.\n\n\ngenconfig command\n\u00b6\n\n\nAnother command is \ngenconfig\n:\n\n\ncentrifugo genconfig -c config.json\n\n\n\n\nIt will generate the minimal required configuration file automatically.\n\n\nImportant options\n\u00b6\n\n\nSome of the most important options you can configure when running Centrifugo:\n\n\n\n\naddress\n \u2013 bind your Centrifugo to specific interface address (by default \n\"\"\n)\n\n\nport\n \u2013 port to bind Centrifugo to (by default \n8000\n)\n\n\nengine\n \u2013 engine to use - \nmemory\n or \nredis\n (by default \nmemory\n). Read more about engines in \nspecial chapter\n.\n\n\n\n\nNote that some options can be set via command-line. Command-line options are more valuable when set than configuration file's options. See description of \nviper\n \u2013 to see more details about configuration options priority.\n\n\nChannel options\n\u00b6\n\n\nLet's look on options related to channels. Channel is an entity to which clients can subscribe to receive messages published into that channel. Channel is just a string (several symbols has special meaning in Centrifugo - see \nspecial chapter\n to find more information about channels). The following options will affect channel behaviour:\n\n\n\n\n\n\npublish\n \u2013 allow clients to publish messages into channels directly (from client side). Your application will never receive those messages. In idiomatic case all messages must be published to Centrifugo by your application backend using Centrifugo API. But this option can be useful when you want to build something without backend-side validation and saving into database. This option can also be useful for demos and prototyping real-time ideas. Note that client can only publish data into channel after successfully subscribed on it. By default it's \nfalse\n.\n\n\n\n\n\n\nsubscribe_to_publish\n - when \npublish\n option enabled client can publish into channel without beong subscribed to it. This option enables automatic check that client subscribed on channel before allowing client to publish into channel.\n\n\n\n\n\n\nanonymous\n \u2013 this option enables anonymous access (with empty \nuser\n ID in connection token). In most situations your application works with authorized users so every user has its own unique id. But if you provide real-time features for public access you may need unauthorized access to some channels. Turn on this option and use empty string as user ID. By default \nfalse\n.\n\n\n\n\n\n\npresence\n \u2013 enable/disable presence information. Presence is a structure with clients currently subscribed on channel. By default \nfalse\n \u2013 i.e. no presence information will be available for channels.\n\n\n\n\n\n\njoin_leave\n \u2013 enable/disable sending join(leave) messages when client subscribes on channel (unsubscribes from channel). By default \nfalse\n.\n\n\n\n\n\n\nhistory_size\n \u2013 history size (amount of messages) for channels. As Centrifugo keeps all history messages in memory it's very important to limit maximum amount of messages in channel history to reasonable minimum. By default history size is \n0\n - this means that channels will have no history messages at all. As soon as history enabled then \nhistory_size\n defines maximum amount of messages that Centrifugo will keep for \neach\n channel in namespace during history lifetime (see below).\n\n\n\n\n\n\nhistory_lifetime\n \u2013 interval in seconds how long to keep channel history messages. As all history is storing in memory it is also very important to get rid of old history data for unused (inactive for a long time) channels. By default history lifetime is \n0\n \u2013 this means that channels will have no history messages at all. \nSo to get history messages you should wisely configure both \nhistory_size\n and \nhistory_lifetime\n options\n.\n\n\n\n\n\n\nhistory_recover\n (\nnew in v1.2.0\n) \u2013 boolean option, when enabled Centrifugo will try to recover missed messages published while client was disconnected for some reason (bad internet connection for example). By default \nfalse\n. This option must be used in conjunction with reasonably configured message history for channel i.e. \nhistory_size\n and \nhistory_lifetime\n \nmust be set\n (because Centrifugo uses channel message history to recover messages). Also note that note all real-time events require this feature turned on so think wisely when you need this. See more details about how this option works in \nspecial chapter\n.\n\n\n\n\n\n\nhistory_drop_inactive\n (\nnew in v1.3.0\n) \u2013 boolean option, allows to drastically reduce resource usage (engine memory usage, messages travelling around) when you use message history for channels. In couple of words when enabled Centrifugo will drop history messages that no one needs. Please, see \nissue on Github\n to get more information about option use case scenario and edge cases it involves.\n\n\n\n\n\n\nLet's look how to set some of these options in config:\n\n\n{\n\n    \n\"secret\"\n:\n \n\"my-secret-key\"\n,\n\n    \n\"anonymous\"\n:\n \ntrue\n,\n\n    \n\"publish\"\n:\n \ntrue\n,\n\n    \n\"subscribe_to_publish\"\n:\n \ntrue\n,\n\n    \n\"presence\"\n:\n \ntrue\n,\n\n    \n\"join_leave\"\n:\n \ntrue\n,\n\n    \n\"history_size\"\n:\n \n10\n,\n\n    \n\"history_lifetime\"\n:\n \n30\n,\n\n    \n\"history_recover\"\n:\n \ntrue\n\n\n}\n\n\n\n\n\nAnd the last channel specific option is \nnamespaces\n. \nnamespaces\n are optional and if set must be an array of namespace objects. Namespace allows to configure custom options for channels starting with namespace name. This provides a great control over channel behaviour.\n\n\nNamespace has a name and the same channel options (with same defaults) as described above.\n\n\n\n\nname\n - unique namespace name (name must must consist of letters, numbers, underscores or hyphens and be more than 2 symbols length i.e. satisfy regexp \n^[-a-zA-Z0-9_]{2,}$\n).\n\n\n\n\nIf you want to use namespace options for channel - you must include namespace name into\nchannel name with \n:\n as separator:\n\n\npublic\n:\nmessages\n\n\ngossips\n:\nmessages\n\n\nWhere \npublic\n and \ngossips\n are namespace names from project \nnamespaces\n.\n\n\nAll things together here is an example of \nconfig.json\n which includes registered project with all options set and 2 additional namespaces in it:\n\n\n{\n\n    \n\"secret\"\n:\n \n\"very-long-secret-key\"\n,\n\n    \n\"anonymous\"\n:\n \ntrue\n,\n\n    \n\"publish\"\n:\n \ntrue\n,\n\n    \n\"presence\"\n:\n \ntrue\n,\n\n    \n\"join_leave\"\n:\n \ntrue\n,\n\n    \n\"history_size\"\n:\n \n10\n,\n\n    \n\"history_lifetime\"\n:\n \n30\n,\n\n    \n\"namespaces\"\n:\n \n[\n\n        \n{\n\n          \n\"name\"\n:\n \n\"public\"\n,\n\n          \n\"publish\"\n:\n \ntrue\n,\n\n          \n\"anonymous\"\n:\n \ntrue\n,\n\n          \n\"history_size\"\n:\n \n10\n,\n\n          \n\"history_lifetime\"\n:\n \n30\n,\n\n          \n\"history_recover\"\n:\n \ntrue\n\n        \n},\n\n        \n{\n\n          \n\"name\"\n:\n \n\"gossips\"\n,\n\n          \n\"presence\"\n:\n \ntrue\n,\n\n          \n\"join_leave\"\n:\n \ntrue\n\n        \n}\n\n    \n]\n\n\n}\n\n\n\n\n\nChannel \nnews\n will use global project options.\n\n\nChannel \npublic\n:\nnews\n will use \npublic\n namespace's options.\n\n\nChannel \ngossips\n:\nnews\n will use \ngossips\n namespace's options.\n\n\nAdvanced configuration\n\u00b6\n\n\nCentrifugo has some options for which default values make sense for most applications. In many case you\ndon't need (and you really should not) change them. This chapter is about such options.\n\n\nclient_channel_limit\n\u00b6\n\n\nDefault: 128\n\n\nSets maximum number of different channel subscriptions single client can have.\n\n\nchannel_max_length\n\u00b6\n\n\nDefault: 255\n\n\nSets maximum length of channel name.\n\n\nchannel_user_connection_limit\n\u00b6\n\n\nDefault: 0\n\n\nMaximum number of connections from user (with known user ID) to Centrifugo node. By default - unlimited.\n\n\nclient_request_max_size\n\u00b6\n\n\nDefault: 65536\n\n\nMaximum allowed size of request from client in bytes.\n\n\nclient_queue_max_size\n\u00b6\n\n\nDefault: 10485760\n\n\nMaximum client message queue size in bytes to close slow reader connections. By default - 10mb.\n\n\nsockjs_heartbeat_delay\n\u00b6\n\n\nDefault: 25\n\n\nInterval in seconds how often to send SockJS h-frames to client.\n\n\nwebsocket_compression\n\u00b6\n\n\nDefault: false\n\n\nEnable websocket compression, see special chapter in docs.\n\n\ngomaxprocs\n\u00b6\n\n\nDefault: 0\n\n\nBy default Centrifugo runs on all available CPU cores. If you want to limit amount of cores Centrifugo can utilize in one moment use this option.\n\n\nAdvanced endpoint configuration.\n\u00b6\n\n\nAfter you started Centrifugo you have several endpoints available. As soon as you have not provided any extra options you have 3 endpoints by default.\n\n\nDefault endpoints.\n\u00b6\n\n\nFirst is SockJS endpoint - it's needed to serve client connections that use SockJS library:\n\n\nhttp://localhost:8000/connection/sockjs\n\n\n\n\nNext is raw Websocket endpoint to serve client connections that use pure Websocket protocol:\n\n\nws://localhost:8000/connection/websocket\n\n\n\n\nAnd finally you have API endpoint to \npublish\n messages to channels (and execute other available API commands):\n\n\nhttp://localhost:8000/api\n\n\n\n\nBy default all endpoints work on port \n8000\n. You can change it using \nport\n option:\n\n\n{\n    \"port\": 9000\n}\n\n\n\n\nIn production setup you will have your domain name in endpoint addresses above instead of \nlocalhost\n. Also if your Centrifugo will be behind proxy or load balancer software you most probably won't have ports in your endpoint addresses. What will always be the same as shown above are URL paths: \n/connection/sockjs\n, \n/connection/websocket\n, \n/api\n.\n\n\nLet's look at possibilities to tweak available endpoints.\n\n\nAdmin endpoints.\n\u00b6\n\n\nFirst is enabling admin endpoints:\n\n\n{\n    ...\n    \"admin\": true,\n    \"admin_password\": \"password\",\n    \"admin_secret\": \"secret\"\n}\n\n\n\n\nThis makes the following endpoint available: http://localhost:8000\n\n\nAt this address you will see admin web interface. You can log into it using \nadmin_password\n value shown above.\n\n\nDebug endpoints.\n\u00b6\n\n\nNext, when Centrifugo started in debug mode some extra debug endpoints become available. To start in debug mode add \ndebug\n option to config:\n\n\n{\n    ...\n    \"debug\": true\n}\n\n\n\n\nAnd endpoint:\n\n\nhttp://localhost:8000/debug/pprof/\n\n\n\n\n\u2013 will show you useful info about internal state of Centrifugo instance. This info is especially helpful when troubleshooting. See \nwiki page\n for more info.\n\n\nCustom admin and API ports\n\u00b6\n\n\nWe strongly recommend to not expose admin, debug and API endpoints to Internet. In case of admin endpoint this step provides extra protection to \n/\n, \n/admin/auth\n, \n/admin/api\n endpoints, debug endpoints. Protecting API endpoint will allow you to use \napi_insecure\n mode to omit passing API key in each request.\n\n\nSo it's a good practice to protect admin and API endpoints with firewall. For example you can do this in \nlocation\n section of Nginx configuration.\n\n\nThough sometimes you don't have access to per-location configuration in your proxy/load balancer software. For example\nwhen using Amazon ELB. In this case you can change ports on which your admin and API endpoints work.\n\n\nTo run admin endpoints on custom port use \nadmin_port\n option:\n\n\n{\n    ...\n    \"admin_port\": 10000\n}\n\n\n\n\nSo admin web interface will work on address:\n\n\nws://localhost:10000\n\n\n\n\nAlso debug page will be available on new custom admin port too:\n\n\nhttp://localhost:10000/debug/pprof/\n\n\n\n\nTo run API server on it's own port use \napi_port\n option:\n\n\n{\n    ...\n    \"api_port\": 10001\n}\n\n\n\n\nNow you should send API requests to:\n\n\nhttp://localhost:10001/api",
            "title": "Configuration"
        },
        {
            "location": "/server/configuration/#configuration",
            "text": "Centrifugo expects JSON, TOML or YAML as format of configuration file. Thanks to brilliant Go library for application configuration -  viper .  First let's look at all available command-line options:  centrifugo -h  You should see something like this as output:  Centrifugo \u2013 real-time messaging server\n\nUsage:\n   [flags]\n   [command]\n\nAvailable Commands:\n  checkconfig Check configuration file\n  genconfig   Generate simple configuration file to start with\n  help        Help about any command\n  version     Centrifugo version information\n\nFlags:\n  -a, --address string             interface address to listen on\n      --admin                      enable admin web interface\n      --admin_insecure             use insecure admin mode \u2013 no auth required for admin socket\n      --api_insecure               use insecure API mode\n      --client_insecure            start in insecure client mode\n  -c, --config string              path to config file (default \"config.json\")\n      --debug                      enable debug endpoints\n  -e, --engine string              engine to use: memory or redis (default \"memory\")\n      --grpc_api                   enable GRPC API server\n  -h, --help                       help for this command\n      --internal_port string       custom port for internal endpoints\n      --log_file string            optional log file - if not specified logs go to STDOUT\n      --log_level string           set the log level: debug, info, error, fatal or none (default \"info\")\n  -n, --name string                unique node name\n      --pid_file string            optional path to create PID file\n  -p, --port string                port to bind HTTP server to (default \"8000\")\n      --prometheus                 enable Prometheus metrics endpoint\n      --redis_db string            Redis database (Redis engine) (default \"0\")\n      --redis_host string          Redis host (Redis engine) (default \"127.0.0.1\")\n      --redis_master_name string   name of Redis master Sentinel monitors (Redis engine)\n      --redis_password string      Redis auth password (Redis engine)\n      --redis_port string          Redis port (Redis engine) (default \"6379\")\n      --redis_sentinels string     comma-separated list of Sentinel addresses (Redis engine)\n      --redis_url string           Redis connection URL in format redis://:password@hostname:port/db (Redis engine)\n      --tls                        enable TLS, requires an X509 certificate and a key file\n      --tls_cert string            path to an X509 certificate file\n      --tls_key string             path to an X509 certificate key\n\nUse \" [command] --help\" for more information about a command.",
            "title": "Configuration"
        },
        {
            "location": "/server/configuration/#version",
            "text": "To show version and exit run:  centrifugo version",
            "title": "version"
        },
        {
            "location": "/server/configuration/#json-file",
            "text": "Centrifugo requires configuration file on start. As was mentioned earlier it must be a file with valid JSON.  This is a minimal Centrifugo configuration file:  { \n   \"secret\" :   \"secret\"  }   The only field that is required is  secret . Secret used to create HMAC signs. Keep it strong and in secret!",
            "title": "JSON file"
        },
        {
            "location": "/server/configuration/#toml-file",
            "text": "Centrifugo also supports TOML format for configuration file:  centrifugo --config=config.toml  Where  config.toml  contains:  secret = \"secret\"\nlog_level = \"debug\"  I.e. the same configuration as JSON file above. We will talk about what is  namespaces  field soon.",
            "title": "TOML file"
        },
        {
            "location": "/server/configuration/#yaml-file",
            "text": "And YAML config also supported.  config.yaml :  secret :   secret  log_level :   debug   With YAML remember to use spaces, not tabs when writing configuration file.",
            "title": "YAML file"
        },
        {
            "location": "/server/configuration/#checkconfig-command",
            "text": "Centrifugo has special command to check configuration file  checkconfig :  centrifugo checkconfig --config = config.json  If any errors found during validation \u2013 program will exit with error message and exit code 1.",
            "title": "checkconfig command"
        },
        {
            "location": "/server/configuration/#genconfig-command",
            "text": "Another command is  genconfig :  centrifugo genconfig -c config.json  It will generate the minimal required configuration file automatically.",
            "title": "genconfig command"
        },
        {
            "location": "/server/configuration/#important-options",
            "text": "Some of the most important options you can configure when running Centrifugo:   address  \u2013 bind your Centrifugo to specific interface address (by default  \"\" )  port  \u2013 port to bind Centrifugo to (by default  8000 )  engine  \u2013 engine to use -  memory  or  redis  (by default  memory ). Read more about engines in  special chapter .   Note that some options can be set via command-line. Command-line options are more valuable when set than configuration file's options. See description of  viper  \u2013 to see more details about configuration options priority.",
            "title": "Important options"
        },
        {
            "location": "/server/configuration/#channel-options",
            "text": "Let's look on options related to channels. Channel is an entity to which clients can subscribe to receive messages published into that channel. Channel is just a string (several symbols has special meaning in Centrifugo - see  special chapter  to find more information about channels). The following options will affect channel behaviour:    publish  \u2013 allow clients to publish messages into channels directly (from client side). Your application will never receive those messages. In idiomatic case all messages must be published to Centrifugo by your application backend using Centrifugo API. But this option can be useful when you want to build something without backend-side validation and saving into database. This option can also be useful for demos and prototyping real-time ideas. Note that client can only publish data into channel after successfully subscribed on it. By default it's  false .    subscribe_to_publish  - when  publish  option enabled client can publish into channel without beong subscribed to it. This option enables automatic check that client subscribed on channel before allowing client to publish into channel.    anonymous  \u2013 this option enables anonymous access (with empty  user  ID in connection token). In most situations your application works with authorized users so every user has its own unique id. But if you provide real-time features for public access you may need unauthorized access to some channels. Turn on this option and use empty string as user ID. By default  false .    presence  \u2013 enable/disable presence information. Presence is a structure with clients currently subscribed on channel. By default  false  \u2013 i.e. no presence information will be available for channels.    join_leave  \u2013 enable/disable sending join(leave) messages when client subscribes on channel (unsubscribes from channel). By default  false .    history_size  \u2013 history size (amount of messages) for channels. As Centrifugo keeps all history messages in memory it's very important to limit maximum amount of messages in channel history to reasonable minimum. By default history size is  0  - this means that channels will have no history messages at all. As soon as history enabled then  history_size  defines maximum amount of messages that Centrifugo will keep for  each  channel in namespace during history lifetime (see below).    history_lifetime  \u2013 interval in seconds how long to keep channel history messages. As all history is storing in memory it is also very important to get rid of old history data for unused (inactive for a long time) channels. By default history lifetime is  0  \u2013 this means that channels will have no history messages at all.  So to get history messages you should wisely configure both  history_size  and  history_lifetime  options .    history_recover  ( new in v1.2.0 ) \u2013 boolean option, when enabled Centrifugo will try to recover missed messages published while client was disconnected for some reason (bad internet connection for example). By default  false . This option must be used in conjunction with reasonably configured message history for channel i.e.  history_size  and  history_lifetime   must be set  (because Centrifugo uses channel message history to recover messages). Also note that note all real-time events require this feature turned on so think wisely when you need this. See more details about how this option works in  special chapter .    history_drop_inactive  ( new in v1.3.0 ) \u2013 boolean option, allows to drastically reduce resource usage (engine memory usage, messages travelling around) when you use message history for channels. In couple of words when enabled Centrifugo will drop history messages that no one needs. Please, see  issue on Github  to get more information about option use case scenario and edge cases it involves.    Let's look how to set some of these options in config:  { \n     \"secret\" :   \"my-secret-key\" , \n     \"anonymous\" :   true , \n     \"publish\" :   true , \n     \"subscribe_to_publish\" :   true , \n     \"presence\" :   true , \n     \"join_leave\" :   true , \n     \"history_size\" :   10 , \n     \"history_lifetime\" :   30 , \n     \"history_recover\" :   true  }   And the last channel specific option is  namespaces .  namespaces  are optional and if set must be an array of namespace objects. Namespace allows to configure custom options for channels starting with namespace name. This provides a great control over channel behaviour.  Namespace has a name and the same channel options (with same defaults) as described above.   name  - unique namespace name (name must must consist of letters, numbers, underscores or hyphens and be more than 2 symbols length i.e. satisfy regexp  ^[-a-zA-Z0-9_]{2,}$ ).   If you want to use namespace options for channel - you must include namespace name into\nchannel name with  :  as separator:  public : messages  gossips : messages  Where  public  and  gossips  are namespace names from project  namespaces .  All things together here is an example of  config.json  which includes registered project with all options set and 2 additional namespaces in it:  { \n     \"secret\" :   \"very-long-secret-key\" , \n     \"anonymous\" :   true , \n     \"publish\" :   true , \n     \"presence\" :   true , \n     \"join_leave\" :   true , \n     \"history_size\" :   10 , \n     \"history_lifetime\" :   30 , \n     \"namespaces\" :   [ \n         { \n           \"name\" :   \"public\" , \n           \"publish\" :   true , \n           \"anonymous\" :   true , \n           \"history_size\" :   10 , \n           \"history_lifetime\" :   30 , \n           \"history_recover\" :   true \n         }, \n         { \n           \"name\" :   \"gossips\" , \n           \"presence\" :   true , \n           \"join_leave\" :   true \n         } \n     ]  }   Channel  news  will use global project options.  Channel  public : news  will use  public  namespace's options.  Channel  gossips : news  will use  gossips  namespace's options.",
            "title": "Channel options"
        },
        {
            "location": "/server/configuration/#advanced-configuration",
            "text": "Centrifugo has some options for which default values make sense for most applications. In many case you\ndon't need (and you really should not) change them. This chapter is about such options.",
            "title": "Advanced configuration"
        },
        {
            "location": "/server/configuration/#client_channel_limit",
            "text": "Default: 128  Sets maximum number of different channel subscriptions single client can have.",
            "title": "client_channel_limit"
        },
        {
            "location": "/server/configuration/#channel_max_length",
            "text": "Default: 255  Sets maximum length of channel name.",
            "title": "channel_max_length"
        },
        {
            "location": "/server/configuration/#channel_user_connection_limit",
            "text": "Default: 0  Maximum number of connections from user (with known user ID) to Centrifugo node. By default - unlimited.",
            "title": "channel_user_connection_limit"
        },
        {
            "location": "/server/configuration/#client_request_max_size",
            "text": "Default: 65536  Maximum allowed size of request from client in bytes.",
            "title": "client_request_max_size"
        },
        {
            "location": "/server/configuration/#client_queue_max_size",
            "text": "Default: 10485760  Maximum client message queue size in bytes to close slow reader connections. By default - 10mb.",
            "title": "client_queue_max_size"
        },
        {
            "location": "/server/configuration/#sockjs_heartbeat_delay",
            "text": "Default: 25  Interval in seconds how often to send SockJS h-frames to client.",
            "title": "sockjs_heartbeat_delay"
        },
        {
            "location": "/server/configuration/#websocket_compression",
            "text": "Default: false  Enable websocket compression, see special chapter in docs.",
            "title": "websocket_compression"
        },
        {
            "location": "/server/configuration/#gomaxprocs",
            "text": "Default: 0  By default Centrifugo runs on all available CPU cores. If you want to limit amount of cores Centrifugo can utilize in one moment use this option.",
            "title": "gomaxprocs"
        },
        {
            "location": "/server/configuration/#advanced-endpoint-configuration",
            "text": "After you started Centrifugo you have several endpoints available. As soon as you have not provided any extra options you have 3 endpoints by default.",
            "title": "Advanced endpoint configuration."
        },
        {
            "location": "/server/configuration/#default-endpoints",
            "text": "First is SockJS endpoint - it's needed to serve client connections that use SockJS library:  http://localhost:8000/connection/sockjs  Next is raw Websocket endpoint to serve client connections that use pure Websocket protocol:  ws://localhost:8000/connection/websocket  And finally you have API endpoint to  publish  messages to channels (and execute other available API commands):  http://localhost:8000/api  By default all endpoints work on port  8000 . You can change it using  port  option:  {\n    \"port\": 9000\n}  In production setup you will have your domain name in endpoint addresses above instead of  localhost . Also if your Centrifugo will be behind proxy or load balancer software you most probably won't have ports in your endpoint addresses. What will always be the same as shown above are URL paths:  /connection/sockjs ,  /connection/websocket ,  /api .  Let's look at possibilities to tweak available endpoints.",
            "title": "Default endpoints."
        },
        {
            "location": "/server/configuration/#admin-endpoints",
            "text": "First is enabling admin endpoints:  {\n    ...\n    \"admin\": true,\n    \"admin_password\": \"password\",\n    \"admin_secret\": \"secret\"\n}  This makes the following endpoint available: http://localhost:8000  At this address you will see admin web interface. You can log into it using  admin_password  value shown above.",
            "title": "Admin endpoints."
        },
        {
            "location": "/server/configuration/#debug-endpoints",
            "text": "Next, when Centrifugo started in debug mode some extra debug endpoints become available. To start in debug mode add  debug  option to config:  {\n    ...\n    \"debug\": true\n}  And endpoint:  http://localhost:8000/debug/pprof/  \u2013 will show you useful info about internal state of Centrifugo instance. This info is especially helpful when troubleshooting. See  wiki page  for more info.",
            "title": "Debug endpoints."
        },
        {
            "location": "/server/configuration/#custom-admin-and-api-ports",
            "text": "We strongly recommend to not expose admin, debug and API endpoints to Internet. In case of admin endpoint this step provides extra protection to  / ,  /admin/auth ,  /admin/api  endpoints, debug endpoints. Protecting API endpoint will allow you to use  api_insecure  mode to omit passing API key in each request.  So it's a good practice to protect admin and API endpoints with firewall. For example you can do this in  location  section of Nginx configuration.  Though sometimes you don't have access to per-location configuration in your proxy/load balancer software. For example\nwhen using Amazon ELB. In this case you can change ports on which your admin and API endpoints work.  To run admin endpoints on custom port use  admin_port  option:  {\n    ...\n    \"admin_port\": 10000\n}  So admin web interface will work on address:  ws://localhost:10000  Also debug page will be available on new custom admin port too:  http://localhost:10000/debug/pprof/  To run API server on it's own port use  api_port  option:  {\n    ...\n    \"api_port\": 10001\n}  Now you should send API requests to:  http://localhost:10001/api",
            "title": "Custom admin and API ports"
        },
        {
            "location": "/server/channels/",
            "text": "Channels\n\u00b6\n\n\nChannel is a route for publication messages. Clients can subscribe to channel to receive events related to this channel \u2013 new publications, join/leave events etc. Also client must be subscribed on channel to get channel presence or history information.\n\n\nChannel is just a string - \nnews\n, \ncomments\n are valid channel names.\n\n\nOnly ASCII symbols must be used in channel string.\n\n\nBUT!\n You should know several things.\n\n\nFirst, channel name length is limited by \n255\n characters by default (can be changed via configuration file option \nchannel_max_length\n)\n\n\nSecond, \n:\n, \n#\n and \n$\n symbols have a special role in channel name.\n\n\nnamespace channel boundary (:)\n\u00b6\n\n\n:\n - is a channel namespace boundary.\n\n\nIf channel is \npublic\n:\nchat\n - then Centrifugo will apply options to this channel from channel namespace with name \npublic\n.\n\n\nuser channel boundary (#)\n\u00b6\n\n\n#\n is a user boundary - separator to create private channels for users (user limited channels) without sending POST request to your web application. For example if channel is \nnews#42\n then only user with ID \n42\n can subscribe on this channel (Centrifugo knows user ID as clients provide it in connection credentials).\n\n\nMoreover you can provide several user IDs in channel name separated by comma: \ndialog#42,43\n \u2013 in this case only user with ID \n42\n and user with ID \n43\n will be able to subscribe on this channel.\n\n\nThis is useful for channels with static allowed users, for example for user personal messages channel, for dialog channel between certainly defined users. As soon as you need dynamic user access to channel this channel type does not suit well.\n\n\nprivate channel prefix ($)\n\u00b6\n\n\nIf channel starts with \n$\n then it considered private. Subscription on private channel must be properly signed by your web application. Read special chapter in docs about private channel subscriptions.",
            "title": "Channels"
        },
        {
            "location": "/server/channels/#channels",
            "text": "Channel is a route for publication messages. Clients can subscribe to channel to receive events related to this channel \u2013 new publications, join/leave events etc. Also client must be subscribed on channel to get channel presence or history information.  Channel is just a string -  news ,  comments  are valid channel names.  Only ASCII symbols must be used in channel string.  BUT!  You should know several things.  First, channel name length is limited by  255  characters by default (can be changed via configuration file option  channel_max_length )  Second,  : ,  #  and  $  symbols have a special role in channel name.",
            "title": "Channels"
        },
        {
            "location": "/server/channels/#namespace-channel-boundary",
            "text": ":  - is a channel namespace boundary.  If channel is  public : chat  - then Centrifugo will apply options to this channel from channel namespace with name  public .",
            "title": "namespace channel boundary (:)"
        },
        {
            "location": "/server/channels/#user-channel-boundary",
            "text": "#  is a user boundary - separator to create private channels for users (user limited channels) without sending POST request to your web application. For example if channel is  news#42  then only user with ID  42  can subscribe on this channel (Centrifugo knows user ID as clients provide it in connection credentials).  Moreover you can provide several user IDs in channel name separated by comma:  dialog#42,43  \u2013 in this case only user with ID  42  and user with ID  43  will be able to subscribe on this channel.  This is useful for channels with static allowed users, for example for user personal messages channel, for dialog channel between certainly defined users. As soon as you need dynamic user access to channel this channel type does not suit well.",
            "title": "user channel boundary (#)"
        },
        {
            "location": "/server/channels/#private-channel-prefix",
            "text": "If channel starts with  $  then it considered private. Subscription on private channel must be properly signed by your web application. Read special chapter in docs about private channel subscriptions.",
            "title": "private channel prefix ($)"
        },
        {
            "location": "/server/authentication/",
            "text": "Authentication\n\u00b6\n\n\nWhen you are using \ncentrifuge\n library from Go language you can implement any user authentication using middleware. In Centrifugo case you need to tell server who is connecting in well-known predefined way. This chapter will describe this mechanism.\n\n\nWhen connecting to Centrifugo client must provide connection JWT token with several predefined credential claims. If you've never heard about JWT before - refer to \njwt.io\n page.\n\n\nAt moment \nthe only supported JWT algorithm is HS256\n - i.e. HMAC SHA-256. This can be extended later.\n\n\nWe will use Javascript Centrifugo client here for example snippets for client side and \nPyJWT\n Python library to generate connection token on backend side.\n\n\nClaims\n\u00b6\n\n\nCredential claims are: \nuser\n, \nexp\n, \ninfo\n and \nb64info\n. What do they mean? Let's describe in detail.\n\n\nuser\n\u00b6\n\n\nThis is simple - it's an ID of current application user (\nas string\n). \n\n\nIf your user not currently authenticated in your application but you want to let him connect to Centrifugo anyway you can use empty string as user ID. This is called anonymous access. In this case \nanonymous\n option must be enabled in Centrifugo configuration for channels that client will subscribe to.\n\n\nexp\n\u00b6\n\n\nThis is an a UNIX timestamp seconds when token will expire. This is standard JWT claim - all JWT libraries for different languages provide an API to set it.\n\n\nIf \nexp\n claim not provided then Centrifugo won't expire any connections. When provided special algorithm will find connections with \nexp\n in the past and activate connection refresh mechanism. Refresh mechanism allows connection to survive and be prolonged. In case of refresh failure client connection will be eventually closed by Centrifugo and won't be accepted until new valid and actual credentials provided in connection token.\n\n\nYou can use connection expiration mechanism in cases when you don't want users of your app be subscribed on channels after being banned/deactivated in application. Or to protect your users from token leak (providing reasonably small time of expiration).\n\n\nChoose \nexp\n value wisely, you don't need to small values because refresh mechanism will hit your application often with refresh requests. But setting this value too large can lead to non very fast user connection deactivation. This is a trade off.\n\n\nRead more about connection expiration in special chapter.\n\n\ninfo\n\u00b6\n\n\nThis claim is optional - this is additional information about client connection that can be provided for Centrifugo. This information will be included in presence information, join/leave events and in channel publication message if it was published from client side.\n\n\nb64info\n\u00b6\n\n\nIf you are using binary protobuf protocol you may want info to be custom bytes. Use this field in this case.\n\n\nThis field contains a \nbase64\n representation of your bytes. After receiving Centrifugo will decode base64 back to bytes and will embed result into various places described above.\n\n\nExamples\n\u00b6\n\n\nLet's look how to generate connection JWT in Python:\n\n\nSimplest token\n\u00b6\n\n\nimport\n \njwt\n\n\n\ntoken\n \n=\n \njwt\n.\nencode\n({\n\"user\"\n:\n \n\"42\"\n},\n \n\"secret\"\n)\n.\ndecode\n()\n\n\n\nprint\n(\ntoken\n)\n\n\n\n\n\nNote that we use the value of \nsecret\n from Centrifugo config here (in this case \nsecret\n value is just \nsecret\n). The only two who must know secret key is your application backend which generates JWT and Centrifugo itself. You should never show secret key to your users. \n\n\nThen you can pass this token to your client side and use it when connecting to Centrifugo:\n\n\nvar\n \ncentrifuge\n \n=\n \nnew\n \nCentrifuge\n(\n\"ws://localhost:8000/connection/websocket\"\n);\n\n\ncentrifuge\n.\nsetToken\n(\ntoken\n);\n\n\ncentrifuge\n.\nconnect\n();\n\n\n\n\n\nToken with expiration\n\u00b6\n\n\nToken that will be valid for 5 minutes:\n\n\nimport\n \njwt\n\n\nimport\n \ntime\n\n\n\ntoken\n \n=\n \njwt\n.\nencode\n({\n\"user\"\n:\n \n\"42\"\n,\n \n\"exp\"\n:\n \nint\n(\ntime\n.\ntime\n())\n \n+\n \n5\n*\n60\n},\n \n\"secret\"\n,\n \nalgorithm\n=\n\"HS256\"\n)\n.\ndecode\n()\n\n\n\nprint\n(\ntoken\n)\n\n\n\n\n\nToken with additional connection info\n\u00b6\n\n\nimport\n \njwt\n\n\n\ntoken\n \n=\n \njwt\n.\nencode\n({\n\"user\"\n:\n \n\"42\"\n,\n \n\"info\"\n:\n \n{\n\"name\"\n:\n \n\"Alexander Emelin\"\n}},\n \n\"secret\"\n,\n \nalgorithm\n=\n\"HS256\"\n)\n.\ndecode\n()\n\n\n\nprint\n(\ntoken\n)",
            "title": "Authentication"
        },
        {
            "location": "/server/authentication/#authentication",
            "text": "When you are using  centrifuge  library from Go language you can implement any user authentication using middleware. In Centrifugo case you need to tell server who is connecting in well-known predefined way. This chapter will describe this mechanism.  When connecting to Centrifugo client must provide connection JWT token with several predefined credential claims. If you've never heard about JWT before - refer to  jwt.io  page.  At moment  the only supported JWT algorithm is HS256  - i.e. HMAC SHA-256. This can be extended later.  We will use Javascript Centrifugo client here for example snippets for client side and  PyJWT  Python library to generate connection token on backend side.",
            "title": "Authentication"
        },
        {
            "location": "/server/authentication/#claims",
            "text": "Credential claims are:  user ,  exp ,  info  and  b64info . What do they mean? Let's describe in detail.",
            "title": "Claims"
        },
        {
            "location": "/server/authentication/#user",
            "text": "This is simple - it's an ID of current application user ( as string ).   If your user not currently authenticated in your application but you want to let him connect to Centrifugo anyway you can use empty string as user ID. This is called anonymous access. In this case  anonymous  option must be enabled in Centrifugo configuration for channels that client will subscribe to.",
            "title": "user"
        },
        {
            "location": "/server/authentication/#exp",
            "text": "This is an a UNIX timestamp seconds when token will expire. This is standard JWT claim - all JWT libraries for different languages provide an API to set it.  If  exp  claim not provided then Centrifugo won't expire any connections. When provided special algorithm will find connections with  exp  in the past and activate connection refresh mechanism. Refresh mechanism allows connection to survive and be prolonged. In case of refresh failure client connection will be eventually closed by Centrifugo and won't be accepted until new valid and actual credentials provided in connection token.  You can use connection expiration mechanism in cases when you don't want users of your app be subscribed on channels after being banned/deactivated in application. Or to protect your users from token leak (providing reasonably small time of expiration).  Choose  exp  value wisely, you don't need to small values because refresh mechanism will hit your application often with refresh requests. But setting this value too large can lead to non very fast user connection deactivation. This is a trade off.  Read more about connection expiration in special chapter.",
            "title": "exp"
        },
        {
            "location": "/server/authentication/#info",
            "text": "This claim is optional - this is additional information about client connection that can be provided for Centrifugo. This information will be included in presence information, join/leave events and in channel publication message if it was published from client side.",
            "title": "info"
        },
        {
            "location": "/server/authentication/#b64info",
            "text": "If you are using binary protobuf protocol you may want info to be custom bytes. Use this field in this case.  This field contains a  base64  representation of your bytes. After receiving Centrifugo will decode base64 back to bytes and will embed result into various places described above.",
            "title": "b64info"
        },
        {
            "location": "/server/authentication/#examples",
            "text": "Let's look how to generate connection JWT in Python:",
            "title": "Examples"
        },
        {
            "location": "/server/authentication/#simplest-token",
            "text": "import   jwt  token   =   jwt . encode ({ \"user\" :   \"42\" },   \"secret\" ) . decode ()  print ( token )   Note that we use the value of  secret  from Centrifugo config here (in this case  secret  value is just  secret ). The only two who must know secret key is your application backend which generates JWT and Centrifugo itself. You should never show secret key to your users.   Then you can pass this token to your client side and use it when connecting to Centrifugo:  var   centrifuge   =   new   Centrifuge ( \"ws://localhost:8000/connection/websocket\" );  centrifuge . setToken ( token );  centrifuge . connect ();",
            "title": "Simplest token"
        },
        {
            "location": "/server/authentication/#token-with-expiration",
            "text": "Token that will be valid for 5 minutes:  import   jwt  import   time  token   =   jwt . encode ({ \"user\" :   \"42\" ,   \"exp\" :   int ( time . time ())   +   5 * 60 },   \"secret\" ,   algorithm = \"HS256\" ) . decode ()  print ( token )",
            "title": "Token with expiration"
        },
        {
            "location": "/server/authentication/#token-with-additional-connection-info",
            "text": "import   jwt  token   =   jwt . encode ({ \"user\" :   \"42\" ,   \"info\" :   { \"name\" :   \"Alexander Emelin\" }},   \"secret\" ,   algorithm = \"HS256\" ) . decode ()  print ( token )",
            "title": "Token with additional connection info"
        },
        {
            "location": "/server/engines/",
            "text": "Engines\n\u00b6\n\n\n\n\nMemory engine\n\n\nRedis engine\n\n\n\n\nEngine in Centrifugo is responsible for publishing messages between nodes, handle PUB/SUB broker subscriptions, save/retrieve presence and history data.\n\n\nBy default Centrifugo uses Memory engine. There is also Redis engine available.\n\n\nThe difference between them - with Memory engine you can start only one node of Centrifugo, while Redis engine allows to run several nodes on different machines and they will be connected via Redis, will know about each other due to Redis and will also keep history and presence data in Redis instead of Centrifugo node process memory so this data can be accessed from each node.\n\n\nTo set engine you can use \nengine\n configuration option. Available values are \nmemory\n and \nredis\n. Default value is \nmemory\n.\n\n\nFor example to work with Redis engine:\n\n\ncentrifugo --config=config.json --engine=redis\n\n\n\n\nOr just set \nengine\n in config:\n\n\n{\n\n    \n...\n\n    \n\"engine\"\n:\n \n\"redis\"\n\n\n}\n\n\n\n\n\nMemory engine\n\u00b6\n\n\nSupports only one node. Nice choice to start with. Supports all features keeping everything in Centrifugo node process memory. You don't need to install Redis when using this engine.\n\n\nAdvantages:\n\n\n\n\nfast\n\n\ndoes not require separate Redis setup\n\n\n\n\nDisadvantages:\n\n\n\n\ndoes not allow to scale nodes (actually you still can scale Centrifugo with Memory engine but you have to publish data into each Centrifugo node and you won't have consistent state of presence)\n\n\n\n\nRedis engine\n\u00b6\n\n\nAllows scaling Centrifugo nodes to different machines. Nodes will use Redis as message broker. Redis engine keeps presence and history data in Redis, uses Redis PUB/SUB for internal nodes communication.\n\n\nSeveral configuration options related to Redis engine:\n\n\n\n\nredis_host\n (string, default \n\"127.0.0.1\"\n) - Redis server host\n\n\nredis_port\n (int, default \n6379\n) - Redis server port\n\n\nredis_url\n (string, default \n\"\"\n) - optional Redis connection URL\n\n\nredis_password\n (string, default \n\"\"\n) - Redis password\n\n\nredis_db\n (int, default \n0\n) - number of Redis db to use\n\n\nredis_sentinels\n (string, default \n\"\"\n) - comma separated list of Sentinels for HA\n\n\nredis_master_name\n (string, default \n\"\"\n) - name of Redis master Sentinel monitors\n\n\n\n\nMost of these options has clear meaning.\n\n\nredis_url\n allows to set Redis connection parameters in a form of URL in format \nredis://:password@hostname:port/db_number\n.\n\n\nWhen \nredis_url\n set Centrifugo will use URL instead of values provided in \nredis_host\n,\n\nredis_port\n, \nredis_password\n, \nredis_db\n options.\n\n\nScaling with Redis tutorial\n\u00b6\n\n\nLet's see how to start several Centrifugo nodes using Redis engine. We will start 3 Centrifugo nodes and all those nodes will be connected via Redis.\n\n\nFirst, you should have Redis running. As soon as it's running - we can launch 3 Centrifugo instances. Open your terminal and start first one:\n\n\ncentrifugo --config=config.json --port=8000 --engine=redis --redis_host=127.0.0.1 --redis_port=6379\n\n\n\n\nIf your Redis on the same machine and runs on its default port you can omit \nredis_host\n and \nredis_port\n options in command above.\n\n\nThen open another terminal and start another Centrifugo instance:\n\n\ncentrifugo --config=config.json --port=8001 --engine=redis --redis_host=127.0.0.1 --redis_port=6379\n\n\n\n\nNote that we use another port number (\n8001\n) as port 8000 already busy by our first Centrifugo instance. If you are starting Centrifugo instances on different machines then you most probably can use\nthe same port number (\n8000\n or whatever you want) for all instances.\n\n\nAnd finally let's start third instance:\n\n\ncentrifugo --config=config.json --port=8002 --engine=redis --redis_host=127.0.0.1 --redis_port=6379\n\n\n\n\nNow you have 3 Centrifugo instances running on ports 8000, 8001, 8002 and clients can connect to any of them. You can also send API requests to any of those nodes \u2013 as all nodes connected over Redis PUB/SUB message will be delivered to all interested clients on all nodes.\n\n\nTo load balance clients between nodes you can use Nginx \u2013 you can find its configuration here in documentation.\n\n\nRedis sharding\n\u00b6\n\n\nCentrifugo has a built-in Redis sharding support.\n\n\nThis resolves situation when Redis becoming a bottleneck on large Centrifugo setup. Redis is single-threaded server, it's very fast but it's power is not infinite so when your Redis approaches 100% CPU usage then sharding feature can help your application to scale.\n\n\nAt moment Centrifugo supports simple comma-based approach to configuring Redis shards. Let's just look on examples.\n\n\nTo start Centrifugo with 2 Redis shards on localhost running on port 6379 and port 6380:\n\n\ncentrifugo --config=config.json --engine=redis --redis_port=6379,6380\n\n\n\n\nTo start Centrifugo with Redis instances on different hosts:\n\n\ncentrifugo --config=config.json --engine=redis --redis_host=192.168.1.34,192.168.1.35\n\n\n\n\nIf you also need to customize AUTH password, Redis DB number then you can use \nredis_url\n option.\n\n\nNote, that due to how Redis PUB/SUB work it's not possible (and it's pretty useless anyway) to run shards in one Redis instances using different Redis DB numbers.\n\n\nWhen sharding enabled Centrifugo will spread channels and history/presence keys over configured Redis instances using consistent hashing algorithm. At moment we use Jump consistent hash algorithm (see \npaper\n and \nimplementation\n)",
            "title": "Engines"
        },
        {
            "location": "/server/engines/#engines",
            "text": "Memory engine  Redis engine   Engine in Centrifugo is responsible for publishing messages between nodes, handle PUB/SUB broker subscriptions, save/retrieve presence and history data.  By default Centrifugo uses Memory engine. There is also Redis engine available.  The difference between them - with Memory engine you can start only one node of Centrifugo, while Redis engine allows to run several nodes on different machines and they will be connected via Redis, will know about each other due to Redis and will also keep history and presence data in Redis instead of Centrifugo node process memory so this data can be accessed from each node.  To set engine you can use  engine  configuration option. Available values are  memory  and  redis . Default value is  memory .  For example to work with Redis engine:  centrifugo --config=config.json --engine=redis  Or just set  engine  in config:  { \n     ... \n     \"engine\" :   \"redis\"  }",
            "title": "Engines"
        },
        {
            "location": "/server/engines/#memory-engine",
            "text": "Supports only one node. Nice choice to start with. Supports all features keeping everything in Centrifugo node process memory. You don't need to install Redis when using this engine.  Advantages:   fast  does not require separate Redis setup   Disadvantages:   does not allow to scale nodes (actually you still can scale Centrifugo with Memory engine but you have to publish data into each Centrifugo node and you won't have consistent state of presence)",
            "title": "Memory engine"
        },
        {
            "location": "/server/engines/#redis-engine",
            "text": "Allows scaling Centrifugo nodes to different machines. Nodes will use Redis as message broker. Redis engine keeps presence and history data in Redis, uses Redis PUB/SUB for internal nodes communication.  Several configuration options related to Redis engine:   redis_host  (string, default  \"127.0.0.1\" ) - Redis server host  redis_port  (int, default  6379 ) - Redis server port  redis_url  (string, default  \"\" ) - optional Redis connection URL  redis_password  (string, default  \"\" ) - Redis password  redis_db  (int, default  0 ) - number of Redis db to use  redis_sentinels  (string, default  \"\" ) - comma separated list of Sentinels for HA  redis_master_name  (string, default  \"\" ) - name of Redis master Sentinel monitors   Most of these options has clear meaning.  redis_url  allows to set Redis connection parameters in a form of URL in format  redis://:password@hostname:port/db_number .  When  redis_url  set Centrifugo will use URL instead of values provided in  redis_host , redis_port ,  redis_password ,  redis_db  options.",
            "title": "Redis engine"
        },
        {
            "location": "/server/engines/#scaling-with-redis-tutorial",
            "text": "Let's see how to start several Centrifugo nodes using Redis engine. We will start 3 Centrifugo nodes and all those nodes will be connected via Redis.  First, you should have Redis running. As soon as it's running - we can launch 3 Centrifugo instances. Open your terminal and start first one:  centrifugo --config=config.json --port=8000 --engine=redis --redis_host=127.0.0.1 --redis_port=6379  If your Redis on the same machine and runs on its default port you can omit  redis_host  and  redis_port  options in command above.  Then open another terminal and start another Centrifugo instance:  centrifugo --config=config.json --port=8001 --engine=redis --redis_host=127.0.0.1 --redis_port=6379  Note that we use another port number ( 8001 ) as port 8000 already busy by our first Centrifugo instance. If you are starting Centrifugo instances on different machines then you most probably can use\nthe same port number ( 8000  or whatever you want) for all instances.  And finally let's start third instance:  centrifugo --config=config.json --port=8002 --engine=redis --redis_host=127.0.0.1 --redis_port=6379  Now you have 3 Centrifugo instances running on ports 8000, 8001, 8002 and clients can connect to any of them. You can also send API requests to any of those nodes \u2013 as all nodes connected over Redis PUB/SUB message will be delivered to all interested clients on all nodes.  To load balance clients between nodes you can use Nginx \u2013 you can find its configuration here in documentation.",
            "title": "Scaling with Redis tutorial"
        },
        {
            "location": "/server/engines/#redis-sharding",
            "text": "Centrifugo has a built-in Redis sharding support.  This resolves situation when Redis becoming a bottleneck on large Centrifugo setup. Redis is single-threaded server, it's very fast but it's power is not infinite so when your Redis approaches 100% CPU usage then sharding feature can help your application to scale.  At moment Centrifugo supports simple comma-based approach to configuring Redis shards. Let's just look on examples.  To start Centrifugo with 2 Redis shards on localhost running on port 6379 and port 6380:  centrifugo --config=config.json --engine=redis --redis_port=6379,6380  To start Centrifugo with Redis instances on different hosts:  centrifugo --config=config.json --engine=redis --redis_host=192.168.1.34,192.168.1.35  If you also need to customize AUTH password, Redis DB number then you can use  redis_url  option.  Note, that due to how Redis PUB/SUB work it's not possible (and it's pretty useless anyway) to run shards in one Redis instances using different Redis DB numbers.  When sharding enabled Centrifugo will spread channels and history/presence keys over configured Redis instances using consistent hashing algorithm. At moment we use Jump consistent hash algorithm (see  paper  and  implementation )",
            "title": "Redis sharding"
        },
        {
            "location": "/server/admin/",
            "text": "Admin web interface\n\u00b6\n\n\nCentrifugo comes with builtin admin web interface.\n\n\nIt can:\n\n\n\n\nshow current server general information and statistics from server nodes.\n\n\ncall \npublish\n, \nbroadcast\n, \nunsubscribe\n, \ndisconnect\n, \nhistory\n, \npresence\n, \npresence_stats\n, \nchannels\n, \ninfo\n server API commands. \n\n\n\n\nFor \npublish\n command Ace JSON editor helps to write JSON to send into channel.\n\n\nTo enable admin interface you must run \ncentrifugo\n with \n--admin\n and provide some security options in configuration file.\n\n\ncentrifugo --config\n=\nconfig.json --admin\n\n\n\n\nAlso you must set two options in config: \nadmin_password\n and \nadmin_secret\n:\n\n\n{\n\n    \n...,\n\n    \n\"admin_password\"\n:\n \n\"<PASSWORD>\"\n,\n\n    \n\"admin_secret\"\n:\n \n\"<SECRET>\"\n\n\n}\n\n\n\n\n\n\n\nadmin_password\n \u2013 this is a password to log into admin web interface\n\n\nadmin_secret\n - this is a secret key for authentication token set on successful login.\n\n\n\n\nMake both strong and keep in secret.\n\n\nAfter setting this in config go to http://localhost:8000 (by default) - and you should see web interface. Although there is \npassword\n based authentication a good advice is to protect web interface by firewall rules in production.\n\n\nIf you don't want to use embedded web interface you can specify path to your own custom web interface directory:\n\n\n{\n\n    \n...,\n\n    \n\"admin_password\"\n:\n \n\"<PASSWORD>\"\n,\n\n    \n\"admin_secret\"\n:\n \n\"<SECRET>\"\n,\n\n    \n\"admin_web_path\"\n:\n \n\"<PATH>\"\n\n\n}\n\n\n\n\n\nThis can be useful if you want to modify official \nweb interface code\n in some way.\n\n\nThere is also an option to run Centrifugo in insecure admin mode - in this case you don't need to set \nadmin_password\n and \nadmin_secret\n in config \u2013 in web interface you will be logged in automatically without any password. Note that this is only an option for productionr if you protected admin web interface with firewall rules. Otherwide anyone in internet will have full access to admin functionality described above. To start Centrifugo with admin web interface in insecure admin mode run:\n\n\ncentrifugo --config=config.json --admin --admin_insecure",
            "title": "Admin web interface"
        },
        {
            "location": "/server/admin/#admin-web-interface",
            "text": "Centrifugo comes with builtin admin web interface.  It can:   show current server general information and statistics from server nodes.  call  publish ,  broadcast ,  unsubscribe ,  disconnect ,  history ,  presence ,  presence_stats ,  channels ,  info  server API commands.    For  publish  command Ace JSON editor helps to write JSON to send into channel.  To enable admin interface you must run  centrifugo  with  --admin  and provide some security options in configuration file.  centrifugo --config = config.json --admin  Also you must set two options in config:  admin_password  and  admin_secret :  { \n     ..., \n     \"admin_password\" :   \"<PASSWORD>\" , \n     \"admin_secret\" :   \"<SECRET>\"  }    admin_password  \u2013 this is a password to log into admin web interface  admin_secret  - this is a secret key for authentication token set on successful login.   Make both strong and keep in secret.  After setting this in config go to http://localhost:8000 (by default) - and you should see web interface. Although there is  password  based authentication a good advice is to protect web interface by firewall rules in production.  If you don't want to use embedded web interface you can specify path to your own custom web interface directory:  { \n     ..., \n     \"admin_password\" :   \"<PASSWORD>\" , \n     \"admin_secret\" :   \"<SECRET>\" , \n     \"admin_web_path\" :   \"<PATH>\"  }   This can be useful if you want to modify official  web interface code  in some way.  There is also an option to run Centrifugo in insecure admin mode - in this case you don't need to set  admin_password  and  admin_secret  in config \u2013 in web interface you will be logged in automatically without any password. Note that this is only an option for productionr if you protected admin web interface with firewall rules. Otherwide anyone in internet will have full access to admin functionality described above. To start Centrifugo with admin web interface in insecure admin mode run:  centrifugo --config=config.json --admin --admin_insecure",
            "title": "Admin web interface"
        },
        {
            "location": "/server/monitoring/",
            "text": "Monitoring\n\u00b6\n\n\nCentrifugo supports reporting metrics in Prometheus format and can automatically export metrics to Graphite.\n\n\nPrometheus\n\u00b6\n\n\nTo enable Prometheus endpoint start Centrifugo with \nprometheus\n option on:\n\n\n{\n\n    \n...\n\n    \n\"prometheus\"\n:\n \ntrue\n\n\n}\n\n\n\n\n\n./centrifugo --config=config.json\n\n\n\n\nThis will enable \n/metrics\n endpoint so Centrifugo instance can be monitored by your Prometheus server.\n\n\nGraphite\n\u00b6\n\n\nTo enable automatic export to Graphite (via TCP):\n\n\n{\n\n    \n\"graphite\"\n:\n \ntrue\n,\n\n    \n\"graphite_host\"\n:\n \n\"localhost\"\n,\n\n    \n\"graphite_port\"\n:\n \n2003\n\n\n}",
            "title": "Monitoring"
        },
        {
            "location": "/server/monitoring/#monitoring",
            "text": "Centrifugo supports reporting metrics in Prometheus format and can automatically export metrics to Graphite.",
            "title": "Monitoring"
        },
        {
            "location": "/server/monitoring/#prometheus",
            "text": "To enable Prometheus endpoint start Centrifugo with  prometheus  option on:  { \n     ... \n     \"prometheus\" :   true  }   ./centrifugo --config=config.json  This will enable  /metrics  endpoint so Centrifugo instance can be monitored by your Prometheus server.",
            "title": "Prometheus"
        },
        {
            "location": "/server/monitoring/#graphite",
            "text": "To enable automatic export to Graphite (via TCP):  { \n     \"graphite\" :   true , \n     \"graphite_host\" :   \"localhost\" , \n     \"graphite_port\" :   2003  }",
            "title": "Graphite"
        },
        {
            "location": "/server/api/",
            "text": "Server HTTP API\n\u00b6\n\n\nHTTP API is a way to send commands to Centrifugo.\n\n\nWhy we need API?\n\n\nIf you look at configuration options you see an option called \npublish\n defined on configuration top level and for channel namespace. When turned on this option allows browser clients to publish into channels directly. If client publishes a message into channel directly \u2013 your application will not receive that message (it just goes through Centrifugo towards subscribed clients). This pattern can be useful sometimes but in most cases you first need to send new event from client to backend over non-Centrifugo transport (for example via AJAX request in web application), then process it on application backend side \u2013 probably validate, save into main app database \u2013 and then \npublish\n into Centrifugo using HTTP API so Centrifugo broadcast message to all clients subscribed on channel.\n\n\nServer API works on \n/api\n endpoint. It's very simple to use: you just have to send POST request with JSON command to this endpoint.\n\n\nIn this chapter we will look at API protocol internals - for new API client library authors and just if you are curious how existing API clients work.\n\n\nAPI request is a POST HTTP request with \napplication/json\n Content-Type and JSON payload in request body.\n\n\nAPI protected by \napi_key\n secret key set in Centrifugo configuration. This API key must be set in request \nAuthorization\n header in this way:\n\n\nAuthorization\n:\n \napikey\n \n<\nKEY\n>\n\n\n\n\n\nIt's possible to disable API key check on Centrifugo side using \napi_insecure\n configuration option. Be sure to protect API endpoint by firewall rules in this case to prevent anyone in internet to send commands over your unprotected Centrifugo API. API key auth is not very safe for man-in-the-middle so recommended way is running Centrifugo with TLS (we are in 2018 in the end).\n\n\nCommand is a JSON object with two properties: \nmethod\n and \nparams\n.\n\n\nmethod\n is a name of command you want to call.\n\nparams\n is an object with command arguments.\n\n\nThere are several commands available. Let's investigate each of available server API commands.\n\n\npublish\n\u00b6\n\n\nPublish command allows to publish data into channel. It looks like this:\n\n\n{\n\n    \n\"method\"\n:\n \n\"publish\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"chat\"\n,\n \n        \n\"data\"\n:\n \n{\n\n            \n\"text\"\n:\n \n\"hello\"\n\n        \n}\n\n    \n}\n \n\n}\n\n\n\n\n\nLet's apply all information said above and send publish command to Centrifugo. We will send request using \nrequests\n library for Python. \n\n\nimport\n \njson\n\n\nimport\n \nrequests\n\n\n\ncommand\n \n=\n \n{\n\n    \n\"method\"\n:\n \n\"publish\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"docs\"\n,\n \n        \n\"data\"\n:\n \n{\n\n            \n\"content\"\n:\n \n\"1\"\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\napi_key\n \n=\n \n\"YOUR_API_KEY\"\n\n\ndata\n \n=\n \njson\n.\ndumps\n(\ncommands\n)\n\n\nheaders\n \n=\n \n{\n'Content-type'\n:\n \n'application/json'\n,\n \n'Authorization'\n:\n \n'apikey '\n \n+\n \napi_key\n}\n\n\nresp\n \n=\n \nrequests\n.\npost\n(\n\"https://centrifuge.example.com/api\"\n,\n \ndata\n=\nencoded_data\n,\n \nheaders\n=\nheaders\n)\n\n\nprint\n(\nresp\n.\njson\n())\n\n\n\n\n\nThe same using \nhttpie\n console tool:\n\n\n$ \necho\n \n'{\"method\": \"publish\", \"params\": {\"channel\": \"chat\", \"data\": {\"text\": \"hello\"}}}'\n \n|\n http \n\"localhost:8000/api\"\n Authorization:\n\"apikey KEY\"\n -vvv\nPOST /api HTTP/1.1\nAccept: application/json, */*\nAccept-Encoding: gzip, deflate\nAuthorization: apikey KEY\nConnection: keep-alive\nContent-Length: \n80\n\nContent-Type: application/json\nHost: localhost:8000\nUser-Agent: HTTPie/0.9.8\n\n\n{\n\n    \n\"method\"\n: \n\"publish\"\n,\n    \n\"params\"\n: \n{\n\n        \n\"channel\"\n: \n\"chat\"\n,\n        \n\"data\"\n: \n{\n\n            \n\"text\"\n: \n\"hello\"\n\n        \n}\n\n    \n}\n\n\n}\n\n\nHTTP/1.1 \n200\n OK\nContent-Length: \n3\n\nContent-Type: application/json\nDate: Thu, \n17\n May \n2018\n \n22\n:01:42 GMT\n\n\n{}\n\n\n\n\n\nIn case of error response object will contain \nerror\n field:\n\n\n$ \necho\n \n'{\"method\": \"publish\", \"params\": {\"channel\": \"unknown:chat\", \"data\": {\"text\": \"hello\"}}}'\n \n|\n http \n\"localhost:8000/api\"\n Authorization:\n\"apikey KEY\"\n\nHTTP/1.1 \n200\n OK\nContent-Length: \n55\n\nContent-Type: application/json\nDate: Thu, \n17\n May \n2018\n \n22\n:03:09 GMT\n\n\n{\n\n    \n\"error\"\n: \n{\n\n        \n\"code\"\n: \n102\n,\n        \n\"message\"\n: \n\"namespace not found\"\n\n    \n}\n\n\n}\n\n\n\n\n\nerror\n object contains error code and message - this also the same for other commands described below.\n\n\npublish\n command is the main command you need. Again - remember that we have client API libraries that can help you avoid some boilerplate we just wrote and help to properly handle error responses from Centrifugo.\n\n\nLet's look at other available commands:\n\n\nbroadcast\n\u00b6\n\n\nSimilar to \npublish\n but allows to send the same data into many channels.\n\n\n{\n\n    \n\"method\"\n:\n \n\"broadcast\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channels\"\n:\n \n[\n\"CHANNEL_1\"\n,\n \n\"CHANNEL_2\"\n],\n\n        \n\"data\"\n:\n \n{\n\n            \n\"text\"\n:\n \n\"hello\"\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\nunsubscribe\n\u00b6\n\n\nunsubscribe\n allows to unsubscribe user from channel. \nparams\n is an objects with two keys: \nchannel\n and \nuser\n (user ID you want to unsubscribe)\n\n\n{\n\n    \n\"method\"\n:\n \n\"unsubscribe\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"CHANNEL NAME\"\n,\n\n        \n\"user\"\n:\n \n\"USER ID\"\n\n    \n}\n\n\n}\n\n\n\n\n\ndisconnect\n\u00b6\n\n\ndisconnect\n allows to disconnect user by ID. \nparams\n in an object with \nuser\n key.\n\n\n{\n\n    \n\"method\"\n:\n \n\"disconnect\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"user\"\n:\n \n\"USER ID\"\n\n    \n}\n\n\n}\n\n\n\n\n\npresence\n\u00b6\n\n\npresence\n allows to get channel presence information (all clients currently subscribed on\nthis channel). \nparams\n is an object with \nchannel\n key.\n\n\n{\n\n    \n\"method\"\n:\n \n\"presence\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"chat\"\n\n    \n}\n\n\n}\n\n\n\n\n\nExample:\n\n\nfz@centrifugo: \necho\n \n'{\"method\": \"presence\", \"params\": {\"channel\": \"chat\"}}'\n \n|\n http \n\"localhost:8000/api\"\n Authorization:\n\"apikey KEY\"\n\nHTTP/1.1 \n200\n OK\nContent-Length: \n127\n\nContent-Type: application/json\nDate: Thu, \n17\n May \n2018\n \n22\n:13:17 GMT\n\n\n{\n\n    \n\"result\"\n: \n{\n\n        \n\"presence\"\n: \n{\n\n            \n\"c54313b2-0442-499a-a70c-051f8588020f\"\n: \n{\n\n                \n\"client\"\n: \n\"c54313b2-0442-499a-a70c-051f8588020f\"\n,\n                \n\"user\"\n: \n\"42\"\n\n            \n}\n,\n            \n\"adad13b1-0442-499a-a70c-051f858802da\"\n: \n{\n\n                \n\"client\"\n: \n\"adad13b1-0442-499a-a70c-051f858802da\"\n,\n                \n\"user\"\n: \n\"42\"\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\npresence_stats\n\u00b6\n\n\npresence_stats\n allows to get short channel presence information.\n\n\n{\n\n    \n\"method\"\n:\n \n\"presence_stats\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"chat\"\n\n    \n}\n\n\n}\n\n\n\n\n\nExample:\n\n\n$ \necho\n \n'{\"method\": \"presence_stats\", \"params\": {\"channel\": \"public:chat\"}}'\n \n|\n http \n\"localhost:8000/api\"\n Authorization:\n\"apikey KEY\"\n\nHTTP/1.1 \n200\n OK\nContent-Length: \n43\n\nContent-Type: application/json\nDate: Thu, \n17\n May \n2018\n \n22\n:09:44 GMT\n\n\n{\n\n    \n\"result\"\n: \n{\n\n        \n\"num_clients\"\n: \n0\n,\n        \n\"num_users\"\n: \n0\n\n    \n}\n\n\n}\n\n\n\n\n\nhistory\n\u00b6\n\n\nhistory\n allows to get channel history information (list of last messages published into channel).\n\n\nparams\n is an object with \nchannel\n key:\n\n\n{\n\n    \n\"method\"\n:\n \n\"history\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"chat\"\n\n    \n}\n\n\n}\n\n\n\n\n\nExample:\n\n\n$ \necho\n \n'{\"method\": \"history\", \"params\": {\"channel\": \"public:chat\"}}'\n \n|\n http \n\"localhost:8000/api\"\n Authorization:\n\"apikey KEY\"\n\nHTTP/1.1 \n200\n OK\nContent-Length: \n87\n\nContent-Type: application/json\nDate: Thu, \n17\n May \n2018\n \n22\n:14:10 GMT\n\n\n{\n\n    \n\"result\"\n: \n{\n\n        \n\"publications\"\n: \n[\n\n            \n{\n\n                \n\"data\"\n: \n{\n\n                    \n\"text\"\n: \n\"hello\"\n\n                \n}\n,\n                \n\"uid\"\n: \n\"BWcn14OTBrqUhTXyjNg0fg\"\n\n            \n}\n, \n{\n\n                \n\"data\"\n: \n{\n\n                    \n\"text\"\n: \n\"hi!\"\n\n                \n}\n,\n                \n\"uid\"\n: \n\"Ascn14OTBrq14OXyjNg0hg\"\n\n            \n}\n\n        \n]\n\n    \n}\n\n\n}\n\n\n\n\n\nchannels\n\u00b6\n\n\nchannels\n allows to get list of active (with one or more subscribers) channels.\n\n\n{\n\n    \n\"method\"\n:\n \n\"channels\"\n,\n\n    \n\"params\"\n:\n \n{}\n\n\n}\n\n\n\n\n\nExample:\n\n\n$ \necho\n \n'{\"method\": \"channels\", \"params\": {}}'\n \n|\n http \n\"localhost:8000/api\"\n Authorization:\n\"apikey KEY\"\n\nHTTP/1.1 \n200\n OK\nContent-Length: \n27\n\nContent-Type: application/json\nDate: Thu, \n17\n May \n2018\n \n22\n:08:31 GMT\n\n\n{\n\n    \n\"result\"\n: \n{\n\n        \n\"channels\"\n: \n[\n\n            \n\"chat\"\n\n        \n]\n\n    \n}\n\n\n}\n\n\n\n\n\ninfo\n\u00b6\n\n\ninfo\n method allows to get information about running Centrifugo nodes.\n\n\n{\n\n    \n\"method\"\n:\n \n\"info\"\n,\n\n    \n\"params\"\n:\n \n{}\n\n\n}\n\n\n\n\n\nExample:\n\n\n$ \necho\n \n'{\"method\": \"info\", \"params\": {}}'\n \n|\n http \n\"localhost:8000/api\"\n Authorization:\n\"apikey KEY\"\n\nHTTP/1.1 \n200\n OK\nContent-Length: \n184\n\nContent-Type: application/json\nDate: Thu, \n17\n May \n2018\n \n22\n:07:58 GMT\n\n\n{\n\n    \n\"result\"\n: \n{\n\n        \n\"nodes\"\n: \n[\n\n            \n{\n\n                \n\"name\"\n: \n\"Alexanders-MacBook-Pro.local_8000\"\n,\n                \n\"num_channels\"\n: \n0\n,\n                \n\"num_clients\"\n: \n0\n,\n                \n\"num_users\"\n: \n0\n,\n                \n\"uid\"\n: \n\"f844a2ed-5edf-4815-b83c-271974003db9\"\n,\n                \n\"uptime\"\n: \n0\n,\n                \n\"version\"\n: \n\"\"\n\n            \n}\n\n        \n]\n\n    \n}\n\n\n}",
            "title": "Server HTTP API"
        },
        {
            "location": "/server/api/#server-http-api",
            "text": "HTTP API is a way to send commands to Centrifugo.  Why we need API?  If you look at configuration options you see an option called  publish  defined on configuration top level and for channel namespace. When turned on this option allows browser clients to publish into channels directly. If client publishes a message into channel directly \u2013 your application will not receive that message (it just goes through Centrifugo towards subscribed clients). This pattern can be useful sometimes but in most cases you first need to send new event from client to backend over non-Centrifugo transport (for example via AJAX request in web application), then process it on application backend side \u2013 probably validate, save into main app database \u2013 and then  publish  into Centrifugo using HTTP API so Centrifugo broadcast message to all clients subscribed on channel.  Server API works on  /api  endpoint. It's very simple to use: you just have to send POST request with JSON command to this endpoint.  In this chapter we will look at API protocol internals - for new API client library authors and just if you are curious how existing API clients work.  API request is a POST HTTP request with  application/json  Content-Type and JSON payload in request body.  API protected by  api_key  secret key set in Centrifugo configuration. This API key must be set in request  Authorization  header in this way:  Authorization :   apikey   < KEY >   It's possible to disable API key check on Centrifugo side using  api_insecure  configuration option. Be sure to protect API endpoint by firewall rules in this case to prevent anyone in internet to send commands over your unprotected Centrifugo API. API key auth is not very safe for man-in-the-middle so recommended way is running Centrifugo with TLS (we are in 2018 in the end).  Command is a JSON object with two properties:  method  and  params .  method  is a name of command you want to call. params  is an object with command arguments.  There are several commands available. Let's investigate each of available server API commands.",
            "title": "Server HTTP API"
        },
        {
            "location": "/server/api/#publish",
            "text": "Publish command allows to publish data into channel. It looks like this:  { \n     \"method\" :   \"publish\" , \n     \"params\" :   { \n         \"channel\" :   \"chat\" ,  \n         \"data\" :   { \n             \"text\" :   \"hello\" \n         } \n     }   }   Let's apply all information said above and send publish command to Centrifugo. We will send request using  requests  library for Python.   import   json  import   requests  command   =   { \n     \"method\" :   \"publish\" , \n     \"params\" :   { \n         \"channel\" :   \"docs\" ,  \n         \"data\" :   { \n             \"content\" :   \"1\" \n         } \n     }  }  api_key   =   \"YOUR_API_KEY\"  data   =   json . dumps ( commands )  headers   =   { 'Content-type' :   'application/json' ,   'Authorization' :   'apikey '   +   api_key }  resp   =   requests . post ( \"https://centrifuge.example.com/api\" ,   data = encoded_data ,   headers = headers )  print ( resp . json ())   The same using  httpie  console tool:  $  echo   '{\"method\": \"publish\", \"params\": {\"channel\": \"chat\", \"data\": {\"text\": \"hello\"}}}'   |  http  \"localhost:8000/api\"  Authorization: \"apikey KEY\"  -vvv\nPOST /api HTTP/1.1\nAccept: application/json, */*\nAccept-Encoding: gzip, deflate\nAuthorization: apikey KEY\nConnection: keep-alive\nContent-Length:  80 \nContent-Type: application/json\nHost: localhost:8000\nUser-Agent: HTTPie/0.9.8 { \n     \"method\" :  \"publish\" ,\n     \"params\" :  { \n         \"channel\" :  \"chat\" ,\n         \"data\" :  { \n             \"text\" :  \"hello\" \n         } \n     }  } \n\nHTTP/1.1  200  OK\nContent-Length:  3 \nContent-Type: application/json\nDate: Thu,  17  May  2018   22 :01:42 GMT {}   In case of error response object will contain  error  field:  $  echo   '{\"method\": \"publish\", \"params\": {\"channel\": \"unknown:chat\", \"data\": {\"text\": \"hello\"}}}'   |  http  \"localhost:8000/api\"  Authorization: \"apikey KEY\" \nHTTP/1.1  200  OK\nContent-Length:  55 \nContent-Type: application/json\nDate: Thu,  17  May  2018   22 :03:09 GMT { \n     \"error\" :  { \n         \"code\" :  102 ,\n         \"message\" :  \"namespace not found\" \n     }  }   error  object contains error code and message - this also the same for other commands described below.  publish  command is the main command you need. Again - remember that we have client API libraries that can help you avoid some boilerplate we just wrote and help to properly handle error responses from Centrifugo.  Let's look at other available commands:",
            "title": "publish"
        },
        {
            "location": "/server/api/#broadcast",
            "text": "Similar to  publish  but allows to send the same data into many channels.  { \n     \"method\" :   \"broadcast\" , \n     \"params\" :   { \n         \"channels\" :   [ \"CHANNEL_1\" ,   \"CHANNEL_2\" ], \n         \"data\" :   { \n             \"text\" :   \"hello\" \n         } \n     }  }",
            "title": "broadcast"
        },
        {
            "location": "/server/api/#unsubscribe",
            "text": "unsubscribe  allows to unsubscribe user from channel.  params  is an objects with two keys:  channel  and  user  (user ID you want to unsubscribe)  { \n     \"method\" :   \"unsubscribe\" , \n     \"params\" :   { \n         \"channel\" :   \"CHANNEL NAME\" , \n         \"user\" :   \"USER ID\" \n     }  }",
            "title": "unsubscribe"
        },
        {
            "location": "/server/api/#disconnect",
            "text": "disconnect  allows to disconnect user by ID.  params  in an object with  user  key.  { \n     \"method\" :   \"disconnect\" , \n     \"params\" :   { \n         \"user\" :   \"USER ID\" \n     }  }",
            "title": "disconnect"
        },
        {
            "location": "/server/api/#presence",
            "text": "presence  allows to get channel presence information (all clients currently subscribed on\nthis channel).  params  is an object with  channel  key.  { \n     \"method\" :   \"presence\" , \n     \"params\" :   { \n         \"channel\" :   \"chat\" \n     }  }   Example:  fz@centrifugo:  echo   '{\"method\": \"presence\", \"params\": {\"channel\": \"chat\"}}'   |  http  \"localhost:8000/api\"  Authorization: \"apikey KEY\" \nHTTP/1.1  200  OK\nContent-Length:  127 \nContent-Type: application/json\nDate: Thu,  17  May  2018   22 :13:17 GMT { \n     \"result\" :  { \n         \"presence\" :  { \n             \"c54313b2-0442-499a-a70c-051f8588020f\" :  { \n                 \"client\" :  \"c54313b2-0442-499a-a70c-051f8588020f\" ,\n                 \"user\" :  \"42\" \n             } ,\n             \"adad13b1-0442-499a-a70c-051f858802da\" :  { \n                 \"client\" :  \"adad13b1-0442-499a-a70c-051f858802da\" ,\n                 \"user\" :  \"42\" \n             } \n         } \n     }  }",
            "title": "presence"
        },
        {
            "location": "/server/api/#presence_stats",
            "text": "presence_stats  allows to get short channel presence information.  { \n     \"method\" :   \"presence_stats\" , \n     \"params\" :   { \n         \"channel\" :   \"chat\" \n     }  }   Example:  $  echo   '{\"method\": \"presence_stats\", \"params\": {\"channel\": \"public:chat\"}}'   |  http  \"localhost:8000/api\"  Authorization: \"apikey KEY\" \nHTTP/1.1  200  OK\nContent-Length:  43 \nContent-Type: application/json\nDate: Thu,  17  May  2018   22 :09:44 GMT { \n     \"result\" :  { \n         \"num_clients\" :  0 ,\n         \"num_users\" :  0 \n     }  }",
            "title": "presence_stats"
        },
        {
            "location": "/server/api/#history",
            "text": "history  allows to get channel history information (list of last messages published into channel).  params  is an object with  channel  key:  { \n     \"method\" :   \"history\" , \n     \"params\" :   { \n         \"channel\" :   \"chat\" \n     }  }   Example:  $  echo   '{\"method\": \"history\", \"params\": {\"channel\": \"public:chat\"}}'   |  http  \"localhost:8000/api\"  Authorization: \"apikey KEY\" \nHTTP/1.1  200  OK\nContent-Length:  87 \nContent-Type: application/json\nDate: Thu,  17  May  2018   22 :14:10 GMT { \n     \"result\" :  { \n         \"publications\" :  [ \n             { \n                 \"data\" :  { \n                     \"text\" :  \"hello\" \n                 } ,\n                 \"uid\" :  \"BWcn14OTBrqUhTXyjNg0fg\" \n             } ,  { \n                 \"data\" :  { \n                     \"text\" :  \"hi!\" \n                 } ,\n                 \"uid\" :  \"Ascn14OTBrq14OXyjNg0hg\" \n             } \n         ] \n     }  }",
            "title": "history"
        },
        {
            "location": "/server/api/#channels",
            "text": "channels  allows to get list of active (with one or more subscribers) channels.  { \n     \"method\" :   \"channels\" , \n     \"params\" :   {}  }   Example:  $  echo   '{\"method\": \"channels\", \"params\": {}}'   |  http  \"localhost:8000/api\"  Authorization: \"apikey KEY\" \nHTTP/1.1  200  OK\nContent-Length:  27 \nContent-Type: application/json\nDate: Thu,  17  May  2018   22 :08:31 GMT { \n     \"result\" :  { \n         \"channels\" :  [ \n             \"chat\" \n         ] \n     }  }",
            "title": "channels"
        },
        {
            "location": "/server/api/#info",
            "text": "info  method allows to get information about running Centrifugo nodes.  { \n     \"method\" :   \"info\" , \n     \"params\" :   {}  }   Example:  $  echo   '{\"method\": \"info\", \"params\": {}}'   |  http  \"localhost:8000/api\"  Authorization: \"apikey KEY\" \nHTTP/1.1  200  OK\nContent-Length:  184 \nContent-Type: application/json\nDate: Thu,  17  May  2018   22 :07:58 GMT { \n     \"result\" :  { \n         \"nodes\" :  [ \n             { \n                 \"name\" :  \"Alexanders-MacBook-Pro.local_8000\" ,\n                 \"num_channels\" :  0 ,\n                 \"num_clients\" :  0 ,\n                 \"num_users\" :  0 ,\n                 \"uid\" :  \"f844a2ed-5edf-4815-b83c-271974003db9\" ,\n                 \"uptime\" :  0 ,\n                 \"version\" :  \"\" \n             } \n         ] \n     }  }",
            "title": "info"
        },
        {
            "location": "/server/recover/",
            "text": "How message recovery works\n\u00b6\n\n\nOne of the most important features of Centrifugo is message recovery after short network disconnects. This is often the case when we are moving around - for example sudden tunnel can result in internet connection lost. Or when we switching networks on our device. Message recovery feature is especially useful when dealing with Centrifugo node restart - many client connection disconnect and then reconnect at once - if users subscribed on channels with important data it's a good practice to restore missed state on successful reconnect. In general you would query your application backend for actual state on every network/shutdown reconnect - but message recovery feature allows Centrifugo itself to deal with this and restore missed messages from history cache thus reducing load on your application backend during reconnects.\n\n\nWhen subscribing on channels Centrifugo will return missed \npublications\n to client and also special \nrecovered\n boolean flag to indicate whether all messages were recovered after disconnect or not.\n\n\nTo enable recovery mechanism for channels set \nhistory_recover\n boolean configuration option to \ntrue\n on configuration top level or for channel namespace.\n\n\nCentrifugo recovery model based on two fields in protocol: \nlast\n and \naway\n. Both fields are managed automatically by Centrifugo client libraries but it's good to know how recovery works under the hood.\n\n\nEvery time client receives a new publication from channel client library remembers \nuid\n of received \nPublication\n. When resubscribing to channel after reconnect client passes last seen publication \nuid\n in subscribe command.\n\n\nClient also passes \naway\n field when resubscribing which is a number of seconds client was in unsubscribed state. This is a number of seconds rounded to the upper value. Client also adds timeout values in seconds to this interval to compensate possible network latencies when communicating with server.\n\n\nWhen server receives subscribe request with \nlast\n field set it can look at history cache and find all next publications (following one with provided \nlast\n uid). If \nlast\n field not provided (for example there were no new messages in channel for a long time) then server will only rely on \naway\n field. In this case server will set \nrecovered\n flag to \ntrue\n only if client was away (absent) for an interval of time that is not larger than history lifetime and amount of messages in history cache less than configured history size.\n\n\nMessage recovery in Centrifugo is not a 100% bulletproof scheme (as it has some assumptions regarding to time) but it should work for significant amount of real life cases without message loss. If you need more reliability in channel message recovery then you can manually implement your own recovery algorithm on top of basic PUB/SUB possibilities that Centrifugo provides.\n\n\nAnd you can always simply ask your backend for an actual state after client reconnect completely bypassing recovery mechanism described here.\n\n\nRecovery on example\n\u00b6\n\n\nConsider channel \nchat_messages\n client subscribed to.\n\n\nFirst let's imagine a situation when client receives new message from this channel. Let the \nuid\n value of that message be a \nZZaavc\n.\n\n\nAnd then client disconnects because of lost internet connection.\n\n\nWhen connection lost client saves current time for each subscription. This saved time will be used to calculate \naway\n field value when client will do resubscription attempt.\n\n\nLet's suppose client will be 5 seconds in disconnected state and then connection will be restored and client will resubscribe on channel.\n\n\nIt will pass two fields in subscribe command:\n\n\n\n\nlast\n - in this case \nZZaavc\n\n\naway\n - in this case \n5\n + client request timeout. I.e \n10\n in case of client request timeout of \n5 seconds\n.\n\n\n\n\nIf server finds publication with \nZZaavc\n uid in history it can be sure that all following messages are all messages client lost during reconnect (and will set \nrecovered\n flag to \ntrue\n). \n\n\nIf there were no publication with uid \nZZaavc\n in history then \nrecovered\n flag will be set to true only if provided \naway\n value is less than channel \nhistory_lifetime\n and history currently contains amount of publications strictly less than \nhistory_size\n. Actually server adds one more second to \naway\n value to compensate rounding errors.\n\n\nThis means that if \nhistory_size\n is \n10\n and \nhistory_lifetime\n is \n60\n then client must reconnect in 0-49 seconds to be sure all missed publications were successfully recovered.",
            "title": "Message recovery"
        },
        {
            "location": "/server/recover/#how-message-recovery-works",
            "text": "One of the most important features of Centrifugo is message recovery after short network disconnects. This is often the case when we are moving around - for example sudden tunnel can result in internet connection lost. Or when we switching networks on our device. Message recovery feature is especially useful when dealing with Centrifugo node restart - many client connection disconnect and then reconnect at once - if users subscribed on channels with important data it's a good practice to restore missed state on successful reconnect. In general you would query your application backend for actual state on every network/shutdown reconnect - but message recovery feature allows Centrifugo itself to deal with this and restore missed messages from history cache thus reducing load on your application backend during reconnects.  When subscribing on channels Centrifugo will return missed  publications  to client and also special  recovered  boolean flag to indicate whether all messages were recovered after disconnect or not.  To enable recovery mechanism for channels set  history_recover  boolean configuration option to  true  on configuration top level or for channel namespace.  Centrifugo recovery model based on two fields in protocol:  last  and  away . Both fields are managed automatically by Centrifugo client libraries but it's good to know how recovery works under the hood.  Every time client receives a new publication from channel client library remembers  uid  of received  Publication . When resubscribing to channel after reconnect client passes last seen publication  uid  in subscribe command.  Client also passes  away  field when resubscribing which is a number of seconds client was in unsubscribed state. This is a number of seconds rounded to the upper value. Client also adds timeout values in seconds to this interval to compensate possible network latencies when communicating with server.  When server receives subscribe request with  last  field set it can look at history cache and find all next publications (following one with provided  last  uid). If  last  field not provided (for example there were no new messages in channel for a long time) then server will only rely on  away  field. In this case server will set  recovered  flag to  true  only if client was away (absent) for an interval of time that is not larger than history lifetime and amount of messages in history cache less than configured history size.  Message recovery in Centrifugo is not a 100% bulletproof scheme (as it has some assumptions regarding to time) but it should work for significant amount of real life cases without message loss. If you need more reliability in channel message recovery then you can manually implement your own recovery algorithm on top of basic PUB/SUB possibilities that Centrifugo provides.  And you can always simply ask your backend for an actual state after client reconnect completely bypassing recovery mechanism described here.",
            "title": "How message recovery works"
        },
        {
            "location": "/server/recover/#recovery-on-example",
            "text": "Consider channel  chat_messages  client subscribed to.  First let's imagine a situation when client receives new message from this channel. Let the  uid  value of that message be a  ZZaavc .  And then client disconnects because of lost internet connection.  When connection lost client saves current time for each subscription. This saved time will be used to calculate  away  field value when client will do resubscription attempt.  Let's suppose client will be 5 seconds in disconnected state and then connection will be restored and client will resubscribe on channel.  It will pass two fields in subscribe command:   last  - in this case  ZZaavc  away  - in this case  5  + client request timeout. I.e  10  in case of client request timeout of  5 seconds .   If server finds publication with  ZZaavc  uid in history it can be sure that all following messages are all messages client lost during reconnect (and will set  recovered  flag to  true ).   If there were no publication with uid  ZZaavc  in history then  recovered  flag will be set to true only if provided  away  value is less than channel  history_lifetime  and history currently contains amount of publications strictly less than  history_size . Actually server adds one more second to  away  value to compensate rounding errors.  This means that if  history_size  is  10  and  history_lifetime  is  60  then client must reconnect in 0-49 seconds to be sure all missed publications were successfully recovered.",
            "title": "Recovery on example"
        },
        {
            "location": "/server/signals/",
            "text": "Signal handling\n\u00b6\n\n\nYou can send HUP signal to Centrifugo to reload configuration:\n\n\nkill -HUP <PID>\n\n\n\n\nThough at moment this will only reload channel and namespace configuration.\n\n\nAlso Centrifugo tries to gracefully shutdown client connections when SIGINT or SIGTERM signals received. By default maximum graceful shutdown period is 30 seconds but can be changed using \nshutdown_timeout\n configuration option.",
            "title": "Signal handling"
        },
        {
            "location": "/server/signals/#signal-handling",
            "text": "You can send HUP signal to Centrifugo to reload configuration:  kill -HUP <PID>  Though at moment this will only reload channel and namespace configuration.  Also Centrifugo tries to gracefully shutdown client connections when SIGINT or SIGTERM signals received. By default maximum graceful shutdown period is 30 seconds but can be changed using  shutdown_timeout  configuration option.",
            "title": "Signal handling"
        },
        {
            "location": "/server/connection_expiration/",
            "text": "Connection expiration\n\u00b6\n\n\nIn authentication chapter we mentioned \nexp\n claim in connection token that allows to expire client connection at some point of time. In this chapter we will look at details on what happens when Centrifugo detects that connection is going to expire.\n\n\nSo first you should do is enable client expiration mechanism in Centrifugo providing connection token with expiration:\n\n\nimport\n \njwt\n\n\nimport\n \ntime\n\n\n\ntoken\n \n=\n \njwt\n.\nencode\n({\n\"user\"\n:\n \n\"42\"\n,\n \n\"exp\"\n:\n \nint\n(\ntime\n.\ntime\n())\n \n+\n \n10\n*\n60\n},\n \n\"secret\"\n)\n.\ndecode\n()\n\n\n\nprint\n(\ntoken\n)\n\n\n\n\n\nLet's suppose that you set \nexp\n field to timestamp that will expire in 10 minutes and client connected to Centrifugo with this token. During 10 mins connection will be kept by Centrifugo. When this time passed Centrifugo gives connection some time (configured, 25 seconds by default) to refresh its credentials and provide new valid token with new \nexp\n.\n\n\nWhen client first connects to Centrifugo it receives \nttl\n value in connect reply. That \nttl\n value contains number of seconds after which client must send \nrefresh\n command with new credentials to Centrifugo. Centrifugo clients must handle this \nttl\n field and automatically start refresh process.\n\n\nFor example Javascript browser client  will send AJAX POST request to your application when it's time to refresh credentials. By default this request goes to \n/centrifuge/refresh\n url endpoint. In response your server must return JSON with new connection token:\n\n\n{\n\n    \n\"token\"\n:\n \ntoken\n\n\n}\n\n\n\n\n\nSo you must just return the same connection token for \nuser\n when rendering page initially. But with actual \nexp\n. Javascript client will then send them to Centrifugo server and connection will be refreshed for a time you set in \nexp\n.\n\n\nIn this case you know which user want to refresh its connection because this is just a general request to your app - so your session mechanism will tell you about the user.\n\n\nIf you don't want to refresh connection for this user - just return 403 Forbidden on refresh request to your application backend.\n\n\nJavascript client also has options to hook into refresh mechanism to implement your custom way of refreshing. Other Centrifugo clients also should have hooks to refresh credentials but depending on client API for this can be different - see specific client docs.",
            "title": "Connection expiration"
        },
        {
            "location": "/server/connection_expiration/#connection-expiration",
            "text": "In authentication chapter we mentioned  exp  claim in connection token that allows to expire client connection at some point of time. In this chapter we will look at details on what happens when Centrifugo detects that connection is going to expire.  So first you should do is enable client expiration mechanism in Centrifugo providing connection token with expiration:  import   jwt  import   time  token   =   jwt . encode ({ \"user\" :   \"42\" ,   \"exp\" :   int ( time . time ())   +   10 * 60 },   \"secret\" ) . decode ()  print ( token )   Let's suppose that you set  exp  field to timestamp that will expire in 10 minutes and client connected to Centrifugo with this token. During 10 mins connection will be kept by Centrifugo. When this time passed Centrifugo gives connection some time (configured, 25 seconds by default) to refresh its credentials and provide new valid token with new  exp .  When client first connects to Centrifugo it receives  ttl  value in connect reply. That  ttl  value contains number of seconds after which client must send  refresh  command with new credentials to Centrifugo. Centrifugo clients must handle this  ttl  field and automatically start refresh process.  For example Javascript browser client  will send AJAX POST request to your application when it's time to refresh credentials. By default this request goes to  /centrifuge/refresh  url endpoint. In response your server must return JSON with new connection token:  { \n     \"token\" :   token  }   So you must just return the same connection token for  user  when rendering page initially. But with actual  exp . Javascript client will then send them to Centrifugo server and connection will be refreshed for a time you set in  exp .  In this case you know which user want to refresh its connection because this is just a general request to your app - so your session mechanism will tell you about the user.  If you don't want to refresh connection for this user - just return 403 Forbidden on refresh request to your application backend.  Javascript client also has options to hook into refresh mechanism to implement your custom way of refreshing. Other Centrifugo clients also should have hooks to refresh credentials but depending on client API for this can be different - see specific client docs.",
            "title": "Connection expiration"
        },
        {
            "location": "/server/private_channels/",
            "text": "Private channels\n\u00b6\n\n\nIn channels chapter we mentioned private channels. This chapter has more information about private channel mechanism in Centrifugo.\n\n\nAll channels starting with \n$\n considered private. In this case your backend should additionally provide token for subscription request. The way how this token is obtained varies depending on client implementation.\n\n\nFor example in Javascript client AJAX POST request is automatically made to\u00a0\n/centrifuge/subscribe\n endpoint. Other client libraries can provide a hook for your custom code that will obtain private subscription token from application backend. \n\n\nThe subscription token is similar to connection token. It's also JWT. But has different claims.\n\n\nClaims\n\u00b6\n\n\nPrivate subscription claims are: \nclient\n, \nchannel\n, \ninfo\n and \nb64info\n. What do they mean? Let's describe in detail.\n\n\nclient\n\u00b6\n\n\nRequired. Client ID which wants to subscribe on channel (\nstring\n).\n\n\nchannel\n\u00b6\n\n\nRequired. Channel that client tries to subscribe to (\nstring\n).\n\n\ninfo\n\u00b6\n\n\nOptional. Additional information for connection regarding to channel (\nvalid JSON\n).\n\n\nb64info\n\u00b6\n\n\nOptional. Additional information for connection regarding to channel in base64 format (\nstring\n).\n\n\nExample\n\u00b6\n\n\nSo to generate subscription token you can use smth like this in Python (assuming client ID is \nXXX\n and private channel is \n$gossips\n):\n\n\nimport\n \njwt\n\n\n\ntoken\n \n=\n \njwt\n.\nencode\n({\n\"client\"\n:\n \n\"XXX\"\n,\n \n\"channel\"\n:\n \n\"$gossips\"\n},\n \n\"secret\"\n,\n \nalgorithm\n=\n\"HS256\"\n)\n.\ndecode\n()\n\n\n\nprint\n(\ntoken\n)\n\n\n\n\n\nAgain - the same \nsecret\n from Centrifugo configuration is used to generate JWT. And as with connection JWT only \nHS256\n algorithm is supported at moment.",
            "title": "Private channels"
        },
        {
            "location": "/server/private_channels/#private-channels",
            "text": "In channels chapter we mentioned private channels. This chapter has more information about private channel mechanism in Centrifugo.  All channels starting with  $  considered private. In this case your backend should additionally provide token for subscription request. The way how this token is obtained varies depending on client implementation.  For example in Javascript client AJAX POST request is automatically made to\u00a0 /centrifuge/subscribe  endpoint. Other client libraries can provide a hook for your custom code that will obtain private subscription token from application backend.   The subscription token is similar to connection token. It's also JWT. But has different claims.",
            "title": "Private channels"
        },
        {
            "location": "/server/private_channels/#claims",
            "text": "Private subscription claims are:  client ,  channel ,  info  and  b64info . What do they mean? Let's describe in detail.",
            "title": "Claims"
        },
        {
            "location": "/server/private_channels/#client",
            "text": "Required. Client ID which wants to subscribe on channel ( string ).",
            "title": "client"
        },
        {
            "location": "/server/private_channels/#channel",
            "text": "Required. Channel that client tries to subscribe to ( string ).",
            "title": "channel"
        },
        {
            "location": "/server/private_channels/#info",
            "text": "Optional. Additional information for connection regarding to channel ( valid JSON ).",
            "title": "info"
        },
        {
            "location": "/server/private_channels/#b64info",
            "text": "Optional. Additional information for connection regarding to channel in base64 format ( string ).",
            "title": "b64info"
        },
        {
            "location": "/server/private_channels/#example",
            "text": "So to generate subscription token you can use smth like this in Python (assuming client ID is  XXX  and private channel is  $gossips ):  import   jwt  token   =   jwt . encode ({ \"client\" :   \"XXX\" ,   \"channel\" :   \"$gossips\" },   \"secret\" ,   algorithm = \"HS256\" ) . decode ()  print ( token )   Again - the same  secret  from Centrifugo configuration is used to generate JWT. And as with connection JWT only  HS256  algorithm is supported at moment.",
            "title": "Example"
        },
        {
            "location": "/server/protocol/",
            "text": "Client protocol\n\u00b6\n\n\nThis chapter describes internal client-server protocol in details to help developers build custom client libraries.\n\n\nNote that you can always look at existing client implementations in case of any questions, for example \ncentrifuge-js\n.\n\n\nWhat client should do\n\u00b6\n\n\nHere we will look at list of features client library should support. Depending on client implementation some features can be not implemented. If you an author of such library you can use this list as checklist:\n\n\n\n\nconnect to server using JSON protocol format\n\n\nconnect to server using Protobuf protocol format\n\n\nsupport automatic reconnect in case of errors, network problems etc\n\n\nsubscribe on channel and handle asynchronous Publications\n\n\nhandle Join and Leave messages\n\n\nhandle unsubscribe notifications\n\n\nsend asynchronous messages to server\n\n\nhandle asynchronous messages from server\n\n\nsend RPC commands\n\n\nconnect with JWT\n\n\nsubscribe to private channels with JWT\n\n\ncall \npublish\n, \npresence\n, \npresence_stats\n, \nhistory\n methods.\n\n\nsupport connection JWT refresh\n\n\nsupport private channel subscription JWT refresh\n\n\nping/pong to find broken connection\n\n\nsupport message recovery mechanism\n\n\n\n\nThis document describes protocol specifics for Websocket transport which supports binary and text formats to transfer data. As Centrifuge has various types of messages it serializes protocol messages using JSON or Protobuf (in case of binary websockets).\n\n\n\n\nNote\n\n\nSockJS works almost the same way as JSON websocket described here but has its own extra framing on top of Centrifuge protocol messages. SockJS can only work with JSON - it's not possible to transfer binary data over it. SockJS is only needed as fallback to Websocket in web browsers.\n\n\n\n\nTop level framing\n\u00b6\n\n\nCentrifuge protocol defined in \nProtobuf schema\n. That schema is a source of truth and all protocol description below describes messages from that schema.\n\n\nClient sends \nCommand\n to server.\n\n\nServer sends \nReply\n to client.\n\n\nOne request from client to server and one response from server to client can have more than one \nCommand\n or \nReply\n.\n\n\nWhen JSON format is used then many \nCommand\n can be sent from client to server in JSON streaming line-delimited format. I.e. many commands delimited by new line symbol \n\\n\n.\n\n\n{\n\"id\"\n:\n \n1\n,\n \n\"method\"\n:\n \n\"subscribe\"\n,\n \n\"params\"\n:\n \n{\n\"channel\"\n:\n \n\"ch1\"\n}}\n\n\n{\n\"id\"\n:\n \n2\n,\n \n\"method\"\n:\n \n\"subscribe\"\n,\n \n\"params\"\n:\n \n{\n\"channel\"\n:\n \n\"ch2\"\n}}\n\n\n\n\n\n\n\nNote\n\n\nThis doc will use JSON format for examples because it's human-readable. Everything said here for JSON is also true for Protobuf encoded case. \n\n\n\n\n\n\nNote\n\n\nMethod is made as ENUM in protobuf schema and can be sent as integer value but it's possible to send it as string in JSON case \u2013 this was made to make JSON protocol human-friendly.\n\n\n\n\nWhen Protobuf format is used then many \nCommand\n can be sent from client to server in length-delimited format where each individual \nCommand\n marshaled to bytes prepended by \nvarint\n length.\n\n\nThe same relates to many \nReply\n in one response from server to client. Line-delimited JSON and varint-length prefixed Protobuf.\n\n\nAs you see above each \nCommand\n has \nid\n field. This is an incremental integer field. This field will be echoed in server to client replies to commands so client could match a certain \nReply\n to \nCommand\n sent before. This is important because Websocket is asynchronous protocol where server and client both send messages in full-duplex mode.\n\n\nSo you can expect something like this when sending commands to server:\n\n\n{\n\"id\"\n:\n \n1\n,\n \n\"result\"\n:\n \n{}}\n\n\n{\n\"id\"\n:\n \n2\n,\n \n\"result\"\n:\n \n{}}\n\n\n\n\n\nBesides \nid\n \nReply\n from server to client have two important fields: \nresult\n and \nerror\n.\n\n\nresult\n contains useful payload object which can be different depending on \nReply\n.\n\n\nerror\n contains error object in case of \nCommand\n processing resulted in some error on server. \nerror\n is optional and if \nReply\n does not have \nerror\n then it means that \nCommand\n processed successfuly and client can parse \nresult\n object in an appropriate way.\n\n\nerror\n objects looks like this:\n\n\n{\n\n    \n\"code\"\n:\n \n100\n,\n\n    \n\"message\"\n:\n \n\"internal server error\"\n\n\n}\n\n\n\n\n\nWe will talk more about error handling below.\n\n\nThe special type of \nReply\n is asynchronous \nReply\n. Those replies have no \nid\n field set (or \nid\n can be equal to zero). Async replies can come to client in any moment - not as reaction to issued \nCommand\n but as message from server to client in arbitrary time. For example this can be message published into channel.\n\n\nCentrifuge library defines several command types client can issue. And well-written client must be aware of all those commands and client workflow. Communication with Centrifuge/Centrifugo server starts with \nconnect\n command.\n\n\nConnect\n\u00b6\n\n\nFirst of all client must dial with server and then send \nconnect\n \nCommand\n to it.\n\n\nDefault Websocket endpoint in Centrifugo is:\n\n\nws://centrifugo.example.com/connection/websocket\n\n\n\n\nIn case of using TLS:\n\n\nwss://centrifugo.example.com/connection/websocket\n\n\n\n\nAfter successful dial to websocket endpoint client must send \nconnect\n command to server to authorize itself.\n\n\nconnect\n command looks like:\n\n\n{\n\n    \n\"id\"\n:\n \n1\n,\n\n    \n\"method\"\n:\n \n\"connect\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"token\"\n:\n \n\"JWT\"\n,\n\n        \n\"data\"\n:\n \n{}\n\n    \n}\n\n\n}\n\n\n\n\n\nWhere params fields are passed to client from application backend:\n\n\n\n\nstring \ntoken\n - connection token.\n\n\nJSON \ndata\n - this is only available for Centrifuge library and not for Centrifugo server. It contains custom connect data, for example it can contain client settings. \n\n\n\n\nIn response to \nconnect\n command server sends connect reply. It looks this way:\n\n\n{\n\n    \n\"id\"\n:\n1\n,\n\n    \n\"result\"\n:\n{\n\n        \n\"client\"\n:\n\"421bf374-dd01-4f82-9def-8c31697e956f\"\n,\n\n        \n\"version\"\n:\n\"2.0.0\"\n\n    \n}\n\n\n}\n\n\n\n\n\nresult\n has some fields:\n\n\n\n\nstring \nclient\n - unique client connection ID server issued to this connection\n\n\nstring \nversion\n - server version\n\n\noptional bool \nexpires\n - whether or not server will expire connection\n\n\noptional bool \nexpired\n - whether or not connection credentials already expired and must be refreshed\n\n\noptional int32 \nttl\n - time in seconds until connection will expire\n\n\n\n\nSubscribe\n\u00b6\n\n\nAs soon as client successfully connected and got unique connection ID it is ready to\nsubscribe on channels. To do this it must send \nsubscribe\n command to server:\n\n\n{\n\n    \n\"id\"\n:\n \n2\n,\n\n    \n\"method\"\n:\n \n\"subscribe\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"ch1\"\n\n    \n}\n\n\n}\n\n\n\n\n\nFields that can be set in \nparams\n are:\n\n\n\n\nstring \nchannel\n - channel to subscribe\n\n\n\n\nIn response to subscribe client receives reply like:\n\n\n{\n\n    \n\"id\"\n:\n2\n,\n\n    \n\"result\"\n:\n{}\n\n\n}\n\n\n\n\n\nresult\n can have the following fields:\n\n\n\n\noptional array \npublications\n - this is an array of missed publications in channel. When received client must call general publication event handler for each message in this array\n\n\noptional string \nlast\n - this field contains uid of last publication in channel. This allows fresh client which have not received publications before recover messages setting this value into next subscription request. \n\n\noptional bool \nrecovered\n - this flag is set to \ntrue\n when server thinks that all missed publications were successfully recovered and send in subscribe reply (in \npublications\n array) and \nfalse\n otherwise.\n\n\n\n\nAfter client received successful reply on \nsubscribe\n command it will receive asynchronous \nreply messages published to this channel. Messages can be of several types:\n\n\n\n\nPublication message\n\n\nJoin message\n\n\nLeave message\n\n\nUnsub message\n\n\n\n\nSee more about asynchronous messages below. \n\n\nUnsubscribe\n\u00b6\n\n\nThis is simple. When client wants to unsubscribe from channel and therefore stop receiving asynchronous subscription messages from connection related to channel it must call \nunsubscribe\n command:\n\n\n{\n\n    \n\"id\"\n:\n \n3\n,\n\n    \n\"method\"\n:\n \n\"unsubscribe\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"ch1\"\n\n    \n}\n\n\n}\n\n\n\n\n\nActually server response does not mean a lot for client - it must immediately remove channel subscription from internal implementation data structures and ignore all messages related to channel.\n\n\nRefresh\n\u00b6\n\n\nIt's possible to turn on client connection expiration mechanism on server. While enabled server will keep track of connections whose time of life (defined by \nexp\n timestamp) is close to the end. In this case connection will be closed. Client can prevent closing connection refreshing it's connection credentials. To do this it must send \nrefresh\n command to server. \nrefresh\n command similar to \nconnect\n:\n\n\n{\n\n    \n\"id\"\n:\n \n4\n,\n\n    \n\"method\"\n:\n \n\"refresh\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"token\"\n:\n \n\"JWT\"\n\n    \n}\n\n\n}\n\n\n\n\n\nJust with actual \nexp\n and new \nsign\n.\n\n\nThe tip whether or not connection must be refreshed comes in reply to \nconnect\n command shown above - fields \nexpires\n, \nexpired\n and \nttl\n.\n\n\nWhen client connection expire mechanism is on the value of field \nexpires\n in connect reply is \ntrue\n. In this case client implementation should look at \nttl\n value which is seconds left until connection will be considered expired. Client must send \nrefresh\n command after this \nttl\n seconds. Server gives client a configured window to refresh token after \nttl\n passed and then closes connection if client have not updated its token. \nexpired\n field set to \ntrue\n when client connection already expired. In this case client should immediately send \nrefresh\n command to update token. And after doing this it can work the usual way.\n\n\nRPC-like calls: publish, history, presence\n\u00b6\n\n\nThe mechanics of these calls is simple - client sends command and expects response from server.\n\n\npublish\n command allows to publish message into channel from client.\n\n\n\n\nNote\n\n\nTo publish from client \npublish\n option in server configuration must be set to \ntrue\n\n\n\n\nhistory\n allows to ask server for channel history if enabled.\n\n\npresence\n allows to ask server for channel presence information if enabled.\n\n\nAsynchronous server-to-client messages\n\u00b6\n\n\nThere are several types of asynchronous messages that can come from server to client. All of them relate to current client subscriptions.\n\n\nThe most important message is \nPublication\n:\n\n\n{\n\n    \n\"result\"\n:\n{\n\n        \n\"channel\"\n:\n\"ch1\"\n,\n\n        \n\"data\"\n:\n{\n\n            \n\"uid\"\n:\n\"Ry4z8l6GvNMejwMxB7Sohe\"\n,\n\n            \n\"data\"\n:\n{\n\"input\"\n:\n\"1\"\n},\n\n            \n\"info\"\n:\n{\n\n                \n\"user\"\n:\n\"2694\"\n,\n\n                \n\"client\"\n:\n\"5c48510e-cf49-4fa8-a9b2-490b22231e74\"\n,\n\n                \n\"conn_info\"\n:\n{\n\"name\"\n:\n\"Alexander\"\n},\n\n                \n\"chan_info\"\n:\n{}\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\nPublication\n is a message published into channel. Note that there is no \nid\n field in this message - this symptom\nallows to distinguish it from \nReply\n to \nCommand\n.  \n\n\nNext message is \nJoin\n message:\n\n\n{\n\n    \n\"result\"\n:\n{\n\n        \n\"type\"\n:\n1\n,\n\n        \n\"channel\"\n:\n\"ch1\"\n,\n\n        \n\"data\"\n:\n{\n\n            \n\"info\"\n:\n{\n\n                \n\"user\"\n:\n\"2694\"\n,\n\n                \n\"client\"\n:\n\"5c48510e-cf49-4fa8-a9b2-490b22231e74\"\n,\n\n                \n\"conn_info\"\n:\n{\n\"name\"\n:\n\"Alexander\"\n},\n\n                \n\"chan_info\"\n:\n{}\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\nJoin\n messages sent when someone joined (subscribed on) channel.\n\n\n\n\nNote\n\n\nTo enable \nJoin\n and \nLeave\n messages \njoin_leave\n option must be enabled on server globally or for channel namespace.\n\n\n\n\nLeave\n messages sent when someone left (unsubscribed from) channel.\n\n\n{\n\n    \n\"result\"\n:\n{\n\n        \n\"type\"\n:\n2\n,\n\n        \n\"channel\"\n:\n\"ch1\"\n,\n\n        \n\"data\"\n:\n{\n\n            \n\"info\"\n:\n{\n\n                \n\"user\"\n:\n\"2694\"\n,\n\n                \n\"client\"\n:\n\"5c48510e-cf49-4fa8-a9b2-490b22231e74\"\n,\n\n                \n\"conn_info\"\n:\n{\n\"name\"\n:\n\"Alexander\"\n},\n\n                \n\"chan_info\"\n:\n{}\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\nAnd finally \nUnsub\n message that means that server unsubscribed current client from channel:\n\n\n{\n\n    \n\"result\"\n:\n{\n\n        \n\"type\"\n:\n3\n,\n\n        \n\"channel\"\n:\n\"ch1\"\n,\n\n        \n\"data\"\n:\n{}\n\n    \n}\n\n\n}\n\n\n\n\n\nIt's possible to distinguish between different types of asynchronous messages looking at \ntype\n field (for \nPublication\n this field not set or \n0\n).\n\n\nPing Pong\n\u00b6\n\n\nTo maintain connection alive and detect broken connections client must periodically send \nping\n commands to server and expect replies to it. Ping command looks like:\n\n\n{\n\n    \n\"id\"\n:\n32\n,\n\n    \n\"method\"\n:\n\"ping\"\n\n\n}\n\n\n\n\n\nServer just echoes this command back. When client does not receive ping reply for some time it must consider connection broken and try to reconnect. Recommended ping interval is 25 seconds, recommended period to wait for pong is 1-5 seconds. Though those numbers can vary.\n\n\nHandle disconnects\n\u00b6\n\n\nClient should handle disconnect advices from server. In websocket case disconnect advice is sent in reason field of CLOSE Websocket frame. Reason contains string which is \ndisconnect\n object encoded into JSON (even in case of Protobuf scenario). That objects looks like:\n\n\n{\n\n    \n\"reason\"\n:\n \n\"shutdown\"\n,\n\n    \n\"reconnect\"\n:\n \ntrue\n \n\n}\n\n\n\n\n\nIt contains string reason of connection closing and advice to reconnect or not. Client should take this reconnect advice into account.\n\n\nIn case of network problems and random disconnect from server without well known reason client should always try to  reconnect with exponential intervals.\n\n\nHandle errors\n\u00b6\n\n\nThis section contains advices to error handling in client implementations.\n\n\nErrors can happen during various operations and can be handled in special way in context of some commands to tolerate network and server problems.\n\n\nErrors during \nconnect\n must result in full client reconnect.\n\n\nErrors during \nsubscribe\n must result in full client reconnect if error is temporary. And be sent to subscribe error event handler of subscription if received error is persistent. Persistent errors are errors like \npermission denied\n, \nbad request\n, \nnamespace not found\n etc. Persistent errors in most situation mean a mistake from developers side.\n\n\nThe special corner case is client-side timeout during \nsubscribe\n operation. As protocol is asynchronous it's possible in this case that server will eventually subscribe client on channel but client will think that it's not subscribed. It's possible to retry subscription request and tolerate \nalready subscribed\n error as expected. But the simplest solution is to reconnect entirely as this is simpler and gives client a chance to connect to working server instance.\n\n\nErrors during rpc-like operations can be just returned to caller - i.e. user javascript code. Calls like \nhistory\n and \npresence\n are idempotent. You should be accurate with unidempotent operations like \npublish\n - in case of client timeout it's possible to send the same message into channel twice if retry publish after timeout - so if you care about this case make sure you have some protection from displaying message twice on client side (maybe some sort of unique key in payload).\n\n\nClient implementation advices\n\u00b6\n\n\nHere are some advices about client public API. Examples here are in Javascript language. This is just an attempt to help in developing a client - but rules here is not obligatorily the best way to implement client.\n\n\nCreate client instance:\n\n\nvar\n \ncentrifuge\n \n=\n \nnew\n \nCentrifuge\n(\n\"ws://localhost:8000/connection/websocket\"\n,\n \n{});\n\n\n\n\n\nSet connection token (in case of using Centrifugo):\n\n\ncentrifuge\n.\nsetToken\n(\n\"XXX\"\n)\n\n\n\n\n\nConnect to server:\n\n\ncentrifuge\n.\nconnect\n();\n\n\n\n\n\n2 event handlers can be set to \ncentrifuge\n object: \nconnect\n and \ndisconnect\n\n\ncentrifuge\n.\non\n(\n'connect'\n,\n \nfunction\n(\ncontext\n)\n \n{\n\n    \nconsole\n.\nlog\n(\ncontext\n);\n\n\n});\n\n\n\ncentrifuge\n.\non\n(\n'disconnect'\n,\n \nfunction\n(\ncontext\n)\n \n{\n\n    \nconsole\n.\nlog\n(\ncontext\n);\n\n\n});\n\n\n\n\n\nClient created in \ndisconnected\n state with \nreconnect\n attribute set to \ntrue\n and \nreconnecting\n flag set to \nfalse\n . After \nconnect()\n called state goes to \nconnecting\n. It's only possible to connect from \ndisconnected\n state. Every time \nconnect()\n called \nreconnect\n flag of client must be set to \ntrue\n. After each failed connect attempt state must be set to \ndisconnected\n, \ndisconnect\n event must be emitted (only if \nreconnecting\n flag is \nfalse\n), and then \nreconnecting\n flag must be set to \ntrue\n (if client should continue reconnecting) to not emit \ndisconnect\n event again after next in a row connect attempt failure. In case of failure next connection attempt must be scheduled automatically with backof strategy. On successful connect \nreconnecting\n flag must be set to \nfalse\n, backoff retry must be resetted and \nconnect\n event must be emitted. When connection lost then the same set of actions as when connect failed must be performed.\n\n\nClient must allow to subscribe on channels:\n\n\nvar\n \nsubscription\n \n=\n \ncentrifuge\n.\nsubscribe\n(\n\"channel\"\n,\n \neventHandlers\n);\n\n\n\n\n\nSubscription object created and control immediately returned to caller - subscribing must be performed asynchronously. This is required because client can automatically reconnect later so event-based model better suites for subscriptions. \n\n\nSubscription should support several event handlers:\n\n\n\n\nhandler for publication received from channel\n\n\njoin message handler\n\n\nleave message handler\n\n\nerror handler\n\n\nsubscribe success event handler\n\n\nunsubscribe event handler\n\n\n\n\nEvery time client connects to server it must restore all subscriptions.\n\n\nEvery time client disconnects from server it must call unsubscribe handlers for all active subscriptions and then emit disconnect event.\n\n\nClient must periodically (once in 25 secs, configurable) send ping messages to server. If pong has not beed received in 5 secs (configurable) then client must disconnect from server and try to reconnect with backoff strategy.\n\n\nClient can automatically batch several requests into one frame to server and also must be able to handle several replies received from server in one frame.\n\n\nTimeout on subscription requests must result in full client reconnect workflow.",
            "title": "Client protocol"
        },
        {
            "location": "/server/protocol/#client-protocol",
            "text": "This chapter describes internal client-server protocol in details to help developers build custom client libraries.  Note that you can always look at existing client implementations in case of any questions, for example  centrifuge-js .",
            "title": "Client protocol"
        },
        {
            "location": "/server/protocol/#what-client-should-do",
            "text": "Here we will look at list of features client library should support. Depending on client implementation some features can be not implemented. If you an author of such library you can use this list as checklist:   connect to server using JSON protocol format  connect to server using Protobuf protocol format  support automatic reconnect in case of errors, network problems etc  subscribe on channel and handle asynchronous Publications  handle Join and Leave messages  handle unsubscribe notifications  send asynchronous messages to server  handle asynchronous messages from server  send RPC commands  connect with JWT  subscribe to private channels with JWT  call  publish ,  presence ,  presence_stats ,  history  methods.  support connection JWT refresh  support private channel subscription JWT refresh  ping/pong to find broken connection  support message recovery mechanism   This document describes protocol specifics for Websocket transport which supports binary and text formats to transfer data. As Centrifuge has various types of messages it serializes protocol messages using JSON or Protobuf (in case of binary websockets).   Note  SockJS works almost the same way as JSON websocket described here but has its own extra framing on top of Centrifuge protocol messages. SockJS can only work with JSON - it's not possible to transfer binary data over it. SockJS is only needed as fallback to Websocket in web browsers.",
            "title": "What client should do"
        },
        {
            "location": "/server/protocol/#top-level-framing",
            "text": "Centrifuge protocol defined in  Protobuf schema . That schema is a source of truth and all protocol description below describes messages from that schema.  Client sends  Command  to server.  Server sends  Reply  to client.  One request from client to server and one response from server to client can have more than one  Command  or  Reply .  When JSON format is used then many  Command  can be sent from client to server in JSON streaming line-delimited format. I.e. many commands delimited by new line symbol  \\n .  { \"id\" :   1 ,   \"method\" :   \"subscribe\" ,   \"params\" :   { \"channel\" :   \"ch1\" }}  { \"id\" :   2 ,   \"method\" :   \"subscribe\" ,   \"params\" :   { \"channel\" :   \"ch2\" }}    Note  This doc will use JSON format for examples because it's human-readable. Everything said here for JSON is also true for Protobuf encoded case.     Note  Method is made as ENUM in protobuf schema and can be sent as integer value but it's possible to send it as string in JSON case \u2013 this was made to make JSON protocol human-friendly.   When Protobuf format is used then many  Command  can be sent from client to server in length-delimited format where each individual  Command  marshaled to bytes prepended by  varint  length.  The same relates to many  Reply  in one response from server to client. Line-delimited JSON and varint-length prefixed Protobuf.  As you see above each  Command  has  id  field. This is an incremental integer field. This field will be echoed in server to client replies to commands so client could match a certain  Reply  to  Command  sent before. This is important because Websocket is asynchronous protocol where server and client both send messages in full-duplex mode.  So you can expect something like this when sending commands to server:  { \"id\" :   1 ,   \"result\" :   {}}  { \"id\" :   2 ,   \"result\" :   {}}   Besides  id   Reply  from server to client have two important fields:  result  and  error .  result  contains useful payload object which can be different depending on  Reply .  error  contains error object in case of  Command  processing resulted in some error on server.  error  is optional and if  Reply  does not have  error  then it means that  Command  processed successfuly and client can parse  result  object in an appropriate way.  error  objects looks like this:  { \n     \"code\" :   100 , \n     \"message\" :   \"internal server error\"  }   We will talk more about error handling below.  The special type of  Reply  is asynchronous  Reply . Those replies have no  id  field set (or  id  can be equal to zero). Async replies can come to client in any moment - not as reaction to issued  Command  but as message from server to client in arbitrary time. For example this can be message published into channel.  Centrifuge library defines several command types client can issue. And well-written client must be aware of all those commands and client workflow. Communication with Centrifuge/Centrifugo server starts with  connect  command.",
            "title": "Top level framing"
        },
        {
            "location": "/server/protocol/#connect",
            "text": "First of all client must dial with server and then send  connect   Command  to it.  Default Websocket endpoint in Centrifugo is:  ws://centrifugo.example.com/connection/websocket  In case of using TLS:  wss://centrifugo.example.com/connection/websocket  After successful dial to websocket endpoint client must send  connect  command to server to authorize itself.  connect  command looks like:  { \n     \"id\" :   1 , \n     \"method\" :   \"connect\" , \n     \"params\" :   { \n         \"token\" :   \"JWT\" , \n         \"data\" :   {} \n     }  }   Where params fields are passed to client from application backend:   string  token  - connection token.  JSON  data  - this is only available for Centrifuge library and not for Centrifugo server. It contains custom connect data, for example it can contain client settings.    In response to  connect  command server sends connect reply. It looks this way:  { \n     \"id\" : 1 , \n     \"result\" : { \n         \"client\" : \"421bf374-dd01-4f82-9def-8c31697e956f\" , \n         \"version\" : \"2.0.0\" \n     }  }   result  has some fields:   string  client  - unique client connection ID server issued to this connection  string  version  - server version  optional bool  expires  - whether or not server will expire connection  optional bool  expired  - whether or not connection credentials already expired and must be refreshed  optional int32  ttl  - time in seconds until connection will expire",
            "title": "Connect"
        },
        {
            "location": "/server/protocol/#subscribe",
            "text": "As soon as client successfully connected and got unique connection ID it is ready to\nsubscribe on channels. To do this it must send  subscribe  command to server:  { \n     \"id\" :   2 , \n     \"method\" :   \"subscribe\" , \n     \"params\" :   { \n         \"channel\" :   \"ch1\" \n     }  }   Fields that can be set in  params  are:   string  channel  - channel to subscribe   In response to subscribe client receives reply like:  { \n     \"id\" : 2 , \n     \"result\" : {}  }   result  can have the following fields:   optional array  publications  - this is an array of missed publications in channel. When received client must call general publication event handler for each message in this array  optional string  last  - this field contains uid of last publication in channel. This allows fresh client which have not received publications before recover messages setting this value into next subscription request.   optional bool  recovered  - this flag is set to  true  when server thinks that all missed publications were successfully recovered and send in subscribe reply (in  publications  array) and  false  otherwise.   After client received successful reply on  subscribe  command it will receive asynchronous \nreply messages published to this channel. Messages can be of several types:   Publication message  Join message  Leave message  Unsub message   See more about asynchronous messages below.",
            "title": "Subscribe"
        },
        {
            "location": "/server/protocol/#unsubscribe",
            "text": "This is simple. When client wants to unsubscribe from channel and therefore stop receiving asynchronous subscription messages from connection related to channel it must call  unsubscribe  command:  { \n     \"id\" :   3 , \n     \"method\" :   \"unsubscribe\" , \n     \"params\" :   { \n         \"channel\" :   \"ch1\" \n     }  }   Actually server response does not mean a lot for client - it must immediately remove channel subscription from internal implementation data structures and ignore all messages related to channel.",
            "title": "Unsubscribe"
        },
        {
            "location": "/server/protocol/#refresh",
            "text": "It's possible to turn on client connection expiration mechanism on server. While enabled server will keep track of connections whose time of life (defined by  exp  timestamp) is close to the end. In this case connection will be closed. Client can prevent closing connection refreshing it's connection credentials. To do this it must send  refresh  command to server.  refresh  command similar to  connect :  { \n     \"id\" :   4 , \n     \"method\" :   \"refresh\" , \n     \"params\" :   { \n         \"token\" :   \"JWT\" \n     }  }   Just with actual  exp  and new  sign .  The tip whether or not connection must be refreshed comes in reply to  connect  command shown above - fields  expires ,  expired  and  ttl .  When client connection expire mechanism is on the value of field  expires  in connect reply is  true . In this case client implementation should look at  ttl  value which is seconds left until connection will be considered expired. Client must send  refresh  command after this  ttl  seconds. Server gives client a configured window to refresh token after  ttl  passed and then closes connection if client have not updated its token.  expired  field set to  true  when client connection already expired. In this case client should immediately send  refresh  command to update token. And after doing this it can work the usual way.",
            "title": "Refresh"
        },
        {
            "location": "/server/protocol/#rpc-like-calls-publish-history-presence",
            "text": "The mechanics of these calls is simple - client sends command and expects response from server.  publish  command allows to publish message into channel from client.   Note  To publish from client  publish  option in server configuration must be set to  true   history  allows to ask server for channel history if enabled.  presence  allows to ask server for channel presence information if enabled.",
            "title": "RPC-like calls: publish, history, presence"
        },
        {
            "location": "/server/protocol/#asynchronous-server-to-client-messages",
            "text": "There are several types of asynchronous messages that can come from server to client. All of them relate to current client subscriptions.  The most important message is  Publication :  { \n     \"result\" : { \n         \"channel\" : \"ch1\" , \n         \"data\" : { \n             \"uid\" : \"Ry4z8l6GvNMejwMxB7Sohe\" , \n             \"data\" : { \"input\" : \"1\" }, \n             \"info\" : { \n                 \"user\" : \"2694\" , \n                 \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \n                 \"conn_info\" : { \"name\" : \"Alexander\" }, \n                 \"chan_info\" : {} \n             } \n         } \n     }  }   Publication  is a message published into channel. Note that there is no  id  field in this message - this symptom\nallows to distinguish it from  Reply  to  Command .    Next message is  Join  message:  { \n     \"result\" : { \n         \"type\" : 1 , \n         \"channel\" : \"ch1\" , \n         \"data\" : { \n             \"info\" : { \n                 \"user\" : \"2694\" , \n                 \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \n                 \"conn_info\" : { \"name\" : \"Alexander\" }, \n                 \"chan_info\" : {} \n             } \n         } \n     }  }   Join  messages sent when someone joined (subscribed on) channel.   Note  To enable  Join  and  Leave  messages  join_leave  option must be enabled on server globally or for channel namespace.   Leave  messages sent when someone left (unsubscribed from) channel.  { \n     \"result\" : { \n         \"type\" : 2 , \n         \"channel\" : \"ch1\" , \n         \"data\" : { \n             \"info\" : { \n                 \"user\" : \"2694\" , \n                 \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \n                 \"conn_info\" : { \"name\" : \"Alexander\" }, \n                 \"chan_info\" : {} \n             } \n         } \n     }  }   And finally  Unsub  message that means that server unsubscribed current client from channel:  { \n     \"result\" : { \n         \"type\" : 3 , \n         \"channel\" : \"ch1\" , \n         \"data\" : {} \n     }  }   It's possible to distinguish between different types of asynchronous messages looking at  type  field (for  Publication  this field not set or  0 ).",
            "title": "Asynchronous server-to-client messages"
        },
        {
            "location": "/server/protocol/#ping-pong",
            "text": "To maintain connection alive and detect broken connections client must periodically send  ping  commands to server and expect replies to it. Ping command looks like:  { \n     \"id\" : 32 , \n     \"method\" : \"ping\"  }   Server just echoes this command back. When client does not receive ping reply for some time it must consider connection broken and try to reconnect. Recommended ping interval is 25 seconds, recommended period to wait for pong is 1-5 seconds. Though those numbers can vary.",
            "title": "Ping Pong"
        },
        {
            "location": "/server/protocol/#handle-disconnects",
            "text": "Client should handle disconnect advices from server. In websocket case disconnect advice is sent in reason field of CLOSE Websocket frame. Reason contains string which is  disconnect  object encoded into JSON (even in case of Protobuf scenario). That objects looks like:  { \n     \"reason\" :   \"shutdown\" , \n     \"reconnect\" :   true   }   It contains string reason of connection closing and advice to reconnect or not. Client should take this reconnect advice into account.  In case of network problems and random disconnect from server without well known reason client should always try to  reconnect with exponential intervals.",
            "title": "Handle disconnects"
        },
        {
            "location": "/server/protocol/#handle-errors",
            "text": "This section contains advices to error handling in client implementations.  Errors can happen during various operations and can be handled in special way in context of some commands to tolerate network and server problems.  Errors during  connect  must result in full client reconnect.  Errors during  subscribe  must result in full client reconnect if error is temporary. And be sent to subscribe error event handler of subscription if received error is persistent. Persistent errors are errors like  permission denied ,  bad request ,  namespace not found  etc. Persistent errors in most situation mean a mistake from developers side.  The special corner case is client-side timeout during  subscribe  operation. As protocol is asynchronous it's possible in this case that server will eventually subscribe client on channel but client will think that it's not subscribed. It's possible to retry subscription request and tolerate  already subscribed  error as expected. But the simplest solution is to reconnect entirely as this is simpler and gives client a chance to connect to working server instance.  Errors during rpc-like operations can be just returned to caller - i.e. user javascript code. Calls like  history  and  presence  are idempotent. You should be accurate with unidempotent operations like  publish  - in case of client timeout it's possible to send the same message into channel twice if retry publish after timeout - so if you care about this case make sure you have some protection from displaying message twice on client side (maybe some sort of unique key in payload).",
            "title": "Handle errors"
        },
        {
            "location": "/server/protocol/#client-implementation-advices",
            "text": "Here are some advices about client public API. Examples here are in Javascript language. This is just an attempt to help in developing a client - but rules here is not obligatorily the best way to implement client.  Create client instance:  var   centrifuge   =   new   Centrifuge ( \"ws://localhost:8000/connection/websocket\" ,   {});   Set connection token (in case of using Centrifugo):  centrifuge . setToken ( \"XXX\" )   Connect to server:  centrifuge . connect ();   2 event handlers can be set to  centrifuge  object:  connect  and  disconnect  centrifuge . on ( 'connect' ,   function ( context )   { \n     console . log ( context );  });  centrifuge . on ( 'disconnect' ,   function ( context )   { \n     console . log ( context );  });   Client created in  disconnected  state with  reconnect  attribute set to  true  and  reconnecting  flag set to  false  . After  connect()  called state goes to  connecting . It's only possible to connect from  disconnected  state. Every time  connect()  called  reconnect  flag of client must be set to  true . After each failed connect attempt state must be set to  disconnected ,  disconnect  event must be emitted (only if  reconnecting  flag is  false ), and then  reconnecting  flag must be set to  true  (if client should continue reconnecting) to not emit  disconnect  event again after next in a row connect attempt failure. In case of failure next connection attempt must be scheduled automatically with backof strategy. On successful connect  reconnecting  flag must be set to  false , backoff retry must be resetted and  connect  event must be emitted. When connection lost then the same set of actions as when connect failed must be performed.  Client must allow to subscribe on channels:  var   subscription   =   centrifuge . subscribe ( \"channel\" ,   eventHandlers );   Subscription object created and control immediately returned to caller - subscribing must be performed asynchronously. This is required because client can automatically reconnect later so event-based model better suites for subscriptions.   Subscription should support several event handlers:   handler for publication received from channel  join message handler  leave message handler  error handler  subscribe success event handler  unsubscribe event handler   Every time client connects to server it must restore all subscriptions.  Every time client disconnects from server it must call unsubscribe handlers for all active subscriptions and then emit disconnect event.  Client must periodically (once in 25 secs, configurable) send ping messages to server. If pong has not beed received in 5 secs (configurable) then client must disconnect from server and try to reconnect with backoff strategy.  Client can automatically batch several requests into one frame to server and also must be able to handle several replies received from server in one frame.  Timeout on subscription requests must result in full client reconnect workflow.",
            "title": "Client implementation advices"
        },
        {
            "location": "/transports/",
            "text": "This docs section describes client transports that Centrifugo supports and some specific topics and configuration regarding to each of those transports.",
            "title": "Overview"
        },
        {
            "location": "/transports/websocket/",
            "text": "Websocket\n\u00b6\n\n\nhttps://en.wikipedia.org/wiki/WebSocket\n\n\nThis chapter is work in progress.",
            "title": "Websocket"
        },
        {
            "location": "/transports/websocket/#websocket",
            "text": "https://en.wikipedia.org/wiki/WebSocket  This chapter is work in progress.",
            "title": "Websocket"
        },
        {
            "location": "/transports/sockjs/",
            "text": "SockJS\n\u00b6\n\n\nhttps://github.com/sockjs/sockjs-client\n\n\nThis chapter is work in progress.",
            "title": "SockJS"
        },
        {
            "location": "/transports/sockjs/#sockjs",
            "text": "https://github.com/sockjs/sockjs-client  This chapter is work in progress.",
            "title": "SockJS"
        },
        {
            "location": "/libraries/client/",
            "text": "Client connection libraries\n\u00b6\n\n\nIn progress:\n\n\n\n\ncentrifuge-js\n \u2013 for browser, NodeJS and React Native.\n\n\ncentrifuge-go\n - for Go language.\n\n\ncentrifuge-mobile\n - for iOS and Android using \ncentrifuge-go\n as basis and \ngomobile\n project to create bindings.\n\n\n\n\nThere are no native mobile clients at moment but hopefully this will change soon - stay tuned.",
            "title": "Client libraries"
        },
        {
            "location": "/libraries/client/#client-connection-libraries",
            "text": "In progress:   centrifuge-js  \u2013 for browser, NodeJS and React Native.  centrifuge-go  - for Go language.  centrifuge-mobile  - for iOS and Android using  centrifuge-go  as basis and  gomobile  project to create bindings.   There are no native mobile clients at moment but hopefully this will change soon - stay tuned.",
            "title": "Client connection libraries"
        },
        {
            "location": "/libraries/api/",
            "text": "HTTP API clients\n\u00b6\n\n\nIf you look at server API docs you will find that sending API request to Centrifugo is a very simple task to do in any programming language - this is just a POST request with JSON payload in body. See more in special chapter in server section.\n\n\nWe have several client libraries for different languages so you don't have to construct proper HTTP requests manually:\n\n\n\n\ncent\n for Python\n\n\nrubycent\n for Ruby (\nnot available for Centrifugo v2 yet\n)\n\n\nphpcent\n for PHP (\nnot available for Centrifugo v2 yet\n)\n\n\njscent\n for NodeJS (\nnot available for Centrifugo v2 yet\n)\n\n\ngocent\n for Go (\nnot available for Centrifugo v2 yet\n)",
            "title": "API libraries"
        },
        {
            "location": "/libraries/api/#http-api-clients",
            "text": "If you look at server API docs you will find that sending API request to Centrifugo is a very simple task to do in any programming language - this is just a POST request with JSON payload in body. See more in special chapter in server section.  We have several client libraries for different languages so you don't have to construct proper HTTP requests manually:   cent  for Python  rubycent  for Ruby ( not available for Centrifugo v2 yet )  phpcent  for PHP ( not available for Centrifugo v2 yet )  jscent  for NodeJS ( not available for Centrifugo v2 yet )  gocent  for Go ( not available for Centrifugo v2 yet )",
            "title": "HTTP API clients"
        },
        {
            "location": "/deploy/packages/",
            "text": "RPM and DEB packages\n\u00b6\n\n\nEvery time we make new Centrifugo release we upload rpm and deb packages for\npopular linux distributions on \npackagecloud.io\n.\n\n\nCurrently we support versions of the following distributions:\n\n\n\n\n64-bit Debian 8 Jessie\n\n\n64-bit Debian 9 Stretch\n\n\n64-bit Ubuntu 16.04 Xenial\n\n\n64-bit Ubuntu 18.04 Bionic\n\n\n64-bit Centos 7\n\n\n\n\nSee \nfull list of available packages\n and\n\ninstallation instructions\n.\n\n\nAlso note that if your linux distro is not in list you can ask us to package\nfor it or just download appropriate package from packagecloud that fits your\ndistribution.\n\n\nCentrifugo also works on 32-bit architectures, but we don't support packaging for it\nas 64-bit is more convenient for servers today.",
            "title": "RPM and DEB packages"
        },
        {
            "location": "/deploy/packages/#rpm-and-deb-packages",
            "text": "Every time we make new Centrifugo release we upload rpm and deb packages for\npopular linux distributions on  packagecloud.io .  Currently we support versions of the following distributions:   64-bit Debian 8 Jessie  64-bit Debian 9 Stretch  64-bit Ubuntu 16.04 Xenial  64-bit Ubuntu 18.04 Bionic  64-bit Centos 7   See  full list of available packages  and installation instructions .  Also note that if your linux distro is not in list you can ask us to package\nfor it or just download appropriate package from packagecloud that fits your\ndistribution.  Centrifugo also works on 32-bit architectures, but we don't support packaging for it\nas 64-bit is more convenient for servers today.",
            "title": "RPM and DEB packages"
        },
        {
            "location": "/deploy/docker/",
            "text": "Docker image\n\u00b6\n\n\nCentrifugo server has docker image \navailable on Docker Hub\n.\n\n\ndocker pull centrifugo/centrifugo\n\n\n\n\nRun:\n\n\ndocker run --ulimit \nnofile\n=\n65536\n:65536 -v /host/dir/with/config/file:/centrifugo -p \n8000\n:8000 centrifugo/centrifugo centrifugo -c config.json\n\n\n\n\nNote that docker allows to set \nnofile\n limits in command-line arguments which is pretty important to handle lots of simultenious persistent connections.",
            "title": "Docker image"
        },
        {
            "location": "/deploy/docker/#docker-image",
            "text": "Centrifugo server has docker image  available on Docker Hub .  docker pull centrifugo/centrifugo  Run:  docker run --ulimit  nofile = 65536 :65536 -v /host/dir/with/config/file:/centrifugo -p  8000 :8000 centrifugo/centrifugo centrifugo -c config.json  Note that docker allows to set  nofile  limits in command-line arguments which is pretty important to handle lots of simultenious persistent connections.",
            "title": "Docker image"
        },
        {
            "location": "/deploy/nginx/",
            "text": "Nginx configuration\n\u00b6\n\n\nAlthough it's possible to  use Centrifugo without any reverse proxy before it,\nit's still a good idea to keep Centrifugo behind mature reverse proxy to deal with\nedge cases when handling HTTP/Websocket connections from the wild. Also you probably\nwant some sort of load balancing eventually between Centrifugo nodes so that proxy\ncan be such a balancer too.\n\n\nIn this section we will look at \nNginx\n configuration to deploy Centrifugo.\n\n\nMinimal Nginx version \u2013 \n1.3.13\n because it was the first version that can proxy\nWebsocket connections.\n\n\nThere are 2 ways: running Centrifugo server as separate service on its own\ndomain or embed it to a location of your web site (for example to \n/centrifugo\n).\n\n\nSeparate domain for Centrifugo\n\u00b6\n\n\nupstream\n \ncentrifugo\n \n{\n\n    \n#\n \nEnumerate\n \nall\n \nupstream\n \nservers\n \nhere\n\n    \n#sticky\n;\n\n    \nip_hash\n;\n\n    \nserver\n \n127.0.0.1:8000\n;\n\n    \n#server\n \n127.0.0.1:8001\n;\n\n\n}\n\n\n\nmap\n \n$\nhttp_upgrade\n \n$\nconnection_upgrade\n \n{\n\n    \ndefault\n \nupgrade\n;\n\n    \n''\n      \nclose\n;\n\n\n}\n\n\n\n#\nserver\n \n{\n\n\n#\n   \nlisten\n \n80\n;\n\n\n#\n   \nserver_name\n \ncentrifugo.example.com\n;\n\n\n#\n   \nrewrite\n \n^(.*)\n \nhttps\n:\n//\n$\nserver_name\n$\n1\n \npermanent\n;\n\n\n#\n}\n\n\n\nserver\n \n{\n\n\n    \nserver_name\n \ncentrifugo.example.com\n;\n\n\n    \nlisten\n \n80\n;\n\n\n    \n#listen\n \n443\n;\n\n    \n#ssl\n \non\n;\n\n    \n#ssl_protocols\n \nTLSv1\n \nTLSv1.1\n \nTLSv1.2\n;\n\n    \n#ssl_ciphers\n \nAES128-SHA\n:\nAES256-SHA\n:\nRC4-SHA\n:\nDES-CBC3-SHA\n:\nRC4-MD5\n;\n\n    \n#ssl_certificate\n \n/etc/nginx/ssl/wildcard.example.com.crt\n;\n\n    \n#ssl_certificate_key\n \n/etc/nginx/ssl/wildcard.example.com.key\n;\n\n    \n#ssl_session_cache\n \nshared\n:\nSSL\n:\n10\nm\n;\nssl_session_timeout\n \n10m\n;\n\n\n    \ninclude\n \n/etc/nginx/mime.types\n;\n\n    \ndefault_type\n \napplication/octet-stream\n;\n\n\n    \nsendfile\n \non\n;\n\n    \ntcp_nopush\n \non\n;\n\n    \ntcp_nodelay\n \non\n;\n\n    \ngzip\n \non\n;\n\n    \ngzip_min_length\n \n1000\n;\n\n    \ngzip_proxied\n \nany\n;\n\n\n    \n#\n \nOnly\n \nretry\n \nif\n \nthere\n \nwas\n \na\n \ncommunication\n \nerror,\n \nnot\n \na\n \ntimeout\n\n    \n#\n \non\n \nthe\n \nTornado\n \nserver\n \n(to\n \navoid\n \npropagating\n \n\"queries\n \nof\n \ndeath\"\n\n    \n#\n \nto\n \nall\n \nfrontends)\n\n    \nproxy_next_upstream\n \nerror\n;\n\n\n    \nproxy_set_header\n \nX-Real-IP\n \n$remote_addr\n;\n\n    \nproxy_set_header\n \nX-Scheme\n \n$scheme\n;\n\n    \nproxy_set_header\n \nHost\n \n$http_host\n;\n\n\n    \nlocation\n \n/connection\n \n{\n\n        \nproxy_pass\n \nhttp\n:\n//\ncentrifugo\n;\n\n        \nproxy_buffering\n \noff\n;\n\n        \nkeepalive_timeout\n \n65\n;\n\n        \nproxy_read_timeout\n \n60s\n;\n\n        \nproxy_http_version\n \n1.1\n;\n\n        \nproxy_set_header\n \nX-Real-IP\n \n$remote_addr\n;\n\n        \nproxy_set_header\n \nX-Scheme\n \n$scheme\n;\n\n        \nproxy_set_header\n \nHost\n \n$http_host\n;\n\n        \nproxy_set_header\n \nUpgrade\n \n$http_upgrade\n;\n\n        \nproxy_set_header\n \nConnection\n \n$connection_upgrade\n;\n\n    \n}\n\n\n    \nlocation\n \n/\n \n{\n\n        \nproxy_pass\n \nhttp\n:\n//\ncentrifugo\n;\n\n    \n}\n\n\n    \nerror_page\n   \n500\n \n502\n \n503\n \n504\n  \n/\n50x\n.\nhtml\n;\n\n\n    \nlocation\n \n=\n \n/\n50x\n.\nhtml\n \n{\n\n        \nroot\n   \n/usr/share/nginx/html\n;\n\n    \n}\n\n\n\n}\n\n\n\n\n\nEmbed to a location of web site\n\u00b6\n\n\nupstream\n \ncentrifugo\n \n{\n\n    \n#\n \nEnumerate\n \nall\n \nthe\n \nTornado\n \nservers\n \nhere\n\n    \n#sticky\n;\n\n    \nip_hash\n;\n\n    \nserver\n \n127.0.0.1:8000\n;\n\n    \n#server\n \n127.0.0.1:8001\n;\n\n\n}\n\n\n\nmap\n \n$\nhttp_upgrade\n \n$\nconnection_upgrade\n \n{\n\n    \ndefault\n \nupgrade\n;\n\n    \n''\n      \nclose\n;\n\n\n}\n\n\n\nserver\n \n{\n\n\n    \n#\n \n...\n \nyour\n \nweb\n \nsite\n \nNginx\n \nconfig\n\n\n    \nlocation\n \n/centrifugo/\n \n{\n\n        \nrewrite\n \n^/centrifugo/(.*)\n        \n/$1\n \nbreak\n;\n\n        \nproxy_pass_header\n \nServer\n;\n\n        \nproxy_set_header\n \nHost\n \n$http_host\n;\n\n        \nproxy_redirect\n \noff\n;\n\n        \nproxy_set_header\n \nX-Real-IP\n \n$remote_addr\n;\n\n        \nproxy_set_header\n \nX-Scheme\n \n$scheme\n;\n\n        \nproxy_pass\n \nhttp\n:\n//\ncentrifugo\n;\n\n    \n}\n\n\n    \nlocation\n \n/\ncentrifugo\n/\nconnection\n \n{\n\n        \nrewrite\n \n^/centrifugo(.*)\n        \n$1\n \nbreak\n;\n\n\n        \nproxy_next_upstream\n \nerror\n;\n\n        \ngzip\n \non\n;\n\n        \ngzip_min_length\n \n1000\n;\n\n        \ngzip_proxied\n \nany\n;\n\n        \nproxy_buffering\n \noff\n;\n\n        \nkeepalive_timeout\n \n65\n;\n\n        \nproxy_pass\n \nhttp\n:\n//\ncentrifugo\n;\n\n        \nproxy_read_timeout\n \n60s\n;\n\n        \nproxy_set_header\n \nX-Real-IP\n \n$remote_addr\n;\n\n        \nproxy_set_header\n \nX-Scheme\n \n$scheme\n;\n\n        \nproxy_set_header\n \nHost\n \n$http_host\n;\n\n        \nproxy_http_version\n \n1.1\n;\n\n        \nproxy_set_header\n \nUpgrade\n \n$http_upgrade\n;\n\n        \nproxy_set_header\n \nConnection\n \n$connection_upgrade\n;\n\n    \n}\n\n\n\n}\n\n\n\n\n\nsticky\n\u00b6\n\n\nYou may be noticed commented \nsticky;\n directive in nginx upstream configuration.\n\n\nWhen using SockJS and client connects to Centrifugo - SockJS session created - and\nto communicate client must send all next requests to the same upstream backend.\n\n\nIn this configuration we use \nip_hash;\n directive to proxy clients with the same ip\naddress to the same upstream backend.\n\n\nBut \nip_hash;\n is not the best choice in this case, because there could be situations\nwhere a lot of different browsers are coming with the same IP address (behind proxies)\nand the load balancing system won't be fair. Also fair load balancing does not work\nduring development - when all clients connecting from localhost.\n\n\nSo the best solution would be using something like \nnginx-sticky-module\n\nwhich uses setting a special cookie to track the upstream server for client.\n\n\nworker_connections\n\u00b6\n\n\nYou may also need to update \nworker_connections\n option of Nginx:\n\n\nevents {\n    worker_connections 40000;\n}\n\n\n\n\nUpstream keepalive\n\u00b6\n\n\nSee chapter about operating system tuning for more details.",
            "title": "Nginx configuration"
        },
        {
            "location": "/deploy/nginx/#nginx-configuration",
            "text": "Although it's possible to  use Centrifugo without any reverse proxy before it,\nit's still a good idea to keep Centrifugo behind mature reverse proxy to deal with\nedge cases when handling HTTP/Websocket connections from the wild. Also you probably\nwant some sort of load balancing eventually between Centrifugo nodes so that proxy\ncan be such a balancer too.  In this section we will look at  Nginx  configuration to deploy Centrifugo.  Minimal Nginx version \u2013  1.3.13  because it was the first version that can proxy\nWebsocket connections.  There are 2 ways: running Centrifugo server as separate service on its own\ndomain or embed it to a location of your web site (for example to  /centrifugo ).",
            "title": "Nginx configuration"
        },
        {
            "location": "/deploy/nginx/#separate-domain-for-centrifugo",
            "text": "upstream   centrifugo   { \n     #   Enumerate   all   upstream   servers   here \n     #sticky ; \n     ip_hash ; \n     server   127.0.0.1:8000 ; \n     #server   127.0.0.1:8001 ;  }  map   $ http_upgrade   $ connection_upgrade   { \n     default   upgrade ; \n     ''        close ;  }  # server   {  #     listen   80 ;  #     server_name   centrifugo.example.com ;  #     rewrite   ^(.*)   https : // $ server_name $ 1   permanent ;  # }  server   { \n\n     server_name   centrifugo.example.com ; \n\n     listen   80 ; \n\n     #listen   443 ; \n     #ssl   on ; \n     #ssl_protocols   TLSv1   TLSv1.1   TLSv1.2 ; \n     #ssl_ciphers   AES128-SHA : AES256-SHA : RC4-SHA : DES-CBC3-SHA : RC4-MD5 ; \n     #ssl_certificate   /etc/nginx/ssl/wildcard.example.com.crt ; \n     #ssl_certificate_key   /etc/nginx/ssl/wildcard.example.com.key ; \n     #ssl_session_cache   shared : SSL : 10 m ; ssl_session_timeout   10m ; \n\n     include   /etc/nginx/mime.types ; \n     default_type   application/octet-stream ; \n\n     sendfile   on ; \n     tcp_nopush   on ; \n     tcp_nodelay   on ; \n     gzip   on ; \n     gzip_min_length   1000 ; \n     gzip_proxied   any ; \n\n     #   Only   retry   if   there   was   a   communication   error,   not   a   timeout \n     #   on   the   Tornado   server   (to   avoid   propagating   \"queries   of   death\" \n     #   to   all   frontends) \n     proxy_next_upstream   error ; \n\n     proxy_set_header   X-Real-IP   $remote_addr ; \n     proxy_set_header   X-Scheme   $scheme ; \n     proxy_set_header   Host   $http_host ; \n\n     location   /connection   { \n         proxy_pass   http : // centrifugo ; \n         proxy_buffering   off ; \n         keepalive_timeout   65 ; \n         proxy_read_timeout   60s ; \n         proxy_http_version   1.1 ; \n         proxy_set_header   X-Real-IP   $remote_addr ; \n         proxy_set_header   X-Scheme   $scheme ; \n         proxy_set_header   Host   $http_host ; \n         proxy_set_header   Upgrade   $http_upgrade ; \n         proxy_set_header   Connection   $connection_upgrade ; \n     } \n\n     location   /   { \n         proxy_pass   http : // centrifugo ; \n     } \n\n     error_page     500   502   503   504    / 50x . html ; \n\n     location   =   / 50x . html   { \n         root     /usr/share/nginx/html ; \n     }  }",
            "title": "Separate domain for Centrifugo"
        },
        {
            "location": "/deploy/nginx/#embed-to-a-location-of-web-site",
            "text": "upstream   centrifugo   { \n     #   Enumerate   all   the   Tornado   servers   here \n     #sticky ; \n     ip_hash ; \n     server   127.0.0.1:8000 ; \n     #server   127.0.0.1:8001 ;  }  map   $ http_upgrade   $ connection_upgrade   { \n     default   upgrade ; \n     ''        close ;  }  server   { \n\n     #   ...   your   web   site   Nginx   config \n\n     location   /centrifugo/   { \n         rewrite   ^/centrifugo/(.*)          /$1   break ; \n         proxy_pass_header   Server ; \n         proxy_set_header   Host   $http_host ; \n         proxy_redirect   off ; \n         proxy_set_header   X-Real-IP   $remote_addr ; \n         proxy_set_header   X-Scheme   $scheme ; \n         proxy_pass   http : // centrifugo ; \n     } \n\n     location   / centrifugo / connection   { \n         rewrite   ^/centrifugo(.*)          $1   break ; \n\n         proxy_next_upstream   error ; \n         gzip   on ; \n         gzip_min_length   1000 ; \n         gzip_proxied   any ; \n         proxy_buffering   off ; \n         keepalive_timeout   65 ; \n         proxy_pass   http : // centrifugo ; \n         proxy_read_timeout   60s ; \n         proxy_set_header   X-Real-IP   $remote_addr ; \n         proxy_set_header   X-Scheme   $scheme ; \n         proxy_set_header   Host   $http_host ; \n         proxy_http_version   1.1 ; \n         proxy_set_header   Upgrade   $http_upgrade ; \n         proxy_set_header   Connection   $connection_upgrade ; \n     }  }",
            "title": "Embed to a location of web site"
        },
        {
            "location": "/deploy/nginx/#sticky",
            "text": "You may be noticed commented  sticky;  directive in nginx upstream configuration.  When using SockJS and client connects to Centrifugo - SockJS session created - and\nto communicate client must send all next requests to the same upstream backend.  In this configuration we use  ip_hash;  directive to proxy clients with the same ip\naddress to the same upstream backend.  But  ip_hash;  is not the best choice in this case, because there could be situations\nwhere a lot of different browsers are coming with the same IP address (behind proxies)\nand the load balancing system won't be fair. Also fair load balancing does not work\nduring development - when all clients connecting from localhost.  So the best solution would be using something like  nginx-sticky-module \nwhich uses setting a special cookie to track the upstream server for client.",
            "title": "sticky"
        },
        {
            "location": "/deploy/nginx/#worker_connections",
            "text": "You may also need to update  worker_connections  option of Nginx:  events {\n    worker_connections 40000;\n}",
            "title": "worker_connections"
        },
        {
            "location": "/deploy/nginx/#upstream-keepalive",
            "text": "See chapter about operating system tuning for more details.",
            "title": "Upstream keepalive"
        },
        {
            "location": "/deploy/tls/",
            "text": "TLS\n\u00b6\n\n\nTLS/SSL layer is very important not only for securing your connections but also to increase a\nchance to establish Websocket connection. \nIn most situations you will put TLS termination task\non your reverse proxy/load balancing software such as Nginx\n.\n\n\nThere are situations though when you want to serve secure connections by Centrifugo itself.\n\n\nThere are two ways to do this: using TLS certificate \ncert\n and \nkey\n files that you've got\nfrom your CA provider or using automatic certificate handling via \nACME\n provider (only\n\nLet's Encrypt\n at this moment).\n\n\nUsing crt and key files\n\u00b6\n\n\nIn first way you already have \ncert\n and \nkey\n files. For development you can create self-signed\ncertificate - see \nthis instruction\n as\nexample.\n\n\nThen to start Centrifugo use the following command:\n\n\n./centrifugo --config=config.json --tls --tls_key=server.key --tls_cert=server.crt\n\n\n\n\nOr just use configuration file:\n\n\n{\n\n  \n...\n\n  \n\"tls\"\n:\n \ntrue\n,\n\n  \n\"tls_key\"\n:\n \n\"server.key\"\n,\n\n  \n\"tls_cert\"\n:\n \n\"server.crt\"\n\n\n}\n\n\n\n\n\nAnd run:\n\n\n./centrifugo --config=config.json\n\n\n\n\nAutomatic certificates\n\u00b6\n\n\nFor automatic certificates from Let's Encrypt add into configuration file:\n\n\n{\n  ...\n  \"tls_autocert\": true,\n  \"tls_autocert_host_whitelist\": \"www.example.com\",\n  \"tls_autocert_cache_dir\": \"/tmp/certs\",\n  \"tls_autocert_email\": \"user@example.com\",\n  \"tls_autocert_http\": true,\n  \"tls_autocert_http_addr\": \":80\"\n}\n\n\n\n\ntls_autocert\n (boolean) says Centrifugo that you want automatic certificate handling using ACME provider.\n\n\ntls_autocert_host_whitelist\n (string) is a string with your app domain address. This can be comma-separated\nlist. It's optional but recommended for extra security.\n\n\ntls_autocert_cache_dir\n (string) is a path to a folder to cache issued certificate files. This is optional\nbut will increase performance.\n\n\ntls_autocert_email\n (string) is optional - it's an email address ACME provider will send notifications\nabout problems with your certificates.\n\n\ntls_autocert_http\n (boolean) is an option to handle http_01 ACME challenge on non-TLS port.\n\n\ntls_autocert_http_addr\n (string) can be used to set address for handling http_01 ACME challenge (default is \n:80\n)\n\n\nWhen configured correctly and your domain is valid (\nlocalhost\n will not work) - certificates\nwill be retrieved on first request to Centrifugo.\n\n\nAlso Let's Encrypt certificates will be automatically renewed.\n\n\nThere are tho options that allow Centrifugo to support TLS client connections from older\nbrowsers such as Chrome 49 on Windows XP and IE8 on XP:\n\n\n\n\ntls_autocert_force_rsa\n - this is a boolean option, by default \nfalse\n. When enabled it forces\n    autocert manager generate certificates with 2048-bit RSA keys.\n\n\ntls_autocert_server_name\n - string option, allows to set server name for client handshake hello.\n    This can be useful to deal with old browsers without SNI support - see \ncomment",
            "title": "TLS"
        },
        {
            "location": "/deploy/tls/#tls",
            "text": "TLS/SSL layer is very important not only for securing your connections but also to increase a\nchance to establish Websocket connection.  In most situations you will put TLS termination task\non your reverse proxy/load balancing software such as Nginx .  There are situations though when you want to serve secure connections by Centrifugo itself.  There are two ways to do this: using TLS certificate  cert  and  key  files that you've got\nfrom your CA provider or using automatic certificate handling via  ACME  provider (only Let's Encrypt  at this moment).",
            "title": "TLS"
        },
        {
            "location": "/deploy/tls/#using-crt-and-key-files",
            "text": "In first way you already have  cert  and  key  files. For development you can create self-signed\ncertificate - see  this instruction  as\nexample.  Then to start Centrifugo use the following command:  ./centrifugo --config=config.json --tls --tls_key=server.key --tls_cert=server.crt  Or just use configuration file:  { \n   ... \n   \"tls\" :   true , \n   \"tls_key\" :   \"server.key\" , \n   \"tls_cert\" :   \"server.crt\"  }   And run:  ./centrifugo --config=config.json",
            "title": "Using crt and key files"
        },
        {
            "location": "/deploy/tls/#automatic-certificates",
            "text": "For automatic certificates from Let's Encrypt add into configuration file:  {\n  ...\n  \"tls_autocert\": true,\n  \"tls_autocert_host_whitelist\": \"www.example.com\",\n  \"tls_autocert_cache_dir\": \"/tmp/certs\",\n  \"tls_autocert_email\": \"user@example.com\",\n  \"tls_autocert_http\": true,\n  \"tls_autocert_http_addr\": \":80\"\n}  tls_autocert  (boolean) says Centrifugo that you want automatic certificate handling using ACME provider.  tls_autocert_host_whitelist  (string) is a string with your app domain address. This can be comma-separated\nlist. It's optional but recommended for extra security.  tls_autocert_cache_dir  (string) is a path to a folder to cache issued certificate files. This is optional\nbut will increase performance.  tls_autocert_email  (string) is optional - it's an email address ACME provider will send notifications\nabout problems with your certificates.  tls_autocert_http  (boolean) is an option to handle http_01 ACME challenge on non-TLS port.  tls_autocert_http_addr  (string) can be used to set address for handling http_01 ACME challenge (default is  :80 )  When configured correctly and your domain is valid ( localhost  will not work) - certificates\nwill be retrieved on first request to Centrifugo.  Also Let's Encrypt certificates will be automatically renewed.  There are tho options that allow Centrifugo to support TLS client connections from older\nbrowsers such as Chrome 49 on Windows XP and IE8 on XP:   tls_autocert_force_rsa  - this is a boolean option, by default  false . When enabled it forces\n    autocert manager generate certificates with 2048-bit RSA keys.  tls_autocert_server_name  - string option, allows to set server name for client handshake hello.\n    This can be useful to deal with old browsers without SNI support - see  comment",
            "title": "Automatic certificates"
        },
        {
            "location": "/deploy/redis/",
            "text": "Redis\n\u00b6\n\n\nThis section describes some aspects about deploying Redis for Centrifugo server.\n\n\nSentinel for high availability\n\u00b6\n\n\nCentrifugo supports official way to add high availability to Redis - Redis \nSentinel\n.\n\n\nFor this you only need to utilize 2 Redis Engine options: \nredis_master_name\n and \nredis_sentinels\n.\n\n\nredis_master_name\n - is a name of master your Sentinels monitor.\n\n\nredis_sentinels\n - comma-separated addresses of Sentinel servers. At least one known server required.\n\n\nSo you can start Centrifugo which will use Sentinels to discover redis master instance like this:\n\n\ncentrifugo --config=config.json --engine=redis --redis_master_name=mymaster --redis_sentinels=\":26379\"\n\n\n\n\nSentinel configuration files can look like this:\n\n\nport 26379\nsentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 10000\nsentinel failover-timeout mymaster 60000\n\n\n\n\nYou can find how to properly setup Sentinels \nin official documentation\n.\n\n\nNote that when your redis master instance down there will be small downtime interval until Sentinels\ndiscover a problem and come to quorum decision about new master. The length of this period depends on\nSentinel configuration.",
            "title": "Redis HA"
        },
        {
            "location": "/deploy/redis/#redis",
            "text": "This section describes some aspects about deploying Redis for Centrifugo server.",
            "title": "Redis"
        },
        {
            "location": "/deploy/redis/#sentinel-for-high-availability",
            "text": "Centrifugo supports official way to add high availability to Redis - Redis  Sentinel .  For this you only need to utilize 2 Redis Engine options:  redis_master_name  and  redis_sentinels .  redis_master_name  - is a name of master your Sentinels monitor.  redis_sentinels  - comma-separated addresses of Sentinel servers. At least one known server required.  So you can start Centrifugo which will use Sentinels to discover redis master instance like this:  centrifugo --config=config.json --engine=redis --redis_master_name=mymaster --redis_sentinels=\":26379\"  Sentinel configuration files can look like this:  port 26379\nsentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 10000\nsentinel failover-timeout mymaster 60000  You can find how to properly setup Sentinels  in official documentation .  Note that when your redis master instance down there will be small downtime interval until Sentinels\ndiscover a problem and come to quorum decision about new master. The length of this period depends on\nSentinel configuration.",
            "title": "Sentinel for high availability"
        },
        {
            "location": "/deploy/tuning/",
            "text": "Tuning operating system\n\u00b6\n\n\nAs Centrifugo/Centrifuge deals with lots of persistent connections your operating system must be\nready for it.\n\n\nopen files limit\n\u00b6\n\n\nFirst of all you should increase a max number of open files your processes can open.\n\n\nTo get you current open files limit run:\n\n\nulimit -n\n\n\n\n\nThe result shows approximately how many clients your server can handle.\n\n\nSee http://docs.basho.com/riak/latest/ops/tuning/open-files-limit/ to know how to increase this number.\n\n\nIf you install Centrifugo using RPM from repo then it automatically sets max open files limit to 32768.\n\n\nYou may also need to increase max open files for Nginx.\n\n\nlots of sockets in TIME_WAIT state.\n\u00b6\n\n\nLook how many socket descriptors in TIME_WAIT state.\n\n\nnetstat -an |grep TIME_WAIT | grep CENTRIFUGO_PID | wc -l\n\n\n\n\nUnder load when lots of connections and disconnection happen lots of used socket descriptors can\nstay in TIME_WAIT state. Those descriptors can not be reused for a while. So you can get various\nerrors when using Centrifugo. For example something like \n(99: Cannot assign requested address)while connecting to upstream\n in Nginx error log and 502 on client side. In this case there are\nseveral advices that can help.\n\n\nNice article about TIME_WAIT sockets: http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html\n\n\nThere is a perfect article about operating system tuning for lots of connections: https://engineering.gosquared.com/optimising-nginx-node-js-and-networking-for-heavy-workloads.\n\n\nTo summarize:\n\n\n\n\nIncrease ip_local_port_range\n\n\nIf you are using Nginx set \nkeepalive\n directive in upstream.\n\n\n\n\nupstream\n \ncentrifugo\n \n{\n\n    \n#sticky\n;\n\n    \nip_hash\n;\n\n    \nserver\n \n127.0.0.1:8000\n;\n\n    \nkeepalive\n \n512\n;\n\n\n}\n\n\n\n\n\n\n\nAnd finally if the problem is not gone away consider trying to enable \nnet.ipv4.tcp_tw_reuse",
            "title": "OS tuning"
        },
        {
            "location": "/deploy/tuning/#tuning-operating-system",
            "text": "As Centrifugo/Centrifuge deals with lots of persistent connections your operating system must be\nready for it.",
            "title": "Tuning operating system"
        },
        {
            "location": "/deploy/tuning/#open-files-limit",
            "text": "First of all you should increase a max number of open files your processes can open.  To get you current open files limit run:  ulimit -n  The result shows approximately how many clients your server can handle.  See http://docs.basho.com/riak/latest/ops/tuning/open-files-limit/ to know how to increase this number.  If you install Centrifugo using RPM from repo then it automatically sets max open files limit to 32768.  You may also need to increase max open files for Nginx.",
            "title": "open files limit"
        },
        {
            "location": "/deploy/tuning/#lots-of-sockets-in-time_wait-state",
            "text": "Look how many socket descriptors in TIME_WAIT state.  netstat -an |grep TIME_WAIT | grep CENTRIFUGO_PID | wc -l  Under load when lots of connections and disconnection happen lots of used socket descriptors can\nstay in TIME_WAIT state. Those descriptors can not be reused for a while. So you can get various\nerrors when using Centrifugo. For example something like  (99: Cannot assign requested address)while connecting to upstream  in Nginx error log and 502 on client side. In this case there are\nseveral advices that can help.  Nice article about TIME_WAIT sockets: http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html  There is a perfect article about operating system tuning for lots of connections: https://engineering.gosquared.com/optimising-nginx-node-js-and-networking-for-heavy-workloads.  To summarize:   Increase ip_local_port_range  If you are using Nginx set  keepalive  directive in upstream.   upstream   centrifugo   { \n     #sticky ; \n     ip_hash ; \n     server   127.0.0.1:8000 ; \n     keepalive   512 ;  }    And finally if the problem is not gone away consider trying to enable  net.ipv4.tcp_tw_reuse",
            "title": "lots of sockets in TIME_WAIT state."
        },
        {
            "location": "/faq/",
            "text": "FAQ\n\u00b6\n\n\nAnswers on various questions here.\n\n\nHow many connections can one Centrifugo instance handle?\n\u00b6\n\n\nThis depends on many factors. Hardware, message rate, size of messages, channel options enabled, client distribution over channels, websocket compression on/off etc. So no certain answer on this question exists. Common sense, tests and monitoring can help here. Generally we suggest to not put more than 50-100k clients on one node - but you should measure.\n\n\nCan Centrifugo scale horizontally?\n\u00b6\n\n\nYes, it can. It can do this using builtin Redis Engine. Redis is very fast \u2013 for example it can handle hundreds of thousands requests per second. This should be OK for most applications in internet. But if you are using Centrifugo and approaching this limit then it's possible to add sharding support to balance queries between different Redis instances.\n\n\nMessage delivery model and message order guarantees\n\u00b6\n\n\nThe model of message delivery of Centrifugo server is at most once.\n\n\nThis means that message you send to Centrifugo can be theoretically lost while moving towards your clients. Centrifugo tries to do a best effort to prevent message losses but you should be aware of this fact. Your application should tolerate this. Centrifugo has an option to automatically recover messages that have been lost because of short network disconnections. But there are cases when Centrifugo can't guarantee message delivery. We also recommend to model your applications in a way that users don't notice when message have been lost. For example if your user posts a new comment over AJAX call to your application backend - you should not rely only on Centrifugo to get new comment form and display it - you should return new comment data in AJAX call response and render it. Be careful to not draw comments twice in this case.\n\n\nMessage order in channels guaranteed to be the same while you publish messages into channel one after another or publish them in one request. If you do parallel publishes into the same channel then Centrifugo can't guarantee message order.\n\n\nCentrifugo stops accepting new connections, why?\n\u00b6\n\n\nThe most popular reason behind this is reaching open file limit. Just make it higher, we described how to do this nearby in this doc.\n\n\nCan I use Centrifugo without reverse-proxy like Nginx before it?\n\u00b6\n\n\nYes, you can - Go standard library designed to allow this. But proxy before Centrifugo can\nbe very useful for load balancing clients for example.\n\n\nDoes Centrifugo work with HTTP/2?\n\u00b6\n\n\nYes, Centrifugo works with HTTP/2.\n\n\nYou can disable HTTP/2 running Centrifugo server with \nGODEBUG\n environment variable:\n\n\nGODEBUG=\"http2server=0\" centrifugo -c config.json\n\n\n\n\nIs there a way to use single connection to Centrifugo from different browser tabs?\n\u00b6\n\n\nIf underlying transport is HTTP-based and you use HTTP/2 then this will work automatically. In case of websocket connection there is a way to do this using \nSharedWorker\n object though we have no support to work this way in our Javascript library.\n\n\nWhat if I need to send push notifications to mobile or web applications?\n\u00b6\n\n\nSometimes it's confusing to see a difference between real-time messages and push notifications. Centrifugo is a real-time messaging server. It can not send push notifications to devices - to Apple iOS devices via APNS, Android devices via GCM or browsers over Web Push API. This is a goal for another software. But the reasonable question here is how can I know when I need to send real-time message to client online or push notification to its device because application closed at client's device at moment. The solution is pretty simple. You can keep critical notifications for client in database. And when client read message send ack to your backend marking that notification as read by client, you save this ack too. Periodically you can check which notifications were sent to clients but they have not read it (no ack received). For such notification you can send push notification to its device using your own or another open-source solution. Look at Firebase for example!\n\n\nCan I know message was really delivered to client?\n\u00b6\n\n\nYou can but Centrifugo does not have such API. What you have to do to ensure your client received message is sending confirmation ack from your client to your application backend as soon as client processed message coming from Centrifugo channel.\n\n\nCan I publish new messages over websocket connection from client?\n\u00b6\n\n\nCentrifugo designed to stream messages from server to client. Even though it's possible to publish messages into channels directly from client (when \npublish\n channel option enabled) - we strongly discourage this in production usage as those messages will go through Centrifugo without any control. Of course Centrifugo could resend those message to your application endpoint but it would be very inefficient and much worse than just sending new events from client to your backend.\n\n\nSo in general when user generates an event it must be first delivered to your app backend using a convenient way (for example AJAX POST request for web application), processed on backend (validated, saved into main application database) and then published to Centrifugo using Centrifugo HTTP API or Redis queue.\n\n\nSometimes publishing from client directly into channel can be useful though - for personal projects, for demonstrations (like we do in our \nexamples\n) or if you trust your users and want to build application without backend. In all cases when you don't need any message control\non your backend.\n\n\nHow to create secure channel for two users only (private chat case)?\n\u00b6\n\n\nThere are several ways to achieve it:\n\n\n\n\nuse private channel (starting with \n$\n) - every time user will try to subscribe on it your backend should provide sign to confirm that subscription request. Read more in \nspecial chapter about private channels\n\n\nnext is \nuser limited channels\n (with \n#\n) - you can create channel with name like \ndialog#42,567\n to limit subscribers only to user with id \n42\n and user with ID \n567\n\n\nfinally you can create hard to guess channel name (based on some secret key and user IDs or just generate and save this long unique name into your main app database) so other users won't know this channel to subscribe on it. This is the simplest but not the safest way - but can be reasonable to consider in many situations.\n\n\n\n\nWhat's a best way to organize channel configuration?\n\u00b6\n\n\nIn most situations your application need several real-time features. We suggest to use namespaces for every real-time feature if it requires some option enabled.\n\n\nFor example if you need join/leave messages for chat app - create special channel namespace with this \njoin_leave\n option enabled. Otherwise your other channels will receive join/leave messages too - increasing load and traffic in system but not actually used by clients.\n\n\nThe same relates to other channel options.\n\n\nCan I rely on Centrifugo and its message history for guaranteed message delivery?\n\u00b6\n\n\nNo - Centrifugo is best-effort transport. This means that if you want strongly guaranteed message delivery to your clients then you can't just rely on Centrifugo and its message history cache. In this case you still can use Centrifugo for real-time but you should build some additional logic on top your application backend and main data storage to satisfy your guarantees.\n\n\nCentrifugo can keep message history for a while and you can want to rely on it for your needs. Centrifugo is not designed as data storage - it uses message history mostly for recovering missed messages after short client internet connection disconnects. It's not designed to be used to sync client state after being offline for a long time - this logic should be on your app backend.\n\n\nI have not found an answer on my question here:\n\u00b6\n\n\nWe have \ngitter chat room\n - welcome!",
            "title": "FAQ"
        },
        {
            "location": "/faq/#faq",
            "text": "Answers on various questions here.",
            "title": "FAQ"
        },
        {
            "location": "/faq/#how-many-connections-can-one-centrifugo-instance-handle",
            "text": "This depends on many factors. Hardware, message rate, size of messages, channel options enabled, client distribution over channels, websocket compression on/off etc. So no certain answer on this question exists. Common sense, tests and monitoring can help here. Generally we suggest to not put more than 50-100k clients on one node - but you should measure.",
            "title": "How many connections can one Centrifugo instance handle?"
        },
        {
            "location": "/faq/#can-centrifugo-scale-horizontally",
            "text": "Yes, it can. It can do this using builtin Redis Engine. Redis is very fast \u2013 for example it can handle hundreds of thousands requests per second. This should be OK for most applications in internet. But if you are using Centrifugo and approaching this limit then it's possible to add sharding support to balance queries between different Redis instances.",
            "title": "Can Centrifugo scale horizontally?"
        },
        {
            "location": "/faq/#message-delivery-model-and-message-order-guarantees",
            "text": "The model of message delivery of Centrifugo server is at most once.  This means that message you send to Centrifugo can be theoretically lost while moving towards your clients. Centrifugo tries to do a best effort to prevent message losses but you should be aware of this fact. Your application should tolerate this. Centrifugo has an option to automatically recover messages that have been lost because of short network disconnections. But there are cases when Centrifugo can't guarantee message delivery. We also recommend to model your applications in a way that users don't notice when message have been lost. For example if your user posts a new comment over AJAX call to your application backend - you should not rely only on Centrifugo to get new comment form and display it - you should return new comment data in AJAX call response and render it. Be careful to not draw comments twice in this case.  Message order in channels guaranteed to be the same while you publish messages into channel one after another or publish them in one request. If you do parallel publishes into the same channel then Centrifugo can't guarantee message order.",
            "title": "Message delivery model and message order guarantees"
        },
        {
            "location": "/faq/#centrifugo-stops-accepting-new-connections-why",
            "text": "The most popular reason behind this is reaching open file limit. Just make it higher, we described how to do this nearby in this doc.",
            "title": "Centrifugo stops accepting new connections, why?"
        },
        {
            "location": "/faq/#can-i-use-centrifugo-without-reverse-proxy-like-nginx-before-it",
            "text": "Yes, you can - Go standard library designed to allow this. But proxy before Centrifugo can\nbe very useful for load balancing clients for example.",
            "title": "Can I use Centrifugo without reverse-proxy like Nginx before it?"
        },
        {
            "location": "/faq/#does-centrifugo-work-with-http2",
            "text": "Yes, Centrifugo works with HTTP/2.  You can disable HTTP/2 running Centrifugo server with  GODEBUG  environment variable:  GODEBUG=\"http2server=0\" centrifugo -c config.json",
            "title": "Does Centrifugo work with HTTP/2?"
        },
        {
            "location": "/faq/#is-there-a-way-to-use-single-connection-to-centrifugo-from-different-browser-tabs",
            "text": "If underlying transport is HTTP-based and you use HTTP/2 then this will work automatically. In case of websocket connection there is a way to do this using  SharedWorker  object though we have no support to work this way in our Javascript library.",
            "title": "Is there a way to use single connection to Centrifugo from different browser tabs?"
        },
        {
            "location": "/faq/#what-if-i-need-to-send-push-notifications-to-mobile-or-web-applications",
            "text": "Sometimes it's confusing to see a difference between real-time messages and push notifications. Centrifugo is a real-time messaging server. It can not send push notifications to devices - to Apple iOS devices via APNS, Android devices via GCM or browsers over Web Push API. This is a goal for another software. But the reasonable question here is how can I know when I need to send real-time message to client online or push notification to its device because application closed at client's device at moment. The solution is pretty simple. You can keep critical notifications for client in database. And when client read message send ack to your backend marking that notification as read by client, you save this ack too. Periodically you can check which notifications were sent to clients but they have not read it (no ack received). For such notification you can send push notification to its device using your own or another open-source solution. Look at Firebase for example!",
            "title": "What if I need to send push notifications to mobile or web applications?"
        },
        {
            "location": "/faq/#can-i-know-message-was-really-delivered-to-client",
            "text": "You can but Centrifugo does not have such API. What you have to do to ensure your client received message is sending confirmation ack from your client to your application backend as soon as client processed message coming from Centrifugo channel.",
            "title": "Can I know message was really delivered to client?"
        },
        {
            "location": "/faq/#can-i-publish-new-messages-over-websocket-connection-from-client",
            "text": "Centrifugo designed to stream messages from server to client. Even though it's possible to publish messages into channels directly from client (when  publish  channel option enabled) - we strongly discourage this in production usage as those messages will go through Centrifugo without any control. Of course Centrifugo could resend those message to your application endpoint but it would be very inefficient and much worse than just sending new events from client to your backend.  So in general when user generates an event it must be first delivered to your app backend using a convenient way (for example AJAX POST request for web application), processed on backend (validated, saved into main application database) and then published to Centrifugo using Centrifugo HTTP API or Redis queue.  Sometimes publishing from client directly into channel can be useful though - for personal projects, for demonstrations (like we do in our  examples ) or if you trust your users and want to build application without backend. In all cases when you don't need any message control\non your backend.",
            "title": "Can I publish new messages over websocket connection from client?"
        },
        {
            "location": "/faq/#how-to-create-secure-channel-for-two-users-only-private-chat-case",
            "text": "There are several ways to achieve it:   use private channel (starting with  $ ) - every time user will try to subscribe on it your backend should provide sign to confirm that subscription request. Read more in  special chapter about private channels  next is  user limited channels  (with  # ) - you can create channel with name like  dialog#42,567  to limit subscribers only to user with id  42  and user with ID  567  finally you can create hard to guess channel name (based on some secret key and user IDs or just generate and save this long unique name into your main app database) so other users won't know this channel to subscribe on it. This is the simplest but not the safest way - but can be reasonable to consider in many situations.",
            "title": "How to create secure channel for two users only (private chat case)?"
        },
        {
            "location": "/faq/#whats-a-best-way-to-organize-channel-configuration",
            "text": "In most situations your application need several real-time features. We suggest to use namespaces for every real-time feature if it requires some option enabled.  For example if you need join/leave messages for chat app - create special channel namespace with this  join_leave  option enabled. Otherwise your other channels will receive join/leave messages too - increasing load and traffic in system but not actually used by clients.  The same relates to other channel options.",
            "title": "What's a best way to organize channel configuration?"
        },
        {
            "location": "/faq/#can-i-rely-on-centrifugo-and-its-message-history-for-guaranteed-message-delivery",
            "text": "No - Centrifugo is best-effort transport. This means that if you want strongly guaranteed message delivery to your clients then you can't just rely on Centrifugo and its message history cache. In this case you still can use Centrifugo for real-time but you should build some additional logic on top your application backend and main data storage to satisfy your guarantees.  Centrifugo can keep message history for a while and you can want to rely on it for your needs. Centrifugo is not designed as data storage - it uses message history mostly for recovering missed messages after short client internet connection disconnects. It's not designed to be used to sync client state after being offline for a long time - this logic should be on your app backend.",
            "title": "Can I rely on Centrifugo and its message history for guaranteed message delivery?"
        },
        {
            "location": "/faq/#i-have-not-found-an-answer-on-my-question-here",
            "text": "We have  gitter chat room  - welcome!",
            "title": "I have not found an answer on my question here:"
        }
    ]
}