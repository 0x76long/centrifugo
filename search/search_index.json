{
    "docs": [
        {
            "location": "/",
            "text": "Centrifugo\n\u00b6\n\n\nThis is a work in progress documentation for Centrifugo v2\n\n\nCentrifugo is a language-agnostic real-time server. It's main goal is to help adding real-time messages to your application. Language-agnostic means that it does not matter which programming language your application uses on frontend or backend sides - Centrifugo can work in conjunction with any. Real-time messages are messages that delivered to your clients almost immediately after some event happened - think live comments, real-time charts, updated counters.\n\n\nThere are several main transports Centrifugo supports at moment:\n\n\n\n\nSockJS (library that tries to establish Websocket connection and falls back to HTTP transports automatically in case of problems with Websockets)\n\n\nWebsocket (JSON or binary Protobuf)\n\n\nGRPC\n\n\n\n\nOverview\n\u00b6\n\n\nOverview",
            "title": "Getting Started"
        },
        {
            "location": "/#centrifugo",
            "text": "This is a work in progress documentation for Centrifugo v2  Centrifugo is a language-agnostic real-time server. It's main goal is to help adding real-time messages to your application. Language-agnostic means that it does not matter which programming language your application uses on frontend or backend sides - Centrifugo can work in conjunction with any. Real-time messages are messages that delivered to your clients almost immediately after some event happened - think live comments, real-time charts, updated counters.  There are several main transports Centrifugo supports at moment:   SockJS (library that tries to establish Websocket connection and falls back to HTTP transports automatically in case of problems with Websockets)  Websocket (JSON or binary Protobuf)  GRPC",
            "title": "Centrifugo"
        },
        {
            "location": "/#overview",
            "text": "Overview",
            "title": "Overview"
        },
        {
            "location": "/concepts/",
            "text": "Concepts\n\u00b6\n\n\nCentrifugo is language-agnostic real-time server. It is running as standalone server and takes care of handling persistent connections from your frontend application users. Your application backend and frontend can be written in any programming language. Your clients connect to Centrifugo from frontend using connection credentials provided by application backend, subscribe on channels. As soon as some event happens your application backend can publish message with event into channel using Centrifugo API. And that message will be delivered to all clients currently subscribed on channel. Here is a simplified scheme:",
            "title": "Concepts"
        },
        {
            "location": "/concepts/#concepts",
            "text": "Centrifugo is language-agnostic real-time server. It is running as standalone server and takes care of handling persistent connections from your frontend application users. Your application backend and frontend can be written in any programming language. Your clients connect to Centrifugo from frontend using connection credentials provided by application backend, subscribe on channels. As soon as some event happens your application backend can publish message with event into channel using Centrifugo API. And that message will be delivered to all clients currently subscribed on channel. Here is a simplified scheme:",
            "title": "Concepts"
        },
        {
            "location": "/server/",
            "text": "Server overview\n\u00b6\n\n\nCentrifugo server is written in Go language. It's an open-source software, the source code is available \non Github\n.\n\n\nCentrifugo is built around \ncentrifuge\n library for Go language. That library defines custom protocol and message types which must be sent over various transports (Websocket, GRPC, SockJS). Server clients use that protocol internally and provide simple API to features - making persistent connection, subscribing on channels, calling RPC commands and more.\n\n\nThis documentation chapter covers some server concepts in detail. This is documentation for Centrifugo server but many things said here are also valid for centrifuge library as it's a core of Centrifugo server.",
            "title": "Overview"
        },
        {
            "location": "/server/#server-overview",
            "text": "Centrifugo server is written in Go language. It's an open-source software, the source code is available  on Github .  Centrifugo is built around  centrifuge  library for Go language. That library defines custom protocol and message types which must be sent over various transports (Websocket, GRPC, SockJS). Server clients use that protocol internally and provide simple API to features - making persistent connection, subscribing on channels, calling RPC commands and more.  This documentation chapter covers some server concepts in detail. This is documentation for Centrifugo server but many things said here are also valid for centrifuge library as it's a core of Centrifugo server.",
            "title": "Server overview"
        },
        {
            "location": "/server/install/",
            "text": "Install and quick start\n\u00b6\n\n\nGo is a perfect language - it gives developers an opportunity to have single binary executable file for application and cross-compile application on all target operating systems for distribution. This means that all you need to get Centrifugo \u2013 \ndownload latest release\n for you operating system, unpack it and you are done!\n\n\nNow you can see help information for Centrifugo:\n\n\n./centrifugo -h\n\n\n\n\nCentrifugo server node requires configuration file with secret key. If you are new to Centrifugo then there is \ngenconfig\n command which generates minimal required configuration file:\n\n\n./centrifugo genconfig\n\n\n\n\nIt generates secret key automatically and creates configuration file \nconfig.json\n in current directory (by default) so you can finally run Centrifugo instance:\n\n\n./centrifugo --config\n=\nconfig.json\n\n\n\n\nWe will talk about configuration in detail in next sections.\n\n\nYou can also put or symlink \ncentrifugo\n into your \nbin\n OS directory and run it from anywhere:\n\n\ncentrifugo --config\n=\nconfig.json\n\n\n\n\nIn production you will need to daemonize Centrifugo. We have prebuilt \nrpm\n and \ndeb\n packages for\nmost popular Linux distributions and Docker image. See \nDeploy\n section for more information.",
            "title": "Installation"
        },
        {
            "location": "/server/install/#install-and-quick-start",
            "text": "Go is a perfect language - it gives developers an opportunity to have single binary executable file for application and cross-compile application on all target operating systems for distribution. This means that all you need to get Centrifugo \u2013  download latest release  for you operating system, unpack it and you are done!  Now you can see help information for Centrifugo:  ./centrifugo -h  Centrifugo server node requires configuration file with secret key. If you are new to Centrifugo then there is  genconfig  command which generates minimal required configuration file:  ./centrifugo genconfig  It generates secret key automatically and creates configuration file  config.json  in current directory (by default) so you can finally run Centrifugo instance:  ./centrifugo --config = config.json  We will talk about configuration in detail in next sections.  You can also put or symlink  centrifugo  into your  bin  OS directory and run it from anywhere:  centrifugo --config = config.json  In production you will need to daemonize Centrifugo. We have prebuilt  rpm  and  deb  packages for\nmost popular Linux distributions and Docker image. See  Deploy  section for more information.",
            "title": "Install and quick start"
        },
        {
            "location": "/server/configuration/",
            "text": "Configuration\n\u00b6\n\n\nCentrifugo expects JSON, TOML or YAML as format of configuration file. Thanks to brilliant Go library for application configuration - \nviper\n.\n\n\nBut first let's inspect all available command-line options:\n\n\ncentrifugo -h\n\n\n\n\nYou should see something like this as output:\n\n\nCentrifugo \u2013 real-time messaging server\n\nUsage:\n   [flags]\n   [command]\n\nAvailable Commands:\n  checkconfig Check configuration file\n  genconfig   Generate simple configuration file to start with\n  help        Help about any command\n  version     Centrifugo version number\n\nFlags:\n  -a, --address string             interface address to listen on\n      --admin                      enable admin web interface\n      --admin_insecure             use insecure admin mode \u2013 no auth required for admin socket\n      --api_insecure               use insecure API mode\n      --client_insecure            start in insecure client mode\n  -c, --config string              path to config file (default \"config.json\")\n      --debug                      enable debug endpoints\n  -e, --engine string              engine to use: memory or redis (default \"memory\")\n      --grpc_api                   enable GRPC API server\n      --grpc_client                enable GRPC client server\n  -h, --help                       help for this command\n      --internal_port string       custom port for internal endpoints\n      --log_file string            optional log file - if not specified logs go to STDOUT\n      --log_level string           set the log level: debug, info, error, fatal or none (default \"info\")\n  -n, --name string                unique node name\n      --pid_file string            optional path to create PID file\n  -p, --port string                port to bind HTTP server to (default \"8000\")\n      --prometheus                 enable Prometheus metrics endpoint\n      --redis_db string            Redis database (Redis engine) (default \"0\")\n      --redis_host string          Redis host (Redis engine) (default \"127.0.0.1\")\n      --redis_master_name string   name of Redis master Sentinel monitors (Redis engine)\n      --redis_password string      Redis auth password (Redis engine)\n      --redis_pool int             Redis pool size (Redis engine) (default 256)\n      --redis_port string          Redis port (Redis engine) (default \"6379\")\n      --redis_sentinels string     comma-separated list of Sentinel addresses (Redis engine)\n      --redis_url string           Redis connection URL in format redis://:password@hostname:port/db (Redis engine)\n      --tls                        enable TLS, requires an X509 certificate and a key file\n      --tls_cert string            path to an X509 certificate file\n      --tls_key string             path to an X509 certificate key\n\nUse \" [command] --help\" for more information about a command.\n\n\n\n\nversion\n\u00b6\n\n\nTo show version and exit run:\n\n\ncentrifugo version\n\n\n\n\nJSON file\n\u00b6\n\n\nCentrifugo requires configuration file on start. As was mentioned earlier it must be a file with valid JSON.\n\n\nThis is a minimal Centrifugo configuration file:\n\n\n{\n\n  \n\"secret\"\n:\n \n\"secret\"\n\n\n}\n\n\n\n\n\nThe only field that is required is \nsecret\n. Secret used to create HMAC signs. Keep it strong and in secret!\n\n\nTOML file\n\u00b6\n\n\nCentrifugo also supports TOML format for configuration file:\n\n\ncentrifugo --config=config.toml\n\n\n\n\nWhere \nconfig.toml\n contains:\n\n\nsecret = \"secret\"\nlog_level = \"debug\"\n\n\n\n\nI.e. the same configuration as JSON file above. We will talk about what is \nnamespaces\n field soon.\n\n\nYAML file\n\u00b6\n\n\nAnd YAML config also supported. \nconfig.yaml\n:\n\n\nsecret\n:\n \nsecret\n\n\nlog_level\n:\n \ndebug\n\n\n\n\n\nWith YAML remember to use spaces, not tabs when writing configuration file.\n\n\ncheckconfig command\n\u00b6\n\n\nCentrifugo has special command to check configuration file \ncheckconfig\n:\n\n\ncentrifugo checkconfig --config\n=\nconfig.json\n\n\n\n\nIf any errors found during validation \u2013 program will exit with error message and exit code 1.\n\n\ngenconfig command\n\u00b6\n\n\nAnother command is \ngenconfig\n:\n\n\ncentrifugo genconfig -c config.json\n\n\n\n\nIt will generate the minimal required configuration file automatically.\n\n\nImportant options\n\u00b6\n\n\nSome of the most important options you can configure when running Centrifugo:\n\n\n\n\naddress\n \u2013 bind your Centrifugo to specific interface address (by default \n\"\"\n)\n\n\nport\n \u2013 port to bind Centrifugo to (by default \n8000\n)\n\n\nengine\n \u2013 engine to use - \nmemory\n or \nredis\n (by default \nmemory\n). Read more about engines in next sections.\n\n\n\n\nNote that some options can be set via command-line. Command-line options are more valuable when set than configuration file's options. See description of \nviper\n \u2013 to see more details about configuration options priority.\n\n\nChannel options\n\u00b6\n\n\nLet's look on options related to channels. Channel is an entity to which clients can subscribe to receive messages published into that channel. Channel is just a string (several symbols has special meaning in Centrifugo - see special chapter to find more information about channels). The following options will affect channel behaviour:\n\n\n\n\n\n\npublish\n \u2013 allow clients to publish messages into channels directly (from client side). Your application will never receive those messages. In idiomatic case all messages must be published by your application backend using Centrifugo API. But this option can be useful when you want to build something without backend-side validation and saving into database. This option can also be useful for demos and prototyping real-time ideas. Note that client can only publish data into channel after successfully subscribed on it. By default it's \nfalse\n.\n\n\n\n\n\n\nanonymous\n \u2013 this option enables anonymous access (with empty user ID in connection parameters). In most situations your application works with authorized users so every user has its own unique id. But if you provide real-time features for public access you may need unauthorized access to some channels. Turn on this option and use empty string as user ID. By default \nfalse\n.\n\n\n\n\n\n\npresence\n \u2013 enable/disable presence information. Presence is a structure with clients currently subscribed on channel. By default \nfalse\n \u2013 i.e. no presence information available for channels.\n\n\n\n\n\n\njoin_leave\n \u2013 enable/disable sending join(leave) messages when client subscribes on channel (unsubscribes from channel). By default \nfalse\n.\n\n\n\n\n\n\nhistory_size\n \u2013 history size (amount of messages) for channels. As Centrifugo keeps all history messages in memory it's very important to limit maximum amount of messages in channel history to reasonable minimum. By default history size is \n0\n - this means that channels will have no history messages at all. As soon as history enabled then \nhistory_size\n defines maximum amount of messages that Centrifugo will keep for \neach\n channel in namespace during history lifetime (see below).\n\n\n\n\n\n\nhistory_lifetime\n \u2013 interval in seconds how long to keep channel history messages. As all history is storing in memory it is also very important to get rid of old history data for unused (inactive for a long time) channels. By default history lifetime is \n0\n \u2013 this means that channels will have no history messages at all. \nSo to get history messages you should wisely configure both \nhistory_size\n and \nhistory_lifetime\n options\n.\n\n\n\n\n\n\nhistory_recover\n (\nnew in v1.2.0\n) \u2013 boolean option, when enabled Centrifugo will try to recover missed messages published while client was disconnected for some reason (bad internet connection for example). By default \nfalse\n. This option must be used in conjunction with reasonably configured message history for channel i.e. \nhistory_size\n and \nhistory_lifetime\n \nmust be set\n (because Centrifugo uses channel message history to recover messages). Also note that note all real-time events require this feature turned on so think wisely when you need this. See more details about how this option works in \nspecial chapter\n.\n\n\n\n\n\n\nhistory_drop_inactive\n (\nnew in v1.3.0\n) \u2013 boolean option, allows to drastically reduce resource usage (engine memory usage, messages travelling around) when you use message history for channels. In couple of words when enabled Centrifugo will drop history messages that no one needs. Please, see \nissue on Github\n to get more information about option use case scenario and edge cases it involves.\n\n\n\n\n\n\nLet's look how to set some of these options in config:\n\n\n{\n\n    \n\"secret\"\n:\n \n\"my-secret-key\"\n,\n\n    \n\"anonymous\"\n:\n \ntrue\n,\n\n    \n\"publish\"\n:\n \ntrue\n,\n\n    \n\"presence\"\n:\n \ntrue\n,\n\n    \n\"join_leave\"\n:\n \ntrue\n,\n\n    \n\"history_size\"\n:\n \n10\n,\n\n    \n\"history_lifetime\"\n:\n \n30\n,\n\n    \n\"history_recover\"\n:\n \ntrue\n\n\n}\n\n\n\n\n\nAnd the last channel specific option is \nnamespaces\n. \nnamespaces\n are optional and if set must be an array of namespace objects. Namespace allows to configure custom options for channels starting with namespace name. This provides a great control over channel behaviour.\n\n\nNamespace has a name and the same channel options (with same defaults) as described above.\n\n\n\n\nname\n - unique namespace name (name must must consist of letters, numbers, underscores or hyphens and be more than 2 symbols length i.e. satisfy regexp \n^[-a-zA-Z0-9_]{2,}$\n).\n\n\n\n\nIf you want to use namespace options for channel - you must include namespace name into\nchannel name with \n:\n as separator:\n\n\npublic\n:\nmessages\n\n\ngossips\n:\nmessages\n\n\nWhere \npublic\n and \ngossips\n are namespace names from project \nnamespaces\n.\n\n\nAll things together here is an example of \nconfig.json\n which includes registered project with all options set and 2 additional namespaces in it:\n\n\n{\n\n    \n\"secret\"\n:\n \n\"very-long-secret-key\"\n,\n\n    \n\"anonymous\"\n:\n \ntrue\n,\n\n    \n\"publish\"\n:\n \ntrue\n,\n\n    \n\"presence\"\n:\n \ntrue\n,\n\n    \n\"join_leave\"\n:\n \ntrue\n,\n\n    \n\"history_size\"\n:\n \n10\n,\n\n    \n\"history_lifetime\"\n:\n \n30\n,\n\n    \n\"namespaces\"\n:\n \n[\n\n        \n{\n\n          \n\"name\"\n:\n \n\"public\"\n,\n\n          \n\"publish\"\n:\n \ntrue\n,\n\n          \n\"anonymous\"\n:\n \ntrue\n,\n\n          \n\"history_size\"\n:\n \n10\n,\n\n          \n\"history_lifetime\"\n:\n \n30\n,\n\n          \n\"history_recover\"\n:\n \ntrue\n\n        \n},\n\n        \n{\n\n          \n\"name\"\n:\n \n\"gossips\"\n,\n\n          \n\"presence\"\n:\n \ntrue\n,\n\n          \n\"join_leave\"\n:\n \ntrue\n\n        \n}\n\n    \n]\n\n\n}\n\n\n\n\n\nChannel \nnews\n will use global project options.\n\n\nChannel \npublic\n:\nnews\n will use \npublic\n namespace's options.\n\n\nChannel \ngossips\n:\nnews\n will use \ngossips\n namespace's options.\n\n\nAdvanced configuration\n\u00b6\n\n\nCentrifugo has some options for which default values make sense for most applications. In many case you\ndon't need (and you really should not) change them. This chapter is about such options.\n\n\nclient_channel_limit\n\u00b6\n\n\nDefault: 128\n\n\nSets maximum number of different channel subscriptions single client can have.\n\n\nchannel_max_length\n\u00b6\n\n\nDefault: 255\n\n\nSets maximum length of channel name.\n\n\nchannel_user_connection_limit\n\u00b6\n\n\nDefault: 0\n\n\nMaximum number of connections from user (with known user ID) to Centrifugo node. By default - unlimited.\n\n\nclient_request_max_size\n\u00b6\n\n\nDefault: 65536\n\n\nMaximum allowed size of request from client in bytes.\n\n\nclient_queue_max_size\n\u00b6\n\n\nDefault: 10485760\n\n\nMaximum client message queue size in bytes to close slow reader connections. By default - 10mb.\n\n\nsockjs_heartbeat_delay\n\u00b6\n\n\nDefault: 25\n\n\nInterval in seconds how often to send SockJS h-frames to client.\n\n\nwebsocket_compression\n\u00b6\n\n\nDefault: false\n\n\nEnable websocket compression, see special chapter in docs.\n\n\ngomaxprocs\n\u00b6\n\n\nDefault: 0\n\n\nBy default Centrifugo runs on all available CPU cores. If you want to limit amount of cores Centrifugo can utilize in one moment use this option.\n\n\nAdvanced endpoint configuration.\n\u00b6\n\n\nAfter you started Centrifugo you have several endpoints available. As soon as you have not provided any extra options you have 3 endpoints by default.\n\n\nDefault endpoints.\n\u00b6\n\n\nFirst is SockJS endpoint - it's needed to serve client connections that use SockJS library:\n\n\nhttp://localhost:8000/connection/sockjs\n\n\n\n\nNext is raw Websocket endpoint to serve client connections that use pure Websocket protocol:\n\n\nws://localhost:8000/connection/websocket\n\n\n\n\nAnd finally you have API endpoint to \npublish\n messages to channels (and execute other available API commands):\n\n\nhttp://localhost:8000/api\n\n\n\n\nBy default all endpoints work on port \n8000\n. You can change it using \nport\n option:\n\n\n{\n    \"port\": 9000\n}\n\n\n\n\nIn production setup you will have your domain name in endpoint addresses above instead of \nlocalhost\n. Also if your Centrifugo will be behind proxy or load balancer software you most probably won't have ports in your endpoint addresses. What will always be the same as shown above are URL paths: \n/connection/sockjs\n, \n/connection/websocket\n, \n/api\n.\n\n\nLet's look at possibilities to tweak available endpoints.\n\n\nAdmin endpoints.\n\u00b6\n\n\nFirst is enabling admin endpoints:\n\n\n{\n    ...\n    \"admin\": true,\n    \"admin_password\": \"password\",\n    \"admin_secret\": \"secret\"\n}\n\n\n\n\nThis makes the following endpoint available:\n\n\nws://localhost:8000\n\n\n\n\nAt this address you will see embedded admin web interface. You can log into it using \nadmin_password\n value shown above.\n\n\nDebug endpoints.\n\u00b6\n\n\nNext, when Centrifugo started in debug mode some extra debug endpoints become available. To start in debug mode add \ndebug\n option to config:\n\n\n{\n    ...\n    \"debug\": true\n}\n\n\n\n\nAnd endpoint:\n\n\nhttp://localhost:8000/debug/pprof/\n\n\n\n\n\u2013 will show you useful info about internal state of Centrifugo instance. This info is especially helpful when troubleshooting.\n\n\nCustom admin and API ports\n\u00b6\n\n\nWe strongly recommend to not expose admin, debug and API endpoints to Internet. In case of admin endpoint this step provides extra protection to \n/\n, \n/admin/auth\n, \n/admin/api\n endpoints, debug endpoints. Protecting API endpoint will allow you to use \napi_insecure\n mode to omit passing API key in each request.\n\n\nSo it's a good practice to protect admin and API endpoints with firewall. For example you can do this in \nlocation\n section of Nginx configuration.\n\n\nThough sometimes you don't have access to per-location configuration in your proxy/load balancer software. For example\nwhen using Amazon ELB. In this case you can change ports on which your admin and API endpoints work.\n\n\nTo run admin endpoints on custom port use \nadmin_port\n option:\n\n\n{\n    ...\n    \"admin_port\": 10000\n}\n\n\n\n\nSo admin web interface will work on address:\n\n\nws://localhost:10000\n\n\n\n\nAlso debug page will be available on new custom admin port too:\n\n\nhttp://localhost:10000/debug/pprof/\n\n\n\n\nTo run API server on it's own port use \napi_port\n option:\n\n\n{\n    ...\n    \"api_port\": 10001\n}\n\n\n\n\nNow you should send API requests to:\n\n\nhttp://localhost:10001/api",
            "title": "Configuration"
        },
        {
            "location": "/server/configuration/#configuration",
            "text": "Centrifugo expects JSON, TOML or YAML as format of configuration file. Thanks to brilliant Go library for application configuration -  viper .  But first let's inspect all available command-line options:  centrifugo -h  You should see something like this as output:  Centrifugo \u2013 real-time messaging server\n\nUsage:\n   [flags]\n   [command]\n\nAvailable Commands:\n  checkconfig Check configuration file\n  genconfig   Generate simple configuration file to start with\n  help        Help about any command\n  version     Centrifugo version number\n\nFlags:\n  -a, --address string             interface address to listen on\n      --admin                      enable admin web interface\n      --admin_insecure             use insecure admin mode \u2013 no auth required for admin socket\n      --api_insecure               use insecure API mode\n      --client_insecure            start in insecure client mode\n  -c, --config string              path to config file (default \"config.json\")\n      --debug                      enable debug endpoints\n  -e, --engine string              engine to use: memory or redis (default \"memory\")\n      --grpc_api                   enable GRPC API server\n      --grpc_client                enable GRPC client server\n  -h, --help                       help for this command\n      --internal_port string       custom port for internal endpoints\n      --log_file string            optional log file - if not specified logs go to STDOUT\n      --log_level string           set the log level: debug, info, error, fatal or none (default \"info\")\n  -n, --name string                unique node name\n      --pid_file string            optional path to create PID file\n  -p, --port string                port to bind HTTP server to (default \"8000\")\n      --prometheus                 enable Prometheus metrics endpoint\n      --redis_db string            Redis database (Redis engine) (default \"0\")\n      --redis_host string          Redis host (Redis engine) (default \"127.0.0.1\")\n      --redis_master_name string   name of Redis master Sentinel monitors (Redis engine)\n      --redis_password string      Redis auth password (Redis engine)\n      --redis_pool int             Redis pool size (Redis engine) (default 256)\n      --redis_port string          Redis port (Redis engine) (default \"6379\")\n      --redis_sentinels string     comma-separated list of Sentinel addresses (Redis engine)\n      --redis_url string           Redis connection URL in format redis://:password@hostname:port/db (Redis engine)\n      --tls                        enable TLS, requires an X509 certificate and a key file\n      --tls_cert string            path to an X509 certificate file\n      --tls_key string             path to an X509 certificate key\n\nUse \" [command] --help\" for more information about a command.",
            "title": "Configuration"
        },
        {
            "location": "/server/configuration/#version",
            "text": "To show version and exit run:  centrifugo version",
            "title": "version"
        },
        {
            "location": "/server/configuration/#json-file",
            "text": "Centrifugo requires configuration file on start. As was mentioned earlier it must be a file with valid JSON.  This is a minimal Centrifugo configuration file:  { \n   \"secret\" :   \"secret\"  }   The only field that is required is  secret . Secret used to create HMAC signs. Keep it strong and in secret!",
            "title": "JSON file"
        },
        {
            "location": "/server/configuration/#toml-file",
            "text": "Centrifugo also supports TOML format for configuration file:  centrifugo --config=config.toml  Where  config.toml  contains:  secret = \"secret\"\nlog_level = \"debug\"  I.e. the same configuration as JSON file above. We will talk about what is  namespaces  field soon.",
            "title": "TOML file"
        },
        {
            "location": "/server/configuration/#yaml-file",
            "text": "And YAML config also supported.  config.yaml :  secret :   secret  log_level :   debug   With YAML remember to use spaces, not tabs when writing configuration file.",
            "title": "YAML file"
        },
        {
            "location": "/server/configuration/#checkconfig-command",
            "text": "Centrifugo has special command to check configuration file  checkconfig :  centrifugo checkconfig --config = config.json  If any errors found during validation \u2013 program will exit with error message and exit code 1.",
            "title": "checkconfig command"
        },
        {
            "location": "/server/configuration/#genconfig-command",
            "text": "Another command is  genconfig :  centrifugo genconfig -c config.json  It will generate the minimal required configuration file automatically.",
            "title": "genconfig command"
        },
        {
            "location": "/server/configuration/#important-options",
            "text": "Some of the most important options you can configure when running Centrifugo:   address  \u2013 bind your Centrifugo to specific interface address (by default  \"\" )  port  \u2013 port to bind Centrifugo to (by default  8000 )  engine  \u2013 engine to use -  memory  or  redis  (by default  memory ). Read more about engines in next sections.   Note that some options can be set via command-line. Command-line options are more valuable when set than configuration file's options. See description of  viper  \u2013 to see more details about configuration options priority.",
            "title": "Important options"
        },
        {
            "location": "/server/configuration/#channel-options",
            "text": "Let's look on options related to channels. Channel is an entity to which clients can subscribe to receive messages published into that channel. Channel is just a string (several symbols has special meaning in Centrifugo - see special chapter to find more information about channels). The following options will affect channel behaviour:    publish  \u2013 allow clients to publish messages into channels directly (from client side). Your application will never receive those messages. In idiomatic case all messages must be published by your application backend using Centrifugo API. But this option can be useful when you want to build something without backend-side validation and saving into database. This option can also be useful for demos and prototyping real-time ideas. Note that client can only publish data into channel after successfully subscribed on it. By default it's  false .    anonymous  \u2013 this option enables anonymous access (with empty user ID in connection parameters). In most situations your application works with authorized users so every user has its own unique id. But if you provide real-time features for public access you may need unauthorized access to some channels. Turn on this option and use empty string as user ID. By default  false .    presence  \u2013 enable/disable presence information. Presence is a structure with clients currently subscribed on channel. By default  false  \u2013 i.e. no presence information available for channels.    join_leave  \u2013 enable/disable sending join(leave) messages when client subscribes on channel (unsubscribes from channel). By default  false .    history_size  \u2013 history size (amount of messages) for channels. As Centrifugo keeps all history messages in memory it's very important to limit maximum amount of messages in channel history to reasonable minimum. By default history size is  0  - this means that channels will have no history messages at all. As soon as history enabled then  history_size  defines maximum amount of messages that Centrifugo will keep for  each  channel in namespace during history lifetime (see below).    history_lifetime  \u2013 interval in seconds how long to keep channel history messages. As all history is storing in memory it is also very important to get rid of old history data for unused (inactive for a long time) channels. By default history lifetime is  0  \u2013 this means that channels will have no history messages at all.  So to get history messages you should wisely configure both  history_size  and  history_lifetime  options .    history_recover  ( new in v1.2.0 ) \u2013 boolean option, when enabled Centrifugo will try to recover missed messages published while client was disconnected for some reason (bad internet connection for example). By default  false . This option must be used in conjunction with reasonably configured message history for channel i.e.  history_size  and  history_lifetime   must be set  (because Centrifugo uses channel message history to recover messages). Also note that note all real-time events require this feature turned on so think wisely when you need this. See more details about how this option works in  special chapter .    history_drop_inactive  ( new in v1.3.0 ) \u2013 boolean option, allows to drastically reduce resource usage (engine memory usage, messages travelling around) when you use message history for channels. In couple of words when enabled Centrifugo will drop history messages that no one needs. Please, see  issue on Github  to get more information about option use case scenario and edge cases it involves.    Let's look how to set some of these options in config:  { \n     \"secret\" :   \"my-secret-key\" , \n     \"anonymous\" :   true , \n     \"publish\" :   true , \n     \"presence\" :   true , \n     \"join_leave\" :   true , \n     \"history_size\" :   10 , \n     \"history_lifetime\" :   30 , \n     \"history_recover\" :   true  }   And the last channel specific option is  namespaces .  namespaces  are optional and if set must be an array of namespace objects. Namespace allows to configure custom options for channels starting with namespace name. This provides a great control over channel behaviour.  Namespace has a name and the same channel options (with same defaults) as described above.   name  - unique namespace name (name must must consist of letters, numbers, underscores or hyphens and be more than 2 symbols length i.e. satisfy regexp  ^[-a-zA-Z0-9_]{2,}$ ).   If you want to use namespace options for channel - you must include namespace name into\nchannel name with  :  as separator:  public : messages  gossips : messages  Where  public  and  gossips  are namespace names from project  namespaces .  All things together here is an example of  config.json  which includes registered project with all options set and 2 additional namespaces in it:  { \n     \"secret\" :   \"very-long-secret-key\" , \n     \"anonymous\" :   true , \n     \"publish\" :   true , \n     \"presence\" :   true , \n     \"join_leave\" :   true , \n     \"history_size\" :   10 , \n     \"history_lifetime\" :   30 , \n     \"namespaces\" :   [ \n         { \n           \"name\" :   \"public\" , \n           \"publish\" :   true , \n           \"anonymous\" :   true , \n           \"history_size\" :   10 , \n           \"history_lifetime\" :   30 , \n           \"history_recover\" :   true \n         }, \n         { \n           \"name\" :   \"gossips\" , \n           \"presence\" :   true , \n           \"join_leave\" :   true \n         } \n     ]  }   Channel  news  will use global project options.  Channel  public : news  will use  public  namespace's options.  Channel  gossips : news  will use  gossips  namespace's options.",
            "title": "Channel options"
        },
        {
            "location": "/server/configuration/#advanced-configuration",
            "text": "Centrifugo has some options for which default values make sense for most applications. In many case you\ndon't need (and you really should not) change them. This chapter is about such options.",
            "title": "Advanced configuration"
        },
        {
            "location": "/server/configuration/#client_channel_limit",
            "text": "Default: 128  Sets maximum number of different channel subscriptions single client can have.",
            "title": "client_channel_limit"
        },
        {
            "location": "/server/configuration/#channel_max_length",
            "text": "Default: 255  Sets maximum length of channel name.",
            "title": "channel_max_length"
        },
        {
            "location": "/server/configuration/#channel_user_connection_limit",
            "text": "Default: 0  Maximum number of connections from user (with known user ID) to Centrifugo node. By default - unlimited.",
            "title": "channel_user_connection_limit"
        },
        {
            "location": "/server/configuration/#client_request_max_size",
            "text": "Default: 65536  Maximum allowed size of request from client in bytes.",
            "title": "client_request_max_size"
        },
        {
            "location": "/server/configuration/#client_queue_max_size",
            "text": "Default: 10485760  Maximum client message queue size in bytes to close slow reader connections. By default - 10mb.",
            "title": "client_queue_max_size"
        },
        {
            "location": "/server/configuration/#sockjs_heartbeat_delay",
            "text": "Default: 25  Interval in seconds how often to send SockJS h-frames to client.",
            "title": "sockjs_heartbeat_delay"
        },
        {
            "location": "/server/configuration/#websocket_compression",
            "text": "Default: false  Enable websocket compression, see special chapter in docs.",
            "title": "websocket_compression"
        },
        {
            "location": "/server/configuration/#gomaxprocs",
            "text": "Default: 0  By default Centrifugo runs on all available CPU cores. If you want to limit amount of cores Centrifugo can utilize in one moment use this option.",
            "title": "gomaxprocs"
        },
        {
            "location": "/server/configuration/#advanced-endpoint-configuration",
            "text": "After you started Centrifugo you have several endpoints available. As soon as you have not provided any extra options you have 3 endpoints by default.",
            "title": "Advanced endpoint configuration."
        },
        {
            "location": "/server/configuration/#default-endpoints",
            "text": "First is SockJS endpoint - it's needed to serve client connections that use SockJS library:  http://localhost:8000/connection/sockjs  Next is raw Websocket endpoint to serve client connections that use pure Websocket protocol:  ws://localhost:8000/connection/websocket  And finally you have API endpoint to  publish  messages to channels (and execute other available API commands):  http://localhost:8000/api  By default all endpoints work on port  8000 . You can change it using  port  option:  {\n    \"port\": 9000\n}  In production setup you will have your domain name in endpoint addresses above instead of  localhost . Also if your Centrifugo will be behind proxy or load balancer software you most probably won't have ports in your endpoint addresses. What will always be the same as shown above are URL paths:  /connection/sockjs ,  /connection/websocket ,  /api .  Let's look at possibilities to tweak available endpoints.",
            "title": "Default endpoints."
        },
        {
            "location": "/server/configuration/#admin-endpoints",
            "text": "First is enabling admin endpoints:  {\n    ...\n    \"admin\": true,\n    \"admin_password\": \"password\",\n    \"admin_secret\": \"secret\"\n}  This makes the following endpoint available:  ws://localhost:8000  At this address you will see embedded admin web interface. You can log into it using  admin_password  value shown above.",
            "title": "Admin endpoints."
        },
        {
            "location": "/server/configuration/#debug-endpoints",
            "text": "Next, when Centrifugo started in debug mode some extra debug endpoints become available. To start in debug mode add  debug  option to config:  {\n    ...\n    \"debug\": true\n}  And endpoint:  http://localhost:8000/debug/pprof/  \u2013 will show you useful info about internal state of Centrifugo instance. This info is especially helpful when troubleshooting.",
            "title": "Debug endpoints."
        },
        {
            "location": "/server/configuration/#custom-admin-and-api-ports",
            "text": "We strongly recommend to not expose admin, debug and API endpoints to Internet. In case of admin endpoint this step provides extra protection to  / ,  /admin/auth ,  /admin/api  endpoints, debug endpoints. Protecting API endpoint will allow you to use  api_insecure  mode to omit passing API key in each request.  So it's a good practice to protect admin and API endpoints with firewall. For example you can do this in  location  section of Nginx configuration.  Though sometimes you don't have access to per-location configuration in your proxy/load balancer software. For example\nwhen using Amazon ELB. In this case you can change ports on which your admin and API endpoints work.  To run admin endpoints on custom port use  admin_port  option:  {\n    ...\n    \"admin_port\": 10000\n}  So admin web interface will work on address:  ws://localhost:10000  Also debug page will be available on new custom admin port too:  http://localhost:10000/debug/pprof/  To run API server on it's own port use  api_port  option:  {\n    ...\n    \"api_port\": 10001\n}  Now you should send API requests to:  http://localhost:10001/api",
            "title": "Custom admin and API ports"
        },
        {
            "location": "/server/protocol/",
            "text": "Client protocol\n\u00b6\n\n\nThis chapter describes internal client-server protocol in details to help developers build custom client libraries.\n\n\nNote that you can always look at existing client implementations in case of any questions, for example \ncentrifuge-js\n.\n\n\nWhat client should do\n\u00b6\n\n\nWhen you are using Centrifuge/Centrifugo client you expect some core things from it:\n\n\n\n\nconnect to server and authenticate. Depending on transport endpoint address can differ. For example Centrifugo JSON-encoded Websocket endpoint is \nws://centrifugo.example.com/connection/websocket\n.\n\n\nsubscribe on channels developer wants. This allows to recieve messages published into channels in real-time.\n\n\nhave a possibility to make RPC calls, publish, asking for presence etc.\n\n\nrefresh client connection credentials when connection session lifetime is going to expire.\n\n\nhandle ping/pong messaging with server under the hood to maintain connection alive and detect broken connection.\n\n\nhandle protocol-specific errors, reconnect and recover missed messages automatically.\n\n\n\n\nAt moment Centrifuge/Centrifugo can work with several transports:\n\n\n\n\nWebsocket\n\n\nSockJS\n\n\nGRPC\n\n\n\n\nThis document describes protocol specifics for Websocket transport which supports binary and text formats to transfer data. As Centrifuge has various types of messages it serializes protocol messages using JSON or Protobuf (in case of binary websockets).\n\n\n\n\nNote\n\n\nSockJS works almost the same way as JSON websocket described here but has its own extra framing on top of Centrifuge protocol messages. SockJS can only work with JSON - it's not possible to transfer binary data over it. SockJS is only needed as fallback to Websocket in web browsers.\n\n\n\n\n\n\nNote\n\n\nGRPC support is an experimental at moment. GRPC works similar to what described here but it has its own transport details - Centrifuge library can not control how data travel over network and just uses GRPC generated API to pass messages between server and client over bidirectional streaming.\n\n\n\n\nTop level framing\n\u00b6\n\n\nCentrifuge protocol defined in \nProtobuf schema\n. That schema is a source of truth and all protocol description below describes messages from that schema.\n\n\nClient sends \nCommand\n to server.\n\n\nServer sends \nReply\n to client.\n\n\nOne request from client to server and one response from server to client can have more than one \nCommand\n or \nReply\n.\n\n\nWhen JSON format is used then many \nCommand\n can be sent from client to server in JSON streaming line-delimited format. I.e. many commands delimited by new line symbol \n\\n\n.\n\n\n{\n\"id\"\n:\n \n1\n,\n \n\"method\"\n:\n \n\"subscribe\"\n,\n \n\"params\"\n:\n \n{\n\"channel\"\n:\n \n\"ch1\"\n}}\n\n\n{\n\"id\"\n:\n \n2\n,\n \n\"method\"\n:\n \n\"subscribe\"\n,\n \n\"params\"\n:\n \n{\n\"channel\"\n:\n \n\"ch2\"\n}}\n\n\n\n\n\n\n\nNote\n\n\nThis doc will use JSON format for examples because it's human-readable. Everything said here for JSON is also true for Protobuf encoded case. \n\n\n\n\n\n\nNote\n\n\nMethod is made as ENUM in protobuf schema and can be sent as integer value but it's possible to send it as string in JSON case \u2013 this was made to make JSON protocol human-friendly.\n\n\n\n\nWhen Protobuf format is used then many \nCommand\n can be sent from client to server in length-delimited format where each individual \nCommand\n marshaled to bytes prepended by \nvarint\n length.\n\n\nThe same relates to many \nReply\n in one response from server to client. Line-delimited JSON and varint-length prefixed Protobuf.\n\n\nAs you see above each \nCommand\n has \nid\n field. This is an incremental integer field. This field will be echoed in server to client replies to commands so client could match a certain \nReply\n to \nCommand\n sent before. This is important because Websocket is asynchronous protocol where server and client both send messages in full-duplex mode.\n\n\nSo you can expect something like this when sending commands to server:\n\n\n{\n\"id\"\n:\n \n1\n,\n \n\"result\"\n:\n \n{}}\n\n\n{\n\"id\"\n:\n \n2\n,\n \n\"result\"\n:\n \n{}}\n\n\n\n\n\nBesides \nid\n \nReply\n from server to client have two important fields: \nresult\n and \nerror\n.\n\n\nresult\n contains useful payload object which can be different depending on \nReply\n.\n\n\nerror\n contains error object in case of \nCommand\n processing resulted in some error on server. \nerror\n is optional and if \nReply\n does not have \nerror\n then it means that \nCommand\n processed successfuly and client can parse \nresult\n object in an appropriate way.\n\n\nerror\n objects looks like this:\n\n\n{\n\n    \n\"code\"\n:\n \n100\n,\n\n    \n\"message\"\n:\n \n\"internal server error\"\n\n\n}\n\n\n\n\n\nWe will talk more about error handling below.\n\n\nThe special type of \nReply\n is asynchronous \nReply\n. Those replies have no \nid\n field set (or \nid\n can be equal to zero). Async replies can come to client in any moment - not as reaction to issued \nCommand\n but as message from server to client in arbitrary time. For example this can be message published into channel.\n\n\nCentrifuge library defines several command types client can issue. And well-written client must be aware of all those commands and client workflow. Communication with Centrifuge/Centrifugo server starts with \nconnect\n command.\n\n\nConnect\n\u00b6\n\n\nFirst of all client must dial with server and then send \nconnect\n \nCommand\n to it.\n\n\nDefault Websocket endpoint in Centrifugo is:\n\n\nws://centrifugo.example.com/connection/websocket\n\n\n\n\nIn case of using TLS:\n\n\nwss://centrifugo.example.com/connection/websocket\n\n\n\n\nAfter successful dial to websocket endpoint client must send \nconnect\n command to server to authorize itself.\n\n\nconnect\n command looks like:\n\n\n{\n\n    \n\"id\"\n:\n \n1\n,\n\n    \n\"method\"\n:\n \n\"connect\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"user\"\n:\n \n\"42\"\n,\n\n        \n\"exp\"\n:\n \n\"1520094208\"\n,\n\n        \n\"info\"\n:\n \n\"\"\n,\n\n        \n\"sign\"\n:\n \n\"xxx\"\n\n    \n}\n\n\n}\n\n\n\n\n\nWhere params fields are passed to client from application backend:\n\n\n\n\nstring \nuser\n - current user ID. Can be empty string for unauthorized user.\n\n\nstring \nexp\n - timestamp seconds when client connection expires.\n\n\nstring \ninfo\n - optional base64 encoded information about connection. This is JSON object encoded to base64 in case of JSON format used and arbitrary bytes for Protobuf format.\n\n\nstring \nsign\n - HMAC SHA-256 sign generated on backend side from Centrifugo secret and fields above. This sign helps to prove the fact that client passed valid \nuser\n, \nexp\n, \ninfo\n fields to server.\n\n\n\n\nIn response to \nconnect\n command server sends connect reply. It looks this way:\n\n\n{\n\n    \n\"id\"\n:\n1\n,\n\n    \n\"result\"\n:\n{\n\n        \n\"client\"\n:\n\"421bf374-dd01-4f82-9def-8c31697e956f\"\n,\n\n        \n\"version\"\n:\n\"2.0.0\"\n\n    \n}\n\n\n}\n\n\n\n\n\nresult\n has some fields:\n\n\n\n\nstring \nclient\n - unique client connection ID server issued to this connection\n\n\nstring \nversion\n - server version\n\n\noptional bool \nexpires\n - whether or not server will expire connection\n\n\noptional bool \nexpired\n - whether or not connection credentials already expired and must be refreshed\n\n\noptional int32 \nttl\n - time in seconds until connection will expire\n\n\n\n\nSubscribe\n\u00b6\n\n\nAs soon as client successfully connected and got unique connection ID it is ready to\nsubscribe on channels. To do this it must send \nsubscribe\n command to server:\n\n\n{\n\n    \n\"id\"\n:\n \n2\n,\n\n    \n\"method\"\n:\n \n\"subscribe\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"ch1\"\n\n    \n}\n\n\n}\n\n\n\n\n\nFields that can be set in \nparams\n are:\n\n\n\n\nstring \nchannel\n - channel to subscribe\n\n\n\n\nIn response to subscribe client receives reply like:\n\n\n{\n\n    \n\"id\"\n:\n2\n,\n\n    \n\"result\"\n:\n{}\n\n\n}\n\n\n\n\n\nresult\n can have the following fields:\n\n\n\n\noptional array \npublications\n - this is an array of missed publications in channel. When received client must call general publication event handler for each message in this array\n\n\noptional string \nlast\n - this field contains uid of last publication in channel. This allows fresh client which have not received publications before recover messages setting this value into next subscription request. \n\n\noptional bool \nrecovered\n - this flag is set to \ntrue\n when server thinks that all missed publications were successfully recovered and send in subscribe reply (in \npublications\n array) and \nfalse\n otherwise.\n\n\n\n\nAfter client received successful reply on \nsubscribe\n command it will receive asynchronous \nreply messages published to this channel. Messages can be of several types:\n\n\n\n\nPublication message\n\n\nJoin message\n\n\nLeave message\n\n\nUnsub message\n\n\n\n\nSee more about asynchronous messages below. \n\n\nUnsubscribe\n\u00b6\n\n\nThis is simple. When client wants to unsubscribe from channel and therefore stop receiving asynchronous subscription messages from connection related to channel it must call \nunsubscribe\n command:\n\n\n{\n\n    \n\"id\"\n:\n \n3\n,\n\n    \n\"method\"\n:\n \n\"unsubscribe\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"channel\"\n:\n \n\"ch1\"\n\n    \n}\n\n\n}\n\n\n\n\n\nActually server response does not mean a lot for client - it must immediately remove channel subscription from internal implementation data structures and ignore all messages related to channel.\n\n\nRefresh\n\u00b6\n\n\nIt's possible to turn on client connection expiration mechanism on server. While enabled server will keep track of connections whose time of life (defined by \nexp\n timestamp) is close to the end. In this case connection will be closed. Client can prevent closing connection refreshing it's connection credentials. To do this it must send \nrefresh\n command to server. \nrefresh\n command similar to \nconnect\n:\n\n\n{\n\n    \n\"id\"\n:\n \n4\n,\n\n    \n\"method\"\n:\n \n\"refresh\"\n,\n\n    \n\"params\"\n:\n \n{\n\n        \n\"user\"\n:\n \n\"42\"\n,\n\n        \n\"exp\"\n:\n \n\"1520096218\"\n,\n\n        \n\"info\"\n:\n \n\"\"\n,\n\n        \n\"sign\"\n:\n \n\"xxx\"\n\n    \n}\n\n\n}\n\n\n\n\n\nJust with actual \nexp\n and new \nsign\n.\n\n\nThe tip whether or not connection must be refreshed comes in reply to \nconnect\n command shown above - fields \nexpires\n, \nexpired\n and \nttl\n.\n\n\nWhen client connection expire mechanism is on the value of field \nexpires\n in connect reply is \ntrue\n. In this case client implementation should look at \nttl\n value which is seconds left until connection will be considered expired. Client must send \nrefresh\n command after this \nttl\n seconds. Server gives client a configured window to refresh credentials after \nttl\n passed and then closes connection if client have not updated its credentials. \nexpired\n field set to \ntrue\n when client connection already expired. In this case client should immediately send \nrefresh\n command to update credentials. And after doing this it can work the usual way.\n\n\nRPC-like calls: publish, history, presence\n\u00b6\n\n\nThe mechanics of these calls is simple - client sends command and expects response from server.\n\n\npublish\n command allows to publish message into channel from client.\n\n\n\n\nNote\n\n\nTo publish from client \npublish\n option in server configuration must be set to \ntrue\n\n\n\n\nhistory\n allows to ask server for channel history if enabled.\n\n\npresence\n allows to ask server for channel presence information if enabled.\n\n\nAsynchronous server-to-client messages\n\u00b6\n\n\nThere are several types of asynchronous messages that can come from server to client. All of them relate to current client subscriptions.\n\n\nThe most important message is \nPublication\n:\n\n\n{\n\n    \n\"result\"\n:\n{\n\n        \n\"channel\"\n:\n\"ch1\"\n,\n\n        \n\"data\"\n:\n{\n\n            \n\"uid\"\n:\n\"Ry4z8l6GvNMejwMxB7Sohe\"\n,\n\n            \n\"data\"\n:\n{\n\"input\"\n:\n\"1\"\n},\n\n            \n\"info\"\n:\n{\n\n                \n\"user\"\n:\n\"2694\"\n,\n\n                \n\"client\"\n:\n\"5c48510e-cf49-4fa8-a9b2-490b22231e74\"\n,\n\n                \n\"conn_info\"\n:\n{\n\"name\"\n:\n\"Alexander\"\n},\n\n                \n\"chan_info\"\n:\n{}\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\nPublication\n is a message published into channel. Note that there is no \nid\n field in this message - this symptom\nallows to distinguish it from \nReply\n to \nCommand\n.  \n\n\nNext message is \nJoin\n message:\n\n\n{\n\n    \n\"result\"\n:\n{\n\n        \n\"type\"\n:\n1\n,\n\n        \n\"channel\"\n:\n\"ch1\"\n,\n\n        \n\"data\"\n:\n{\n\n            \n\"info\"\n:\n{\n\n                \n\"user\"\n:\n\"2694\"\n,\n\n                \n\"client\"\n:\n\"5c48510e-cf49-4fa8-a9b2-490b22231e74\"\n,\n\n                \n\"conn_info\"\n:\n{\n\"name\"\n:\n\"Alexander\"\n},\n\n                \n\"chan_info\"\n:\n{}\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\nJoin\n messages sent when someone joined (subscribed on) channel.\n\n\n\n\nNote\n\n\nTo enable \nJoin\n and \nLeave\n messages \njoin_leave\n option must be enabled on server globally or for channel namespace.\n\n\n\n\nLeave\n messages sent when someone left (unsubscribed from) channel.\n\n\n{\n\n    \n\"result\"\n:\n{\n\n        \n\"type\"\n:\n2\n,\n\n        \n\"channel\"\n:\n\"ch1\"\n,\n\n        \n\"data\"\n:\n{\n\n            \n\"info\"\n:\n{\n\n                \n\"user\"\n:\n\"2694\"\n,\n\n                \n\"client\"\n:\n\"5c48510e-cf49-4fa8-a9b2-490b22231e74\"\n,\n\n                \n\"conn_info\"\n:\n{\n\"name\"\n:\n\"Alexander\"\n},\n\n                \n\"chan_info\"\n:\n{}\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\nAnd finally \nUnsub\n message that means that server unsubscribed current client from channel:\n\n\n{\n\n    \n\"result\"\n:\n{\n\n        \n\"type\"\n:\n3\n,\n\n        \n\"channel\"\n:\n\"ch1\"\n,\n\n        \n\"data\"\n:\n{}\n\n    \n}\n\n\n}\n\n\n\n\n\nIt's possible to distinguish between different types of asynchronous messages looking at \ntype\n field (for \nPublication\n this field not set or \n0\n).\n\n\nPing Pong\n\u00b6\n\n\nTo maintain connection alive and detect broken connections client must periodically send \nping\n commands to server and expect replies to it. Ping command looks like:\n\n\n{\n\n    \n\"id\"\n:\n32\n,\n\n    \n\"method\"\n:\n\"ping\"\n\n\n}\n\n\n\n\n\nServer just echoes this command back. When client does not receive ping reply for some time it must consider connection broken and try to reconnect. Recommended ping interval is 25 seconds, recommended period to wait for pong is 1-5 seconds. Though those numbers can vary.\n\n\nHandle disconnects\n\u00b6\n\n\nClient should handle disconnect advices from server. In websocket case disconnect advice is sent in reason field of CLOSE Websocket frame. Reason contains string which is \ndisconnect\n object encoded into JSON (even in case of Protobuf scenario). That objects looks like:\n\n\n{\n\n    \n\"reason\"\n:\n \n\"shutdown\"\n,\n\n    \n\"reconnect\"\n:\n \ntrue\n \n\n}\n\n\n\n\n\nIt contains string reason of connection closing and advice to reconnect or not. Client should take this reconnect advice into account.\n\n\nIn case of network problems and random disconnect from server without well known reason client should always try to  reconnect with exponential intervals.\n\n\nHandle errors\n\u00b6\n\n\nThis section contains advices to error handling in client implementations.\n\n\nErrors can happen during various operations and can be handled in special way in context of some commands to tolerate network and server problems.\n\n\nErrors during \nconnect\n must result in full client reconnect.\n\n\nErrors during \nsubscribe\n must result in full client reconnect if error is temporary. And be sent to subscribe error event handler of subscription if received error is persistent. Persistent errors are errors like \npermission denied\n, \nbad request\n, \nnamespace not found\n etc. Persistent errors in most situation mean a mistake from developers side.\n\n\nThe special corner case is client-side timeout during \nsubscribe\n operation. As protocol is asynchronous it's possible in this case that server will eventually subscribe client on channel but client will think that it's not subscribed. It's possible to retry subscription request and tolerate \nalready subscribed\n error as expected. But the simplest solution is to reconnect entirely as this is simpler and gives client a chance to connect to working server instance.\n\n\nErrors during rpc-like operations can be just returned to caller - i.e. user javascript code. Calls like \nhistory\n and \npresence\n are idempotent. You should be accurate with unidempotent operations like \npublish\n - in case of client timeout it's possible to send the same message into channel twice if retry publish after timeout - so if you care about this case make sure you have some protection from displaying message twice on client side (maybe some sort of unique key in payload).",
            "title": "Client protocol"
        },
        {
            "location": "/server/protocol/#client-protocol",
            "text": "This chapter describes internal client-server protocol in details to help developers build custom client libraries.  Note that you can always look at existing client implementations in case of any questions, for example  centrifuge-js .",
            "title": "Client protocol"
        },
        {
            "location": "/server/protocol/#what-client-should-do",
            "text": "When you are using Centrifuge/Centrifugo client you expect some core things from it:   connect to server and authenticate. Depending on transport endpoint address can differ. For example Centrifugo JSON-encoded Websocket endpoint is  ws://centrifugo.example.com/connection/websocket .  subscribe on channels developer wants. This allows to recieve messages published into channels in real-time.  have a possibility to make RPC calls, publish, asking for presence etc.  refresh client connection credentials when connection session lifetime is going to expire.  handle ping/pong messaging with server under the hood to maintain connection alive and detect broken connection.  handle protocol-specific errors, reconnect and recover missed messages automatically.   At moment Centrifuge/Centrifugo can work with several transports:   Websocket  SockJS  GRPC   This document describes protocol specifics for Websocket transport which supports binary and text formats to transfer data. As Centrifuge has various types of messages it serializes protocol messages using JSON or Protobuf (in case of binary websockets).   Note  SockJS works almost the same way as JSON websocket described here but has its own extra framing on top of Centrifuge protocol messages. SockJS can only work with JSON - it's not possible to transfer binary data over it. SockJS is only needed as fallback to Websocket in web browsers.    Note  GRPC support is an experimental at moment. GRPC works similar to what described here but it has its own transport details - Centrifuge library can not control how data travel over network and just uses GRPC generated API to pass messages between server and client over bidirectional streaming.",
            "title": "What client should do"
        },
        {
            "location": "/server/protocol/#top-level-framing",
            "text": "Centrifuge protocol defined in  Protobuf schema . That schema is a source of truth and all protocol description below describes messages from that schema.  Client sends  Command  to server.  Server sends  Reply  to client.  One request from client to server and one response from server to client can have more than one  Command  or  Reply .  When JSON format is used then many  Command  can be sent from client to server in JSON streaming line-delimited format. I.e. many commands delimited by new line symbol  \\n .  { \"id\" :   1 ,   \"method\" :   \"subscribe\" ,   \"params\" :   { \"channel\" :   \"ch1\" }}  { \"id\" :   2 ,   \"method\" :   \"subscribe\" ,   \"params\" :   { \"channel\" :   \"ch2\" }}    Note  This doc will use JSON format for examples because it's human-readable. Everything said here for JSON is also true for Protobuf encoded case.     Note  Method is made as ENUM in protobuf schema and can be sent as integer value but it's possible to send it as string in JSON case \u2013 this was made to make JSON protocol human-friendly.   When Protobuf format is used then many  Command  can be sent from client to server in length-delimited format where each individual  Command  marshaled to bytes prepended by  varint  length.  The same relates to many  Reply  in one response from server to client. Line-delimited JSON and varint-length prefixed Protobuf.  As you see above each  Command  has  id  field. This is an incremental integer field. This field will be echoed in server to client replies to commands so client could match a certain  Reply  to  Command  sent before. This is important because Websocket is asynchronous protocol where server and client both send messages in full-duplex mode.  So you can expect something like this when sending commands to server:  { \"id\" :   1 ,   \"result\" :   {}}  { \"id\" :   2 ,   \"result\" :   {}}   Besides  id   Reply  from server to client have two important fields:  result  and  error .  result  contains useful payload object which can be different depending on  Reply .  error  contains error object in case of  Command  processing resulted in some error on server.  error  is optional and if  Reply  does not have  error  then it means that  Command  processed successfuly and client can parse  result  object in an appropriate way.  error  objects looks like this:  { \n     \"code\" :   100 , \n     \"message\" :   \"internal server error\"  }   We will talk more about error handling below.  The special type of  Reply  is asynchronous  Reply . Those replies have no  id  field set (or  id  can be equal to zero). Async replies can come to client in any moment - not as reaction to issued  Command  but as message from server to client in arbitrary time. For example this can be message published into channel.  Centrifuge library defines several command types client can issue. And well-written client must be aware of all those commands and client workflow. Communication with Centrifuge/Centrifugo server starts with  connect  command.",
            "title": "Top level framing"
        },
        {
            "location": "/server/protocol/#connect",
            "text": "First of all client must dial with server and then send  connect   Command  to it.  Default Websocket endpoint in Centrifugo is:  ws://centrifugo.example.com/connection/websocket  In case of using TLS:  wss://centrifugo.example.com/connection/websocket  After successful dial to websocket endpoint client must send  connect  command to server to authorize itself.  connect  command looks like:  { \n     \"id\" :   1 , \n     \"method\" :   \"connect\" , \n     \"params\" :   { \n         \"user\" :   \"42\" , \n         \"exp\" :   \"1520094208\" , \n         \"info\" :   \"\" , \n         \"sign\" :   \"xxx\" \n     }  }   Where params fields are passed to client from application backend:   string  user  - current user ID. Can be empty string for unauthorized user.  string  exp  - timestamp seconds when client connection expires.  string  info  - optional base64 encoded information about connection. This is JSON object encoded to base64 in case of JSON format used and arbitrary bytes for Protobuf format.  string  sign  - HMAC SHA-256 sign generated on backend side from Centrifugo secret and fields above. This sign helps to prove the fact that client passed valid  user ,  exp ,  info  fields to server.   In response to  connect  command server sends connect reply. It looks this way:  { \n     \"id\" : 1 , \n     \"result\" : { \n         \"client\" : \"421bf374-dd01-4f82-9def-8c31697e956f\" , \n         \"version\" : \"2.0.0\" \n     }  }   result  has some fields:   string  client  - unique client connection ID server issued to this connection  string  version  - server version  optional bool  expires  - whether or not server will expire connection  optional bool  expired  - whether or not connection credentials already expired and must be refreshed  optional int32  ttl  - time in seconds until connection will expire",
            "title": "Connect"
        },
        {
            "location": "/server/protocol/#subscribe",
            "text": "As soon as client successfully connected and got unique connection ID it is ready to\nsubscribe on channels. To do this it must send  subscribe  command to server:  { \n     \"id\" :   2 , \n     \"method\" :   \"subscribe\" , \n     \"params\" :   { \n         \"channel\" :   \"ch1\" \n     }  }   Fields that can be set in  params  are:   string  channel  - channel to subscribe   In response to subscribe client receives reply like:  { \n     \"id\" : 2 , \n     \"result\" : {}  }   result  can have the following fields:   optional array  publications  - this is an array of missed publications in channel. When received client must call general publication event handler for each message in this array  optional string  last  - this field contains uid of last publication in channel. This allows fresh client which have not received publications before recover messages setting this value into next subscription request.   optional bool  recovered  - this flag is set to  true  when server thinks that all missed publications were successfully recovered and send in subscribe reply (in  publications  array) and  false  otherwise.   After client received successful reply on  subscribe  command it will receive asynchronous \nreply messages published to this channel. Messages can be of several types:   Publication message  Join message  Leave message  Unsub message   See more about asynchronous messages below.",
            "title": "Subscribe"
        },
        {
            "location": "/server/protocol/#unsubscribe",
            "text": "This is simple. When client wants to unsubscribe from channel and therefore stop receiving asynchronous subscription messages from connection related to channel it must call  unsubscribe  command:  { \n     \"id\" :   3 , \n     \"method\" :   \"unsubscribe\" , \n     \"params\" :   { \n         \"channel\" :   \"ch1\" \n     }  }   Actually server response does not mean a lot for client - it must immediately remove channel subscription from internal implementation data structures and ignore all messages related to channel.",
            "title": "Unsubscribe"
        },
        {
            "location": "/server/protocol/#refresh",
            "text": "It's possible to turn on client connection expiration mechanism on server. While enabled server will keep track of connections whose time of life (defined by  exp  timestamp) is close to the end. In this case connection will be closed. Client can prevent closing connection refreshing it's connection credentials. To do this it must send  refresh  command to server.  refresh  command similar to  connect :  { \n     \"id\" :   4 , \n     \"method\" :   \"refresh\" , \n     \"params\" :   { \n         \"user\" :   \"42\" , \n         \"exp\" :   \"1520096218\" , \n         \"info\" :   \"\" , \n         \"sign\" :   \"xxx\" \n     }  }   Just with actual  exp  and new  sign .  The tip whether or not connection must be refreshed comes in reply to  connect  command shown above - fields  expires ,  expired  and  ttl .  When client connection expire mechanism is on the value of field  expires  in connect reply is  true . In this case client implementation should look at  ttl  value which is seconds left until connection will be considered expired. Client must send  refresh  command after this  ttl  seconds. Server gives client a configured window to refresh credentials after  ttl  passed and then closes connection if client have not updated its credentials.  expired  field set to  true  when client connection already expired. In this case client should immediately send  refresh  command to update credentials. And after doing this it can work the usual way.",
            "title": "Refresh"
        },
        {
            "location": "/server/protocol/#rpc-like-calls-publish-history-presence",
            "text": "The mechanics of these calls is simple - client sends command and expects response from server.  publish  command allows to publish message into channel from client.   Note  To publish from client  publish  option in server configuration must be set to  true   history  allows to ask server for channel history if enabled.  presence  allows to ask server for channel presence information if enabled.",
            "title": "RPC-like calls: publish, history, presence"
        },
        {
            "location": "/server/protocol/#asynchronous-server-to-client-messages",
            "text": "There are several types of asynchronous messages that can come from server to client. All of them relate to current client subscriptions.  The most important message is  Publication :  { \n     \"result\" : { \n         \"channel\" : \"ch1\" , \n         \"data\" : { \n             \"uid\" : \"Ry4z8l6GvNMejwMxB7Sohe\" , \n             \"data\" : { \"input\" : \"1\" }, \n             \"info\" : { \n                 \"user\" : \"2694\" , \n                 \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \n                 \"conn_info\" : { \"name\" : \"Alexander\" }, \n                 \"chan_info\" : {} \n             } \n         } \n     }  }   Publication  is a message published into channel. Note that there is no  id  field in this message - this symptom\nallows to distinguish it from  Reply  to  Command .    Next message is  Join  message:  { \n     \"result\" : { \n         \"type\" : 1 , \n         \"channel\" : \"ch1\" , \n         \"data\" : { \n             \"info\" : { \n                 \"user\" : \"2694\" , \n                 \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \n                 \"conn_info\" : { \"name\" : \"Alexander\" }, \n                 \"chan_info\" : {} \n             } \n         } \n     }  }   Join  messages sent when someone joined (subscribed on) channel.   Note  To enable  Join  and  Leave  messages  join_leave  option must be enabled on server globally or for channel namespace.   Leave  messages sent when someone left (unsubscribed from) channel.  { \n     \"result\" : { \n         \"type\" : 2 , \n         \"channel\" : \"ch1\" , \n         \"data\" : { \n             \"info\" : { \n                 \"user\" : \"2694\" , \n                 \"client\" : \"5c48510e-cf49-4fa8-a9b2-490b22231e74\" , \n                 \"conn_info\" : { \"name\" : \"Alexander\" }, \n                 \"chan_info\" : {} \n             } \n         } \n     }  }   And finally  Unsub  message that means that server unsubscribed current client from channel:  { \n     \"result\" : { \n         \"type\" : 3 , \n         \"channel\" : \"ch1\" , \n         \"data\" : {} \n     }  }   It's possible to distinguish between different types of asynchronous messages looking at  type  field (for  Publication  this field not set or  0 ).",
            "title": "Asynchronous server-to-client messages"
        },
        {
            "location": "/server/protocol/#ping-pong",
            "text": "To maintain connection alive and detect broken connections client must periodically send  ping  commands to server and expect replies to it. Ping command looks like:  { \n     \"id\" : 32 , \n     \"method\" : \"ping\"  }   Server just echoes this command back. When client does not receive ping reply for some time it must consider connection broken and try to reconnect. Recommended ping interval is 25 seconds, recommended period to wait for pong is 1-5 seconds. Though those numbers can vary.",
            "title": "Ping Pong"
        },
        {
            "location": "/server/protocol/#handle-disconnects",
            "text": "Client should handle disconnect advices from server. In websocket case disconnect advice is sent in reason field of CLOSE Websocket frame. Reason contains string which is  disconnect  object encoded into JSON (even in case of Protobuf scenario). That objects looks like:  { \n     \"reason\" :   \"shutdown\" , \n     \"reconnect\" :   true   }   It contains string reason of connection closing and advice to reconnect or not. Client should take this reconnect advice into account.  In case of network problems and random disconnect from server without well known reason client should always try to  reconnect with exponential intervals.",
            "title": "Handle disconnects"
        },
        {
            "location": "/server/protocol/#handle-errors",
            "text": "This section contains advices to error handling in client implementations.  Errors can happen during various operations and can be handled in special way in context of some commands to tolerate network and server problems.  Errors during  connect  must result in full client reconnect.  Errors during  subscribe  must result in full client reconnect if error is temporary. And be sent to subscribe error event handler of subscription if received error is persistent. Persistent errors are errors like  permission denied ,  bad request ,  namespace not found  etc. Persistent errors in most situation mean a mistake from developers side.  The special corner case is client-side timeout during  subscribe  operation. As protocol is asynchronous it's possible in this case that server will eventually subscribe client on channel but client will think that it's not subscribed. It's possible to retry subscription request and tolerate  already subscribed  error as expected. But the simplest solution is to reconnect entirely as this is simpler and gives client a chance to connect to working server instance.  Errors during rpc-like operations can be just returned to caller - i.e. user javascript code. Calls like  history  and  presence  are idempotent. You should be accurate with unidempotent operations like  publish  - in case of client timeout it's possible to send the same message into channel twice if retry publish after timeout - so if you care about this case make sure you have some protection from displaying message twice on client side (maybe some sort of unique key in payload).",
            "title": "Handle errors"
        }
    ]
}