{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Centrifugo overview First of all we have chats on Gitter and in Telegram \u2013 welcome! Centrifugo is a language-agnostic real-time messaging server. Language-agnostic means that it does not matter which programming language your application uses on frontend or backend sides \u2013 Centrifugo can work in conjunction with any. Real-time messages are messages that delivered to your application users almost immediately after some event happened - think live comments, chats, real-time charts, dynamic counters and games. There are several real-time messaging transports Centrifugo supports at moment: Websocket with JSON or binary Protobuf protocols SockJS \u2013 library that tries to establish Websocket connection first and then falls back to HTTP transports (Server-Sent Events, XHR-streaming, XHR-polling etc) automatically in case of problems with Websocket connection Motivation of project Centrifugo was originally born to help applications written in language or framework without builtin concurency support to introduce real-time updates. For example frameworks like Django, Flask, Yii, Laravel, Ruby on Rails etc has poor support of working with many persistent connections. Centrifugo aims to help with this and continue to write backend in your favorite language and favorite framework. It also has some features (performance, scalability, connection management, message recovery on reconnect etc) that can simplify your life as a developer even if you are writing backend in asynchronous concurrent language. Concepts Centrifugo runs as standalone server and takes care of handling persistent connections from your application users. Your application backend and frontend can be written in any programming language. Your clients connect to Centrifugo from frontend using connection token (JWT) provided by your application backend and subscribe to channels. As soon as some event happens your application backend can publish message with event into channel using Centrifugo API. And that message will be delivered to all clients currently subscribed on channel. So actually Centrifugo is a user-facing PUB/SUB server. Here is a simplified scheme:","title":"Getting Started"},{"location":"#centrifugo-overview","text":"First of all we have chats on Gitter and in Telegram \u2013 welcome! Centrifugo is a language-agnostic real-time messaging server. Language-agnostic means that it does not matter which programming language your application uses on frontend or backend sides \u2013 Centrifugo can work in conjunction with any. Real-time messages are messages that delivered to your application users almost immediately after some event happened - think live comments, chats, real-time charts, dynamic counters and games. There are several real-time messaging transports Centrifugo supports at moment: Websocket with JSON or binary Protobuf protocols SockJS \u2013 library that tries to establish Websocket connection first and then falls back to HTTP transports (Server-Sent Events, XHR-streaming, XHR-polling etc) automatically in case of problems with Websocket connection","title":"Centrifugo overview"},{"location":"#motivation-of-project","text":"Centrifugo was originally born to help applications written in language or framework without builtin concurency support to introduce real-time updates. For example frameworks like Django, Flask, Yii, Laravel, Ruby on Rails etc has poor support of working with many persistent connections. Centrifugo aims to help with this and continue to write backend in your favorite language and favorite framework. It also has some features (performance, scalability, connection management, message recovery on reconnect etc) that can simplify your life as a developer even if you are writing backend in asynchronous concurrent language.","title":"Motivation of project"},{"location":"#concepts","text":"Centrifugo runs as standalone server and takes care of handling persistent connections from your application users. Your application backend and frontend can be written in any programming language. Your clients connect to Centrifugo from frontend using connection token (JWT) provided by your application backend and subscribe to channels. As soon as some event happens your application backend can publish message with event into channel using Centrifugo API. And that message will be delivered to all clients currently subscribed on channel. So actually Centrifugo is a user-facing PUB/SUB server. Here is a simplified scheme:","title":"Concepts"},{"location":"faq/","text":"FAQ Answers on various questions here. How many connections can one Centrifugo instance handle? This depends on many factors. Hardware, message rate, size of messages, channel options enabled, client distribution over channels, websocket compression on/off etc. So no certain answer on this question exists. Common sense, tests and monitoring can help here. Generally we suggest to not put more than 50-100k clients on one node - but you should measure. Can Centrifugo scale horizontally? Yes, it can. It can do this using builtin Redis Engine. Redis is very fast \u2013 for example it can handle hundreds of thousands requests per second. This should be OK for most applications in internet. But if you are using Centrifugo and approaching this limit then it s possible to add sharding support to balance queries between different Redis instances. Message delivery model and message order guarantees The model of message delivery of Centrifugo server is at most once. This means that message you send to Centrifugo can be theoretically lost while moving towards your clients. Centrifugo tries to do a best effort to prevent message losses but you should be aware of this fact. Your application should tolerate this. Centrifugo has an option to automatically recover messages that have been lost because of short network disconnections. But there are cases when Centrifugo can t guarantee message delivery. We also recommend to model your applications in a way that users don t notice when message have been lost. For example if your user posts a new comment over AJAX call to your application backend - you should not rely only on Centrifugo to get new comment form and display it - you should return new comment data in AJAX call response and render it. Be careful to not draw comments twice in this case. Message order in channels guaranteed to be the same while you publish messages into channel one after another or publish them in one request. If you do parallel publishes into the same channel then Centrifugo can t guarantee message order. Centrifugo stops accepting new connections, why? The most popular reason behind this is reaching open file limit. Just make it higher, we described how to do this nearby in this doc. Can I use Centrifugo without reverse-proxy like Nginx before it? Yes, you can - Go standard library designed to allow this. But proxy before Centrifugo can be very useful for load balancing clients for example. Does Centrifugo work with HTTP/2? Yes, Centrifugo works with HTTP/2. You can disable HTTP/2 running Centrifugo server with GODEBUG environment variable: GODEBUG= http2server=0 centrifugo -c config.json Is there a way to use single connection to Centrifugo from different browser tabs? If underlying transport is HTTP-based and you use HTTP/2 then this will work automatically. In case of websocket connection there is a way to do this using SharedWorker object though we have no support to work this way in our Javascript library. What if I need to send push notifications to mobile or web applications? Sometimes it s confusing to see a difference between real-time messages and push notifications. Centrifugo is a real-time messaging server. It can not send push notifications to devices - to Apple iOS devices via APNS, Android devices via GCM or browsers over Web Push API. This is a goal for another software. But the reasonable question here is how can I know when I need to send real-time message to client online or push notification to its device because application closed at client s device at moment. The solution is pretty simple. You can keep critical notifications for client in database. And when client read message send ack to your backend marking that notification as read by client, you save this ack too. Periodically you can check which notifications were sent to clients but they have not read it (no ack received). For such notification you can send push notification to its device using your own or another open-source solution. Look at Firebase for example! Can I know message was really delivered to client? You can but Centrifugo does not have such API. What you have to do to ensure your client received message is sending confirmation ack from your client to your application backend as soon as client processed message coming from Centrifugo channel. Can I publish new messages over websocket connection from client? Centrifugo designed to stream messages from server to client. Even though it s possible to publish messages into channels directly from client (when publish channel option enabled) - we strongly discourage this in production usage as those messages will go through Centrifugo without any control. Theoretically Centrifugo could resend messages published from client to your application backend endpoint (i.e. having some sort of webhook built in) but it does not seem beneficial it terms of overall performance and application architecture at moment. And this will require extra layer of convetions about Centrifugo-to-backend communication. So in general when user generates an event it must be first delivered to your app backend using a convenient way (for example AJAX POST request for web application), processed on backend (validated, saved into main application database) and then published to Centrifugo using Centrifugo HTTP API or Redis queue. Sometimes publishing from client directly into channel can be useful though - for personal projects, for demonstrations (like we do in our examples ) or if you trust your users and want to build application without backend. In all cases when you don t need any message control on your backend. How to create secure channel for two users only (private chat case)? There are several ways to achieve it: use private channel (starting with $ ) - every time user will try to subscribe on it your backend should provide sign to confirm that subscription request. Read more in special chapter about channels next is user limited channels (with # ) - you can create channel with name like dialog#42,567 to limit subscribers only to user with id 42 and user with ID 567 finally you can create hard to guess channel name (based on some secret key and user IDs or just generate and save this long unique name into your main app database) so other users won t know this channel to subscribe on it. This is the simplest but not the safest way - but can be reasonable to consider in many situations. What s a best way to organize channel configuration? In most situations your application need several real-time features. We suggest to use namespaces for every real-time feature if it requires some option enabled. For example if you need join/leave messages for chat app - create special channel namespace with this join_leave option enabled. Otherwise your other channels will receive join/leave messages too - increasing load and traffic in system but not actually used by clients. The same relates to other channel options. Can I rely on Centrifugo and its message history for guaranteed message delivery? No - Centrifugo is best-effort transport. This means that if you want strongly guaranteed message delivery to your clients then you can t just rely on Centrifugo and its message history cache. In this case you still can use Centrifugo for real-time but you should build some additional logic on top your application backend and main data storage to satisfy your guarantees. Centrifugo can keep message history for a while and you can want to rely on it for your needs. Centrifugo is not designed as data storage - it uses message history mostly for recovering missed messages after short client internet connection disconnects. It s not designed to be used to sync client state after being offline for a long time - this logic should be on your app backend. Does Centrifugo support webhooks? Not at moment. Centrifugo designed in a way where messages mostly from one direction: from server to client. If you need any callbacks you can call your application backend yourself from client side. There are several reasons why we can t simply add webhooks \u2013 some of them described in this issue . If you need to know that client disconnected and program your business logic around this fact then a reasonable approach is periodically call your backend from client side and update user status somewhere on backend (use Redis maybe). This is a pretty robust solution where you can t occasionally miss disconnect event. What is the difference between Centrifugo and Centrifuge Centrifugo is server built on top of Centrifuge library for Go language. This documentation was built to describe Centrifugo. Though many things said here can be considered as extra documentation for Centrifuge library. I have not found an answer on my question here: We have Gitter chat room and Telegram group - welcome! I want to contribute to this awesome project We have many things you can help with \u2013 just ask us in our chat rooms.","title":"FAQ"},{"location":"faq/#faq","text":"Answers on various questions here.","title":"FAQ"},{"location":"faq/#how-many-connections-can-one-centrifugo-instance-handle","text":"This depends on many factors. Hardware, message rate, size of messages, channel options enabled, client distribution over channels, websocket compression on/off etc. So no certain answer on this question exists. Common sense, tests and monitoring can help here. Generally we suggest to not put more than 50-100k clients on one node - but you should measure.","title":"How many connections can one Centrifugo instance handle?"},{"location":"faq/#can-centrifugo-scale-horizontally","text":"Yes, it can. It can do this using builtin Redis Engine. Redis is very fast \u2013 for example it can handle hundreds of thousands requests per second. This should be OK for most applications in internet. But if you are using Centrifugo and approaching this limit then it s possible to add sharding support to balance queries between different Redis instances.","title":"Can Centrifugo scale horizontally?"},{"location":"faq/#message-delivery-model-and-message-order-guarantees","text":"The model of message delivery of Centrifugo server is at most once. This means that message you send to Centrifugo can be theoretically lost while moving towards your clients. Centrifugo tries to do a best effort to prevent message losses but you should be aware of this fact. Your application should tolerate this. Centrifugo has an option to automatically recover messages that have been lost because of short network disconnections. But there are cases when Centrifugo can t guarantee message delivery. We also recommend to model your applications in a way that users don t notice when message have been lost. For example if your user posts a new comment over AJAX call to your application backend - you should not rely only on Centrifugo to get new comment form and display it - you should return new comment data in AJAX call response and render it. Be careful to not draw comments twice in this case. Message order in channels guaranteed to be the same while you publish messages into channel one after another or publish them in one request. If you do parallel publishes into the same channel then Centrifugo can t guarantee message order.","title":"Message delivery model and message order guarantees"},{"location":"faq/#centrifugo-stops-accepting-new-connections-why","text":"The most popular reason behind this is reaching open file limit. Just make it higher, we described how to do this nearby in this doc.","title":"Centrifugo stops accepting new connections, why?"},{"location":"faq/#can-i-use-centrifugo-without-reverse-proxy-like-nginx-before-it","text":"Yes, you can - Go standard library designed to allow this. But proxy before Centrifugo can be very useful for load balancing clients for example.","title":"Can I use Centrifugo without reverse-proxy like Nginx before it?"},{"location":"faq/#does-centrifugo-work-with-http2","text":"Yes, Centrifugo works with HTTP/2. You can disable HTTP/2 running Centrifugo server with GODEBUG environment variable: GODEBUG= http2server=0 centrifugo -c config.json","title":"Does Centrifugo work with HTTP/2?"},{"location":"faq/#is-there-a-way-to-use-single-connection-to-centrifugo-from-different-browser-tabs","text":"If underlying transport is HTTP-based and you use HTTP/2 then this will work automatically. In case of websocket connection there is a way to do this using SharedWorker object though we have no support to work this way in our Javascript library.","title":"Is there a way to use single connection to Centrifugo from different browser tabs?"},{"location":"faq/#what-if-i-need-to-send-push-notifications-to-mobile-or-web-applications","text":"Sometimes it s confusing to see a difference between real-time messages and push notifications. Centrifugo is a real-time messaging server. It can not send push notifications to devices - to Apple iOS devices via APNS, Android devices via GCM or browsers over Web Push API. This is a goal for another software. But the reasonable question here is how can I know when I need to send real-time message to client online or push notification to its device because application closed at client s device at moment. The solution is pretty simple. You can keep critical notifications for client in database. And when client read message send ack to your backend marking that notification as read by client, you save this ack too. Periodically you can check which notifications were sent to clients but they have not read it (no ack received). For such notification you can send push notification to its device using your own or another open-source solution. Look at Firebase for example!","title":"What if I need to send push notifications to mobile or web applications?"},{"location":"faq/#can-i-know-message-was-really-delivered-to-client","text":"You can but Centrifugo does not have such API. What you have to do to ensure your client received message is sending confirmation ack from your client to your application backend as soon as client processed message coming from Centrifugo channel.","title":"Can I know message was really delivered to client?"},{"location":"faq/#can-i-publish-new-messages-over-websocket-connection-from-client","text":"Centrifugo designed to stream messages from server to client. Even though it s possible to publish messages into channels directly from client (when publish channel option enabled) - we strongly discourage this in production usage as those messages will go through Centrifugo without any control. Theoretically Centrifugo could resend messages published from client to your application backend endpoint (i.e. having some sort of webhook built in) but it does not seem beneficial it terms of overall performance and application architecture at moment. And this will require extra layer of convetions about Centrifugo-to-backend communication. So in general when user generates an event it must be first delivered to your app backend using a convenient way (for example AJAX POST request for web application), processed on backend (validated, saved into main application database) and then published to Centrifugo using Centrifugo HTTP API or Redis queue. Sometimes publishing from client directly into channel can be useful though - for personal projects, for demonstrations (like we do in our examples ) or if you trust your users and want to build application without backend. In all cases when you don t need any message control on your backend.","title":"Can I publish new messages over websocket connection from client?"},{"location":"faq/#how-to-create-secure-channel-for-two-users-only-private-chat-case","text":"There are several ways to achieve it: use private channel (starting with $ ) - every time user will try to subscribe on it your backend should provide sign to confirm that subscription request. Read more in special chapter about channels next is user limited channels (with # ) - you can create channel with name like dialog#42,567 to limit subscribers only to user with id 42 and user with ID 567 finally you can create hard to guess channel name (based on some secret key and user IDs or just generate and save this long unique name into your main app database) so other users won t know this channel to subscribe on it. This is the simplest but not the safest way - but can be reasonable to consider in many situations.","title":"How to create secure channel for two users only (private chat case)?"},{"location":"faq/#whats-a-best-way-to-organize-channel-configuration","text":"In most situations your application need several real-time features. We suggest to use namespaces for every real-time feature if it requires some option enabled. For example if you need join/leave messages for chat app - create special channel namespace with this join_leave option enabled. Otherwise your other channels will receive join/leave messages too - increasing load and traffic in system but not actually used by clients. The same relates to other channel options.","title":"What's a best way to organize channel configuration?"},{"location":"faq/#can-i-rely-on-centrifugo-and-its-message-history-for-guaranteed-message-delivery","text":"No - Centrifugo is best-effort transport. This means that if you want strongly guaranteed message delivery to your clients then you can t just rely on Centrifugo and its message history cache. In this case you still can use Centrifugo for real-time but you should build some additional logic on top your application backend and main data storage to satisfy your guarantees. Centrifugo can keep message history for a while and you can want to rely on it for your needs. Centrifugo is not designed as data storage - it uses message history mostly for recovering missed messages after short client internet connection disconnects. It s not designed to be used to sync client state after being offline for a long time - this logic should be on your app backend.","title":"Can I rely on Centrifugo and its message history for guaranteed message delivery?"},{"location":"faq/#does-centrifugo-support-webhooks","text":"Not at moment. Centrifugo designed in a way where messages mostly from one direction: from server to client. If you need any callbacks you can call your application backend yourself from client side. There are several reasons why we can t simply add webhooks \u2013 some of them described in this issue . If you need to know that client disconnected and program your business logic around this fact then a reasonable approach is periodically call your backend from client side and update user status somewhere on backend (use Redis maybe). This is a pretty robust solution where you can t occasionally miss disconnect event.","title":"Does Centrifugo support webhooks?"},{"location":"faq/#what-is-the-difference-between-centrifugo-and-centrifuge","text":"Centrifugo is server built on top of Centrifuge library for Go language. This documentation was built to describe Centrifugo. Though many things said here can be considered as extra documentation for Centrifuge library.","title":"What is the difference between Centrifugo and Centrifuge"},{"location":"faq/#i-have-not-found-an-answer-on-my-question-here","text":"We have Gitter chat room and Telegram group - welcome!","title":"I have not found an answer on my question here:"},{"location":"faq/#i-want-to-contribute-to-this-awesome-project","text":"We have many things you can help with \u2013 just ask us in our chat rooms.","title":"I want to contribute to this awesome project"},{"location":"guide/","text":"Centrifugo integration guide This chapter aims to help you get started with Centrifugo. We will look at step-by-step workflow of integrating your application with Centrifugo providing links to relevant parts of this documentation. As Centrifugo is language-agnostic and can be used together with any language/framework we won t be specific here about any backend or frontend technology your application can be built with. Only abstract steps which you can extrapolate to your stack. So first of all let s look again at simplified scheme: There are three parts involved into idiomatic Centrifugo usage scenario: your clients (frontend app), your application backend and Centrifugo. It s possible to use Centrifugo without any application backend involved but here we won t consider this use case. Here let s suppose you already have 2 of 3 elements: clients and backend. And you want to add Centrifugo for real-time events. 1) First you need to do is download/install Centrifugo server. See install chapter for details. 2) Create basic configuration file with secret and api_key set and then run Centrifugo. See this chapter for details about secret key and chapter about API for API description. The simplest way to do this automatically is by using genconfig command: ./centrifugo genconfig \u2013 which will generate config.json file for you with all required fields. 3) In configuration file of your application backend register several variables: Centrifugo secret and Centrifugo API key you set on previous step and Centrifugo API address. By default API address is http://localhost:8000/api . You must never reveal secret and API key to your users . 4) Now your users can start connecting to Centrifugo. You should get client library (see list of available client libraries ) for your application frontend. Every library has method to connect to Centrifugo. See information about Centrifugo connection endpoints here . Every client should provide connection token (JWT) on connect. You must generate this token on your backend side using Centrifugo secret key you set to backend configuration. See how to generate this JWT in special chapter . You pass this token from backend to your frontend app (pass it in template context or use separate request from client side to get user specific JWT from backend side). And use this token when connecting to Centrifugo (for example browser client has special method setToken ). 5) After connecting to Centrifugo subscribe clients to channels they are interested in. See more about channels in special chapter . All client libraries provide a way to handle messages coming to client from channel after subscribing to it. 6) So everything should work now \u2013 as soon as user opens some page of your application it must successfully connect to Centrifugo and subscribe to channel (or channels). Now let s imagine you want to send real-time message to users subscribed on specific channel. This message can be a reaction on some event happened in your app: someone posted new comment, administrator just created new post, user pressed like button etc. Anyway this is an event your backend just got and you want to immediately share it with interested users. You can do this using Centrifugo HTTP API . To simplify your life we have several API libraries for different languages. You can publish message into channel using one of those libraries or you can simply follow API description to construct API request yourself - this is very simple. Also Centrifugo supports GRPC API . As soon as you published message to channel it must be delivered to your client. 7) To put this all into production you need to deploy Centrifugo on your production server. To help you with this we have many things like Docker image, rpm and deb packages, Nginx configuration. You can find more information in Deploy section of this doc. 8) Don t forget to monitor your production Centrifugo setup. That s all for basics. Documentation actually covers lots of other concepts Centrifugo server has: like scalability, private channels, admin web interface, SockJS fallback, Protobuf support and more. And don t forget to read our FAQ .","title":"Integration Guide"},{"location":"guide/#centrifugo-integration-guide","text":"This chapter aims to help you get started with Centrifugo. We will look at step-by-step workflow of integrating your application with Centrifugo providing links to relevant parts of this documentation. As Centrifugo is language-agnostic and can be used together with any language/framework we won t be specific here about any backend or frontend technology your application can be built with. Only abstract steps which you can extrapolate to your stack. So first of all let s look again at simplified scheme: There are three parts involved into idiomatic Centrifugo usage scenario: your clients (frontend app), your application backend and Centrifugo. It s possible to use Centrifugo without any application backend involved but here we won t consider this use case. Here let s suppose you already have 2 of 3 elements: clients and backend. And you want to add Centrifugo for real-time events. 1) First you need to do is download/install Centrifugo server. See install chapter for details. 2) Create basic configuration file with secret and api_key set and then run Centrifugo. See this chapter for details about secret key and chapter about API for API description. The simplest way to do this automatically is by using genconfig command: ./centrifugo genconfig \u2013 which will generate config.json file for you with all required fields. 3) In configuration file of your application backend register several variables: Centrifugo secret and Centrifugo API key you set on previous step and Centrifugo API address. By default API address is http://localhost:8000/api . You must never reveal secret and API key to your users . 4) Now your users can start connecting to Centrifugo. You should get client library (see list of available client libraries ) for your application frontend. Every library has method to connect to Centrifugo. See information about Centrifugo connection endpoints here . Every client should provide connection token (JWT) on connect. You must generate this token on your backend side using Centrifugo secret key you set to backend configuration. See how to generate this JWT in special chapter . You pass this token from backend to your frontend app (pass it in template context or use separate request from client side to get user specific JWT from backend side). And use this token when connecting to Centrifugo (for example browser client has special method setToken ). 5) After connecting to Centrifugo subscribe clients to channels they are interested in. See more about channels in special chapter . All client libraries provide a way to handle messages coming to client from channel after subscribing to it. 6) So everything should work now \u2013 as soon as user opens some page of your application it must successfully connect to Centrifugo and subscribe to channel (or channels). Now let s imagine you want to send real-time message to users subscribed on specific channel. This message can be a reaction on some event happened in your app: someone posted new comment, administrator just created new post, user pressed like button etc. Anyway this is an event your backend just got and you want to immediately share it with interested users. You can do this using Centrifugo HTTP API . To simplify your life we have several API libraries for different languages. You can publish message into channel using one of those libraries or you can simply follow API description to construct API request yourself - this is very simple. Also Centrifugo supports GRPC API . As soon as you published message to channel it must be delivered to your client. 7) To put this all into production you need to deploy Centrifugo on your production server. To help you with this we have many things like Docker image, rpm and deb packages, Nginx configuration. You can find more information in Deploy section of this doc. 8) Don t forget to monitor your production Centrifugo setup. That s all for basics. Documentation actually covers lots of other concepts Centrifugo server has: like scalability, private channels, admin web interface, SockJS fallback, Protobuf support and more. And don t forget to read our FAQ .","title":"Centrifugo integration guide"},{"location":"deploy/docker/","text":"Docker image Centrifugo server has docker image available on Docker Hub . docker pull centrifugo/centrifugo Run: docker run --ulimit nofile = 65536 :65536 -v /host/dir/with/config/file:/centrifugo -p 8000 :8000 centrifugo/centrifugo centrifugo -c config.json Note that docker allows to set nofile limits in command-line arguments which is pretty important to handle lots of simultaneous persistent connections and not run out of open file limit.","title":"Docker image"},{"location":"deploy/docker/#docker-image","text":"Centrifugo server has docker image available on Docker Hub . docker pull centrifugo/centrifugo Run: docker run --ulimit nofile = 65536 :65536 -v /host/dir/with/config/file:/centrifugo -p 8000 :8000 centrifugo/centrifugo centrifugo -c config.json Note that docker allows to set nofile limits in command-line arguments which is pretty important to handle lots of simultaneous persistent connections and not run out of open file limit.","title":"Docker image"},{"location":"deploy/nginx/","text":"Nginx configuration Although it s possible to use Centrifugo without any reverse proxy before it, it s still a good idea to keep Centrifugo behind mature reverse proxy to deal with edge cases when handling HTTP/Websocket connections from the wild. Also you probably want some sort of load balancing eventually between Centrifugo nodes so that proxy can be such a balancer too. In this section we will look at Nginx configuration to deploy Centrifugo. Minimal Nginx version \u2013 1.3.13 because it was the first version that can proxy Websocket connections. There are 2 ways: running Centrifugo server as separate service on its own domain or embed it to a location of your web site (for example to /centrifugo ). Separate domain for Centrifugo upstream centrifugo { # Enumerate all upstream servers here #sticky ; ip_hash ; server 127.0.0.1:8000 ; #server 127.0.0.1:8001 ; } map $ http_upgrade $ connection_upgrade { default upgrade ; close ; } # server { # listen 80 ; # server_name centrifugo.example.com ; # rewrite ^(.*) https : // $ server_name $ 1 permanent ; # } server { server_name centrifugo.example.com ; listen 80 ; #listen 443 ; #ssl on ; #ssl_protocols TLSv1 TLSv1.1 TLSv1.2 ; #ssl_ciphers AES128-SHA : AES256-SHA : RC4-SHA : DES-CBC3-SHA : RC4-MD5 ; #ssl_certificate /etc/nginx/ssl/wildcard.example.com.crt ; #ssl_certificate_key /etc/nginx/ssl/wildcard.example.com.key ; #ssl_session_cache shared : SSL : 10 m ; ssl_session_timeout 10m ; include /etc/nginx/mime.types ; default_type application/octet-stream ; sendfile on ; tcp_nopush on ; tcp_nodelay on ; gzip on ; gzip_min_length 1000 ; gzip_proxied any ; # Only retry if there was a communication error, not a timeout # on the Tornado server (to avoid propagating queries of death # to all frontends) proxy_next_upstream error ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Scheme $scheme ; proxy_set_header Host $http_host ; location /connection { proxy_pass http : // centrifugo ; proxy_buffering off ; keepalive_timeout 65 ; proxy_read_timeout 60s ; proxy_http_version 1.1 ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Scheme $scheme ; proxy_set_header Host $http_host ; proxy_set_header Upgrade $http_upgrade ; proxy_set_header Connection $connection_upgrade ; } location / { proxy_pass http : // centrifugo ; } error_page 500 502 503 504 / 50x . html ; location = / 50x . html { root /usr/share/nginx/html ; } } Embed to a location of web site upstream centrifugo { # Enumerate all the Tornado servers here #sticky ; ip_hash ; server 127.0.0.1:8000 ; #server 127.0.0.1:8001 ; } map $ http_upgrade $ connection_upgrade { default upgrade ; close ; } server { # ... your web site Nginx config location /centrifugo/ { rewrite ^/centrifugo/(.*) /$1 break ; proxy_pass_header Server ; proxy_set_header Host $http_host ; proxy_redirect off ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Scheme $scheme ; proxy_pass http : // centrifugo ; } location / centrifugo / connection { rewrite ^/centrifugo(.*) $1 break ; proxy_next_upstream error ; gzip on ; gzip_min_length 1000 ; gzip_proxied any ; proxy_buffering off ; keepalive_timeout 65 ; proxy_pass http : // centrifugo ; proxy_read_timeout 60s ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Scheme $scheme ; proxy_set_header Host $http_host ; proxy_http_version 1.1 ; proxy_set_header Upgrade $http_upgrade ; proxy_set_header Connection $connection_upgrade ; } } sticky You may be noticed commented sticky; directive in nginx upstream configuration. When using SockJS and client connects to Centrifugo - SockJS session created - and to communicate client must send all next requests to the same upstream backend. In this configuration we use ip_hash; directive to proxy clients with the same ip address to the same upstream backend. But ip_hash; is not the best choice in this case, because there could be situations where a lot of different browsers are coming with the same IP address (behind proxies) and the load balancing system won t be fair. Also fair load balancing does not work during development - when all clients connecting from localhost. So the best solution would be using something like nginx-sticky-module which uses setting a special cookie to track the upstream server for client. worker_connections You may also need to update worker_connections option of Nginx: events { worker_connections 40000; } Upstream keepalive See chapter about operating system tuning for more details.","title":"Nginx configuration"},{"location":"deploy/nginx/#nginx-configuration","text":"Although it s possible to use Centrifugo without any reverse proxy before it, it s still a good idea to keep Centrifugo behind mature reverse proxy to deal with edge cases when handling HTTP/Websocket connections from the wild. Also you probably want some sort of load balancing eventually between Centrifugo nodes so that proxy can be such a balancer too. In this section we will look at Nginx configuration to deploy Centrifugo. Minimal Nginx version \u2013 1.3.13 because it was the first version that can proxy Websocket connections. There are 2 ways: running Centrifugo server as separate service on its own domain or embed it to a location of your web site (for example to /centrifugo ).","title":"Nginx configuration"},{"location":"deploy/nginx/#separate-domain-for-centrifugo","text":"upstream centrifugo { # Enumerate all upstream servers here #sticky ; ip_hash ; server 127.0.0.1:8000 ; #server 127.0.0.1:8001 ; } map $ http_upgrade $ connection_upgrade { default upgrade ; close ; } # server { # listen 80 ; # server_name centrifugo.example.com ; # rewrite ^(.*) https : // $ server_name $ 1 permanent ; # } server { server_name centrifugo.example.com ; listen 80 ; #listen 443 ; #ssl on ; #ssl_protocols TLSv1 TLSv1.1 TLSv1.2 ; #ssl_ciphers AES128-SHA : AES256-SHA : RC4-SHA : DES-CBC3-SHA : RC4-MD5 ; #ssl_certificate /etc/nginx/ssl/wildcard.example.com.crt ; #ssl_certificate_key /etc/nginx/ssl/wildcard.example.com.key ; #ssl_session_cache shared : SSL : 10 m ; ssl_session_timeout 10m ; include /etc/nginx/mime.types ; default_type application/octet-stream ; sendfile on ; tcp_nopush on ; tcp_nodelay on ; gzip on ; gzip_min_length 1000 ; gzip_proxied any ; # Only retry if there was a communication error, not a timeout # on the Tornado server (to avoid propagating queries of death # to all frontends) proxy_next_upstream error ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Scheme $scheme ; proxy_set_header Host $http_host ; location /connection { proxy_pass http : // centrifugo ; proxy_buffering off ; keepalive_timeout 65 ; proxy_read_timeout 60s ; proxy_http_version 1.1 ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Scheme $scheme ; proxy_set_header Host $http_host ; proxy_set_header Upgrade $http_upgrade ; proxy_set_header Connection $connection_upgrade ; } location / { proxy_pass http : // centrifugo ; } error_page 500 502 503 504 / 50x . html ; location = / 50x . html { root /usr/share/nginx/html ; } }","title":"Separate domain for Centrifugo"},{"location":"deploy/nginx/#embed-to-a-location-of-web-site","text":"upstream centrifugo { # Enumerate all the Tornado servers here #sticky ; ip_hash ; server 127.0.0.1:8000 ; #server 127.0.0.1:8001 ; } map $ http_upgrade $ connection_upgrade { default upgrade ; close ; } server { # ... your web site Nginx config location /centrifugo/ { rewrite ^/centrifugo/(.*) /$1 break ; proxy_pass_header Server ; proxy_set_header Host $http_host ; proxy_redirect off ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Scheme $scheme ; proxy_pass http : // centrifugo ; } location / centrifugo / connection { rewrite ^/centrifugo(.*) $1 break ; proxy_next_upstream error ; gzip on ; gzip_min_length 1000 ; gzip_proxied any ; proxy_buffering off ; keepalive_timeout 65 ; proxy_pass http : // centrifugo ; proxy_read_timeout 60s ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Scheme $scheme ; proxy_set_header Host $http_host ; proxy_http_version 1.1 ; proxy_set_header Upgrade $http_upgrade ; proxy_set_header Connection $connection_upgrade ; } }","title":"Embed to a location of web site"},{"location":"deploy/nginx/#sticky","text":"You may be noticed commented sticky; directive in nginx upstream configuration. When using SockJS and client connects to Centrifugo - SockJS session created - and to communicate client must send all next requests to the same upstream backend. In this configuration we use ip_hash; directive to proxy clients with the same ip address to the same upstream backend. But ip_hash; is not the best choice in this case, because there could be situations where a lot of different browsers are coming with the same IP address (behind proxies) and the load balancing system won t be fair. Also fair load balancing does not work during development - when all clients connecting from localhost. So the best solution would be using something like nginx-sticky-module which uses setting a special cookie to track the upstream server for client.","title":"sticky"},{"location":"deploy/nginx/#worker_connections","text":"You may also need to update worker_connections option of Nginx: events { worker_connections 40000; }","title":"worker_connections"},{"location":"deploy/nginx/#upstream-keepalive","text":"See chapter about operating system tuning for more details.","title":"Upstream keepalive"},{"location":"deploy/packages/","text":"RPM and DEB packages Every time we make new Centrifugo release we upload rpm and deb packages for popular linux distributions on packagecloud.io . Currently we support versions of the following distributions: 64-bit Debian 8 Jessie 64-bit Debian 9 Stretch 64-bit Ubuntu 16.04 Xenial 64-bit Ubuntu 18.04 Bionic 64-bit Centos 7 See full list of available packages and installation instructions . Also note that if your Linux distro is not in list you can ask us to package for it or just download appropriate package from packagecloud that fits your distribution. Centrifugo also works on 32-bit architectures, but we don t support packaging for it as 64-bit is more convenient for servers today.","title":"RPM and DEB packages"},{"location":"deploy/packages/#rpm-and-deb-packages","text":"Every time we make new Centrifugo release we upload rpm and deb packages for popular linux distributions on packagecloud.io . Currently we support versions of the following distributions: 64-bit Debian 8 Jessie 64-bit Debian 9 Stretch 64-bit Ubuntu 16.04 Xenial 64-bit Ubuntu 18.04 Bionic 64-bit Centos 7 See full list of available packages and installation instructions . Also note that if your Linux distro is not in list you can ask us to package for it or just download appropriate package from packagecloud that fits your distribution. Centrifugo also works on 32-bit architectures, but we don t support packaging for it as 64-bit is more convenient for servers today.","title":"RPM and DEB packages"},{"location":"deploy/redis/","text":"Redis This section describes some aspects about deploying Redis for Centrifugo server. Sentinel for high availability Centrifugo supports official way to add high availability to Redis - Redis Sentinel . For this you only need to utilize 2 Redis Engine options: redis_master_name and redis_sentinels . redis_master_name - is a name of master your Sentinels monitor. redis_sentinels - comma-separated addresses of Sentinel servers. At least one known server required. So you can start Centrifugo which will use Sentinels to discover redis master instance like this: centrifugo --config=config.json --engine=redis --redis_master_name=mymaster --redis_sentinels= :26379 Sentinel configuration files can look like this: port 26379 sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 10000 sentinel failover-timeout mymaster 60000 You can find how to properly setup Sentinels in official documentation . Note that when your redis master instance down there will be small downtime interval until Sentinels discover a problem and come to quorum decision about new master. The length of this period depends on Sentinel configuration. Haproxy Alternatively you can use Haproxy between Centrifugo and Redis to let it properly balance traffic to Redis master. In this case you still need to configure Sentinels but you can omit Sentinel specifics from Centrifugo configuration and just use Redis address as in simple non-HA case. For example you can use something like this in Haproxy config: listen redis server redis-01 127.0.0.1:6380 check port 6380 check inter 2s weight 1 inter 2s downinter 5s rise 10 fall 2 server redis-02 127.0.0.1:6381 check port 6381 check inter 2s weight 1 inter 2s downinter 5s rise 10 fall 2 backup bind *:16379 mode tcp option tcpka option tcplog option tcp-check tcp-check send PING\\r\\n tcp-check expect string +PONG tcp-check send info\\ replication\\r\\n tcp-check expect string role:master tcp-check send QUIT\\r\\n tcp-check expect string +OK balance roundrobin And then just point Centrifugo to this Haproxy: centrifugo --config=config.json --engine=redis --redis_host=localhost --redis_port=16379","title":"Redis HA"},{"location":"deploy/redis/#redis","text":"This section describes some aspects about deploying Redis for Centrifugo server.","title":"Redis"},{"location":"deploy/redis/#sentinel-for-high-availability","text":"Centrifugo supports official way to add high availability to Redis - Redis Sentinel . For this you only need to utilize 2 Redis Engine options: redis_master_name and redis_sentinels . redis_master_name - is a name of master your Sentinels monitor. redis_sentinels - comma-separated addresses of Sentinel servers. At least one known server required. So you can start Centrifugo which will use Sentinels to discover redis master instance like this: centrifugo --config=config.json --engine=redis --redis_master_name=mymaster --redis_sentinels= :26379 Sentinel configuration files can look like this: port 26379 sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 10000 sentinel failover-timeout mymaster 60000 You can find how to properly setup Sentinels in official documentation . Note that when your redis master instance down there will be small downtime interval until Sentinels discover a problem and come to quorum decision about new master. The length of this period depends on Sentinel configuration.","title":"Sentinel for high availability"},{"location":"deploy/redis/#haproxy","text":"Alternatively you can use Haproxy between Centrifugo and Redis to let it properly balance traffic to Redis master. In this case you still need to configure Sentinels but you can omit Sentinel specifics from Centrifugo configuration and just use Redis address as in simple non-HA case. For example you can use something like this in Haproxy config: listen redis server redis-01 127.0.0.1:6380 check port 6380 check inter 2s weight 1 inter 2s downinter 5s rise 10 fall 2 server redis-02 127.0.0.1:6381 check port 6381 check inter 2s weight 1 inter 2s downinter 5s rise 10 fall 2 backup bind *:16379 mode tcp option tcpka option tcplog option tcp-check tcp-check send PING\\r\\n tcp-check expect string +PONG tcp-check send info\\ replication\\r\\n tcp-check expect string role:master tcp-check send QUIT\\r\\n tcp-check expect string +OK balance roundrobin And then just point Centrifugo to this Haproxy: centrifugo --config=config.json --engine=redis --redis_host=localhost --redis_port=16379","title":"Haproxy"},{"location":"deploy/tls/","text":"TLS TLS/SSL layer is very important not only for securing your connections but also to increase a chance to establish Websocket connection. In most situations you will put TLS termination task on your reverse proxy/load balancing software such as Nginx . There are situations though when you want to serve secure connections by Centrifugo itself. There are two ways to do this: using TLS certificate cert and key files that you ve got from your CA provider or using automatic certificate handling via ACME provider (only Let s Encrypt at this moment). Using crt and key files In first way you already have cert and key files. For development you can create self-signed certificate - see this instruction as example. Then to start Centrifugo use the following command: ./centrifugo --config=config.json --tls --tls_key=server.key --tls_cert=server.crt Or just use configuration file: { ... tls : true , tls_key : server.key , tls_cert : server.crt } And run: ./centrifugo --config=config.json Automatic certificates For automatic certificates from Let s Encrypt add into configuration file: { ... tls_autocert : true, tls_autocert_host_whitelist : www.example.com , tls_autocert_cache_dir : /tmp/certs , tls_autocert_email : user@example.com , tls_autocert_http : true, tls_autocert_http_addr : :80 } tls_autocert (boolean) says Centrifugo that you want automatic certificate handling using ACME provider. tls_autocert_host_whitelist (string) is a string with your app domain address. This can be comma-separated list. It s optional but recommended for extra security. tls_autocert_cache_dir (string) is a path to a folder to cache issued certificate files. This is optional but will increase performance. tls_autocert_email (string) is optional - it s an email address ACME provider will send notifications about problems with your certificates. tls_autocert_http (boolean) is an option to handle http_01 ACME challenge on non-TLS port. tls_autocert_http_addr (string) can be used to set address for handling http_01 ACME challenge (default is :80 ) When configured correctly and your domain is valid ( localhost will not work) - certificates will be retrieved on first request to Centrifugo. Also Let s Encrypt certificates will be automatically renewed. There are tho options that allow Centrifugo to support TLS client connections from older browsers such as Chrome 49 on Windows XP and IE8 on XP: tls_autocert_force_rsa - this is a boolean option, by default false . When enabled it forces autocert manager generate certificates with 2048-bit RSA keys. tls_autocert_server_name - string option, allows to set server name for client handshake hello. This can be useful to deal with old browsers without SNI support - see comment","title":"TLS"},{"location":"deploy/tls/#tls","text":"TLS/SSL layer is very important not only for securing your connections but also to increase a chance to establish Websocket connection. In most situations you will put TLS termination task on your reverse proxy/load balancing software such as Nginx . There are situations though when you want to serve secure connections by Centrifugo itself. There are two ways to do this: using TLS certificate cert and key files that you ve got from your CA provider or using automatic certificate handling via ACME provider (only Let s Encrypt at this moment).","title":"TLS"},{"location":"deploy/tls/#using-crt-and-key-files","text":"In first way you already have cert and key files. For development you can create self-signed certificate - see this instruction as example. Then to start Centrifugo use the following command: ./centrifugo --config=config.json --tls --tls_key=server.key --tls_cert=server.crt Or just use configuration file: { ... tls : true , tls_key : server.key , tls_cert : server.crt } And run: ./centrifugo --config=config.json","title":"Using crt and key files"},{"location":"deploy/tls/#automatic-certificates","text":"For automatic certificates from Let s Encrypt add into configuration file: { ... tls_autocert : true, tls_autocert_host_whitelist : www.example.com , tls_autocert_cache_dir : /tmp/certs , tls_autocert_email : user@example.com , tls_autocert_http : true, tls_autocert_http_addr : :80 } tls_autocert (boolean) says Centrifugo that you want automatic certificate handling using ACME provider. tls_autocert_host_whitelist (string) is a string with your app domain address. This can be comma-separated list. It s optional but recommended for extra security. tls_autocert_cache_dir (string) is a path to a folder to cache issued certificate files. This is optional but will increase performance. tls_autocert_email (string) is optional - it s an email address ACME provider will send notifications about problems with your certificates. tls_autocert_http (boolean) is an option to handle http_01 ACME challenge on non-TLS port. tls_autocert_http_addr (string) can be used to set address for handling http_01 ACME challenge (default is :80 ) When configured correctly and your domain is valid ( localhost will not work) - certificates will be retrieved on first request to Centrifugo. Also Let s Encrypt certificates will be automatically renewed. There are tho options that allow Centrifugo to support TLS client connections from older browsers such as Chrome 49 on Windows XP and IE8 on XP: tls_autocert_force_rsa - this is a boolean option, by default false . When enabled it forces autocert manager generate certificates with 2048-bit RSA keys. tls_autocert_server_name - string option, allows to set server name for client handshake hello. This can be useful to deal with old browsers without SNI support - see comment","title":"Automatic certificates"},{"location":"deploy/tuning/","text":"Tuning operating system As Centrifugo/Centrifuge deals with lots of persistent connections your operating system must be ready for it. open files limit First of all you should increase a max number of open files your processes can open. To get you current open files limit run: ulimit -n The result shows approximately how many clients your server can handle. See this document to get more info on how to increase this number. If you install Centrifugo using RPM from repo then it automatically sets max open files limit to 32768. You may also need to increase max open files for Nginx. lots of sockets in TIME_WAIT state. Look how many socket descriptors in TIME_WAIT state. netstat -an |grep TIME_WAIT | grep CENTRIFUGO_PID | wc -l Under load when lots of connections and disconnection happen lots of used socket descriptors can stay in TIME_WAIT state. Those descriptors can not be reused for a while. So you can get various errors when using Centrifugo. For example something like (99: Cannot assign requested address) while connecting to upstream in Nginx error log and 502 on client side. In this case there are several advices that can help. Nice article about TIME_WAIT sockets: http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html There is a perfect article about operating system tuning for lots of connections: https://engineering.gosquared.com/optimising-nginx-node-js-and-networking-for-heavy-workloads. To summarize: Increase ip_local_port_range If you are using Nginx set keepalive directive in upstream. upstream centrifugo { #sticky ; ip_hash ; server 127.0.0.1:8000 ; keepalive 512 ; } And finally if the problem is not gone away consider trying to enable net.ipv4.tcp_tw_reuse","title":"OS tuning"},{"location":"deploy/tuning/#tuning-operating-system","text":"As Centrifugo/Centrifuge deals with lots of persistent connections your operating system must be ready for it.","title":"Tuning operating system"},{"location":"deploy/tuning/#open-files-limit","text":"First of all you should increase a max number of open files your processes can open. To get you current open files limit run: ulimit -n The result shows approximately how many clients your server can handle. See this document to get more info on how to increase this number. If you install Centrifugo using RPM from repo then it automatically sets max open files limit to 32768. You may also need to increase max open files for Nginx.","title":"open files limit"},{"location":"deploy/tuning/#lots-of-sockets-in-time_wait-state","text":"Look how many socket descriptors in TIME_WAIT state. netstat -an |grep TIME_WAIT | grep CENTRIFUGO_PID | wc -l Under load when lots of connections and disconnection happen lots of used socket descriptors can stay in TIME_WAIT state. Those descriptors can not be reused for a while. So you can get various errors when using Centrifugo. For example something like (99: Cannot assign requested address) while connecting to upstream in Nginx error log and 502 on client side. In this case there are several advices that can help. Nice article about TIME_WAIT sockets: http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html There is a perfect article about operating system tuning for lots of connections: https://engineering.gosquared.com/optimising-nginx-node-js-and-networking-for-heavy-workloads. To summarize: Increase ip_local_port_range If you are using Nginx set keepalive directive in upstream. upstream centrifugo { #sticky ; ip_hash ; server 127.0.0.1:8000 ; keepalive 512 ; } And finally if the problem is not gone away consider trying to enable net.ipv4.tcp_tw_reuse","title":"lots of sockets in TIME_WAIT state."},{"location":"libraries/api/","text":"HTTP API clients If you look at server API docs you will find that sending API request to Centrifugo is a very simple task to do in any programming language - this is just a POST request with JSON payload in body and Authorization header. See more in special chapter in server section. We have several client libraries for different languages so you don t have to construct proper HTTP requests manually: cent for Python phpcent for PHP gocent for Go rubycent for Ruby ( not available for Centrifugo v2 yet ) jscent for NodeJS ( not available for Centrifugo v2 yet )","title":"API libraries"},{"location":"libraries/api/#http-api-clients","text":"If you look at server API docs you will find that sending API request to Centrifugo is a very simple task to do in any programming language - this is just a POST request with JSON payload in body and Authorization header. See more in special chapter in server section. We have several client libraries for different languages so you don t have to construct proper HTTP requests manually: cent for Python phpcent for PHP gocent for Go rubycent for Ruby ( not available for Centrifugo v2 yet ) jscent for NodeJS ( not available for Centrifugo v2 yet )","title":"HTTP API clients"},{"location":"libraries/client/","text":"Client libraries These libraries allow your users to connect to Centrifugo from application frontend. centrifuge-js \u2013 for browser, NodeJS and React Native centrifuge-go - for Go language centrifuge-mobile - for iOS and Android using centrifuge-go as basis and gomobile project to create bindings centrifuge-dart - for Dart and Flutter centrifuge-swift \u2013 for native iOS development centrifuge-java \u2013 for native Android development and general Java","title":"Client libraries"},{"location":"libraries/client/#client-libraries","text":"These libraries allow your users to connect to Centrifugo from application frontend. centrifuge-js \u2013 for browser, NodeJS and React Native centrifuge-go - for Go language centrifuge-mobile - for iOS and Android using centrifuge-go as basis and gomobile project to create bindings centrifuge-dart - for Dart and Flutter centrifuge-swift \u2013 for native iOS development centrifuge-java \u2013 for native Android development and general Java","title":"Client libraries"},{"location":"misc/insecure_modes/","text":"Insecure modes This chapter describes several insecure options that enable several insecure modes in Centrifugo. Insecure client connection The boolean option client_insecure (default false ) allows to connect to Centrifugo without JWT token. This means there is no user authentication involved. This mode can be useful to demo projects based on Centrifugo, personal projects or real-time application prototyping. Insecure API mode This mode can be enabled using boolean option api_insecure (default false ). When on there is no need to provide API key in HTTP requests. When using this mode everyone that has access to /api endpoint can send any command to server. Enabling this option can be reasonable if /api endpoint protected by firewall rules. The option is also useful in development to simplify sending API commands to Centrifugo using CURL for example without specifying Authorization header in requests. Insecure admin mode This mode can be enabled using boolean option admin_insecure (default false ). When on there is no authentication in admin web interface. Again - this is not secure but can be justified if you protected admin interface by firewall rules or you want to use basic authentication for Centrifugo admin interface.","title":"Insecure modes"},{"location":"misc/insecure_modes/#insecure-modes","text":"This chapter describes several insecure options that enable several insecure modes in Centrifugo.","title":"Insecure modes"},{"location":"misc/insecure_modes/#insecure-client-connection","text":"The boolean option client_insecure (default false ) allows to connect to Centrifugo without JWT token. This means there is no user authentication involved. This mode can be useful to demo projects based on Centrifugo, personal projects or real-time application prototyping.","title":"Insecure client connection"},{"location":"misc/insecure_modes/#insecure-api-mode","text":"This mode can be enabled using boolean option api_insecure (default false ). When on there is no need to provide API key in HTTP requests. When using this mode everyone that has access to /api endpoint can send any command to server. Enabling this option can be reasonable if /api endpoint protected by firewall rules. The option is also useful in development to simplify sending API commands to Centrifugo using CURL for example without specifying Authorization header in requests.","title":"Insecure API mode"},{"location":"misc/insecure_modes/#insecure-admin-mode","text":"This mode can be enabled using boolean option admin_insecure (default false ). When on there is no authentication in admin web interface. Again - this is not secure but can be justified if you protected admin interface by firewall rules or you want to use basic authentication for Centrifugo admin interface.","title":"Insecure admin mode"},{"location":"misc/migrate/","text":"Migration notes from Centrifugo v1 In version 2 of Centrifugo many things changed in backwards incompatible way comparing to version 1. This document aims to help Centrifugo v1 users to migrate their projects to version 2 (if they want to). New client protocol and client libraries In Centrifugo v2 internal client-server protocol changed meaning that old client library version won t work with new server. So first step in migrating - update client libraries to new version with Centrifugo v2 support. While refactoring client s API changed a bit so you have to adapt your code to those changes. For the moment of this writing we have no native mobile libraries for Centrifugo v2. So if you are using centrifuge-ios or centrifuge-android then you can t migrate to v2 until those libraries will be ported. Migrate communication with API Centrifugo v2 simplified communication with API - requests should not be signed with secret key anymore thus you can simply integrate your backend with Centrifugo without using any of our helper libraries - just send JSON API command as POST request to api endpoint. Don t forget to use api key and protect API endpoint with TLS (more information in server API description document). Centrifugo v1 could process messages published in Redis queue. In v2 this possibility was removed because this technique is not good in terms of error handling and non-deterministic delay before message will be processed by Centrifugo node worker. Migrate to using HTTP or GRPC API. Use JWT instead of hand-crafted connection token In Centrifugo v2 you must use JWT instead of hand-crafted tokens of v1. This means that you need to download JWT library for your language (there are plenty of them \u2013 see jwt.io) and build connection token with it. See dedicated docs chapter to see how token can be built. All connection information will be passed inside this single token string. This means you only need to pass one string to your frontend. No need to pass user , timestamp , info anymore. This also means that you will have less problems with escaping features of template engines - because JWT is safe base64 string. Connection expiration (connection check mechanism) now based on exp claim of JWT \u2013 you don t need to enable it globally in configuration. Use JWT instead of hand-crafted signature for private subscriptions Read chapter about private subscriptions to find how you should now use JWT for private channel subscriptions. Channel options changed Channel option recover now called history_recover . There is no watch channel option anymore - in Centrifugo v2 admin websocket connection was removed as it made code base much more overhelmed for almost nothing. SockJS endpoint changed It s now /connection/sockjs instead of /connection New way to export metrics Centrifugo is now uses Prometheus primitives internally so if you are using Prometheus you can simply configure it to monitor Centrifugo. Also Centrifugo is able to automatically convert and export metrics to Graphite. See special Monitoring chapter in server docs. Previously you have to periodically call stats command and export metrics manually. This is gone in Centrifugo v2. Options renamed Some of advanced options have been renamed \u2013 if you are using advanced configuration then refer to documentation to find actual option names. No client limited channels anymore That was a pretty useless feature of Centrifugo v1. New reserved symbols in channel name Symbols * and / in channel name are now reserved for Centrifugo future needs - please do not use it in channels. Centrifugo v1 repos Here some links for those who still use Centrifugo v1 Centrifugo v1 source code Centrifugo v1 documentation centrifuge-js v1 centrifuge-go centrifuge-mobile examples","title":"Migrate from Centrifugo v1"},{"location":"misc/migrate/#migration-notes-from-centrifugo-v1","text":"In version 2 of Centrifugo many things changed in backwards incompatible way comparing to version 1. This document aims to help Centrifugo v1 users to migrate their projects to version 2 (if they want to).","title":"Migration notes from Centrifugo v1"},{"location":"misc/migrate/#new-client-protocol-and-client-libraries","text":"In Centrifugo v2 internal client-server protocol changed meaning that old client library version won t work with new server. So first step in migrating - update client libraries to new version with Centrifugo v2 support. While refactoring client s API changed a bit so you have to adapt your code to those changes. For the moment of this writing we have no native mobile libraries for Centrifugo v2. So if you are using centrifuge-ios or centrifuge-android then you can t migrate to v2 until those libraries will be ported.","title":"New client protocol and client libraries"},{"location":"misc/migrate/#migrate-communication-with-api","text":"Centrifugo v2 simplified communication with API - requests should not be signed with secret key anymore thus you can simply integrate your backend with Centrifugo without using any of our helper libraries - just send JSON API command as POST request to api endpoint. Don t forget to use api key and protect API endpoint with TLS (more information in server API description document). Centrifugo v1 could process messages published in Redis queue. In v2 this possibility was removed because this technique is not good in terms of error handling and non-deterministic delay before message will be processed by Centrifugo node worker. Migrate to using HTTP or GRPC API.","title":"Migrate communication with API"},{"location":"misc/migrate/#use-jwt-instead-of-hand-crafted-connection-token","text":"In Centrifugo v2 you must use JWT instead of hand-crafted tokens of v1. This means that you need to download JWT library for your language (there are plenty of them \u2013 see jwt.io) and build connection token with it. See dedicated docs chapter to see how token can be built. All connection information will be passed inside this single token string. This means you only need to pass one string to your frontend. No need to pass user , timestamp , info anymore. This also means that you will have less problems with escaping features of template engines - because JWT is safe base64 string. Connection expiration (connection check mechanism) now based on exp claim of JWT \u2013 you don t need to enable it globally in configuration.","title":"Use JWT instead of hand-crafted connection token"},{"location":"misc/migrate/#use-jwt-instead-of-hand-crafted-signature-for-private-subscriptions","text":"Read chapter about private subscriptions to find how you should now use JWT for private channel subscriptions.","title":"Use JWT instead of hand-crafted signature for private subscriptions"},{"location":"misc/migrate/#channel-options-changed","text":"Channel option recover now called history_recover . There is no watch channel option anymore - in Centrifugo v2 admin websocket connection was removed as it made code base much more overhelmed for almost nothing.","title":"Channel options changed"},{"location":"misc/migrate/#sockjs-endpoint-changed","text":"It s now /connection/sockjs instead of /connection","title":"SockJS endpoint changed"},{"location":"misc/migrate/#new-way-to-export-metrics","text":"Centrifugo is now uses Prometheus primitives internally so if you are using Prometheus you can simply configure it to monitor Centrifugo. Also Centrifugo is able to automatically convert and export metrics to Graphite. See special Monitoring chapter in server docs. Previously you have to periodically call stats command and export metrics manually. This is gone in Centrifugo v2.","title":"New way to export metrics"},{"location":"misc/migrate/#options-renamed","text":"Some of advanced options have been renamed \u2013 if you are using advanced configuration then refer to documentation to find actual option names.","title":"Options renamed"},{"location":"misc/migrate/#no-client-limited-channels-anymore","text":"That was a pretty useless feature of Centrifugo v1.","title":"No client limited channels anymore"},{"location":"misc/migrate/#new-reserved-symbols-in-channel-name","text":"Symbols * and / in channel name are now reserved for Centrifugo future needs - please do not use it in channels.","title":"New reserved symbols in channel name"},{"location":"misc/migrate/#centrifugo-v1-repos","text":"Here some links for those who still use Centrifugo v1 Centrifugo v1 source code Centrifugo v1 documentation centrifuge-js v1 centrifuge-go centrifuge-mobile examples","title":"Centrifugo v1 repos"},{"location":"server/","text":"Server overview Centrifugo server is written in Go language. It s an open-source software, the source code is available on Github . Centrifugo is built around centrifuge library for Go language. That library defines custom protocol and message types which must be sent over various transports (Websocket, SockJS). Server clients use that protocol internally and provide simple API to features - making persistent connection, subscribing on channels, calling RPC commands and more. This documentation chapter covers some server concepts in detail. This is documentation for Centrifugo server but many things said here are also valid for centrifuge library as it s a core of Centrifugo server.","title":"Overview"},{"location":"server/#server-overview","text":"Centrifugo server is written in Go language. It s an open-source software, the source code is available on Github . Centrifugo is built around centrifuge library for Go language. That library defines custom protocol and message types which must be sent over various transports (Websocket, SockJS). Server clients use that protocol internally and provide simple API to features - making persistent connection, subscribing on channels, calling RPC commands and more. This documentation chapter covers some server concepts in detail. This is documentation for Centrifugo server but many things said here are also valid for centrifuge library as it s a core of Centrifugo server.","title":"Server overview"},{"location":"server/admin/","text":"Admin web interface Centrifugo comes with builtin admin web interface. It can: show current server general information and statistics from server nodes. call publish , broadcast , unsubscribe , disconnect , history , presence , presence_stats , channels , info server API commands. For publish command Ace JSON editor helps to write JSON to send into channel. To enable admin interface you must run centrifugo with --admin and provide some security options in configuration file. centrifugo --config = config.json --admin Also you must set two options in config: admin_password and admin_secret : { ..., admin_password : PASSWORD , admin_secret : SECRET } admin_password \u2013 this is a password to log into admin web interface admin_secret - this is a secret key for authentication token set on successful login. Make both strong and keep in secret. After setting this in config go to http://localhost:8000 (by default) - and you should see web interface. Although there is password based authentication a good advice is to protect web interface by firewall rules in production. If you don t want to use embedded web interface you can specify path to your own custom web interface directory: { ..., admin_password : PASSWORD , admin_secret : SECRET , admin_web_path : PATH } This can be useful if you want to modify official web interface code in some way. There is also an option to run Centrifugo in insecure admin mode - in this case you don t need to set admin_password and admin_secret in config \u2013 in web interface you will be logged in automatically without any password. Note that this is only an option for production if you protected admin web interface with firewall rules. Otherwise anyone in internet will have full access to admin functionality described above. To start Centrifugo with admin web interface in insecure admin mode run: centrifugo --config=config.json --admin --admin_insecure","title":"Admin web interface"},{"location":"server/admin/#admin-web-interface","text":"Centrifugo comes with builtin admin web interface. It can: show current server general information and statistics from server nodes. call publish , broadcast , unsubscribe , disconnect , history , presence , presence_stats , channels , info server API commands. For publish command Ace JSON editor helps to write JSON to send into channel. To enable admin interface you must run centrifugo with --admin and provide some security options in configuration file. centrifugo --config = config.json --admin Also you must set two options in config: admin_password and admin_secret : { ..., admin_password : PASSWORD , admin_secret : SECRET } admin_password \u2013 this is a password to log into admin web interface admin_secret - this is a secret key for authentication token set on successful login. Make both strong and keep in secret. After setting this in config go to http://localhost:8000 (by default) - and you should see web interface. Although there is password based authentication a good advice is to protect web interface by firewall rules in production. If you don t want to use embedded web interface you can specify path to your own custom web interface directory: { ..., admin_password : PASSWORD , admin_secret : SECRET , admin_web_path : PATH } This can be useful if you want to modify official web interface code in some way. There is also an option to run Centrifugo in insecure admin mode - in this case you don t need to set admin_password and admin_secret in config \u2013 in web interface you will be logged in automatically without any password. Note that this is only an option for production if you protected admin web interface with firewall rules. Otherwise anyone in internet will have full access to admin functionality described above. To start Centrifugo with admin web interface in insecure admin mode run: centrifugo --config=config.json --admin --admin_insecure","title":"Admin web interface"},{"location":"server/authentication/","text":"Authentication When you are using centrifuge library from Go language you can implement any user authentication using middleware. In Centrifugo case you need to tell server who is connecting in well-known predefined way. This chapter will describe this mechanism. When connecting to Centrifugo client must provide connection JWT token with several predefined credential claims. If you ve never heard about JWT before - refer to jwt.io page. At moment the only supported JWT algorithm is HS256 - i.e. HMAC SHA-256. This can be extended later. We will use Javascript Centrifugo client here for example snippets for client side and PyJWT Python library to generate connection token on backend side. Claims Centrifugo uses the following claims in JWT: sub , exp , info and b64info . What do they mean? Let s describe in detail. sub This is a standard JWT claim which must contain an ID of current application user ( as string ). If your user is not currently authenticated in your application but you want to let him connect to Centrifugo anyway you can use empty string as user ID in this sub claim. This is called anonymous access. In this case anonymous option must be enabled in Centrifugo configuration for channels that client will subscribe to. exp This is an a UNIX timestamp seconds when token will expire. This is standard JWT claim - all JWT libraries for different languages provide an API to set it. If exp claim not provided then Centrifugo won t expire any connections. When provided special algorithm will find connections with exp in the past and activate connection refresh mechanism. Refresh mechanism allows connection to survive and be prolonged. In case of refresh failure client connection will be eventually closed by Centrifugo and won t be accepted until new valid and actual credentials provided in connection token. You can use connection expiration mechanism in cases when you don t want users of your app be subscribed on channels after being banned/deactivated in application. Or to protect your users from token leak (providing reasonably small time of expiration). Choose exp value wisely, you don t need small values because refresh mechanism will hit your application often with refresh requests. But setting this value too large can lead to non very fast user connection deactivation. This is a trade off. Read more about connection expiration in special chapter. info This claim is optional - this is additional information about client connection that can be provided for Centrifugo. This information will be included in presence information, join/leave events and in channel publication message if it was published from client side. b64info If you are using binary protobuf protocol you may want info to be custom bytes. Use this field in this case. This field contains a base64 representation of your bytes. After receiving Centrifugo will decode base64 back to bytes and will embed result into various places described above. Examples Let s look how to generate connection JWT in Python: Simplest token import jwt token = jwt . encode ({ sub : 42 }, secret ) . decode () print ( token ) Note that we use the value of secret from Centrifugo config here (in this case secret value is just secret ). The only two who must know secret key is your application backend which generates JWT and Centrifugo itself. You should never show secret key to your users. Then you can pass this token to your client side and use it when connecting to Centrifugo: var centrifuge = new Centrifuge ( ws://localhost:8000/connection/websocket ); centrifuge . setToken ( token ); centrifuge . connect (); Token with expiration Token that will be valid for 5 minutes: import jwt import time claims = { sub : 42 , exp : int ( time . time ()) + 5 * 60 } token = jwt . encode ( claims , secret , algorithm = HS256 ) . decode () print ( token ) Token with additional connection info import jwt claims = { sub : 42 , info : { name : Alexander Emelin }} token = jwt . encode ( claims , secret , algorithm = HS256 ) . decode () print ( token )","title":"Authentication"},{"location":"server/authentication/#authentication","text":"When you are using centrifuge library from Go language you can implement any user authentication using middleware. In Centrifugo case you need to tell server who is connecting in well-known predefined way. This chapter will describe this mechanism. When connecting to Centrifugo client must provide connection JWT token with several predefined credential claims. If you ve never heard about JWT before - refer to jwt.io page. At moment the only supported JWT algorithm is HS256 - i.e. HMAC SHA-256. This can be extended later. We will use Javascript Centrifugo client here for example snippets for client side and PyJWT Python library to generate connection token on backend side.","title":"Authentication"},{"location":"server/authentication/#claims","text":"Centrifugo uses the following claims in JWT: sub , exp , info and b64info . What do they mean? Let s describe in detail.","title":"Claims"},{"location":"server/authentication/#sub","text":"This is a standard JWT claim which must contain an ID of current application user ( as string ). If your user is not currently authenticated in your application but you want to let him connect to Centrifugo anyway you can use empty string as user ID in this sub claim. This is called anonymous access. In this case anonymous option must be enabled in Centrifugo configuration for channels that client will subscribe to.","title":"sub"},{"location":"server/authentication/#exp","text":"This is an a UNIX timestamp seconds when token will expire. This is standard JWT claim - all JWT libraries for different languages provide an API to set it. If exp claim not provided then Centrifugo won t expire any connections. When provided special algorithm will find connections with exp in the past and activate connection refresh mechanism. Refresh mechanism allows connection to survive and be prolonged. In case of refresh failure client connection will be eventually closed by Centrifugo and won t be accepted until new valid and actual credentials provided in connection token. You can use connection expiration mechanism in cases when you don t want users of your app be subscribed on channels after being banned/deactivated in application. Or to protect your users from token leak (providing reasonably small time of expiration). Choose exp value wisely, you don t need small values because refresh mechanism will hit your application often with refresh requests. But setting this value too large can lead to non very fast user connection deactivation. This is a trade off. Read more about connection expiration in special chapter.","title":"exp"},{"location":"server/authentication/#info","text":"This claim is optional - this is additional information about client connection that can be provided for Centrifugo. This information will be included in presence information, join/leave events and in channel publication message if it was published from client side.","title":"info"},{"location":"server/authentication/#b64info","text":"If you are using binary protobuf protocol you may want info to be custom bytes. Use this field in this case. This field contains a base64 representation of your bytes. After receiving Centrifugo will decode base64 back to bytes and will embed result into various places described above.","title":"b64info"},{"location":"server/authentication/#examples","text":"Let s look how to generate connection JWT in Python:","title":"Examples"},{"location":"server/authentication/#simplest-token","text":"import jwt token = jwt . encode ({ sub : 42 }, secret ) . decode () print ( token ) Note that we use the value of secret from Centrifugo config here (in this case secret value is just secret ). The only two who must know secret key is your application backend which generates JWT and Centrifugo itself. You should never show secret key to your users. Then you can pass this token to your client side and use it when connecting to Centrifugo: var centrifuge = new Centrifuge ( ws://localhost:8000/connection/websocket ); centrifuge . setToken ( token ); centrifuge . connect ();","title":"Simplest token"},{"location":"server/authentication/#token-with-expiration","text":"Token that will be valid for 5 minutes: import jwt import time claims = { sub : 42 , exp : int ( time . time ()) + 5 * 60 } token = jwt . encode ( claims , secret , algorithm = HS256 ) . decode () print ( token )","title":"Token with expiration"},{"location":"server/authentication/#token-with-additional-connection-info","text":"import jwt claims = { sub : 42 , info : { name : Alexander Emelin }} token = jwt . encode ( claims , secret , algorithm = HS256 ) . decode () print ( token )","title":"Token with additional connection info"},{"location":"server/channels/","text":"Channels Channel is a route for publication messages. Clients can subscribe to channel to receive events related to this channel \u2013 new publications, join/leave events etc. Also client must be subscribed on channel to get channel presence or history information. Channel is just a string - news , comments are valid channel names. Channel name rules Only ASCII symbols must be used in channel string. Channel name length is limited by 255 characters by default (can be changed via configuration file option channel_max_length ). Several symbols in channel names are reserved for Centrifugo internal needs: : \u2013 for namespace channel boundary (see below) $ \u2013 for private channel prefix (see below) # \u2013 for user channel boundary (see below) * \u2013 for future Centrifugo needs \u2013 for future Centrifugo needs / \u2013 for future Centrifugo needs namespace channel boundary (:) : \u2013 is a channel namespace boundary. If channel is public:chat - then Centrifugo will apply options to this channel from channel namespace with name public . private channel prefix ($) If channel starts with $ then it considered private. Subscription on private channel must be properly signed by your web application. Read special chapter in docs about private channel subscriptions. user channel boundary (#) # \u2013 is a user channel boundary. This is a separator to create private channels for users (user limited channels) without sending POST request to your web application. For example if channel is news#42 then only user with ID 42 can subscribe on this channel (Centrifugo knows user ID as clients provide it in connection credentials). Moreover you can provide several user IDs in channel name separated by comma: dialog#42,43 \u2013 in this case only user with ID 42 and user with ID 43 will be able to subscribe on this channel. This is useful for channels with static allowed users, for example for user personal messages channel, for dialog channel between certainly defined users. As soon as you need dynamic user access to channel this channel type does not suit well.","title":"Channels"},{"location":"server/channels/#channels","text":"Channel is a route for publication messages. Clients can subscribe to channel to receive events related to this channel \u2013 new publications, join/leave events etc. Also client must be subscribed on channel to get channel presence or history information. Channel is just a string - news , comments are valid channel names.","title":"Channels"},{"location":"server/channels/#channel-name-rules","text":"Only ASCII symbols must be used in channel string. Channel name length is limited by 255 characters by default (can be changed via configuration file option channel_max_length ). Several symbols in channel names are reserved for Centrifugo internal needs: : \u2013 for namespace channel boundary (see below) $ \u2013 for private channel prefix (see below) # \u2013 for user channel boundary (see below) * \u2013 for future Centrifugo needs \u2013 for future Centrifugo needs / \u2013 for future Centrifugo needs","title":"Channel name rules"},{"location":"server/channels/#namespace-channel-boundary","text":": \u2013 is a channel namespace boundary. If channel is public:chat - then Centrifugo will apply options to this channel from channel namespace with name public .","title":"namespace channel boundary (:)"},{"location":"server/channels/#private-channel-prefix","text":"If channel starts with $ then it considered private. Subscription on private channel must be properly signed by your web application. Read special chapter in docs about private channel subscriptions.","title":"private channel prefix ($)"},{"location":"server/channels/#user-channel-boundary","text":"# \u2013 is a user channel boundary. This is a separator to create private channels for users (user limited channels) without sending POST request to your web application. For example if channel is news#42 then only user with ID 42 can subscribe on this channel (Centrifugo knows user ID as clients provide it in connection credentials). Moreover you can provide several user IDs in channel name separated by comma: dialog#42,43 \u2013 in this case only user with ID 42 and user with ID 43 will be able to subscribe on this channel. This is useful for channels with static allowed users, for example for user personal messages channel, for dialog channel between certainly defined users. As soon as you need dynamic user access to channel this channel type does not suit well.","title":"user channel boundary (#)"},{"location":"server/configuration/","text":"Configuration Centrifugo expects JSON, TOML or YAML as configuration file format. Thanks to brilliant Go library for application configuration - viper . First let s look at all available command-line options: centrifugo -h You should see something like this as output: Centrifugo \u2013 real-time messaging server Usage: [flags] [command] Available Commands: checkconfig Check configuration file genconfig Generate simple configuration file to start with help Help about any command version Centrifugo version information Flags: -a, --address string interface address to listen on --admin enable admin web interface --admin_insecure use insecure admin mode \u2013 no auth required for admin socket --api_insecure use insecure API mode --client_insecure start in insecure client mode -c, --config string path to config file (default config.json ) --debug enable debug endpoints -e, --engine string engine to use: memory or redis (default memory ) --grpc_api enable GRPC API server -h, --help help for this command --internal_port string custom port for internal endpoints --log_file string optional log file - if not specified logs go to STDOUT --log_level string set the log level: debug, info, error, fatal or none (default info ) -n, --name string unique node name --pid_file string optional path to create PID file -p, --port string port to bind HTTP server to (default 8000 ) --prometheus enable Prometheus metrics endpoint --redis_db int Redis database (Redis engine) --redis_host string Redis host (Redis engine) (default 127.0.0.1 ) --redis_master_name string name of Redis master Sentinel monitors (Redis engine) --redis_password string Redis auth password (Redis engine) --redis_port string Redis port (Redis engine) (default 6379 ) --redis_sentinels string comma-separated list of Sentinel addresses (Redis engine) --redis_tls enable Redis TLS connection --redis_tls_skip_verify disable Redis TLS host verification --redis_url string Redis connection URL in format redis://:password@hostname:port/db (Redis engine) --tls enable TLS, requires an X509 certificate and a key file --tls_cert string path to an X509 certificate file --tls_key string path to an X509 certificate key version To show version and exit run: centrifugo version JSON file Centrifugo requires configuration file on start. As was mentioned earlier it must be a file with valid JSON. This is a minimal Centrifugo configuration file: { secret : YOUR-SECRET-STRING-HERE , api_key : YOUR-API-KEY-HERE } The only two fields required are secret and api_key . Secret used to check JWT signature (more about JWT in authentication chapter ). API key used for Centrifugo API endpoint authorization, see more in chapter about server HTTP API . Keep both values in secret and never reveal to clients. TOML file Centrifugo also supports TOML format for configuration file: centrifugo --config=config.toml Where config.toml contains: secret = YOUR-SECRET-STRING-HERE api_key = YOUR-API-KEY-HERE log_level = debug I.e. the same configuration as JSON file above with one extra option. YAML file And YAML config also supported. config.yaml : secret: YOUR-SECRET-STRING-HERE api_key: YOUR-API-KEY-HERE log_level: debug With YAML remember to use spaces, not tabs when writing configuration file. checkconfig command Centrifugo has special command to check configuration file checkconfig : centrifugo checkconfig --config = config.json If any errors found during validation \u2013 program will exit with error message and exit code 1. genconfig command Another command is genconfig : centrifugo genconfig -c config.json It will automatically generate the minimal required configuration file. Important options Some of the most important options you can configure when running Centrifugo: address \u2013 bind your Centrifugo to specific interface address (by default \"\" ) port \u2013 port to bind Centrifugo to (by default 8000 ) engine \u2013 engine to use - memory or redis (by default memory ). Read more about engines in special chapter . Note that some options can be set via command-line. Command-line options are more valuable when set than configuration file s options. See description of viper \u2013 to see more details about configuration options priority. Channel options Let s look at options related to channels. Channel is an entity to which clients can subscribe to receive messages published into that channel. Channel is just a string (several symbols has special meaning in Centrifugo - see special chapter to find more information about channels). The following options will affect channel behaviour: publish \u2013 allow clients to publish messages into channels directly (from client side). Your application will never receive those messages. In idiomatic case all messages must be published to Centrifugo by your application backend using Centrifugo API. But this option can be useful when you want to build something without backend-side validation and saving into database. This option can also be useful for demos and prototyping real-time ideas. By default it s false . subscribe_to_publish - when publish option enabled client can publish into channel without being subscribed to it. This option enables automatic check that client subscribed on channel before allowing client to publish into channel. anonymous \u2013 this option enables anonymous access (with empty sub claim in connection token). In most situations your application works with authenticated users so every user has its own unique id. But if you provide real-time features for public access you may need unauthorized access to some channels. Turn on this option and use empty string as user ID. By default false . presence \u2013 enable/disable presence information. Presence is an information about clients currently subscribed on channel. By default false \u2013 i.e. no presence information will be available for channels. join_leave \u2013 enable/disable sending join(leave) messages when client subscribes on channel (unsubscribes from channel). By default false . history_size \u2013 history size (amount of messages) for channels. As Centrifugo keeps all history messages in memory it s very important to limit maximum amount of messages in channel history to reasonable value. history_size defines maximum amount of messages that Centrifugo will keep for each channel in namespace during history lifetime (see below). By default history size is 0 - this means that channels will have no history messages at all. history_lifetime \u2013 interval in seconds how long to keep channel history messages. As all history is storing in memory it is also very important to get rid of old history data for unused (inactive for a long time) channels. By default history lifetime is 0 \u2013 this means that channels will have no history messages at all. So to turn on keeping history messages you should wisely configure both history_size and history_lifetime options . history_recover \u2013 boolean option, when enabled Centrifugo will try to recover missed publications while client was disconnected for some reason (bad internet connection for example). By default false . This option must be used in conjunction with reasonably configured message history for channel i.e. history_size and history_lifetime must be set (because Centrifugo uses channel history to recover messages). Also note that not all real-time events require this feature turned on so think wisely when you need this. When this option turned on your application should be designed in a way to tolerate duplicate messages coming from channel (currently Centrifugo returns recovered publications in order and without duplicates but this is implementation detail that can be theoretically changed in future). See more details about how recovery works in special chapter . Let s look how to set some of these options in config: { secret : my-secret-key , api_key : secret-api-key , anonymous : true , publish : true , subscribe_to_publish : true , presence : true , join_leave : true , history_size : 10 , history_lifetime : 300 , history_recover : true } And the last channel specific option is namespaces . namespaces are optional and if set must be an array of namespace objects. Namespace allows to configure custom options for channels starting with namespace name. This provides a great control over channel behaviour. Namespace has a name and the same channel options (with same defaults) as described above. name - unique namespace name (name must consist of letters, numbers, underscores or hyphens and be more than 2 symbols length i.e. satisfy regexp ^[-a-zA-Z0-9_]{2,}$ ). If you want to use namespace options for channel - you must include namespace name into channel name with : as separator: public:messages gossips:messages Where public and gossips are namespace names from project namespaces . All things together here is an example of config.json which includes registered project with all options set and 2 additional namespaces in it: { secret : very-long-secret-key , api_key : secret-api-key , anonymous : true , publish : true , presence : true , join_leave : true , history_size : 10 , history_lifetime : 30 , namespaces : [ { name : public , publish : true , anonymous : true , history_size : 10 , history_lifetime : 300 , history_recover : true }, { name : gossips , presence : true , join_leave : true } ] } Channel news will use globally defined channel options. Channel public:news will use public namespace s options. Channel gossips:news will use gossips namespace s options. There is no inheritance in channel options and namespaces \u2013 so if for example you defined presence: true on top level of configuration and then defined namespace \u2013 that namespace won t have presence enabled - you must enable it for namespace explicitly. Advanced configuration Centrifugo has some options for which default values make sense for most applications. In many case you don t need (and you really should not) change them. This chapter is about such options. client_channel_limit Default: 128 Sets maximum number of different channel subscriptions single client can have. channel_max_length Default: 255 Sets maximum length of channel name. channel_user_connection_limit Default: 0 Maximum number of connections from user (with known user ID) to Centrifugo node. By default - unlimited. client_request_max_size Default: 65536 Maximum allowed size of request from client in bytes. client_queue_max_size Default: 10485760 Maximum client message queue size in bytes to close slow reader connections. By default - 10mb. client_anonymous Default: false Enable mode when all clients can connect to Centrifugo without JWT connection token. In this case all connections will be treated as anonymous (i.e. with empty user ID) and only can subscribe to channels with anonymous option enabled. sockjs_heartbeat_delay Default: 25 Interval in seconds how often to send SockJS h-frames to client. websocket_compression Default: false Enable websocket compression, see chapter about websocket transport for more details. gomaxprocs Default: 0 By default Centrifugo runs on all available CPU cores. If you want to limit amount of cores Centrifugo can utilize in one moment use this option. Advanced endpoint configuration. After you started Centrifugo you have several endpoints available. As soon as you have not provided any extra options you have 3 endpoints by default. Default endpoints. The main endpoint is raw Websocket endpoint to serve client connections that use pure Websocket protocol: ws://localhost:8000/connection/websocket Then there is SockJS endpoint - it s needed to serve client connections that use SockJS library: http://localhost:8000/connection/sockjs And finally you have API endpoint to publish messages to channels (and execute other available API commands): http://localhost:8000/api By default all endpoints work on port 8000 . You can change it using port option: { port : 9000 } In production setup you will have your domain name in endpoint addresses above instead of localhost . Also if your Centrifugo will be behind proxy or load balancer software you most probably won t have ports in your endpoint addresses. What will always be the same as shown above are URL paths: /connection/sockjs , /connection/websocket , /api . Let s look at possibilities to tweak available endpoints. Admin endpoints. First is enabling admin endpoints: { ... admin : true, admin_password : password , admin_secret : secret } This makes the following endpoint available: http://localhost:8000 At this address you will see admin web interface. You can log into it using admin_password value shown above. Debug endpoints. Next, when Centrifugo started in debug mode some extra debug endpoints become available. To start in debug mode add debug option to config: { ... debug : true } And endpoint: http://localhost:8000/debug/pprof/ \u2013 will show you useful info about internal state of Centrifugo instance. This info is especially helpful when troubleshooting. See wiki page for more info. Healthcheck endpoint New in v2.1.0 Use health boolean option (by default false ) to enable healthcheck endpoint which will be available on path /health . Also available over command-line flag: ./centrifugo -c config.json --health Custom internal ports We strongly recommend to not expose API, admin, debug and prometheus endpoints to Internet. The following Centrifugo endpoints are considered internal: API endpoint ( /api ) - for HTTP API requests Admin web interface endpoints ( / , /admin/auth , /admin/api ) - used by web interface Prometheus endpoint ( /metrics ) - used for exposing server metrics in Prometheus format Healthcheck endpoint ( /health ) - used to do healthchecks Debug endpoints ( /debug/pprof ) - used to inspect internal server state It s a good practice to protect those endpoints with firewall. For example you can do this in location section of Nginx configuration. Though sometimes you don t have access to per-location configuration in your proxy/load balancer software. For example when using Amazon ELB. In this case you can change ports on which your internal endpoints work. To run internal endpoints on custom port use internal_port option: { ... internal_port : 9000 } So admin web interface will work on address: http://localhost:9000 Also debug page will be available on new custom port too: http://localhost:9000/debug/pprof/ The same for API and prometheus endpoint.","title":"Configuration"},{"location":"server/configuration/#configuration","text":"Centrifugo expects JSON, TOML or YAML as configuration file format. Thanks to brilliant Go library for application configuration - viper . First let s look at all available command-line options: centrifugo -h You should see something like this as output: Centrifugo \u2013 real-time messaging server Usage: [flags] [command] Available Commands: checkconfig Check configuration file genconfig Generate simple configuration file to start with help Help about any command version Centrifugo version information Flags: -a, --address string interface address to listen on --admin enable admin web interface --admin_insecure use insecure admin mode \u2013 no auth required for admin socket --api_insecure use insecure API mode --client_insecure start in insecure client mode -c, --config string path to config file (default config.json ) --debug enable debug endpoints -e, --engine string engine to use: memory or redis (default memory ) --grpc_api enable GRPC API server -h, --help help for this command --internal_port string custom port for internal endpoints --log_file string optional log file - if not specified logs go to STDOUT --log_level string set the log level: debug, info, error, fatal or none (default info ) -n, --name string unique node name --pid_file string optional path to create PID file -p, --port string port to bind HTTP server to (default 8000 ) --prometheus enable Prometheus metrics endpoint --redis_db int Redis database (Redis engine) --redis_host string Redis host (Redis engine) (default 127.0.0.1 ) --redis_master_name string name of Redis master Sentinel monitors (Redis engine) --redis_password string Redis auth password (Redis engine) --redis_port string Redis port (Redis engine) (default 6379 ) --redis_sentinels string comma-separated list of Sentinel addresses (Redis engine) --redis_tls enable Redis TLS connection --redis_tls_skip_verify disable Redis TLS host verification --redis_url string Redis connection URL in format redis://:password@hostname:port/db (Redis engine) --tls enable TLS, requires an X509 certificate and a key file --tls_cert string path to an X509 certificate file --tls_key string path to an X509 certificate key","title":"Configuration"},{"location":"server/configuration/#version","text":"To show version and exit run: centrifugo version","title":"version"},{"location":"server/configuration/#json-file","text":"Centrifugo requires configuration file on start. As was mentioned earlier it must be a file with valid JSON. This is a minimal Centrifugo configuration file: { secret : YOUR-SECRET-STRING-HERE , api_key : YOUR-API-KEY-HERE } The only two fields required are secret and api_key . Secret used to check JWT signature (more about JWT in authentication chapter ). API key used for Centrifugo API endpoint authorization, see more in chapter about server HTTP API . Keep both values in secret and never reveal to clients.","title":"JSON file"},{"location":"server/configuration/#toml-file","text":"Centrifugo also supports TOML format for configuration file: centrifugo --config=config.toml Where config.toml contains: secret = YOUR-SECRET-STRING-HERE api_key = YOUR-API-KEY-HERE log_level = debug I.e. the same configuration as JSON file above with one extra option.","title":"TOML file"},{"location":"server/configuration/#yaml-file","text":"And YAML config also supported. config.yaml : secret: YOUR-SECRET-STRING-HERE api_key: YOUR-API-KEY-HERE log_level: debug With YAML remember to use spaces, not tabs when writing configuration file.","title":"YAML file"},{"location":"server/configuration/#checkconfig-command","text":"Centrifugo has special command to check configuration file checkconfig : centrifugo checkconfig --config = config.json If any errors found during validation \u2013 program will exit with error message and exit code 1.","title":"checkconfig command"},{"location":"server/configuration/#genconfig-command","text":"Another command is genconfig : centrifugo genconfig -c config.json It will automatically generate the minimal required configuration file.","title":"genconfig command"},{"location":"server/configuration/#important-options","text":"Some of the most important options you can configure when running Centrifugo: address \u2013 bind your Centrifugo to specific interface address (by default \"\" ) port \u2013 port to bind Centrifugo to (by default 8000 ) engine \u2013 engine to use - memory or redis (by default memory ). Read more about engines in special chapter . Note that some options can be set via command-line. Command-line options are more valuable when set than configuration file s options. See description of viper \u2013 to see more details about configuration options priority.","title":"Important options"},{"location":"server/configuration/#channel-options","text":"Let s look at options related to channels. Channel is an entity to which clients can subscribe to receive messages published into that channel. Channel is just a string (several symbols has special meaning in Centrifugo - see special chapter to find more information about channels). The following options will affect channel behaviour: publish \u2013 allow clients to publish messages into channels directly (from client side). Your application will never receive those messages. In idiomatic case all messages must be published to Centrifugo by your application backend using Centrifugo API. But this option can be useful when you want to build something without backend-side validation and saving into database. This option can also be useful for demos and prototyping real-time ideas. By default it s false . subscribe_to_publish - when publish option enabled client can publish into channel without being subscribed to it. This option enables automatic check that client subscribed on channel before allowing client to publish into channel. anonymous \u2013 this option enables anonymous access (with empty sub claim in connection token). In most situations your application works with authenticated users so every user has its own unique id. But if you provide real-time features for public access you may need unauthorized access to some channels. Turn on this option and use empty string as user ID. By default false . presence \u2013 enable/disable presence information. Presence is an information about clients currently subscribed on channel. By default false \u2013 i.e. no presence information will be available for channels. join_leave \u2013 enable/disable sending join(leave) messages when client subscribes on channel (unsubscribes from channel). By default false . history_size \u2013 history size (amount of messages) for channels. As Centrifugo keeps all history messages in memory it s very important to limit maximum amount of messages in channel history to reasonable value. history_size defines maximum amount of messages that Centrifugo will keep for each channel in namespace during history lifetime (see below). By default history size is 0 - this means that channels will have no history messages at all. history_lifetime \u2013 interval in seconds how long to keep channel history messages. As all history is storing in memory it is also very important to get rid of old history data for unused (inactive for a long time) channels. By default history lifetime is 0 \u2013 this means that channels will have no history messages at all. So to turn on keeping history messages you should wisely configure both history_size and history_lifetime options . history_recover \u2013 boolean option, when enabled Centrifugo will try to recover missed publications while client was disconnected for some reason (bad internet connection for example). By default false . This option must be used in conjunction with reasonably configured message history for channel i.e. history_size and history_lifetime must be set (because Centrifugo uses channel history to recover messages). Also note that not all real-time events require this feature turned on so think wisely when you need this. When this option turned on your application should be designed in a way to tolerate duplicate messages coming from channel (currently Centrifugo returns recovered publications in order and without duplicates but this is implementation detail that can be theoretically changed in future). See more details about how recovery works in special chapter . Let s look how to set some of these options in config: { secret : my-secret-key , api_key : secret-api-key , anonymous : true , publish : true , subscribe_to_publish : true , presence : true , join_leave : true , history_size : 10 , history_lifetime : 300 , history_recover : true } And the last channel specific option is namespaces . namespaces are optional and if set must be an array of namespace objects. Namespace allows to configure custom options for channels starting with namespace name. This provides a great control over channel behaviour. Namespace has a name and the same channel options (with same defaults) as described above. name - unique namespace name (name must consist of letters, numbers, underscores or hyphens and be more than 2 symbols length i.e. satisfy regexp ^[-a-zA-Z0-9_]{2,}$ ). If you want to use namespace options for channel - you must include namespace name into channel name with : as separator: public:messages gossips:messages Where public and gossips are namespace names from project namespaces . All things together here is an example of config.json which includes registered project with all options set and 2 additional namespaces in it: { secret : very-long-secret-key , api_key : secret-api-key , anonymous : true , publish : true , presence : true , join_leave : true , history_size : 10 , history_lifetime : 30 , namespaces : [ { name : public , publish : true , anonymous : true , history_size : 10 , history_lifetime : 300 , history_recover : true }, { name : gossips , presence : true , join_leave : true } ] } Channel news will use globally defined channel options. Channel public:news will use public namespace s options. Channel gossips:news will use gossips namespace s options. There is no inheritance in channel options and namespaces \u2013 so if for example you defined presence: true on top level of configuration and then defined namespace \u2013 that namespace won t have presence enabled - you must enable it for namespace explicitly.","title":"Channel options"},{"location":"server/configuration/#advanced-configuration","text":"Centrifugo has some options for which default values make sense for most applications. In many case you don t need (and you really should not) change them. This chapter is about such options.","title":"Advanced configuration"},{"location":"server/configuration/#client_channel_limit","text":"Default: 128 Sets maximum number of different channel subscriptions single client can have.","title":"client_channel_limit"},{"location":"server/configuration/#channel_max_length","text":"Default: 255 Sets maximum length of channel name.","title":"channel_max_length"},{"location":"server/configuration/#channel_user_connection_limit","text":"Default: 0 Maximum number of connections from user (with known user ID) to Centrifugo node. By default - unlimited.","title":"channel_user_connection_limit"},{"location":"server/configuration/#client_request_max_size","text":"Default: 65536 Maximum allowed size of request from client in bytes.","title":"client_request_max_size"},{"location":"server/configuration/#client_queue_max_size","text":"Default: 10485760 Maximum client message queue size in bytes to close slow reader connections. By default - 10mb.","title":"client_queue_max_size"},{"location":"server/configuration/#client_anonymous","text":"Default: false Enable mode when all clients can connect to Centrifugo without JWT connection token. In this case all connections will be treated as anonymous (i.e. with empty user ID) and only can subscribe to channels with anonymous option enabled.","title":"client_anonymous"},{"location":"server/configuration/#sockjs_heartbeat_delay","text":"Default: 25 Interval in seconds how often to send SockJS h-frames to client.","title":"sockjs_heartbeat_delay"},{"location":"server/configuration/#websocket_compression","text":"Default: false Enable websocket compression, see chapter about websocket transport for more details.","title":"websocket_compression"},{"location":"server/configuration/#gomaxprocs","text":"Default: 0 By default Centrifugo runs on all available CPU cores. If you want to limit amount of cores Centrifugo can utilize in one moment use this option.","title":"gomaxprocs"},{"location":"server/configuration/#advanced-endpoint-configuration","text":"After you started Centrifugo you have several endpoints available. As soon as you have not provided any extra options you have 3 endpoints by default.","title":"Advanced endpoint configuration."},{"location":"server/configuration/#default-endpoints","text":"The main endpoint is raw Websocket endpoint to serve client connections that use pure Websocket protocol: ws://localhost:8000/connection/websocket Then there is SockJS endpoint - it s needed to serve client connections that use SockJS library: http://localhost:8000/connection/sockjs And finally you have API endpoint to publish messages to channels (and execute other available API commands): http://localhost:8000/api By default all endpoints work on port 8000 . You can change it using port option: { port : 9000 } In production setup you will have your domain name in endpoint addresses above instead of localhost . Also if your Centrifugo will be behind proxy or load balancer software you most probably won t have ports in your endpoint addresses. What will always be the same as shown above are URL paths: /connection/sockjs , /connection/websocket , /api . Let s look at possibilities to tweak available endpoints.","title":"Default endpoints."},{"location":"server/configuration/#admin-endpoints","text":"First is enabling admin endpoints: { ... admin : true, admin_password : password , admin_secret : secret } This makes the following endpoint available: http://localhost:8000 At this address you will see admin web interface. You can log into it using admin_password value shown above.","title":"Admin endpoints."},{"location":"server/configuration/#debug-endpoints","text":"Next, when Centrifugo started in debug mode some extra debug endpoints become available. To start in debug mode add debug option to config: { ... debug : true } And endpoint: http://localhost:8000/debug/pprof/ \u2013 will show you useful info about internal state of Centrifugo instance. This info is especially helpful when troubleshooting. See wiki page for more info.","title":"Debug endpoints."},{"location":"server/configuration/#healthcheck-endpoint","text":"New in v2.1.0 Use health boolean option (by default false ) to enable healthcheck endpoint which will be available on path /health . Also available over command-line flag: ./centrifugo -c config.json --health","title":"Healthcheck endpoint"},{"location":"server/configuration/#custom-internal-ports","text":"We strongly recommend to not expose API, admin, debug and prometheus endpoints to Internet. The following Centrifugo endpoints are considered internal: API endpoint ( /api ) - for HTTP API requests Admin web interface endpoints ( / , /admin/auth , /admin/api ) - used by web interface Prometheus endpoint ( /metrics ) - used for exposing server metrics in Prometheus format Healthcheck endpoint ( /health ) - used to do healthchecks Debug endpoints ( /debug/pprof ) - used to inspect internal server state It s a good practice to protect those endpoints with firewall. For example you can do this in location section of Nginx configuration. Though sometimes you don t have access to per-location configuration in your proxy/load balancer software. For example when using Amazon ELB. In this case you can change ports on which your internal endpoints work. To run internal endpoints on custom port use internal_port option: { ... internal_port : 9000 } So admin web interface will work on address: http://localhost:9000 Also debug page will be available on new custom port too: http://localhost:9000/debug/pprof/ The same for API and prometheus endpoint.","title":"Custom internal ports"},{"location":"server/connection_expiration/","text":"Connection expiration In authentication chapter we mentioned exp claim in connection token that allows to expire client connection at some point of time. In this chapter we will look at details on what happens when Centrifugo detects that connection is going to expire. So first you should do is enable client expiration mechanism in Centrifugo providing connection token with expiration: import jwt import time token = jwt . encode ({ sub : 42 , exp : int ( time . time ()) + 10 * 60 }, secret ) . decode () print ( token ) Let s suppose that you set exp field to timestamp that will expire in 10 minutes and client connected to Centrifugo with this token. During 10 mins connection will be kept by Centrifugo. When this time passed Centrifugo gives connection some time (configured, 25 seconds by default) to refresh its credentials and provide new valid token with new exp . When client first connects to Centrifugo it receives ttl value in connect reply. That ttl value contains number of seconds after which client must send refresh command with new credentials to Centrifugo. Centrifugo clients must handle this ttl field and automatically start refresh process. For example Javascript browser client will send AJAX POST request to your application when it s time to refresh credentials. By default this request goes to /centrifuge/refresh url endpoint. In response your server must return JSON with new connection token: { token : token } So you must just return the same connection token for your user when rendering page initially. But with actual valid exp . Javascript client will then send them to Centrifugo server and connection will be refreshed for a time you set in exp . In this case you know which user want to refresh its connection because this is just a general request to your app - so your session mechanism will tell you about the user. If you don t want to refresh connection for this user - just return 403 Forbidden on refresh request to your application backend. Javascript client also has options to hook into refresh mechanism to implement your custom way of refreshing. Other Centrifugo clients also should have hooks to refresh credentials but depending on client API for this can be different - see specific client docs.","title":"Connection expiration"},{"location":"server/connection_expiration/#connection-expiration","text":"In authentication chapter we mentioned exp claim in connection token that allows to expire client connection at some point of time. In this chapter we will look at details on what happens when Centrifugo detects that connection is going to expire. So first you should do is enable client expiration mechanism in Centrifugo providing connection token with expiration: import jwt import time token = jwt . encode ({ sub : 42 , exp : int ( time . time ()) + 10 * 60 }, secret ) . decode () print ( token ) Let s suppose that you set exp field to timestamp that will expire in 10 minutes and client connected to Centrifugo with this token. During 10 mins connection will be kept by Centrifugo. When this time passed Centrifugo gives connection some time (configured, 25 seconds by default) to refresh its credentials and provide new valid token with new exp . When client first connects to Centrifugo it receives ttl value in connect reply. That ttl value contains number of seconds after which client must send refresh command with new credentials to Centrifugo. Centrifugo clients must handle this ttl field and automatically start refresh process. For example Javascript browser client will send AJAX POST request to your application when it s time to refresh credentials. By default this request goes to /centrifuge/refresh url endpoint. In response your server must return JSON with new connection token: { token : token } So you must just return the same connection token for your user when rendering page initially. But with actual valid exp . Javascript client will then send them to Centrifugo server and connection will be refreshed for a time you set in exp . In this case you know which user want to refresh its connection because this is just a general request to your app - so your session mechanism will tell you about the user. If you don t want to refresh connection for this user - just return 403 Forbidden on refresh request to your application backend. Javascript client also has options to hook into refresh mechanism to implement your custom way of refreshing. Other Centrifugo clients also should have hooks to refresh credentials but depending on client API for this can be different - see specific client docs.","title":"Connection expiration"},{"location":"server/engines/","text":"Engines Memory engine Redis engine Engine in Centrifugo is responsible for publishing messages between nodes, handle PUB/SUB broker subscriptions, save/retrieve presence and history data. By default Centrifugo uses Memory engine. There is also Redis engine available. The difference between them - with Memory engine you can start only one node of Centrifugo, while Redis engine allows to run several nodes on different machines and they will be connected via Redis, will know about each other due to Redis and will also keep history and presence data in Redis instead of Centrifugo node process memory so this data can be accessed from each node. To set engine you can use engine configuration option. Available values are memory and redis . Default value is memory . For example to work with Redis engine: centrifugo --config=config.json --engine=redis Or just set engine in config: { ... engine : redis } Memory engine Supports only one node. Nice choice to start with. Supports all features keeping everything in Centrifugo node process memory. You don t need to install Redis when using this engine. Advantages: fast does not require separate Redis setup Disadvantages: does not allow to scale nodes (actually you still can scale Centrifugo with Memory engine but you have to publish data into each Centrifugo node and you won t have consistent state of presence) Redis engine Allows scaling Centrifugo nodes to different machines. Nodes will use Redis as message broker. Redis engine keeps presence and history data in Redis, uses Redis PUB/SUB for internal nodes communication. Minimal Redis version is 3.2.0 Several configuration options related to Redis engine: redis_host (string, default \"127.0.0.1\" ) - Redis server host redis_port (int, default 6379 ) - Redis server port redis_url (string, default \"\" ) - optional Redis connection URL redis_password (string, default \"\" ) - Redis password redis_db (int, default 0 ) - number of Redis db to use redis_tls (boolean, default false ) - enable Redis TLS connection (new in v2.0.2) redis_tls_skip_verify (boolean, default false ) - disable Redis TLS host verification (new in v2.0.2) redis_sentinels (string, default \"\" ) - comma separated list of Sentinels for HA redis_master_name (string, default \"\" ) - name of Redis master Sentinel monitors redis_prefix (string, default \"centrifugo\" ) \u2013 custom prefix to use for channels and keys in Redis Some of these options can be set over command-line arguments (see centrifugo -h output), some only over configuration file. Let s describe a bit more redis_url option. redis_url allows to set Redis connection parameters in a form of URL in format redis://:password@hostname:port/db_number . When redis_url set Centrifugo will use URL instead of values provided in redis_host , redis_port , redis_password , redis_db options. Scaling with Redis tutorial Let s see how to start several Centrifugo nodes using Redis engine. We will start 3 Centrifugo nodes and all those nodes will be connected via Redis. First, you should have Redis running. As soon as it s running - we can launch 3 Centrifugo instances. Open your terminal and start first one: centrifugo --config=config.json --port=8000 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 If your Redis on the same machine and runs on its default port you can omit redis_host and redis_port options in command above. Then open another terminal and start another Centrifugo instance: centrifugo --config=config.json --port=8001 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 Note that we use another port number ( 8001 ) as port 8000 already busy by our first Centrifugo instance. If you are starting Centrifugo instances on different machines then you most probably can use the same port number ( 8000 or whatever you want) for all instances. And finally let s start third instance: centrifugo --config=config.json --port=8002 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 Now you have 3 Centrifugo instances running on ports 8000, 8001, 8002 and clients can connect to any of them. You can also send API requests to any of those nodes \u2013 as all nodes connected over Redis PUB/SUB message will be delivered to all interested clients on all nodes. To load balance clients between nodes you can use Nginx \u2013 you can find its configuration here in documentation. Redis sharding Centrifugo has a built-in Redis sharding support. This resolves situation when Redis becoming a bottleneck on large Centrifugo setup. Redis is single-threaded server, it s very fast but it s power is not infinite so when your Redis approaches 100% CPU usage then sharding feature can help your application to scale. At moment Centrifugo supports simple comma-based approach to configuring Redis shards. Let s just look on examples. To start Centrifugo with 2 Redis shards on localhost running on port 6379 and port 6380: centrifugo --config=config.json --engine=redis --redis_port=6379,6380 To start Centrifugo with Redis instances on different hosts: centrifugo --config=config.json --engine=redis --redis_host=192.168.1.34,192.168.1.35 If you also need to customize AUTH password, Redis DB number then you can use redis_url option. Note, that due to how Redis PUB/SUB work it s not possible (and it s pretty useless anyway) to run shards in one Redis instances using different Redis DB numbers. When sharding enabled Centrifugo will spread channels and history/presence keys over configured Redis instances using consistent hashing algorithm. At moment we use Jump consistent hash algorithm (see paper and implementation )","title":"Engines"},{"location":"server/engines/#engines","text":"Memory engine Redis engine Engine in Centrifugo is responsible for publishing messages between nodes, handle PUB/SUB broker subscriptions, save/retrieve presence and history data. By default Centrifugo uses Memory engine. There is also Redis engine available. The difference between them - with Memory engine you can start only one node of Centrifugo, while Redis engine allows to run several nodes on different machines and they will be connected via Redis, will know about each other due to Redis and will also keep history and presence data in Redis instead of Centrifugo node process memory so this data can be accessed from each node. To set engine you can use engine configuration option. Available values are memory and redis . Default value is memory . For example to work with Redis engine: centrifugo --config=config.json --engine=redis Or just set engine in config: { ... engine : redis }","title":"Engines"},{"location":"server/engines/#memory-engine","text":"Supports only one node. Nice choice to start with. Supports all features keeping everything in Centrifugo node process memory. You don t need to install Redis when using this engine. Advantages: fast does not require separate Redis setup Disadvantages: does not allow to scale nodes (actually you still can scale Centrifugo with Memory engine but you have to publish data into each Centrifugo node and you won t have consistent state of presence)","title":"Memory engine"},{"location":"server/engines/#redis-engine","text":"Allows scaling Centrifugo nodes to different machines. Nodes will use Redis as message broker. Redis engine keeps presence and history data in Redis, uses Redis PUB/SUB for internal nodes communication. Minimal Redis version is 3.2.0 Several configuration options related to Redis engine: redis_host (string, default \"127.0.0.1\" ) - Redis server host redis_port (int, default 6379 ) - Redis server port redis_url (string, default \"\" ) - optional Redis connection URL redis_password (string, default \"\" ) - Redis password redis_db (int, default 0 ) - number of Redis db to use redis_tls (boolean, default false ) - enable Redis TLS connection (new in v2.0.2) redis_tls_skip_verify (boolean, default false ) - disable Redis TLS host verification (new in v2.0.2) redis_sentinels (string, default \"\" ) - comma separated list of Sentinels for HA redis_master_name (string, default \"\" ) - name of Redis master Sentinel monitors redis_prefix (string, default \"centrifugo\" ) \u2013 custom prefix to use for channels and keys in Redis Some of these options can be set over command-line arguments (see centrifugo -h output), some only over configuration file. Let s describe a bit more redis_url option. redis_url allows to set Redis connection parameters in a form of URL in format redis://:password@hostname:port/db_number . When redis_url set Centrifugo will use URL instead of values provided in redis_host , redis_port , redis_password , redis_db options.","title":"Redis engine"},{"location":"server/engines/#scaling-with-redis-tutorial","text":"Let s see how to start several Centrifugo nodes using Redis engine. We will start 3 Centrifugo nodes and all those nodes will be connected via Redis. First, you should have Redis running. As soon as it s running - we can launch 3 Centrifugo instances. Open your terminal and start first one: centrifugo --config=config.json --port=8000 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 If your Redis on the same machine and runs on its default port you can omit redis_host and redis_port options in command above. Then open another terminal and start another Centrifugo instance: centrifugo --config=config.json --port=8001 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 Note that we use another port number ( 8001 ) as port 8000 already busy by our first Centrifugo instance. If you are starting Centrifugo instances on different machines then you most probably can use the same port number ( 8000 or whatever you want) for all instances. And finally let s start third instance: centrifugo --config=config.json --port=8002 --engine=redis --redis_host=127.0.0.1 --redis_port=6379 Now you have 3 Centrifugo instances running on ports 8000, 8001, 8002 and clients can connect to any of them. You can also send API requests to any of those nodes \u2013 as all nodes connected over Redis PUB/SUB message will be delivered to all interested clients on all nodes. To load balance clients between nodes you can use Nginx \u2013 you can find its configuration here in documentation.","title":"Scaling with Redis tutorial"},{"location":"server/engines/#redis-sharding","text":"Centrifugo has a built-in Redis sharding support. This resolves situation when Redis becoming a bottleneck on large Centrifugo setup. Redis is single-threaded server, it s very fast but it s power is not infinite so when your Redis approaches 100% CPU usage then sharding feature can help your application to scale. At moment Centrifugo supports simple comma-based approach to configuring Redis shards. Let s just look on examples. To start Centrifugo with 2 Redis shards on localhost running on port 6379 and port 6380: centrifugo --config=config.json --engine=redis --redis_port=6379,6380 To start Centrifugo with Redis instances on different hosts: centrifugo --config=config.json --engine=redis --redis_host=192.168.1.34,192.168.1.35 If you also need to customize AUTH password, Redis DB number then you can use redis_url option. Note, that due to how Redis PUB/SUB work it s not possible (and it s pretty useless anyway) to run shards in one Redis instances using different Redis DB numbers. When sharding enabled Centrifugo will spread channels and history/presence keys over configured Redis instances using consistent hashing algorithm. At moment we use Jump consistent hash algorithm (see paper and implementation )","title":"Redis sharding"},{"location":"server/grpc_api/","text":"Server GRPC API Centrifugo also supports GRPC API. With GRPC it s possible to communicate with Centrifugo using more compact binary representation of commands and use the power of HTTP/2 which is the transport behind GRPC. GRPC API is also useful if you want to publish binary data to Centrifugo channels. You can enable GRPC API in Centrifugo using grpc_api option: ./centrifugo --config=config.json --grpc_api As always in Centrifugo you can just add grpc_api option to configuration file: { ... grpc_api : true } By default GRPC will be served on port 10000 but you can change it using grpc_api_port option. Now as soon as Centrifugo started you can send GRPC commands to it. To do this get our API Protocol Buffer definitions from this file . Then see GRPC docs specific to your language to find out how to generate client code from definitions and use generated code to communicate with Centrifugo. Example for Python For example for Python you need to run sth like this according to GRPC docs: python -m grpc_tools.protoc -I../../protos --python_out=. --grpc_python_out=. api.proto As soon as you run command you will have 2 generated files: api_pb2.py and api_pb2_grpc.py . Now all you need is to write simple program that uses generated code and sends GRPC requests to Centrifugo: import grpc import api_pb2_grpc as api_grpc import api_pb2 as api_pb channel = grpc . insecure_channel ( localhost:10000 ) stub = api_grpc . CentrifugoStub ( channel ) try : resp = stub . Info ( api_pb . InfoRequest ()) except grpc . RpcError as err : # GRPC level error. print ( err . code (), err . details ()) else : if resp . error . code : # Centrifugo server level error. print ( resp . error . code , resp . error . message ) else : print ( resp . result ) Note that you need to explicitly handle Centrifugo API level error which is not transformed automatically into GRPC protocol level error.","title":"Server GRPC API"},{"location":"server/grpc_api/#server-grpc-api","text":"Centrifugo also supports GRPC API. With GRPC it s possible to communicate with Centrifugo using more compact binary representation of commands and use the power of HTTP/2 which is the transport behind GRPC. GRPC API is also useful if you want to publish binary data to Centrifugo channels. You can enable GRPC API in Centrifugo using grpc_api option: ./centrifugo --config=config.json --grpc_api As always in Centrifugo you can just add grpc_api option to configuration file: { ... grpc_api : true } By default GRPC will be served on port 10000 but you can change it using grpc_api_port option. Now as soon as Centrifugo started you can send GRPC commands to it. To do this get our API Protocol Buffer definitions from this file . Then see GRPC docs specific to your language to find out how to generate client code from definitions and use generated code to communicate with Centrifugo.","title":"Server GRPC API"},{"location":"server/grpc_api/#example-for-python","text":"For example for Python you need to run sth like this according to GRPC docs: python -m grpc_tools.protoc -I../../protos --python_out=. --grpc_python_out=. api.proto As soon as you run command you will have 2 generated files: api_pb2.py and api_pb2_grpc.py . Now all you need is to write simple program that uses generated code and sends GRPC requests to Centrifugo: import grpc import api_pb2_grpc as api_grpc import api_pb2 as api_pb channel = grpc . insecure_channel ( localhost:10000 ) stub = api_grpc . CentrifugoStub ( channel ) try : resp = stub . Info ( api_pb . InfoRequest ()) except grpc . RpcError as err : # GRPC level error. print ( err . code (), err . details ()) else : if resp . error . code : # Centrifugo server level error. print ( resp . error . code , resp . error . message ) else : print ( resp . result ) Note that you need to explicitly handle Centrifugo API level error which is not transformed automatically into GRPC protocol level error.","title":"Example for Python"},{"location":"server/http_api/","text":"Server HTTP API HTTP API is a way to send commands to Centrifugo. Why we need API? If you look at configuration options you see an option called publish defined on configuration top level and for channel namespace. When turned on this option allows browser clients to publish into channels directly. If client publishes a message into channel directly \u2013 your application will not receive that message (it just goes through Centrifugo towards subscribed clients). This pattern can be useful sometimes but in most cases you first need to send new event from client to backend over non-Centrifugo transport (for example via AJAX request in web application), then process it on application backend side \u2013 probably validate, save into main app database \u2013 and then publish into Centrifugo using HTTP API so Centrifugo broadcast message to all clients subscribed on channel. Server API works on /api endpoint. It s very simple to use: you just have to send POST request with JSON command to this endpoint. In this chapter we will look at API protocol internals - for new API client library authors and just if you are curious how existing API clients work. API request is a POST HTTP request with application/json Content-Type and JSON payload in request body. API protected by api_key set in Centrifugo configuration. I.e. api_key must be added to config, like: { ... api_key : YOUR API KEY } This API key must be set in request Authorization header in this way: Authorization : apikey KEY It s possible to disable API key check on Centrifugo side using api_insecure configuration option. Be sure to protect API endpoint by firewall rules in this case to prevent anyone in internet to send commands over your unprotected Centrifugo API. API key auth is not very safe for man-in-the-middle so recommended way is running Centrifugo with TLS (we are in 2018 in the end). Command is a JSON object with two properties: method and params . method is a name of command you want to call. params is an object with command arguments. There are several commands available. Let s investigate each of available server API commands. publish Publish command allows to publish data into channel. It looks like this: { method : publish , params : { channel : chat , data : { text : hello } } } Let s apply all information said above and send publish command to Centrifugo. We will send request using requests library for Python. import json import requests command = { method : publish , params : { channel : docs , data : { content : 1 } } } api_key = YOUR_API_KEY data = json . dumps ( command ) headers = { Content-type : application/json , Authorization : apikey + api_key } resp = requests . post ( https://centrifuge.example.com/api , data = data , headers = headers ) print ( resp . json ()) The same using httpie console tool: $ echo { method : publish , params : { channel : chat , data : { text : hello }}} | http localhost:8000/api Authorization: apikey KEY -vvv POST /api HTTP/1.1 Accept: application/json, */* Accept-Encoding: gzip, deflate Authorization: apikey KEY Connection: keep-alive Content-Length: 80 Content-Type: application/json Host: localhost:8000 User-Agent: HTTPie/0.9.8 { method : publish , params : { channel : chat , data : { text : hello } } } HTTP/1.1 200 OK Content-Length: 3 Content-Type: application/json Date: Thu, 17 May 2018 22 :01:42 GMT {} In case of error response object will contain error field: $ echo { method : publish , params : { channel : unknown:chat , data : { text : hello }}} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 55 Content-Type: application/json Date: Thu, 17 May 2018 22 :03:09 GMT { error : { code : 102 , message : namespace not found } } error object contains error code and message - this also the same for other commands described below. publish command is the main command you need. Again - remember that we have client API libraries that can help you avoid some boilerplate we just wrote and help to properly handle error responses from Centrifugo. Let s look at other available commands: broadcast Similar to publish but allows to send the same data into many channels. { method : broadcast , params : { channels : [ CHANNEL_1 , CHANNEL_2 ], data : { text : hello } } } unsubscribe unsubscribe allows to unsubscribe user from channel. params is an objects with two keys: channel and user (user ID you want to unsubscribe) { method : unsubscribe , params : { channel : CHANNEL NAME , user : USER ID } } disconnect disconnect allows to disconnect user by ID. params in an object with user key. { method : disconnect , params : { user : USER ID } } presence presence allows to get channel presence information (all clients currently subscribed on this channel). params is an object with channel key. { method : presence , params : { channel : chat } } Example: fz@centrifugo: echo { method : presence , params : { channel : chat }} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 127 Content-Type: application/json Date: Thu, 17 May 2018 22 :13:17 GMT { result : { presence : { c54313b2-0442-499a-a70c-051f8588020f : { client : c54313b2-0442-499a-a70c-051f8588020f , user : 42 } , adad13b1-0442-499a-a70c-051f858802da : { client : adad13b1-0442-499a-a70c-051f858802da , user : 42 } } } } presence_stats presence_stats allows to get short channel presence information. { method : presence_stats , params : { channel : chat } } Example: $ echo { method : presence_stats , params : { channel : public:chat }} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 43 Content-Type: application/json Date: Thu, 17 May 2018 22 :09:44 GMT { result : { num_clients : 0 , num_users : 0 } } history history allows to get channel history information (list of last messages published into channel). params is an object with channel key: { method : history , params : { channel : chat } } Example: $ echo { method : history , params : { channel : public:chat }} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 87 Content-Type: application/json Date: Thu, 17 May 2018 22 :14:10 GMT { result : { publications : [ { data : { text : hello } , uid : BWcn14OTBrqUhTXyjNg0fg } , { data : { text : hi! } , uid : Ascn14OTBrq14OXyjNg0hg } ] } } channels channels allows to get list of active (with one or more subscribers) channels. { method : channels , params : {} } Example: $ echo { method : channels , params : {}} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 27 Content-Type: application/json Date: Thu, 17 May 2018 22 :08:31 GMT { result : { channels : [ chat ] } } info info method allows to get information about running Centrifugo nodes. { method : info , params : {} } Example: $ echo { method : info , params : {}} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 184 Content-Type: application/json Date: Thu, 17 May 2018 22 :07:58 GMT { result : { nodes : [ { name : Alexanders-MacBook-Pro.local_8000 , num_channels : 0 , num_clients : 0 , num_users : 0 , uid : f844a2ed-5edf-4815-b83c-271974003db9 , uptime : 0 , version : } ] } } Command pipelining It s possible to combine several commands into one request to Centrifugo. To do this use JSON streaming format. This can improve server throughput and reduce traffic travelling around.","title":"Server HTTP API"},{"location":"server/http_api/#server-http-api","text":"HTTP API is a way to send commands to Centrifugo. Why we need API? If you look at configuration options you see an option called publish defined on configuration top level and for channel namespace. When turned on this option allows browser clients to publish into channels directly. If client publishes a message into channel directly \u2013 your application will not receive that message (it just goes through Centrifugo towards subscribed clients). This pattern can be useful sometimes but in most cases you first need to send new event from client to backend over non-Centrifugo transport (for example via AJAX request in web application), then process it on application backend side \u2013 probably validate, save into main app database \u2013 and then publish into Centrifugo using HTTP API so Centrifugo broadcast message to all clients subscribed on channel. Server API works on /api endpoint. It s very simple to use: you just have to send POST request with JSON command to this endpoint. In this chapter we will look at API protocol internals - for new API client library authors and just if you are curious how existing API clients work. API request is a POST HTTP request with application/json Content-Type and JSON payload in request body. API protected by api_key set in Centrifugo configuration. I.e. api_key must be added to config, like: { ... api_key : YOUR API KEY } This API key must be set in request Authorization header in this way: Authorization : apikey KEY It s possible to disable API key check on Centrifugo side using api_insecure configuration option. Be sure to protect API endpoint by firewall rules in this case to prevent anyone in internet to send commands over your unprotected Centrifugo API. API key auth is not very safe for man-in-the-middle so recommended way is running Centrifugo with TLS (we are in 2018 in the end). Command is a JSON object with two properties: method and params . method is a name of command you want to call. params is an object with command arguments. There are several commands available. Let s investigate each of available server API commands.","title":"Server HTTP API"},{"location":"server/http_api/#publish","text":"Publish command allows to publish data into channel. It looks like this: { method : publish , params : { channel : chat , data : { text : hello } } } Let s apply all information said above and send publish command to Centrifugo. We will send request using requests library for Python. import json import requests command = { method : publish , params : { channel : docs , data : { content : 1 } } } api_key = YOUR_API_KEY data = json . dumps ( command ) headers = { Content-type : application/json , Authorization : apikey + api_key } resp = requests . post ( https://centrifuge.example.com/api , data = data , headers = headers ) print ( resp . json ()) The same using httpie console tool: $ echo { method : publish , params : { channel : chat , data : { text : hello }}} | http localhost:8000/api Authorization: apikey KEY -vvv POST /api HTTP/1.1 Accept: application/json, */* Accept-Encoding: gzip, deflate Authorization: apikey KEY Connection: keep-alive Content-Length: 80 Content-Type: application/json Host: localhost:8000 User-Agent: HTTPie/0.9.8 { method : publish , params : { channel : chat , data : { text : hello } } } HTTP/1.1 200 OK Content-Length: 3 Content-Type: application/json Date: Thu, 17 May 2018 22 :01:42 GMT {} In case of error response object will contain error field: $ echo { method : publish , params : { channel : unknown:chat , data : { text : hello }}} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 55 Content-Type: application/json Date: Thu, 17 May 2018 22 :03:09 GMT { error : { code : 102 , message : namespace not found } } error object contains error code and message - this also the same for other commands described below. publish command is the main command you need. Again - remember that we have client API libraries that can help you avoid some boilerplate we just wrote and help to properly handle error responses from Centrifugo. Let s look at other available commands:","title":"publish"},{"location":"server/http_api/#broadcast","text":"Similar to publish but allows to send the same data into many channels. { method : broadcast , params : { channels : [ CHANNEL_1 , CHANNEL_2 ], data : { text : hello } } }","title":"broadcast"},{"location":"server/http_api/#unsubscribe","text":"unsubscribe allows to unsubscribe user from channel. params is an objects with two keys: channel and user (user ID you want to unsubscribe) { method : unsubscribe , params : { channel : CHANNEL NAME , user : USER ID } }","title":"unsubscribe"},{"location":"server/http_api/#disconnect","text":"disconnect allows to disconnect user by ID. params in an object with user key. { method : disconnect , params : { user : USER ID } }","title":"disconnect"},{"location":"server/http_api/#presence","text":"presence allows to get channel presence information (all clients currently subscribed on this channel). params is an object with channel key. { method : presence , params : { channel : chat } } Example: fz@centrifugo: echo { method : presence , params : { channel : chat }} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 127 Content-Type: application/json Date: Thu, 17 May 2018 22 :13:17 GMT { result : { presence : { c54313b2-0442-499a-a70c-051f8588020f : { client : c54313b2-0442-499a-a70c-051f8588020f , user : 42 } , adad13b1-0442-499a-a70c-051f858802da : { client : adad13b1-0442-499a-a70c-051f858802da , user : 42 } } } }","title":"presence"},{"location":"server/http_api/#presence_stats","text":"presence_stats allows to get short channel presence information. { method : presence_stats , params : { channel : chat } } Example: $ echo { method : presence_stats , params : { channel : public:chat }} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 43 Content-Type: application/json Date: Thu, 17 May 2018 22 :09:44 GMT { result : { num_clients : 0 , num_users : 0 } }","title":"presence_stats"},{"location":"server/http_api/#history","text":"history allows to get channel history information (list of last messages published into channel). params is an object with channel key: { method : history , params : { channel : chat } } Example: $ echo { method : history , params : { channel : public:chat }} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 87 Content-Type: application/json Date: Thu, 17 May 2018 22 :14:10 GMT { result : { publications : [ { data : { text : hello } , uid : BWcn14OTBrqUhTXyjNg0fg } , { data : { text : hi! } , uid : Ascn14OTBrq14OXyjNg0hg } ] } }","title":"history"},{"location":"server/http_api/#channels","text":"channels allows to get list of active (with one or more subscribers) channels. { method : channels , params : {} } Example: $ echo { method : channels , params : {}} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 27 Content-Type: application/json Date: Thu, 17 May 2018 22 :08:31 GMT { result : { channels : [ chat ] } }","title":"channels"},{"location":"server/http_api/#info","text":"info method allows to get information about running Centrifugo nodes. { method : info , params : {} } Example: $ echo { method : info , params : {}} | http localhost:8000/api Authorization: apikey KEY HTTP/1.1 200 OK Content-Length: 184 Content-Type: application/json Date: Thu, 17 May 2018 22 :07:58 GMT { result : { nodes : [ { name : Alexanders-MacBook-Pro.local_8000 , num_channels : 0 , num_clients : 0 , num_users : 0 , uid : f844a2ed-5edf-4815-b83c-271974003db9 , uptime : 0 , version : } ] } }","title":"info"},{"location":"server/http_api/#command-pipelining","text":"It s possible to combine several commands into one request to Centrifugo. To do this use JSON streaming format. This can improve server throughput and reduce traffic travelling around.","title":"Command pipelining"},{"location":"server/install/","text":"Install and quick start In this chapter we will look at how you can get Centrifugo. Binary releases Go language gives developers an opportunity to build single binary executable file with application and cross-compile application for all common operating systems. This means that all you need to get Centrifugo \u2013 download latest release for you operating system, unpack it and you are done! Now you can see help information for Centrifugo: ./centrifugo -h Centrifugo server node requires configuration file with secret key. If you are new to Centrifugo then there is genconfig command which generates minimal required configuration file: ./centrifugo genconfig It generates secret key automatically and creates configuration file config.json in current directory (by default) so you can finally run Centrifugo instance: ./centrifugo --config = config.json We will talk about configuration in detail in next sections. You can also put or symlink centrifugo into your bin OS directory and run it from anywhere: centrifugo --config = config.json Linux packages We have prebuilt rpm and deb packages for most popular Linux distributions and Docker image. See this chapter for more information. Docker image And of course we have official Docker image \u2013 see this chapter for more information.","title":"Installation"},{"location":"server/install/#install-and-quick-start","text":"In this chapter we will look at how you can get Centrifugo.","title":"Install and quick start"},{"location":"server/install/#binary-releases","text":"Go language gives developers an opportunity to build single binary executable file with application and cross-compile application for all common operating systems. This means that all you need to get Centrifugo \u2013 download latest release for you operating system, unpack it and you are done! Now you can see help information for Centrifugo: ./centrifugo -h Centrifugo server node requires configuration file with secret key. If you are new to Centrifugo then there is genconfig command which generates minimal required configuration file: ./centrifugo genconfig It generates secret key automatically and creates configuration file config.json in current directory (by default) so you can finally run Centrifugo instance: ./centrifugo --config = config.json We will talk about configuration in detail in next sections. You can also put or symlink centrifugo into your bin OS directory and run it from anywhere: centrifugo --config = config.json","title":"Binary releases"},{"location":"server/install/#linux-packages","text":"We have prebuilt rpm and deb packages for most popular Linux distributions and Docker image. See this chapter for more information.","title":"Linux packages"},{"location":"server/install/#docker-image","text":"And of course we have official Docker image \u2013 see this chapter for more information.","title":"Docker image"},{"location":"server/monitoring/","text":"Monitoring Centrifugo supports reporting metrics in Prometheus format and can automatically export metrics to Graphite. Prometheus To enable Prometheus endpoint start Centrifugo with prometheus option on: { ... prometheus : true } ./centrifugo --config=config.json This will enable /metrics endpoint so Centrifugo instance can be monitored by your Prometheus server. Graphite To enable automatic export to Graphite (via TCP): { graphite : true , graphite_host : localhost , graphite_port : 2003 } By default stats will be aggregated over 10 seconds interval inside Centrifugo and then pushed to Graphite over TCP connection. If you need to change this aggregation interval use graphite_interval option (in seconds, default 10 ). This option available since v2.1.0","title":"Monitoring"},{"location":"server/monitoring/#monitoring","text":"Centrifugo supports reporting metrics in Prometheus format and can automatically export metrics to Graphite.","title":"Monitoring"},{"location":"server/monitoring/#prometheus","text":"To enable Prometheus endpoint start Centrifugo with prometheus option on: { ... prometheus : true } ./centrifugo --config=config.json This will enable /metrics endpoint so Centrifugo instance can be monitored by your Prometheus server.","title":"Prometheus"},{"location":"server/monitoring/#graphite","text":"To enable automatic export to Graphite (via TCP): { graphite : true , graphite_host : localhost , graphite_port : 2003 } By default stats will be aggregated over 10 seconds interval inside Centrifugo and then pushed to Graphite over TCP connection. If you need to change this aggregation interval use graphite_interval option (in seconds, default 10 ). This option available since v2.1.0","title":"Graphite"},{"location":"server/private_channels/","text":"Private channels In channels chapter we mentioned private channels. This chapter has more information about private channel mechanism in Centrifugo. All channels starting with $ considered private. In this case your backend should additionally provide token for subscription request. The way how this token is obtained varies depending on client implementation. For example in Javascript client AJAX POST request is automatically sent to /centrifuge/subscribe endpoint on every private channel subscription attempt. Other client libraries can provide a hook for your custom code that will obtain private channel subscription token from application backend. Private channel subscription token is also JWT (like connection token described in authentication chapter ). But it has different claims. !!! note Connection token and private channel subscription token are different entities. Though both are JWT and you can generate them using any JWT library. Claims Private channel subscription token claims are: client , channel , info , b64info and exp . What do they mean? Let s describe in detail. client Required. Client ID which wants to subscribe on channel ( string ). channel Required. Channel that client tries to subscribe to ( string ). info Optional. Additional information for connection regarding to channel ( valid JSON ). b64info Optional. Additional information for connection regarding to channel in base64 format ( string ). exp Optional. This is standard JWT claim that allows to set private channel subscription token expiration time. At moment if subscription token expires client connection will be closed and client will try to reconnect. In most cases you don t need this and should prefer using exp of connection token to deactivate connection. But if you need more granular per-channel control this may fit your needs. Once exp set in token every subscription token must be periodically refreshed. Refer to specific client documentation in order to see how to refresh subscription tokens. Example So to generate subscription token you can use smth like this in Python (assuming client ID is XXX and private channel is $gossips ): import jwt token = jwt . encode ({ client : XXX , channel : $gossips }, secret , algorithm = HS256 ) . decode () print ( token ) Again - the same secret from Centrifugo configuration is used to generate private channel JWT as was used to generate connection JWT. And as with connection JWT only HS256 algorithm is supported at moment.","title":"Private channels"},{"location":"server/private_channels/#private-channels","text":"In channels chapter we mentioned private channels. This chapter has more information about private channel mechanism in Centrifugo. All channels starting with $ considered private. In this case your backend should additionally provide token for subscription request. The way how this token is obtained varies depending on client implementation. For example in Javascript client AJAX POST request is automatically sent to /centrifuge/subscribe endpoint on every private channel subscription attempt. Other client libraries can provide a hook for your custom code that will obtain private channel subscription token from application backend. Private channel subscription token is also JWT (like connection token described in authentication chapter ). But it has different claims. !!! note Connection token and private channel subscription token are different entities. Though both are JWT and you can generate them using any JWT library.","title":"Private channels"},{"location":"server/private_channels/#claims","text":"Private channel subscription token claims are: client , channel , info , b64info and exp . What do they mean? Let s describe in detail.","title":"Claims"},{"location":"server/private_channels/#client","text":"Required. Client ID which wants to subscribe on channel ( string ).","title":"client"},{"location":"server/private_channels/#channel","text":"Required. Channel that client tries to subscribe to ( string ).","title":"channel"},{"location":"server/private_channels/#info","text":"Optional. Additional information for connection regarding to channel ( valid JSON ).","title":"info"},{"location":"server/private_channels/#b64info","text":"Optional. Additional information for connection regarding to channel in base64 format ( string ).","title":"b64info"},{"location":"server/private_channels/#exp","text":"Optional. This is standard JWT claim that allows to set private channel subscription token expiration time. At moment if subscription token expires client connection will be closed and client will try to reconnect. In most cases you don t need this and should prefer using exp of connection token to deactivate connection. But if you need more granular per-channel control this may fit your needs. Once exp set in token every subscription token must be periodically refreshed. Refer to specific client documentation in order to see how to refresh subscription tokens.","title":"exp"},{"location":"server/private_channels/#example","text":"So to generate subscription token you can use smth like this in Python (assuming client ID is XXX and private channel is $gossips ): import jwt token = jwt . encode ({ client : XXX , channel : $gossips }, secret , algorithm = HS256 ) . decode () print ( token ) Again - the same secret from Centrifugo configuration is used to generate private channel JWT as was used to generate connection JWT. And as with connection JWT only HS256 algorithm is supported at moment.","title":"Example"},{"location":"server/protobuf/","text":"Protobuf binary protocol In most cases you will use Centrifugo with JSON protocol which is used by default. It consists of simple human-readable frames that can be easily inspected. Also it s a very simple task to publish JSON encoded data to HTTP API endpoint. You may want to use binary Protobuf client protocol if: you want less traffic on wire as Protobuf is very compact you want maximum performance as Protobuf encoding/decoding is very efficient you can sacrifice human-readable JSON for your application Binary protobuf protocol only works for raw Websocket connections (as SockJS can t deal with binary). With most clients to use binary you just need to provide query parameter format to Websocket URL, so final URL look like: wss://centrifugo.example.com/connection/websocket?format=protobuf After doing this Centrifugo will use binary frames to pass data between client and server. Your application specific payload can be random bytes. !!! note You still can continue to encode your application specific data as JSON when using Protobuf protocol thus have a possibility to coexist with clients that use JSON protocol on the same Centrifugo installation inside the same channels.","title":"Protobuf protocol"},{"location":"server/protobuf/#protobuf-binary-protocol","text":"In most cases you will use Centrifugo with JSON protocol which is used by default. It consists of simple human-readable frames that can be easily inspected. Also it s a very simple task to publish JSON encoded data to HTTP API endpoint. You may want to use binary Protobuf client protocol if: you want less traffic on wire as Protobuf is very compact you want maximum performance as Protobuf encoding/decoding is very efficient you can sacrifice human-readable JSON for your application Binary protobuf protocol only works for raw Websocket connections (as SockJS can t deal with binary). With most clients to use binary you just need to provide query parameter format to Websocket URL, so final URL look like: wss://centrifugo.example.com/connection/websocket?format=protobuf After doing this Centrifugo will use binary frames to pass data between client and server. Your application specific payload can be random bytes. !!! note You still can continue to encode your application specific data as JSON when using Protobuf protocol thus have a possibility to coexist with clients that use JSON protocol on the same Centrifugo installation inside the same channels.","title":"Protobuf binary protocol"},{"location":"server/protocol/","text":"Client protocol This chapter describes internal client-server protocol in details to help developers build new client libraries and understand how existing client libraries work. Note that you can always look at existing client implementations in case of any questions. Client implementation checklist First we will look at list of features client library should support. Depending on client implementation some features can be not implemented. If you an author of client library you can use this list as checklist. !!! note Field and method names presented in this checklist can have different names depending on programmer s taste and language style guide So, client: Should work both with Centrifugo and Centrifuge library based server. To work with Centrifugo client must have a method to set connection token. To work with Centrifuge lib client must provide a method to set custom headers (the only exception is browser clients where browser automatically sets headers with respect to domain rules) Should allow to use JSON payload Should allow to use binary payload (actually you can only implement Protobuf protocol as you can pass JSON over it) Must handle cases when many different Replies received in one websocket frame. In case of JSON protocol newline-delimited JSON-streaming format is used to combine several Replies into one websocket frame. In case of Protobuf protocol varint length-prefixed format is used Must survive server reload/restart and internet connection lost. In this case client must try to reconnect with exponentioal backoff strategy Must have several callback methods: onConnect , onDisconnect . Depending on implementation you can also use onError callback for critical errors that could not be gracefully handled. Should also have onMessage callback to handle async messages from server. Must have method to subscribe on channel and set several event handlers: onPublish , onJoin , onLeave , onSubscribeSuccess , onSubscribeError , onUnsubscribe . After subscribe method called it should return Subscription object to caller. This subscription object in turn should have some methods: publish , unsubscribe , subscribe , history , presence , presence_stats . Should have publish method to publish into channel without subscribing to it. Should have rpc method to send RPC request to server. Should have send method to send asynchronous message to server (without waiting response). Should handle disconnect reason. In case of Websocket it is sent by server in CLOSE Websocket frame. This is a string containing JSON object with fields: reason (string) and reconnect (bool). Client should give users access to these fields in disconnect event and automatically follow reconnect advice Must send periodic ping commands to server and thus detect broken connection. If no ping reply received from server in configured window reconnect workflow must be initiated Should fully reconnect if subscription request timed out. Timeout can be configured by client library users. Should send commands to server with timeout and handle timeout error - depending on method called timeout error handling can differ a bit. For example as said above timeout on subscription request results in full client reconnect workflow. Should support connection token refresh mechanism Should support private channel subscriptions and private subscription token refresh mechanism Should automatically recover messages after reconnect and set appropriate fields in subscribe event context. Two important fields in onSubscribeSuccess event context are recovered and isResubscribe . First field let user know what server thinks about subscription state - were all messages recovered or not. The second field must only be true if resubscribe was caused by temporary network connection lost. If user initiated resubscribe himself (calling unsubscribe method and then subscribe method) then recover workflow should not be used and isResubscribe must be false . Below in this document we will describe protocol concepts in detail. This document describes protocol specifics for Websocket transport which supports binary and text formats to transfer data. As Centrifuge has various types of messages it serializes protocol messages using JSON or Protobuf (in case of binary websockets). !!! note SockJS works almost the same way as JSON websocket described here but has its own extra framing on top of Centrifuge protocol messages. SockJS can only work with JSON - it s not possible to transfer binary data over it. SockJS is only needed as fallback to Websocket in web browsers. Top level framing Centrifuge protocol defined in Protobuf schema . That schema is a source of truth and all protocol description below describes messages from that schema. Client sends Command to server. Server sends Reply to client. One request from client to server and one response from server to client can have more than one Command or Reply . When JSON format is used then many Command can be sent from client to server in JSON streaming line-delimited format. I.e. each individual Command encoded to JSON and then commands joined together using new line symbol \\n : { id : 1 , method : subscribe , params : { channel : ch1 }} { id : 2 , method : subscribe , params : { channel : ch2 }} For example here is how we do this in Javascript client when JSON format used: function encodeCommands ( commands ) { const encodedCommands = []; for ( const i in commands ) { if ( commands . hasOwnProperty ( i )) { encodedCommands . push ( JSON . stringify ( commands [ i ])); } } return encodedCommands . join ( \\n ); } !!! note This doc will use JSON format for examples because it s human-readable. Everything said here for JSON is also true for Protobuf encoded case. The only difference is how several individual Command or server Reply joined into one request \u2013 see below. !!! note Method is made as ENUM in protobuf schema and can be sent as integer value but it s possible to send it as string in JSON case \u2013 this was made to make JSON protocol human-friendly. When Protobuf format is used then many Command can be sent from client to server in length-delimited format where each individual Command marshaled to bytes prepended by varint length. See existing client implementations for encoding example. The same rules relate to many Reply in one response from server to client. Line-delimited JSON and varint-length prefixed Protobuf. For example here is how we read server response and extracting individual replies in Javascript client when JSON format used: function decodeReplies ( data ) { const replies = []; const encodedReplies = data . split ( \\n ); for ( const i in encodedReplies ) { if ( encodedReplies . hasOwnProperty ( i )) { if ( ! encodedReplies [ i ]) { continue ; } const reply = JSON . parse ( encodedReplies [ i ]); replies . push ( reply ); } } return replies ; } For Protobuf case see existing client implementations for decoding example. As you can see each Command has id field. This is an incremental integer field. This field will be echoed in server to client replies to commands so client could match a certain Reply to Command sent before. This is important because Websocket is asynchronous protocol where server and client both send messages at any moment and there is no builtin request-response pattern. Having id allows to match reply to command send before. So you can expect something like this in response after sending commands to server: { id : 1 , result : {}} { id : 2 , result : {}} Besides id Reply from server to client have two important fields: result and error . result contains useful payload object which can be different depending on Reply . error contains error object in case of Command processing resulted in some error on server. error is optional and if Reply does not have error then it means that Command processed successfuly and client can parse result object in an appropriate way. error objects looks like this: { code : 100 , message : internal server error } We will talk more about error handling below. The special type of Reply is asynchronous Reply . Those replies have no id field set (or id can be equal to zero). Async replies can come to client in any moment - not as reaction to issued Command but as message from server to client in arbitrary time. For example this can be message published into channel. Centrifuge library defines several command types client can issue. And well-written client must be aware of all those commands and client workflow. Communication with Centrifuge/Centrifugo server starts with connect command. Connect First of all client must dial with server and then send connect Command to it. Default Websocket endpoint in Centrifugo is: ws://centrifugo.example.com/connection/websocket In case of using TLS: wss://centrifugo.example.com/connection/websocket After successful dial to websocket endpoint client must send connect command to server to authorize itself. connect command looks like: { id : 1 , method : connect , params : { token : JWT , data : {} } } Where params fields are passed to client from application backend: string token - connection token. JSON data - this is only available for Centrifuge library and not for Centrifugo server. It contains custom connect data, for example it can contain client settings. In response to connect command server sends connect reply. It looks this way: { id : 1 , result : { client : 421bf374-dd01-4f82-9def-8c31697e956f , version : 2.0.0 } } result has some fields: string client - unique client connection ID server issued to this connection string version - server version optional bool expires - whether or not server will expire connection optional int32 ttl - time in seconds until connection will expire Subscribe As soon as client successfully connected and got unique connection ID it is ready to subscribe on channels. To do this it must send subscribe command to server: { id : 2 , method : subscribe , params : { channel : ch1 } } Fields that can be set in params are: string channel - channel to subscribe In response to subscribe client receives reply like: { id : 2 , result : {} } result can have the following fields that relate to subscription expiration: optional bool expires - indicates whether subscription expires or not. optional uint32 ttl - number of seconds until subscription expire. And several fields that relate to message recovery: optional bool recoverable - means that messages can be recovered in this subscription. optional uint32 seq - current publication sequence inside channel optional uint32 gen - current publication generation inside channel optional string epoch - current epoch inside channel optional array publications - this is an array of missed publications in channel. When received client must call general publication event handler for each message in this array. optional bool recovered - this flag is set to true when server thinks that all missed publications were successfully recovered and send in subscribe reply (in publications array) and false otherwise. See more about meaning of recovery related fields in special doc chapter . After client received successful reply on subscribe command it will receive asynchronous reply messages published to this channel. Messages can be of several types: Publication message Join message Leave message Unsub message See more about asynchronous messages below. Unsubscribe This is simple. When client wants to unsubscribe from channel and therefore stop receiving asynchronous subscription messages from connection related to channel it must call unsubscribe command: { id : 3 , method : unsubscribe , params : { channel : ch1 } } Actually server response does not mean a lot for client - it must immediately remove channel subscription from internal implementation data structures and ignore all messages related to channel. Refresh It s possible to turn on client connection expiration mechanism on server. While enabled server will keep track of connections whose time of life (defined by exp timestamp) is close to the end. In this case connection will be closed. Client can prevent closing connection refreshing it s connection credentials. To do this it must send refresh command to server. refresh command similar to connect : { id : 4 , method : refresh , params : { token : JWT } } Just with actual exp and new sign . The tip whether or not connection must be refreshed comes in reply to connect command shown above - fields expires and ttl . When client connection expire mechanism is on the value of field expires in connect reply is true . In this case client implementation should look at ttl value which is seconds left until connection will be considered expired. Client must send refresh command after this ttl seconds. Server gives client a configured window to refresh token after ttl passed and then closes connection if client have not updated its token. When connecting with already expired token an error will be returned (with code 109 ). In this case client should refresh its token and reconnect with exponential backoff. RPC-like calls: publish, history, presence The mechanics of these calls is simple - client sends command and expects response from server. publish command allows to publish message into channel from client. !!! note To publish from client publish option in server configuration must be set to true history allows to ask server for channel history if enabled. presence allows to ask server for channel presence information if enabled. Asynchronous server-to-client messages There are several types of asynchronous messages that can come from server to client. All of them relate to current client subscriptions. The most important message is Publication : { result : { channel : ch1 , data : { data : { input : 1 }, info : { user : 2694 , client : 5c48510e-cf49-4fa8-a9b2-490b22231e74 , conn_info : { name : Alexander }, chan_info : {} } } } } Publication is a message published into channel. Note that there is no id field in this message - this symptom allows to distinguish it from Reply to Command . Next message is Join message: { result : { type : 1 , channel : ch1 , data : { info : { user : 2694 , client : 5c48510e-cf49-4fa8-a9b2-490b22231e74 , conn_info : { name : Alexander }, chan_info : {} } } } } Join messages sent when someone joined (subscribed on) channel. !!! note To enable Join and Leave messages join_leave option must be enabled on server globally or for channel namespace. Leave messages sent when someone left (unsubscribed from) channel. { result : { type : 2 , channel : ch1 , data : { info : { user : 2694 , client : 5c48510e-cf49-4fa8-a9b2-490b22231e74 , conn_info : { name : Alexander }, chan_info : {} } } } } And finally Unsub message that means that server unsubscribed current client from channel: { result : { type : 3 , channel : ch1 , data : {} } } It s possible to distinguish between different types of asynchronous messages looking at type field (for Publication this field not set or 0 ). Ping Pong To maintain connection alive and detect broken connections client must periodically send ping commands to server and expect replies to it. Ping command looks like: { id : 32 , method : ping } Server just echoes this command back. When client does not receive ping reply for some time it must consider connection broken and try to reconnect. Recommended ping interval is 25 seconds, recommended period to wait for pong is 1-5 seconds. Though those numbers can vary. Handle disconnects Client should handle disconnect advices from server. In websocket case disconnect advice is sent in reason field of CLOSE Websocket frame. Reason contains string which is disconnect object encoded into JSON (even in case of Protobuf scenario). That objects looks like: { reason : shutdown , reconnect : true } It contains string reason of connection closing and advice to reconnect or not. Client should take this reconnect advice into account. In case of network problems and random disconnect from server without well known reason client should always try to reconnect with exponential intervals. Handle errors This section contains advices to error handling in client implementations. Errors can happen during various operations and can be handled in special way in context of some commands to tolerate network and server problems. Errors during connect must result in full client reconnect with exponential backoff strategy. The special case is error with code 110 which signals that connection token already expired. As we said above client should update its connection JWT before connecting to server again. Errors during subscribe must result in full client reconnect in case of internal error (code 100 ). And be sent to subscribe error event handler of subscription if received error is persistent. Persistent errors are errors like permission denied , bad request , namespace not found etc. Persistent errors in most situation mean a mistake from developers side. The special corner case is client-side timeout during subscribe operation. As protocol is asynchronous it s possible in this case that server will eventually subscribe client on channel but client will think that it s not subscribed. It s possible to retry subscription request and tolerate already subscribed (code 105 ) error as expected. But the simplest solution is to reconnect entirely as this is simpler and gives client a chance to connect to working server instance. Errors during rpc-like operations can be just returned to caller - i.e. user javascript code. Calls like history and presence are idempotent. You should be accurate with unidempotent operations like publish - in case of client timeout it s possible to send the same message into channel twice if retry publish after timeout - so users of libraries must care about this case \u2013 making sure they have some protection from displaying message twice on client side (maybe some sort of unique key in payload). Client implementation advices Here are some advices about client public API. Examples here are in Javascript language. This is just an attempt to help in developing a client - but rules here is not obligatorily the best way to implement client. Create client instance: var centrifuge = new Centrifuge ( ws://localhost:8000/connection/websocket , {}); Set connection token (in case of using Centrifugo): centrifuge . setToken ( XXX ) Connect to server: centrifuge . connect (); 2 event handlers can be set to centrifuge object: connect and disconnect centrifuge . on ( connect , function ( context ) { console . log ( context ); }); centrifuge . on ( disconnect , function ( context ) { console . log ( context ); }); Client created in disconnected state with reconnect attribute set to true and reconnecting flag set to false . After connect() called state goes to connecting . It s only possible to connect from disconnected state. Every time connect() called reconnect flag of client must be set to true . After each failed connect attempt state must be set to disconnected , disconnect event must be emitted (only if reconnecting flag is false ), and then reconnecting flag must be set to true (if client should continue reconnecting) to not emit disconnect event again after next in a row connect attempt failure. In case of failure next connection attempt must be scheduled automatically with backoff strategy. On successful connect reconnecting flag must be set to false , backoff retry must be resetted and connect event must be emitted. When connection lost then the same set of actions as when connect failed must be performed. Client must allow to subscribe on channels: var subscription = centrifuge . subscribe ( channel , eventHandlers ); Subscription object created and control immediately returned to caller - subscribing must be performed asynchronously. This is required because client can automatically reconnect later so event-based model better suites for subscriptions. Subscription should support several event handlers: handler for publication received from channel join message handler leave message handler error handler subscribe success event handler unsubscribe event handler Every time client connects to server it must restore all subscriptions. Every time client disconnects from server it must call unsubscribe handlers for all active subscriptions and then emit disconnect event. Client must periodically (once in 25 secs, configurable) send ping messages to server. If pong has not beed received in 5 secs (configurable) then client must disconnect from server and try to reconnect with backoff strategy. Client can automatically batch several requests into one frame to server and also must be able to handle several replies received from server in one frame.","title":"Client protocol"},{"location":"server/protocol/#client-protocol","text":"This chapter describes internal client-server protocol in details to help developers build new client libraries and understand how existing client libraries work. Note that you can always look at existing client implementations in case of any questions.","title":"Client protocol"},{"location":"server/protocol/#client-implementation-checklist","text":"First we will look at list of features client library should support. Depending on client implementation some features can be not implemented. If you an author of client library you can use this list as checklist. !!! note Field and method names presented in this checklist can have different names depending on programmer s taste and language style guide So, client: Should work both with Centrifugo and Centrifuge library based server. To work with Centrifugo client must have a method to set connection token. To work with Centrifuge lib client must provide a method to set custom headers (the only exception is browser clients where browser automatically sets headers with respect to domain rules) Should allow to use JSON payload Should allow to use binary payload (actually you can only implement Protobuf protocol as you can pass JSON over it) Must handle cases when many different Replies received in one websocket frame. In case of JSON protocol newline-delimited JSON-streaming format is used to combine several Replies into one websocket frame. In case of Protobuf protocol varint length-prefixed format is used Must survive server reload/restart and internet connection lost. In this case client must try to reconnect with exponentioal backoff strategy Must have several callback methods: onConnect , onDisconnect . Depending on implementation you can also use onError callback for critical errors that could not be gracefully handled. Should also have onMessage callback to handle async messages from server. Must have method to subscribe on channel and set several event handlers: onPublish , onJoin , onLeave , onSubscribeSuccess , onSubscribeError , onUnsubscribe . After subscribe method called it should return Subscription object to caller. This subscription object in turn should have some methods: publish , unsubscribe , subscribe , history , presence , presence_stats . Should have publish method to publish into channel without subscribing to it. Should have rpc method to send RPC request to server. Should have send method to send asynchronous message to server (without waiting response). Should handle disconnect reason. In case of Websocket it is sent by server in CLOSE Websocket frame. This is a string containing JSON object with fields: reason (string) and reconnect (bool). Client should give users access to these fields in disconnect event and automatically follow reconnect advice Must send periodic ping commands to server and thus detect broken connection. If no ping reply received from server in configured window reconnect workflow must be initiated Should fully reconnect if subscription request timed out. Timeout can be configured by client library users. Should send commands to server with timeout and handle timeout error - depending on method called timeout error handling can differ a bit. For example as said above timeout on subscription request results in full client reconnect workflow. Should support connection token refresh mechanism Should support private channel subscriptions and private subscription token refresh mechanism Should automatically recover messages after reconnect and set appropriate fields in subscribe event context. Two important fields in onSubscribeSuccess event context are recovered and isResubscribe . First field let user know what server thinks about subscription state - were all messages recovered or not. The second field must only be true if resubscribe was caused by temporary network connection lost. If user initiated resubscribe himself (calling unsubscribe method and then subscribe method) then recover workflow should not be used and isResubscribe must be false . Below in this document we will describe protocol concepts in detail. This document describes protocol specifics for Websocket transport which supports binary and text formats to transfer data. As Centrifuge has various types of messages it serializes protocol messages using JSON or Protobuf (in case of binary websockets). !!! note SockJS works almost the same way as JSON websocket described here but has its own extra framing on top of Centrifuge protocol messages. SockJS can only work with JSON - it s not possible to transfer binary data over it. SockJS is only needed as fallback to Websocket in web browsers.","title":"Client implementation checklist"},{"location":"server/protocol/#top-level-framing","text":"Centrifuge protocol defined in Protobuf schema . That schema is a source of truth and all protocol description below describes messages from that schema. Client sends Command to server. Server sends Reply to client. One request from client to server and one response from server to client can have more than one Command or Reply . When JSON format is used then many Command can be sent from client to server in JSON streaming line-delimited format. I.e. each individual Command encoded to JSON and then commands joined together using new line symbol \\n : { id : 1 , method : subscribe , params : { channel : ch1 }} { id : 2 , method : subscribe , params : { channel : ch2 }} For example here is how we do this in Javascript client when JSON format used: function encodeCommands ( commands ) { const encodedCommands = []; for ( const i in commands ) { if ( commands . hasOwnProperty ( i )) { encodedCommands . push ( JSON . stringify ( commands [ i ])); } } return encodedCommands . join ( \\n ); } !!! note This doc will use JSON format for examples because it s human-readable. Everything said here for JSON is also true for Protobuf encoded case. The only difference is how several individual Command or server Reply joined into one request \u2013 see below. !!! note Method is made as ENUM in protobuf schema and can be sent as integer value but it s possible to send it as string in JSON case \u2013 this was made to make JSON protocol human-friendly. When Protobuf format is used then many Command can be sent from client to server in length-delimited format where each individual Command marshaled to bytes prepended by varint length. See existing client implementations for encoding example. The same rules relate to many Reply in one response from server to client. Line-delimited JSON and varint-length prefixed Protobuf. For example here is how we read server response and extracting individual replies in Javascript client when JSON format used: function decodeReplies ( data ) { const replies = []; const encodedReplies = data . split ( \\n ); for ( const i in encodedReplies ) { if ( encodedReplies . hasOwnProperty ( i )) { if ( ! encodedReplies [ i ]) { continue ; } const reply = JSON . parse ( encodedReplies [ i ]); replies . push ( reply ); } } return replies ; } For Protobuf case see existing client implementations for decoding example. As you can see each Command has id field. This is an incremental integer field. This field will be echoed in server to client replies to commands so client could match a certain Reply to Command sent before. This is important because Websocket is asynchronous protocol where server and client both send messages at any moment and there is no builtin request-response pattern. Having id allows to match reply to command send before. So you can expect something like this in response after sending commands to server: { id : 1 , result : {}} { id : 2 , result : {}} Besides id Reply from server to client have two important fields: result and error . result contains useful payload object which can be different depending on Reply . error contains error object in case of Command processing resulted in some error on server. error is optional and if Reply does not have error then it means that Command processed successfuly and client can parse result object in an appropriate way. error objects looks like this: { code : 100 , message : internal server error } We will talk more about error handling below. The special type of Reply is asynchronous Reply . Those replies have no id field set (or id can be equal to zero). Async replies can come to client in any moment - not as reaction to issued Command but as message from server to client in arbitrary time. For example this can be message published into channel. Centrifuge library defines several command types client can issue. And well-written client must be aware of all those commands and client workflow. Communication with Centrifuge/Centrifugo server starts with connect command.","title":"Top level framing"},{"location":"server/protocol/#connect","text":"First of all client must dial with server and then send connect Command to it. Default Websocket endpoint in Centrifugo is: ws://centrifugo.example.com/connection/websocket In case of using TLS: wss://centrifugo.example.com/connection/websocket After successful dial to websocket endpoint client must send connect command to server to authorize itself. connect command looks like: { id : 1 , method : connect , params : { token : JWT , data : {} } } Where params fields are passed to client from application backend: string token - connection token. JSON data - this is only available for Centrifuge library and not for Centrifugo server. It contains custom connect data, for example it can contain client settings. In response to connect command server sends connect reply. It looks this way: { id : 1 , result : { client : 421bf374-dd01-4f82-9def-8c31697e956f , version : 2.0.0 } } result has some fields: string client - unique client connection ID server issued to this connection string version - server version optional bool expires - whether or not server will expire connection optional int32 ttl - time in seconds until connection will expire","title":"Connect"},{"location":"server/protocol/#subscribe","text":"As soon as client successfully connected and got unique connection ID it is ready to subscribe on channels. To do this it must send subscribe command to server: { id : 2 , method : subscribe , params : { channel : ch1 } } Fields that can be set in params are: string channel - channel to subscribe In response to subscribe client receives reply like: { id : 2 , result : {} } result can have the following fields that relate to subscription expiration: optional bool expires - indicates whether subscription expires or not. optional uint32 ttl - number of seconds until subscription expire. And several fields that relate to message recovery: optional bool recoverable - means that messages can be recovered in this subscription. optional uint32 seq - current publication sequence inside channel optional uint32 gen - current publication generation inside channel optional string epoch - current epoch inside channel optional array publications - this is an array of missed publications in channel. When received client must call general publication event handler for each message in this array. optional bool recovered - this flag is set to true when server thinks that all missed publications were successfully recovered and send in subscribe reply (in publications array) and false otherwise. See more about meaning of recovery related fields in special doc chapter . After client received successful reply on subscribe command it will receive asynchronous reply messages published to this channel. Messages can be of several types: Publication message Join message Leave message Unsub message See more about asynchronous messages below.","title":"Subscribe"},{"location":"server/protocol/#unsubscribe","text":"This is simple. When client wants to unsubscribe from channel and therefore stop receiving asynchronous subscription messages from connection related to channel it must call unsubscribe command: { id : 3 , method : unsubscribe , params : { channel : ch1 } } Actually server response does not mean a lot for client - it must immediately remove channel subscription from internal implementation data structures and ignore all messages related to channel.","title":"Unsubscribe"},{"location":"server/protocol/#refresh","text":"It s possible to turn on client connection expiration mechanism on server. While enabled server will keep track of connections whose time of life (defined by exp timestamp) is close to the end. In this case connection will be closed. Client can prevent closing connection refreshing it s connection credentials. To do this it must send refresh command to server. refresh command similar to connect : { id : 4 , method : refresh , params : { token : JWT } } Just with actual exp and new sign . The tip whether or not connection must be refreshed comes in reply to connect command shown above - fields expires and ttl . When client connection expire mechanism is on the value of field expires in connect reply is true . In this case client implementation should look at ttl value which is seconds left until connection will be considered expired. Client must send refresh command after this ttl seconds. Server gives client a configured window to refresh token after ttl passed and then closes connection if client have not updated its token. When connecting with already expired token an error will be returned (with code 109 ). In this case client should refresh its token and reconnect with exponential backoff.","title":"Refresh"},{"location":"server/protocol/#rpc-like-calls-publish-history-presence","text":"The mechanics of these calls is simple - client sends command and expects response from server. publish command allows to publish message into channel from client. !!! note To publish from client publish option in server configuration must be set to true history allows to ask server for channel history if enabled. presence allows to ask server for channel presence information if enabled.","title":"RPC-like calls: publish, history, presence"},{"location":"server/protocol/#asynchronous-server-to-client-messages","text":"There are several types of asynchronous messages that can come from server to client. All of them relate to current client subscriptions. The most important message is Publication : { result : { channel : ch1 , data : { data : { input : 1 }, info : { user : 2694 , client : 5c48510e-cf49-4fa8-a9b2-490b22231e74 , conn_info : { name : Alexander }, chan_info : {} } } } } Publication is a message published into channel. Note that there is no id field in this message - this symptom allows to distinguish it from Reply to Command . Next message is Join message: { result : { type : 1 , channel : ch1 , data : { info : { user : 2694 , client : 5c48510e-cf49-4fa8-a9b2-490b22231e74 , conn_info : { name : Alexander }, chan_info : {} } } } } Join messages sent when someone joined (subscribed on) channel. !!! note To enable Join and Leave messages join_leave option must be enabled on server globally or for channel namespace. Leave messages sent when someone left (unsubscribed from) channel. { result : { type : 2 , channel : ch1 , data : { info : { user : 2694 , client : 5c48510e-cf49-4fa8-a9b2-490b22231e74 , conn_info : { name : Alexander }, chan_info : {} } } } } And finally Unsub message that means that server unsubscribed current client from channel: { result : { type : 3 , channel : ch1 , data : {} } } It s possible to distinguish between different types of asynchronous messages looking at type field (for Publication this field not set or 0 ).","title":"Asynchronous server-to-client messages"},{"location":"server/protocol/#ping-pong","text":"To maintain connection alive and detect broken connections client must periodically send ping commands to server and expect replies to it. Ping command looks like: { id : 32 , method : ping } Server just echoes this command back. When client does not receive ping reply for some time it must consider connection broken and try to reconnect. Recommended ping interval is 25 seconds, recommended period to wait for pong is 1-5 seconds. Though those numbers can vary.","title":"Ping Pong"},{"location":"server/protocol/#handle-disconnects","text":"Client should handle disconnect advices from server. In websocket case disconnect advice is sent in reason field of CLOSE Websocket frame. Reason contains string which is disconnect object encoded into JSON (even in case of Protobuf scenario). That objects looks like: { reason : shutdown , reconnect : true } It contains string reason of connection closing and advice to reconnect or not. Client should take this reconnect advice into account. In case of network problems and random disconnect from server without well known reason client should always try to reconnect with exponential intervals.","title":"Handle disconnects"},{"location":"server/protocol/#handle-errors","text":"This section contains advices to error handling in client implementations. Errors can happen during various operations and can be handled in special way in context of some commands to tolerate network and server problems. Errors during connect must result in full client reconnect with exponential backoff strategy. The special case is error with code 110 which signals that connection token already expired. As we said above client should update its connection JWT before connecting to server again. Errors during subscribe must result in full client reconnect in case of internal error (code 100 ). And be sent to subscribe error event handler of subscription if received error is persistent. Persistent errors are errors like permission denied , bad request , namespace not found etc. Persistent errors in most situation mean a mistake from developers side. The special corner case is client-side timeout during subscribe operation. As protocol is asynchronous it s possible in this case that server will eventually subscribe client on channel but client will think that it s not subscribed. It s possible to retry subscription request and tolerate already subscribed (code 105 ) error as expected. But the simplest solution is to reconnect entirely as this is simpler and gives client a chance to connect to working server instance. Errors during rpc-like operations can be just returned to caller - i.e. user javascript code. Calls like history and presence are idempotent. You should be accurate with unidempotent operations like publish - in case of client timeout it s possible to send the same message into channel twice if retry publish after timeout - so users of libraries must care about this case \u2013 making sure they have some protection from displaying message twice on client side (maybe some sort of unique key in payload).","title":"Handle errors"},{"location":"server/protocol/#client-implementation-advices","text":"Here are some advices about client public API. Examples here are in Javascript language. This is just an attempt to help in developing a client - but rules here is not obligatorily the best way to implement client. Create client instance: var centrifuge = new Centrifuge ( ws://localhost:8000/connection/websocket , {}); Set connection token (in case of using Centrifugo): centrifuge . setToken ( XXX ) Connect to server: centrifuge . connect (); 2 event handlers can be set to centrifuge object: connect and disconnect centrifuge . on ( connect , function ( context ) { console . log ( context ); }); centrifuge . on ( disconnect , function ( context ) { console . log ( context ); }); Client created in disconnected state with reconnect attribute set to true and reconnecting flag set to false . After connect() called state goes to connecting . It s only possible to connect from disconnected state. Every time connect() called reconnect flag of client must be set to true . After each failed connect attempt state must be set to disconnected , disconnect event must be emitted (only if reconnecting flag is false ), and then reconnecting flag must be set to true (if client should continue reconnecting) to not emit disconnect event again after next in a row connect attempt failure. In case of failure next connection attempt must be scheduled automatically with backoff strategy. On successful connect reconnecting flag must be set to false , backoff retry must be resetted and connect event must be emitted. When connection lost then the same set of actions as when connect failed must be performed. Client must allow to subscribe on channels: var subscription = centrifuge . subscribe ( channel , eventHandlers ); Subscription object created and control immediately returned to caller - subscribing must be performed asynchronously. This is required because client can automatically reconnect later so event-based model better suites for subscriptions. Subscription should support several event handlers: handler for publication received from channel join message handler leave message handler error handler subscribe success event handler unsubscribe event handler Every time client connects to server it must restore all subscriptions. Every time client disconnects from server it must call unsubscribe handlers for all active subscriptions and then emit disconnect event. Client must periodically (once in 25 secs, configurable) send ping messages to server. If pong has not beed received in 5 secs (configurable) then client must disconnect from server and try to reconnect with backoff strategy. Client can automatically batch several requests into one frame to server and also must be able to handle several replies received from server in one frame.","title":"Client implementation advices"},{"location":"server/recover/","text":"How message recovery works One of the most interesting features of Centrifugo is message recovery after short network disconnects. This mechanism allows client to automatically get missed message on successful resubscribe to channel after being disconnected for a while. In general you would query your application backend for actual state on every client reconnect - but message recovery feature allows Centrifugo itself to deal with this and restore missed messages from history cache thus reducing load on your application backend in some scenarios. To enable recovery mechanism for channels set history_recover boolean configuration option to true on configuration top level or for channel namespace. When subscribing on channels Centrifugo will return missed publications to client in subscribe Reply and also special recovered boolean flag to indicate whether all messages were recovered after disconnect or not. Centrifugo recovery model based on three fields in protocol: seq , gen and epoch . All fields are managed automatically by Centrifugo client libraries but it s good to know how recovery works under the hood. Once history_recover option enabled every publication will have incremental (inside channel) seq field. Once seq exceeds maximum value for uint32 we increment another field gen (also uint32 ) by one. The reason we use 2 uint32 fields instead of one uint64 is that our main target environment - browser Javascript - does not work well with big numbers so we use 2 separate fields as workaround (another possible solution could be passing numbers as strings). Another field is string epoch . It exists to handle cases when history storage has been restarted while client was in disconnected state so publication numeration in channel started from scratch. For example at moment Memory engine does not persist publication sequences on disk so every restart will start numeration from scratch, after each restart new epoch field generated and we can understand in recovery process that client could miss messages thus returning it correct recovered flag. This also applies to Redis engine \u2013 if you do not use AOF with fsync then sequences can be lost after Redis restart. When using Redis engine you need to use fully in-memory model strategy or AOF with fsync to guarantee reliability of recovered flag sent by Centrifugo. When server receives subscribe request with seq , gen and epoch set in subscribe command it can look at history cache and find all missed publications. Recovered messages will be passed to client in subscribe reply in correct order and your publication handler will be automatically called to process each missed message. You can also manually implement your own recovery algorithm on top of basic PUB/SUB possibilities that Centrifugo provides. As we said above you can simply ask your backend for an actual state after every client reconnect completely bypassing recovery mechanism described here.","title":"Message recovery"},{"location":"server/recover/#how-message-recovery-works","text":"One of the most interesting features of Centrifugo is message recovery after short network disconnects. This mechanism allows client to automatically get missed message on successful resubscribe to channel after being disconnected for a while. In general you would query your application backend for actual state on every client reconnect - but message recovery feature allows Centrifugo itself to deal with this and restore missed messages from history cache thus reducing load on your application backend in some scenarios. To enable recovery mechanism for channels set history_recover boolean configuration option to true on configuration top level or for channel namespace. When subscribing on channels Centrifugo will return missed publications to client in subscribe Reply and also special recovered boolean flag to indicate whether all messages were recovered after disconnect or not. Centrifugo recovery model based on three fields in protocol: seq , gen and epoch . All fields are managed automatically by Centrifugo client libraries but it s good to know how recovery works under the hood. Once history_recover option enabled every publication will have incremental (inside channel) seq field. Once seq exceeds maximum value for uint32 we increment another field gen (also uint32 ) by one. The reason we use 2 uint32 fields instead of one uint64 is that our main target environment - browser Javascript - does not work well with big numbers so we use 2 separate fields as workaround (another possible solution could be passing numbers as strings). Another field is string epoch . It exists to handle cases when history storage has been restarted while client was in disconnected state so publication numeration in channel started from scratch. For example at moment Memory engine does not persist publication sequences on disk so every restart will start numeration from scratch, after each restart new epoch field generated and we can understand in recovery process that client could miss messages thus returning it correct recovered flag. This also applies to Redis engine \u2013 if you do not use AOF with fsync then sequences can be lost after Redis restart. When using Redis engine you need to use fully in-memory model strategy or AOF with fsync to guarantee reliability of recovered flag sent by Centrifugo. When server receives subscribe request with seq , gen and epoch set in subscribe command it can look at history cache and find all missed publications. Recovered messages will be passed to client in subscribe reply in correct order and your publication handler will be automatically called to process each missed message. You can also manually implement your own recovery algorithm on top of basic PUB/SUB possibilities that Centrifugo provides. As we said above you can simply ask your backend for an actual state after every client reconnect completely bypassing recovery mechanism described here.","title":"How message recovery works"},{"location":"server/signals/","text":"Signal handling You can send HUP signal to Centrifugo to reload configuration: kill -HUP PID Though at moment this will only reload channel and namespace configuration. Also Centrifugo tries to gracefully shutdown client connections when SIGINT or SIGTERM signals received. By default maximum graceful shutdown period is 30 seconds but can be changed using shutdown_timeout configuration option.","title":"Signal handling"},{"location":"server/signals/#signal-handling","text":"You can send HUP signal to Centrifugo to reload configuration: kill -HUP PID Though at moment this will only reload channel and namespace configuration. Also Centrifugo tries to gracefully shutdown client connections when SIGINT or SIGTERM signals received. By default maximum graceful shutdown period is 30 seconds but can be changed using shutdown_timeout configuration option.","title":"Signal handling"},{"location":"transports/","text":"This section describes client transports that Centrifugo supports and some specific topics and configuration regarding to each of those transports. At moment Centrifugo supports 2 transports: Websocket SockJS Having both of these transport means that it s possible to connect to Centrifugo from everywhere.","title":"Overview"},{"location":"transports/sockjs/","text":"SockJS SockJS is a polyfill browser library which provides HTTP-based fallback transports in case when it s not possible to establish Websocket connection. This can happen in old client browsers or because of some proxy behind client and server that cuts of Websocket traffic. You can find more information on SockJS project Github page . If you have a requirement to work everywhere SockJS is the solution. SockJS will automatically choose best fallback transport if Websocket connection failed for some reason. Some of the fallback transports are: Eventsource (SSE) XHR-streaming Long-polling And more (see SockJS docs) One caveat when using SockJS is that you need to use sticky sessions mechanism if you have many Centrifugo nodes running . This mechanism is usually supported by load balancers (for example Nginx). Sticky sessions mean that all requests from the same client will come to the same Centrifugo node. This is necessary because SockJS maintains connection session in process memory thus allowing bidirectional communication between client and server. Sticky mechanism is not required if you only use one Centrifugo node on backend. See how enable sticky sessions in Nginx in deploy section of this doc. SockJS connection endpoint in Centrifugo is /connection/sockjs . SockJS does not support binary so you only limited in using JSON with it.","title":"SockJS"},{"location":"transports/sockjs/#sockjs","text":"SockJS is a polyfill browser library which provides HTTP-based fallback transports in case when it s not possible to establish Websocket connection. This can happen in old client browsers or because of some proxy behind client and server that cuts of Websocket traffic. You can find more information on SockJS project Github page . If you have a requirement to work everywhere SockJS is the solution. SockJS will automatically choose best fallback transport if Websocket connection failed for some reason. Some of the fallback transports are: Eventsource (SSE) XHR-streaming Long-polling And more (see SockJS docs) One caveat when using SockJS is that you need to use sticky sessions mechanism if you have many Centrifugo nodes running . This mechanism is usually supported by load balancers (for example Nginx). Sticky sessions mean that all requests from the same client will come to the same Centrifugo node. This is necessary because SockJS maintains connection session in process memory thus allowing bidirectional communication between client and server. Sticky mechanism is not required if you only use one Centrifugo node on backend. See how enable sticky sessions in Nginx in deploy section of this doc. SockJS connection endpoint in Centrifugo is /connection/sockjs . SockJS does not support binary so you only limited in using JSON with it.","title":"SockJS"},{"location":"transports/websocket/","text":"Websocket Websocket is the main transport in Centrifugo. It s a very efficient low-overhead protocol on top of TCP. The biggest advantage is that Websocket works out of the box in all modern browsers and almost all programming languages have Websocket implementations. This makes Websocket a pretty universal transport that can even be used to connect to Centrifugo from web apps and mobile apps and other environments. Websocket connection endpoint in Centrifugo is /connection/websocket . If you want to use Protobuf binary protocol then you need to connect to /connection/websocket?format=protobuf Websocket compression An experimental feature for raw websocket endpoint - permessage-deflate compression for websocket messages. Btw look at great article about websocket compression. We consider this experimental because this websocket compression is experimental in Gorilla Websocket library that Centrifugo uses internally. Websocket compression can reduce amount of traffic travelling over the wire. But keep in mind that enabling websocket compression will result in much slower Centrifugo performance and more memory usage \u2013 depending on your message rate this can be very noticeable. To enable websocket compression for raw websocket endpoint set websocket_compression: true in configuration file. After this clients that support permessage-deflate will negotiate compression with server automatically. Note that enabling compression does not mean that every connection will use it - this depends on client support for this feature. Another option is websocket_compression_min_size . Default 0. This is a minimal size of message in bytes for which we use deflate compression when writing it to client s connection. Default value 0 means that we will compress all messages when websocket_compression enabled and compression support negotiated with client. It s also possible to control websocket compression level defined at compress/flate By default when compression with client negotiated Centrifugo uses compression level 1 (BestSpeed). If you want to set custom compression level use websocket_compression_level configuration option.","title":"Websocket"},{"location":"transports/websocket/#websocket","text":"Websocket is the main transport in Centrifugo. It s a very efficient low-overhead protocol on top of TCP. The biggest advantage is that Websocket works out of the box in all modern browsers and almost all programming languages have Websocket implementations. This makes Websocket a pretty universal transport that can even be used to connect to Centrifugo from web apps and mobile apps and other environments. Websocket connection endpoint in Centrifugo is /connection/websocket . If you want to use Protobuf binary protocol then you need to connect to /connection/websocket?format=protobuf","title":"Websocket"},{"location":"transports/websocket/#websocket-compression","text":"An experimental feature for raw websocket endpoint - permessage-deflate compression for websocket messages. Btw look at great article about websocket compression. We consider this experimental because this websocket compression is experimental in Gorilla Websocket library that Centrifugo uses internally. Websocket compression can reduce amount of traffic travelling over the wire. But keep in mind that enabling websocket compression will result in much slower Centrifugo performance and more memory usage \u2013 depending on your message rate this can be very noticeable. To enable websocket compression for raw websocket endpoint set websocket_compression: true in configuration file. After this clients that support permessage-deflate will negotiate compression with server automatically. Note that enabling compression does not mean that every connection will use it - this depends on client support for this feature. Another option is websocket_compression_min_size . Default 0. This is a minimal size of message in bytes for which we use deflate compression when writing it to client s connection. Default value 0 means that we will compress all messages when websocket_compression enabled and compression support negotiated with client. It s also possible to control websocket compression level defined at compress/flate By default when compression with client negotiated Centrifugo uses compression level 1 (BestSpeed). If you want to set custom compression level use websocket_compression_level configuration option.","title":"Websocket compression"}]}